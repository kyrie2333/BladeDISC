2023-05-09 02:51:10.341360: I external/org_tensorflow/tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
======== BEGIN Original Module =========
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = chlo.broadcast_subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
    %2 = chlo.broadcast_multiply %1, %arg0 : (tensor<?x?xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
    return %3 : tensor<?xf32>
  }
}

======= END Original Module ==========
[DISC] Load Input IR takes: 3.252000e-03 s.
[[ INFO ]] Running TF2XLA
// -----// IR Dump After SCCP (sccp) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = chlo.broadcast_subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
    %2 = chlo.broadcast_multiply %1, %arg0 : (tensor<?x?xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
    return %3 : tensor<?xf32>
  }
}


// -----// IR Dump After SCCP (sccp) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = chlo.broadcast_subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
    %2 = chlo.broadcast_multiply %1, %arg0 : (tensor<?x?xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
    return %3 : tensor<?xf32>
  }
}


// -----// IR Dump After LegalizeTF (xla-legalize-tf) //----- //
func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %1 = mhlo.subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
  %2 = shape.shape_of %1 : tensor<?x?xf32> -> tensor<2xindex>
  %3 = shape.shape_of %arg0 : tensor<8192x2560xf32> -> tensor<2xindex>
  %4 = shape.cstr_broadcastable %2, %3 : tensor<2xindex>, tensor<2xindex>
  %5 = shape.assuming %4 -> (tensor<?x?xf32>) {
    %7 = shape.shape_of %1 : tensor<?x?xf32> -> tensor<2xindex>
    %8 = shape.const_shape [8192, 2560] : tensor<2xindex>
    %9 = shape.broadcast %7, %8 : tensor<2xindex>, tensor<2xindex> -> tensor<2xindex>
    %10 = "mhlo.dynamic_broadcast_in_dim"(%1, %9) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x?xf32>, tensor<2xindex>) -> tensor<?x?xf32>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%arg0, %9) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<8192x2560xf32>, tensor<2xindex>) -> tensor<?x?xf32>
    %12 = mhlo.multiply %10, %11 : tensor<?x?xf32>
    shape.assuming_yield %12 : tensor<?x?xf32>
  }
  %6 = mhlo.reduce(%5 init: %0) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
  return %6 : tensor<?xf32>
}

// -----// IR Dump After DiscLowerTfPass (disc-lower-tf) //----- //
func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %0 = shape.const_shape [8192, 2560] : tensor<2xindex>
  %1 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %2 = mhlo.subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
  %3 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
  %4 = shape.cstr_broadcastable %3, %0 : tensor<2xindex>, tensor<2xindex>
  %5 = shape.assuming %4 -> (tensor<?x?xf32>) {
    %7 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
    %8 = shape.broadcast %7, %0 : tensor<2xindex>, tensor<2xindex> -> tensor<2xindex>
    %9 = "mhlo.dynamic_broadcast_in_dim"(%2, %8) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x?xf32>, tensor<2xindex>) -> tensor<?x?xf32>
    %10 = "mhlo.dynamic_broadcast_in_dim"(%arg0, %8) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<8192x2560xf32>, tensor<2xindex>) -> tensor<?x?xf32>
    %11 = mhlo.multiply %9, %10 : tensor<?x?xf32>
    shape.assuming_yield %11 : tensor<?x?xf32>
  }
  %6 = mhlo.reduce(%5 init: %1) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
  return %6 : tensor<?xf32>
}

// -----// IR Dump After SinkConstantsToControlFlowPass (mhlo-sink-constants-to-control-flow) //----- //
func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %0 = shape.const_shape [8192, 2560] : tensor<2xindex>
  %1 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %2 = mhlo.subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
  %3 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
  %4 = shape.cstr_broadcastable %3, %0 : tensor<2xindex>, tensor<2xindex>
  %5 = shape.assuming %4 -> (tensor<?x?xf32>) {
    %7 = shape.const_shape [8192, 2560] : tensor<2xindex>
    %8 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
    %9 = shape.broadcast %8, %7 : tensor<2xindex>, tensor<2xindex> -> tensor<2xindex>
    %10 = "mhlo.dynamic_broadcast_in_dim"(%2, %9) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x?xf32>, tensor<2xindex>) -> tensor<?x?xf32>
    %11 = "mhlo.dynamic_broadcast_in_dim"(%arg0, %9) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<8192x2560xf32>, tensor<2xindex>) -> tensor<?x?xf32>
    %12 = mhlo.multiply %10, %11 : tensor<?x?xf32>
    shape.assuming_yield %12 : tensor<?x?xf32>
  }
  %6 = mhlo.reduce(%5 init: %1) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
  return %6 : tensor<?xf32>
}

===-------------------------------------------------------------------------===
                         ... Execution time report ...
===-------------------------------------------------------------------------===
  Total Execution Time: 0.0063 seconds

  ----Wall Time----  ----Name----
    0.0000 (  0.7%)  ReviseArgumentsForStaticRankPass
    0.0000 (  0.2%)  FunctionalControlFlowToRegionsPass
    0.0004 (  6.5%)  Inliner
    0.0000 (  0.2%)    (A) CallGraph
    0.0002 (  3.0%)  'func.func' Pipeline
    0.0002 (  3.0%)    Canonicalizer
    0.0001 (  1.3%)  'func.func' Pipeline
    0.0000 (  0.1%)    DropWhileShapeInvariantPass
    0.0000 (  0.1%)    ReplicateTensorListInitOpsPass
    0.0001 (  1.0%)    Canonicalizer
    0.0004 (  6.2%)  SCCP
    0.0000 (  0.4%)  GuaranteeAllFuncsOneUsePass
    0.0000 (  0.0%)    (A) CallGraph
    0.0000 (  0.2%)  TensorFlowShapeInferencePass
    0.0003 (  5.3%)  SCCP
    0.0000 (  0.3%)  TensorListOpsDecompositionPass
    0.0000 (  0.2%)  StackOpsDecompositionPass
    0.0000 (  0.2%)  TensorArrayOpsDecompositionPass
    0.0001 (  1.0%)  'func.func' Pipeline
    0.0001 (  0.9%)    DecomposeResourceOpsPass
    0.0000 (  0.4%)  PromoteResourcesToArgsPass
    0.0000 (  0.3%)  SymbolDCE
    0.0000 (  0.2%)  'func.func' Pipeline
    0.0000 (  0.2%)    SinkConstantsToControlFlowPass
    0.0000 (  0.2%)  TensorFlowShapeInferencePass
    0.0002 (  3.8%)  StablehloLegalizeToHloPass
    0.0001 (  1.3%)  'func.func' Pipeline
    0.0001 (  0.9%)    DiscLowerTfPass
    0.0000 (  0.4%)    LowerQuantizedPass
    0.0000 (  0.3%)  LegalizeTfTypesPass
    0.0022 ( 35.3%)  'func.func' Pipeline
    0.0013 ( 20.4%)    LegalizeTF
    0.0009 ( 14.4%)    DiscLowerTfPass
    0.0000 (  0.4%)    mlir::mhlo::{anonymous}::AdjustLayout
    0.0000 (  0.8%)  LegalizeTFCollective
    0.0001 (  1.5%)  'func.func' Pipeline
    0.0001 (  1.5%)    Canonicalizer
    0.0000 (  0.3%)  TensorFlowShapeInferencePass
    0.0004 (  6.1%)  'func.func' Pipeline
    0.0004 (  6.1%)    LegalizeTF
    0.0000 (  0.3%)  LegalizeTFCommunicationPass
    0.0007 ( 11.3%)  'func.func' Pipeline
    0.0000 (  0.8%)    DiscDynamicSliceConverterPass
    0.0007 ( 10.5%)    SinkConstantsToControlFlowPass
    0.0008 ( 12.0%)  Rest
    0.0063 (100.0%)  Total
======== BEGIN After TF2HLO =========
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = shape.const_shape [8192, 2560] : tensor<2xindex>
    %1 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %2 = mhlo.subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
    %3 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
    %4 = shape.cstr_broadcastable %3, %0 : tensor<2xindex>, tensor<2xindex>
    %5 = shape.assuming %4 -> (tensor<?x?xf32>) {
      %7 = shape.const_shape [8192, 2560] : tensor<2xindex>
      %8 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
      %9 = shape.broadcast %8, %7 : tensor<2xindex>, tensor<2xindex> -> tensor<2xindex>
      %10 = "mhlo.dynamic_broadcast_in_dim"(%2, %9) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x?xf32>, tensor<2xindex>) -> tensor<?x?xf32>
      %11 = "mhlo.dynamic_broadcast_in_dim"(%arg0, %9) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<8192x2560xf32>, tensor<2xindex>) -> tensor<?x?xf32>
      %12 = mhlo.multiply %10, %11 : tensor<?x?xf32>
      shape.assuming_yield %12 : tensor<?x?xf32>
    }
    %6 = mhlo.reduce(%5 init: %1) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
    return %6 : tensor<?xf32>
  }
}

======= END After TF2HLO ==========
[DISC] tf2hlo takes: 7.260000e-03 s.
2023-05-09 02:51:10.785792: I external/org_disc_compiler/mlir/disc/transforms/disc_gpu_kernel_to_blob.cc:98] Multiple GPU compute capability compilation is enabled. The AOT compiled binary is functional on sm_60, sm_70, sm_75, sm_80 and sm_86. While the optimal performance can be achived only on currently GPU generation that BladeDISC executes on.
// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %0 = shape.const_shape [8192, 2560] : tensor<2xindex>
  %1 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %2 = mhlo.subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
  %3 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
  %4 = shape.cstr_broadcastable %3, %0 : tensor<2xindex>, tensor<2xindex>
  %5 = shape.assuming %4 -> (tensor<?x?xf32>) {
    %7 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
    %8 = shape.broadcast %7, %0 : tensor<2xindex>, tensor<2xindex> -> tensor<2xindex>
    %9 = "mhlo.dynamic_broadcast_in_dim"(%2, %8) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x?xf32>, tensor<2xindex>) -> tensor<?x?xf32>
    %10 = "mhlo.dynamic_broadcast_in_dim"(%arg0, %8) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<8192x2560xf32>, tensor<2xindex>) -> tensor<?x?xf32>
    %11 = mhlo.multiply %9, %10 : tensor<?x?xf32>
    shape.assuming_yield %11 : tensor<?x?xf32>
  }
  %6 = mhlo.reduce(%5 init: %1) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
  return %6 : tensor<?xf32>
}

// -----// IR Dump After Inliner (inline) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = shape.const_shape [8192, 2560] : tensor<2xindex>
    %1 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %2 = mhlo.subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
    %3 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
    %4 = shape.cstr_broadcastable %3, %0 : tensor<2xindex>, tensor<2xindex>
    %5 = shape.assuming %4 -> (tensor<?x?xf32>) {
      %7 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
      %8 = shape.broadcast %7, %0 : tensor<2xindex>, tensor<2xindex> -> tensor<2xindex>
      %9 = "mhlo.dynamic_broadcast_in_dim"(%2, %8) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x?xf32>, tensor<2xindex>) -> tensor<?x?xf32>
      %10 = "mhlo.dynamic_broadcast_in_dim"(%arg0, %8) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<8192x2560xf32>, tensor<2xindex>) -> tensor<?x?xf32>
      %11 = mhlo.multiply %9, %10 : tensor<?x?xf32>
      shape.assuming_yield %11 : tensor<?x?xf32>
    }
    %6 = mhlo.reduce(%5 init: %1) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
    return %6 : tensor<?xf32>
  }
}


// -----// IR Dump After RemoveShapeConstraintsPass (disc-remove-shape-constraint) //----- //
func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %0 = shape.const_witness true
  %1 = shape.const_shape [8192, 2560] : tensor<2xindex>
  %2 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %3 = mhlo.subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
  %4 = shape.assuming %0 -> (tensor<?x?xf32>) {
    %6 = shape.shape_of %3 : tensor<?x?xf32> -> tensor<2xindex>
    %7 = shape.broadcast %6, %1 : tensor<2xindex>, tensor<2xindex> -> tensor<2xindex>
    %8 = "mhlo.dynamic_broadcast_in_dim"(%3, %7) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x?xf32>, tensor<2xindex>) -> tensor<?x?xf32>
    %9 = "mhlo.dynamic_broadcast_in_dim"(%arg0, %7) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<8192x2560xf32>, tensor<2xindex>) -> tensor<?x?xf32>
    %10 = mhlo.multiply %8, %9 : tensor<?x?xf32>
    shape.assuming_yield %10 : tensor<?x?xf32>
  }
  %5 = mhlo.reduce(%4 init: %2) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
  return %5 : tensor<?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %0 = shape.const_shape [8192, 2560] : tensor<2xindex>
  %1 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %2 = mhlo.subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
  %3 = shape.shape_of %2 : tensor<?x?xf32> -> tensor<2xindex>
  %4 = shape.broadcast %3, %0 : tensor<2xindex>, tensor<2xindex> -> tensor<2xindex>
  %5 = "mhlo.dynamic_broadcast_in_dim"(%2, %4) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x?xf32>, tensor<2xindex>) -> tensor<?x?xf32>
  %6 = "mhlo.dynamic_broadcast_in_dim"(%arg0, %4) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<8192x2560xf32>, tensor<2xindex>) -> tensor<?x?xf32>
  %7 = mhlo.multiply %5, %6 : tensor<?x?xf32>
  %8 = mhlo.reduce(%7 init: %1) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
  return %8 : tensor<?xf32>
}

// -----// IR Dump After ConvertShapeToStandardPass (disc-convert-shape-to-std) //----- //
func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<?xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %c8192 = arith.constant 8192 : index
  %c2560 = arith.constant 2560 : index
  %from_elements = tensor.from_elements %c8192, %c2560 : tensor<2xindex>
  %cast = tensor.cast %from_elements : tensor<2xindex> to tensor<2xindex>
  %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %1 = mhlo.subtract %arg0, %arg1 : (tensor<8192x2560xf32>, tensor<8192x2560xf32>) -> tensor<?x?xf32>
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %1, %c0 : tensor<?x?xf32>
  %c1 = arith.constant 1 : index
  %dim_0 = tensor.dim %1, %c1 : tensor<?x?xf32>
  %from_elements_1 = tensor.from_elements %dim, %dim_0 : tensor<2xindex>
  %c0_2 = arith.constant 0 : index
  %c1_3 = arith.constant 1 : index
  %c0_4 = arith.constant 0 : index
  %extracted = tensor.extract %from_elements_1[%c0_4] : tensor<2xindex>
  %2 = arith.cmpi eq, %extracted, %c1_3 : index
  %3 = arith.select %2, %c1_3, %extracted : index
  %c0_5 = arith.constant 0 : index
  %extracted_6 = tensor.extract %cast[%c0_5] : tensor<2xindex>
  %4 = arith.cmpi eq, %extracted_6, %c1_3 : index
  %5 = arith.select %4, %3, %extracted_6 : index
  %c1_7 = arith.constant 1 : index
  %c1_8 = arith.constant 1 : index
  %extracted_9 = tensor.extract %from_elements_1[%c1_8] : tensor<2xindex>
  %6 = arith.cmpi eq, %extracted_9, %c1_7 : index
  %7 = arith.select %6, %c1_7, %extracted_9 : index
  %c1_10 = arith.constant 1 : index
  %extracted_11 = tensor.extract %cast[%c1_10] : tensor<2xindex>
  %8 = arith.cmpi eq, %extracted_11, %c1_7 : index
  %9 = arith.select %8, %7, %extracted_11 : index
  %from_elements_12 = tensor.from_elements %5, %9 : tensor<2xindex>
  %10 = "mhlo.dynamic_broadcast_in_dim"(%1, %from_elements_12) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<?x?xf32>, tensor<2xindex>) -> tensor<?x?xf32>
  %11 = "mhlo.dynamic_broadcast_in_dim"(%arg0, %from_elements_12) {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<8192x2560xf32>, tensor<2xindex>) -> tensor<?x?xf32>
  %12 = mhlo.multiply %10, %11 : tensor<?x?xf32>
  %13 = mhlo.reduce(%12 init: %0) applies mhlo.add across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
  return %13 : tensor<?xf32>
}

SymbolicDimMgr::save walkRankedTensorValue takes: 2 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 26 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 2 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 1 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 29 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.subtract %arg0, %arg1 : tensor<8192x2560xf32>
    %2 = mhlo.multiply %1, %arg0 : tensor<8192x2560xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
    return %3 : tensor<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 24 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.subtract %arg0, %arg1 : tensor<8192x2560xf32>
    %2 = mhlo.multiply %1, %arg0 : tensor<8192x2560xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
    return %3 : tensor<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 24 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 1 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.subtract %arg0, %arg1 : tensor<8192x2560xf32>
    %2 = mhlo.multiply %1, %arg0 : tensor<8192x2560xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
    return %3 : tensor<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 155 us
SymbolicDimMgr::save updateFunctionType takes: 2 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.subtract %arg0, %arg1 : tensor<8192x2560xf32>
    %2 = mhlo.multiply %1, %arg0 : tensor<8192x2560xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
    return %3 : tensor<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After PlaceOpsPass (mhlo-place-ops) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.subtract %arg0, %arg1 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %2 = mhlo.multiply %1, %arg0 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
    return %3 : tensor<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 24 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.subtract %arg0, %arg1 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %2 = mhlo.multiply %1, %arg0 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
    return %3 : tensor<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 27 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.subtract %arg0, %arg1 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %2 = mhlo.multiply %1, %arg0 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
    return %3 : tensor<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 24 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %1 = mhlo.subtract %arg0, %arg1 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %2 = mhlo.multiply %1, %arg0 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
    return %3 : tensor<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 3 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 24 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %c8192 = arith.constant 8192 : index
    %c2560 = arith.constant 2560 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %1 = "disc_shape.tie_shape"(%arg0, %c8192, %c2560) : (tensor<8192x2560xf32>, index, index) -> tensor<8192x2560xf32>
    %2 = "disc_shape.tie_shape"(%arg1, %c8192, %c2560) : (tensor<8192x2560xf32>, index, index) -> tensor<8192x2560xf32>
    %3 = mhlo.subtract %1, %2 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %4 = "disc_shape.tie_shape"(%3, %c8192, %c2560) : (tensor<8192x2560xf32>, index, index) -> tensor<8192x2560xf32>
    %5 = mhlo.multiply %4, %1 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %6 = "disc_shape.tie_shape"(%5, %c8192, %c2560) : (tensor<8192x2560xf32>, index, index) -> tensor<8192x2560xf32>
    %7 = mhlo.reduce(%6 init: %0) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
    %8 = "disc_shape.tie_shape"(%7, %c2560) : (tensor<2560xf32>, index) -> tensor<2560xf32>
    return %8 : tensor<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<8192x2560xf32>, %arg1: tensor<8192x2560xf32>) -> tensor<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %0 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
  %1 = mhlo.subtract %arg0, %arg1 {disc.device = "gpu"} : tensor<8192x2560xf32>
  %2 = mhlo.multiply %1, %arg0 {disc.device = "gpu"} : tensor<8192x2560xf32>
  %3 = mhlo.reduce(%2 init: %0) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
  return %3 : tensor<2560xf32>
}

// -----// IR Dump After FuncBufferize (func-bufferize) //----- //
module {
  func.func @main(%arg0: memref<8192x2560xf32>, %arg1: memref<8192x2560xf32>) -> memref<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = bufferization.to_tensor %arg1 : memref<8192x2560xf32>
    %1 = bufferization.to_tensor %arg0 : memref<8192x2560xf32>
    %2 = mhlo.constant {disc.device = "gpu"} dense<0.000000e+00> : tensor<f32>
    %3 = mhlo.subtract %1, %0 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %4 = mhlo.multiply %3, %1 {disc.device = "gpu"} : tensor<8192x2560xf32>
    %5 = mhlo.reduce(%4 init: %2) applies mhlo.add across dimensions = [0] : (tensor<8192x2560xf32>, tensor<f32>) -> tensor<2560xf32>
    %6 = bufferization.to_memref %5 : memref<2560xf32>
    return %6 : memref<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After HloLegalizeToLhloPass (hlo-legalize-to-lhlo) //----- //
module {
  func.func @main(%arg0: memref<8192x2560xf32>, %arg1: memref<8192x2560xf32>) -> memref<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = bufferization.to_tensor %arg1 : memref<8192x2560xf32>
    %1 = bufferization.to_memref %0 : memref<8192x2560xf32>
    %2 = bufferization.to_tensor %arg0 : memref<8192x2560xf32>
    %3 = bufferization.to_memref %2 : memref<8192x2560xf32>
    %alloc = memref.alloc() : memref<f32>
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32>) -> ()
    %alloc_0 = memref.alloc() : memref<8192x2560xf32>
    "lmhlo.subtract"(%3, %1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32>, memref<8192x2560xf32>, memref<8192x2560xf32>) -> ()
    %alloc_1 = memref.alloc() : memref<8192x2560xf32>
    "lmhlo.multiply"(%alloc_0, %3, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32>, memref<8192x2560xf32>, memref<8192x2560xf32>) -> ()
    %alloc_2 = memref.alloc() : memref<2560xf32>
    "lmhlo.reduce"(%alloc_1, %alloc, %alloc_2) ({
    ^bb0(%arg2: memref<f32>, %arg3: memref<f32>, %arg4: memref<f32>):
      %alloc_3 = memref.alloc() : memref<f32>
      "lmhlo.add"(%arg2, %arg3, %alloc_3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.copy"(%alloc_3, %arg4) : (memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<8192x2560xf32>, memref<f32>, memref<2560xf32>) -> ()
    %4 = bufferization.to_tensor %alloc_2 : memref<2560xf32>
    %5 = bufferization.to_memref %4 : memref<2560xf32>
    return %5 : memref<2560xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<8192x2560xf32>, %arg1: memref<8192x2560xf32>) -> memref<2560xf32> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32>) -> ()
  %alloc_0 = memref.alloc() : memref<8192x2560xf32>
  "lmhlo.subtract"(%arg0, %arg1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32>, memref<8192x2560xf32>, memref<8192x2560xf32>) -> ()
  %alloc_1 = memref.alloc() : memref<8192x2560xf32>
  "lmhlo.multiply"(%alloc_0, %arg0, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32>, memref<8192x2560xf32>, memref<8192x2560xf32>) -> ()
  %alloc_2 = memref.alloc() : memref<2560xf32>
  "lmhlo.reduce"(%alloc_1, %alloc, %alloc_2) ({
  ^bb0(%arg2: memref<f32>, %arg3: memref<f32>, %arg4: memref<f32>):
    "lmhlo.add"(%arg2, %arg3, %arg4) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<8192x2560xf32>, memref<f32>, memref<2560xf32>) -> ()
  return %alloc_2 : memref<2560xf32>
}

// -----// IR Dump After DiscAssignMemorySpacePass (disc-assign-memory-space) //----- //
module {
  func.func @main(%arg0: memref<8192x2560xf32, "gpu">, %arg1: memref<8192x2560xf32, "gpu">) -> memref<2560xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %alloc = memref.alloc() : memref<f32, "gpu">
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    %alloc_0 = memref.alloc() : memref<8192x2560xf32, "gpu">
    "lmhlo.subtract"(%arg0, %arg1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    %alloc_1 = memref.alloc() : memref<8192x2560xf32, "gpu">
    "lmhlo.multiply"(%alloc_0, %arg0, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    %alloc_2 = memref.alloc() : memref<2560xf32, "gpu">
    "lmhlo.reduce"(%alloc_1, %alloc, %alloc_2) ({
    ^bb0(%arg2: memref<f32>, %arg3: memref<f32>, %arg4: memref<f32>):
      "lmhlo.add"(%arg2, %arg3, %arg4) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<f32, "gpu">, memref<2560xf32, "gpu">) -> ()
    return %alloc_2 : memref<2560xf32, "gpu">
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 2 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 1 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscFusionPass (disc-fusion) //----- //
func.func @main(%arg0: memref<8192x2560xf32, "gpu">, %arg1: memref<8192x2560xf32, "gpu">) -> memref<2560xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_2 = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.subtract"(%arg0, %arg1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    "lmhlo.multiply"(%alloc_0, %arg0, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    "lmhlo.reduce"(%alloc_1, %alloc, %alloc_2) ({
    ^bb0(%arg2: memref<f32>, %arg3: memref<f32>, %arg4: memref<f32>):
      "lmhlo.add"(%arg2, %arg3, %arg4) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<f32, "gpu">, memref<2560xf32, "gpu">) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  return %alloc_2 : memref<2560xf32, "gpu">
}

SymbolicDimMgr::save walkRankedTensorValue takes: 1 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::save updateProductEqualityMap takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 1 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscSpecializeFusionWithSpeculationPass (disc-specialize-fusion-with-speculation) //----- //
func.func @main(%arg0: memref<8192x2560xf32, "gpu">, %arg1: memref<8192x2560xf32, "gpu">) -> memref<2560xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_2 = memref.alloc() : memref<2560xf32, "gpu">
  %c0 = arith.constant 0 : index
  %dim = memref.dim %alloc_1, %c0 : memref<8192x2560xf32, "gpu">
  %c1 = arith.constant 1 : index
  %dim_3 = memref.dim %alloc_1, %c1 : memref<8192x2560xf32, "gpu">
  %0 = arith.muli %dim, %dim_3 : index
  %c256 = arith.constant 256 : index
  %1 = arith.ceildivsi %0, %c256 : index
  %c108 = arith.constant 108 : index
  %2 = arith.cmpi sgt, %1, %c108 : index
  scf.if %2 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.subtract"(%arg0, %arg1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
      "lmhlo.multiply"(%alloc_0, %arg0, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_1, %alloc, %alloc_2) ({
      ^bb0(%arg2: memref<f32>, %arg3: memref<f32>, %arg4: memref<f32>):
        "lmhlo.add"(%arg2, %arg3, %arg4) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<f32, "gpu">, memref<2560xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.subtract"(%arg0, %arg1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
      "lmhlo.multiply"(%alloc_0, %arg0, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_1, %alloc, %alloc_2) ({
      ^bb0(%arg2: memref<f32>, %arg3: memref<f32>, %arg4: memref<f32>):
        "lmhlo.add"(%arg2, %arg3, %arg4) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<f32, "gpu">, memref<2560xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  return %alloc_2 : memref<2560xf32, "gpu">
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<8192x2560xf32, "gpu">, %arg1: memref<8192x2560xf32, "gpu">) -> memref<2560xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_2 = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.subtract"(%arg0, %arg1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    "lmhlo.multiply"(%alloc_0, %arg0, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    "lmhlo.reduce"(%alloc_1, %alloc, %alloc_2) ({
    ^bb0(%arg2: memref<f32>, %arg3: memref<f32>, %arg4: memref<f32>):
      "lmhlo.add"(%arg2, %arg3, %arg4) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<f32, "gpu">, memref<2560xf32, "gpu">) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  return %alloc_2 : memref<2560xf32, "gpu">
}

// -----// IR Dump After BufferDeallocation (buffer-deallocation) //----- //
func.func @main(%arg0: memref<8192x2560xf32, "gpu">, %arg1: memref<8192x2560xf32, "gpu">) -> memref<2560xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_2 = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.subtract"(%arg0, %arg1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    "lmhlo.multiply"(%alloc_0, %arg0, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    "lmhlo.reduce"(%alloc_1, %alloc, %alloc_2) ({
    ^bb0(%arg2: memref<f32>, %arg3: memref<f32>, %arg4: memref<f32>):
      "lmhlo.add"(%arg2, %arg3, %arg4) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<f32, "gpu">, memref<2560xf32, "gpu">) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  memref.dealloc %alloc_1 : memref<8192x2560xf32, "gpu">
  memref.dealloc %alloc_0 : memref<8192x2560xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  return %alloc_2 : memref<2560xf32, "gpu">
}

// -----// IR Dump After RalInjectExecutionContextPass (disc-ral-inject-execution-context) //----- //
module {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.recv_input"(%arg0, %c0) : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %c1 = arith.constant 1 : index
    %1 = "disc_ral.recv_input"(%arg0, %c1) : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %alloc = memref.alloc() : memref<f32, "gpu">
    %alloc_0 = memref.alloc() : memref<8192x2560xf32, "gpu">
    %alloc_1 = memref.alloc() : memref<8192x2560xf32, "gpu">
    %alloc_2 = memref.alloc() : memref<2560xf32, "gpu">
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.subtract"(%0, %1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
      "lmhlo.multiply"(%alloc_0, %0, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_1, %alloc, %alloc_2) ({
      ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
        "lmhlo.add"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<f32, "gpu">, memref<2560xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
    memref.dealloc %alloc_1 : memref<8192x2560xf32, "gpu">
    memref.dealloc %alloc_0 : memref<8192x2560xf32, "gpu">
    memref.dealloc %alloc : memref<f32, "gpu">
    %c0_3 = arith.constant 0 : index
    "disc_ral.send_output"(%arg0, %c0_3, %alloc_2) : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
    return
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscLowerToLibraryCallPass (disc-lower-to-library-call) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_2 = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.subtract"(%0, %1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    "lmhlo.multiply"(%alloc_0, %0, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    "lmhlo.reduce"(%alloc_1, %alloc, %alloc_2) ({
    ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
      "lmhlo.add"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<f32, "gpu">, memref<2560xf32, "gpu">) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  memref.dealloc %alloc_1 : memref<8192x2560xf32, "gpu">
  memref.dealloc %alloc_0 : memref<8192x2560xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

kColReduction <main_kColReduction_reduce__4_1_0___8w32h>, use_new: 0 schedule_hint: 1
SymbolicDimMgr::save walkRankedTensorValue takes: 2 us
SymbolicDimMgr::save update attributes takes: 3 us
SymbolicDimMgr::save updateProductEqualityMap takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 3 us
SymbolicDimMgr::save collect symbolicDim ops takes: 4 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 3 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
// -----// IR Dump After DiscLhloLegalizeRootsToParallelLoopsPass (disc-lhlo-legalize-roots-to-parallel-loops) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_2 = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0.000000e+00> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.subtract"(%0, %1, %alloc_0) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    "lmhlo.multiply"(%alloc_0, %0, %alloc_1) {disc.device = "gpu"} : (memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">, memref<8192x2560xf32, "gpu">) -> ()
    scf.parallel (%arg1) = (%c0) to (%c2560) step (%c1) {
      %2 = "disc_shape.delinearize"(%arg1, %c2560) : (index, index) -> index
      %3 = memref.load %alloc[] : memref<f32, "gpu">
      memref.store %3, %alloc_2[%2] : memref<2560xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c81920, %c256) step (%c1, %c1) {
      %2 = memref.load %alloc[] : memref<f32, "gpu">
      %3 = arith.divui %arg2, %c8 : index
      %4 = arith.remui %arg2, %c8 : index
      %5 = arith.divui %arg1, %c320 : index
      %6 = arith.remui %arg1, %c320 : index
      %7 = arith.muli %5, %c32 : index
      %8 = arith.addi %7, %3 : index
      %9 = arith.muli %6, %c8 : index
      %10 = arith.addi %9, %4 : index
      %alloc_3 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
      %11 = arith.cmpi ult, %8, %c8192 : index
      %12 = arith.cmpi ult, %10, %c2560 : index
      %13 = arith.andi %11, %12 : i1
      scf.if %13 {
        %32 = memref.load %alloc_1[%8, %10] : memref<8192x2560xf32, "gpu">
        %33 = arith.addf %32, %2 : f32
        memref.store %33, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      } else {
        memref.store %2, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %14 = arith.cmpi ult, %3, %c16 : index
      %15 = arith.addi %8, %c16 : index
      %16 = arith.cmpi ult, %15, %c8192 : index
      %17 = arith.andi %14, %16 : i1
      scf.if %17 {
        %32 = arith.addi %arg2, %c128 : index
        %33 = memref.load %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = memref.load %alloc_3[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %35 = arith.addf %33, %34 : f32
        memref.store %35, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %18 = arith.cmpi ult, %3, %c8 : index
      %19 = arith.addi %8, %c8 : index
      %20 = arith.cmpi ult, %19, %c8192 : index
      %21 = arith.andi %18, %20 : i1
      scf.if %21 {
        %32 = arith.addi %arg2, %c64 : index
        %33 = memref.load %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = memref.load %alloc_3[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %35 = arith.addf %33, %34 : f32
        memref.store %35, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %22 = arith.cmpi ult, %3, %c4 : index
      %23 = arith.addi %8, %c4 : index
      %24 = arith.cmpi ult, %23, %c8192 : index
      %25 = arith.andi %22, %24 : i1
      scf.if %25 {
        %32 = arith.addi %arg2, %c32 : index
        %33 = memref.load %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = memref.load %alloc_3[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %35 = arith.addf %33, %34 : f32
        memref.store %35, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %26 = arith.cmpi ult, %3, %c2 : index
      %27 = arith.addi %8, %c2 : index
      %28 = arith.cmpi ult, %27, %c8192 : index
      %29 = arith.andi %26, %28 : i1
      scf.if %29 {
        %32 = arith.addi %arg2, %c16 : index
        %33 = memref.load %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = memref.load %alloc_3[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %35 = arith.addf %33, %34 : f32
        memref.store %35, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %30 = arith.cmpi eq, %3, %c0 : index
      %31 = arith.andi %30, %13 : i1
      scf.if %31 {
        %32 = arith.addi %arg2, %c8 : index
        %33 = memref.load %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = memref.load %alloc_3[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %35 = arith.addf %33, %34 : f32
        %36 = memref.atomic_rmw addf %35, %alloc_2[%10] : (f32, memref<2560xf32, "gpu">) -> f32
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  memref.dealloc %alloc_1 : memref<8192x2560xf32, "gpu">
  memref.dealloc %alloc_0 : memref<8192x2560xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After InputInlineFusionPass (disc-input-inline-fusion) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_2 = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c2560) step (%c1) {
      %2 = "disc_shape.delinearize"(%arg1, %c2560) : (index, index) -> index
      memref.store %cst, %alloc_2[%2] : memref<2560xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c81920, %c256) step (%c1, %c1) {
      %2 = arith.divui %arg2, %c8 : index
      %3 = arith.remui %arg2, %c8 : index
      %4 = arith.divui %arg1, %c320 : index
      %5 = arith.remui %arg1, %c320 : index
      %6 = arith.muli %4, %c32 : index
      %7 = arith.addi %6, %2 : index
      %8 = arith.muli %5, %c8 : index
      %9 = arith.addi %8, %3 : index
      %alloc_3 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
      %10 = arith.cmpi ult, %7, %c8192 : index
      %11 = arith.cmpi ult, %9, %c2560 : index
      %12 = arith.andi %10, %11 : i1
      scf.if %12 {
        %31 = memref.load %0[%7, %9] : memref<8192x2560xf32, "gpu">
        %32 = memref.load %1[%7, %9] : memref<8192x2560xf32, "gpu">
        %33 = arith.subf %31, %32 : f32
        %34 = memref.load %0[%7, %9] : memref<8192x2560xf32, "gpu">
        %35 = arith.mulf %33, %34 : f32
        %36 = arith.addf %35, %cst : f32
        memref.store %36, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      } else {
        memref.store %cst, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %13 = arith.cmpi ult, %2, %c16 : index
      %14 = arith.addi %7, %c16 : index
      %15 = arith.cmpi ult, %14, %c8192 : index
      %16 = arith.andi %13, %15 : i1
      scf.if %16 {
        %31 = arith.addi %arg2, %c128 : index
        %32 = memref.load %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %alloc_3[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %17 = arith.cmpi ult, %2, %c8 : index
      %18 = arith.addi %7, %c8 : index
      %19 = arith.cmpi ult, %18, %c8192 : index
      %20 = arith.andi %17, %19 : i1
      scf.if %20 {
        %31 = arith.addi %arg2, %c64 : index
        %32 = memref.load %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %alloc_3[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %21 = arith.cmpi ult, %2, %c4 : index
      %22 = arith.addi %7, %c4 : index
      %23 = arith.cmpi ult, %22, %c8192 : index
      %24 = arith.andi %21, %23 : i1
      scf.if %24 {
        %31 = arith.addi %arg2, %c32 : index
        %32 = memref.load %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %alloc_3[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %25 = arith.cmpi ult, %2, %c2 : index
      %26 = arith.addi %7, %c2 : index
      %27 = arith.cmpi ult, %26, %c8192 : index
      %28 = arith.andi %25, %27 : i1
      scf.if %28 {
        %31 = arith.addi %arg2, %c16 : index
        %32 = memref.load %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %alloc_3[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %29 = arith.cmpi eq, %2, %c0 : index
      %30 = arith.andi %29, %12 : i1
      scf.if %30 {
        %31 = arith.addi %arg2, %c8 : index
        %32 = memref.load %alloc_3[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %alloc_3[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        %35 = memref.atomic_rmw addf %34, %alloc_2[%9] : (f32, memref<2560xf32, "gpu">) -> f32
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  memref.dealloc %alloc_1 : memref<8192x2560xf32, "gpu">
  memref.dealloc %alloc_0 : memref<8192x2560xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After DiscFlattenMemrefAccessPass (disc-flatten-memref-access) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<8192x2560xf32, "gpu">
  %alloc_2 = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c2560) step (%c1) {
      %2 = "disc_shape.delinearize"(%arg1, %c2560) : (index, index) -> index
      %c2560_3 = arith.constant 2560 : index
      %3 = "disc_shape.linearize"(%2, %c2560_3) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
      %reinterpret_cast = memref.reinterpret_cast %alloc_2 to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%3] : memref<2560xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c81920, %c256) step (%c1, %c1) {
      %2 = arith.divui %arg2, %c8 : index
      %3 = arith.remui %arg2, %c8 : index
      %4 = arith.divui %arg1, %c320 : index
      %5 = arith.remui %arg1, %c320 : index
      %6 = arith.muli %4, %c32 : index
      %7 = arith.addi %6, %2 : index
      %8 = arith.muli %5, %c8 : index
      %9 = arith.addi %8, %3 : index
      %alloc_3 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
      %10 = arith.cmpi ult, %7, %c8192 : index
      %11 = arith.cmpi ult, %9, %c2560 : index
      %12 = arith.andi %10, %11 : i1
      scf.if %12 {
        %c8192_4 = arith.constant 8192 : index
        %c2560_5 = arith.constant 2560 : index
        %31 = "disc_shape.linearize"(%7, %9, %c8192_4, %c2560_5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %32 = memref.load %reinterpret_cast[%31] : memref<20971520xf32, "gpu">
        %c8192_6 = arith.constant 8192 : index
        %c2560_7 = arith.constant 2560 : index
        %33 = "disc_shape.linearize"(%7, %9, %c8192_6, %c2560_7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %reinterpret_cast_8 = memref.reinterpret_cast %1 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %34 = memref.load %reinterpret_cast_8[%33] : memref<20971520xf32, "gpu">
        %35 = arith.subf %32, %34 : f32
        %c8192_9 = arith.constant 8192 : index
        %c2560_10 = arith.constant 2560 : index
        %36 = "disc_shape.linearize"(%7, %9, %c8192_9, %c2560_10) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %reinterpret_cast_11 = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %37 = memref.load %reinterpret_cast_11[%36] : memref<20971520xf32, "gpu">
        %38 = arith.mulf %35, %37 : f32
        %39 = arith.addf %38, %cst : f32
        %c256_12 = arith.constant 256 : index
        %40 = "disc_shape.linearize"(%arg2, %c256_12) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_13 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %39, %reinterpret_cast_13[%40] : memref<256xf32, #gpu.address_space<workgroup>>
      } else {
        %c256_4 = arith.constant 256 : index
        %31 = "disc_shape.linearize"(%arg2, %c256_4) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %cst, %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %13 = arith.cmpi ult, %2, %c16 : index
      %14 = arith.addi %7, %c16 : index
      %15 = arith.cmpi ult, %14, %c8192 : index
      %16 = arith.andi %13, %15 : i1
      scf.if %16 {
        %31 = arith.addi %arg2, %c128 : index
        %c256_4 = arith.constant 256 : index
        %32 = "disc_shape.linearize"(%arg2, %c256_4) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %c256_5 = arith.constant 256 : index
        %34 = "disc_shape.linearize"(%31, %c256_5) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_6 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %35 = memref.load %reinterpret_cast_6[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %c256_7 = arith.constant 256 : index
        %37 = "disc_shape.linearize"(%arg2, %c256_7) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_8 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %36, %reinterpret_cast_8[%37] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %17 = arith.cmpi ult, %2, %c8 : index
      %18 = arith.addi %7, %c8 : index
      %19 = arith.cmpi ult, %18, %c8192 : index
      %20 = arith.andi %17, %19 : i1
      scf.if %20 {
        %31 = arith.addi %arg2, %c64 : index
        %c256_4 = arith.constant 256 : index
        %32 = "disc_shape.linearize"(%arg2, %c256_4) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %c256_5 = arith.constant 256 : index
        %34 = "disc_shape.linearize"(%31, %c256_5) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_6 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %35 = memref.load %reinterpret_cast_6[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %c256_7 = arith.constant 256 : index
        %37 = "disc_shape.linearize"(%arg2, %c256_7) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_8 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %36, %reinterpret_cast_8[%37] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %21 = arith.cmpi ult, %2, %c4 : index
      %22 = arith.addi %7, %c4 : index
      %23 = arith.cmpi ult, %22, %c8192 : index
      %24 = arith.andi %21, %23 : i1
      scf.if %24 {
        %31 = arith.addi %arg2, %c32 : index
        %c256_4 = arith.constant 256 : index
        %32 = "disc_shape.linearize"(%arg2, %c256_4) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %c256_5 = arith.constant 256 : index
        %34 = "disc_shape.linearize"(%31, %c256_5) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_6 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %35 = memref.load %reinterpret_cast_6[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %c256_7 = arith.constant 256 : index
        %37 = "disc_shape.linearize"(%arg2, %c256_7) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_8 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %36, %reinterpret_cast_8[%37] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %25 = arith.cmpi ult, %2, %c2 : index
      %26 = arith.addi %7, %c2 : index
      %27 = arith.cmpi ult, %26, %c8192 : index
      %28 = arith.andi %25, %27 : i1
      scf.if %28 {
        %31 = arith.addi %arg2, %c16 : index
        %c256_4 = arith.constant 256 : index
        %32 = "disc_shape.linearize"(%arg2, %c256_4) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %c256_5 = arith.constant 256 : index
        %34 = "disc_shape.linearize"(%31, %c256_5) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_6 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %35 = memref.load %reinterpret_cast_6[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %c256_7 = arith.constant 256 : index
        %37 = "disc_shape.linearize"(%arg2, %c256_7) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_8 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %36, %reinterpret_cast_8[%37] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %29 = arith.cmpi eq, %2, %c0 : index
      %30 = arith.andi %29, %12 : i1
      scf.if %30 {
        %31 = arith.addi %arg2, %c8 : index
        %c256_4 = arith.constant 256 : index
        %32 = "disc_shape.linearize"(%arg2, %c256_4) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %c256_5 = arith.constant 256 : index
        %34 = "disc_shape.linearize"(%31, %c256_5) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_6 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %35 = memref.load %reinterpret_cast_6[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %37 = memref.atomic_rmw addf %36, %alloc_2[%9] : (f32, memref<2560xf32, "gpu">) -> f32
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  memref.dealloc %alloc_1 : memref<8192x2560xf32, "gpu">
  memref.dealloc %alloc_0 : memref<8192x2560xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %alloc_2) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After Canonicalizer (disc-canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c2560) step (%c1) {
      %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%arg1] : memref<2560xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c81920, %c256) step (%c1, %c1) {
      %2 = arith.divui %arg2, %c8 : index
      %3 = arith.remui %arg2, %c8 : index
      %4 = arith.divui %arg1, %c320 : index
      %5 = arith.remui %arg1, %c320 : index
      %6 = arith.muli %4, %c32 : index
      %7 = arith.addi %6, %2 : index
      %8 = arith.muli %5, %c8 : index
      %9 = arith.addi %8, %3 : index
      %alloc_0 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
      %10 = arith.cmpi ult, %7, %c8192 : index
      %11 = arith.cmpi ult, %9, %c2560 : index
      %12 = arith.andi %10, %11 : i1
      scf.if %12 {
        %31 = "disc_shape.linearize"(%7, %9, %c8192, %c2560) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %32 = memref.load %reinterpret_cast[%31] : memref<20971520xf32, "gpu">
        %33 = "disc_shape.linearize"(%7, %9, %c8192, %c2560) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %reinterpret_cast_1 = memref.reinterpret_cast %1 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %34 = memref.load %reinterpret_cast_1[%33] : memref<20971520xf32, "gpu">
        %35 = arith.subf %32, %34 : f32
        %36 = "disc_shape.linearize"(%7, %9, %c8192, %c2560) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %reinterpret_cast_2 = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %37 = memref.load %reinterpret_cast_2[%36] : memref<20971520xf32, "gpu">
        %38 = arith.mulf %35, %37 : f32
        %39 = arith.addf %38, %cst : f32
        %40 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_3 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %39, %reinterpret_cast_3[%40] : memref<256xf32, #gpu.address_space<workgroup>>
      } else {
        %31 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %cst, %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %13 = arith.cmpi ult, %2, %c16 : index
      %14 = arith.addi %7, %c16 : index
      %15 = arith.cmpi ult, %14, %c8192 : index
      %16 = arith.andi %13, %15 : i1
      scf.if %16 {
        %31 = arith.addi %arg2, %c128 : index
        %32 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = "disc_shape.linearize"(%31, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_1 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %35 = memref.load %reinterpret_cast_1[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %37 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %36, %reinterpret_cast_2[%37] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %17 = arith.cmpi ult, %2, %c8 : index
      %18 = arith.addi %7, %c8 : index
      %19 = arith.cmpi ult, %18, %c8192 : index
      %20 = arith.andi %17, %19 : i1
      scf.if %20 {
        %31 = arith.addi %arg2, %c64 : index
        %32 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = "disc_shape.linearize"(%31, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_1 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %35 = memref.load %reinterpret_cast_1[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %37 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %36, %reinterpret_cast_2[%37] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %21 = arith.cmpi ult, %2, %c4 : index
      %22 = arith.addi %7, %c4 : index
      %23 = arith.cmpi ult, %22, %c8192 : index
      %24 = arith.andi %21, %23 : i1
      scf.if %24 {
        %31 = arith.addi %arg2, %c32 : index
        %32 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = "disc_shape.linearize"(%31, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_1 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %35 = memref.load %reinterpret_cast_1[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %37 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %36, %reinterpret_cast_2[%37] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %25 = arith.cmpi ult, %2, %c2 : index
      %26 = arith.addi %7, %c2 : index
      %27 = arith.cmpi ult, %26, %c8192 : index
      %28 = arith.andi %25, %27 : i1
      scf.if %28 {
        %31 = arith.addi %arg2, %c16 : index
        %32 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = "disc_shape.linearize"(%31, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_1 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %35 = memref.load %reinterpret_cast_1[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %37 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %36, %reinterpret_cast_2[%37] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %29 = arith.cmpi eq, %2, %c0 : index
      %30 = arith.andi %29, %12 : i1
      scf.if %30 {
        %31 = arith.addi %arg2, %c8 : index
        %32 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = "disc_shape.linearize"(%31, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_1 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %35 = memref.load %reinterpret_cast_1[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %37 = memref.atomic_rmw addf %36, %alloc[%9] : (f32, memref<2560xf32, "gpu">) -> f32
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c2560) step (%c1) {
      %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%arg1] : memref<2560xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c81920, %c256) step (%c1, %c1) {
      %2 = arith.divui %arg2, %c8 : index
      %3 = arith.remui %arg2, %c8 : index
      %4 = arith.divui %arg1, %c320 : index
      %5 = arith.remui %arg1, %c320 : index
      %6 = arith.muli %4, %c32 : index
      %7 = arith.addi %6, %2 : index
      %8 = arith.muli %5, %c8 : index
      %9 = arith.addi %8, %3 : index
      %alloc_0 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
      %10 = arith.cmpi ult, %7, %c8192 : index
      %11 = arith.cmpi ult, %9, %c2560 : index
      %12 = arith.andi %10, %11 : i1
      scf.if %12 {
        %31 = "disc_shape.linearize"(%7, %9, %c8192, %c2560) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %32 = memref.load %reinterpret_cast[%31] : memref<20971520xf32, "gpu">
        %reinterpret_cast_1 = memref.reinterpret_cast %1 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %33 = memref.load %reinterpret_cast_1[%31] : memref<20971520xf32, "gpu">
        %34 = arith.subf %32, %33 : f32
        %35 = arith.mulf %34, %32 : f32
        %36 = arith.addf %35, %cst : f32
        %37 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %36, %reinterpret_cast_2[%37] : memref<256xf32, #gpu.address_space<workgroup>>
      } else {
        %31 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %cst, %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %13 = arith.cmpi ult, %2, %c16 : index
      %14 = arith.addi %7, %c16 : index
      %15 = arith.cmpi ult, %14, %c8192 : index
      %16 = arith.andi %13, %15 : i1
      scf.if %16 {
        %31 = arith.addi %arg2, %c128 : index
        %32 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = "disc_shape.linearize"(%31, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %35 = memref.load %reinterpret_cast[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        memref.store %36, %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %17 = arith.cmpi ult, %2, %c8 : index
      %18 = arith.addi %7, %c8 : index
      %19 = arith.cmpi ult, %18, %c8192 : index
      %20 = arith.andi %17, %19 : i1
      scf.if %20 {
        %31 = arith.addi %arg2, %c64 : index
        %32 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = "disc_shape.linearize"(%31, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %35 = memref.load %reinterpret_cast[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        memref.store %36, %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %21 = arith.cmpi ult, %2, %c4 : index
      %22 = arith.addi %7, %c4 : index
      %23 = arith.cmpi ult, %22, %c8192 : index
      %24 = arith.andi %21, %23 : i1
      scf.if %24 {
        %31 = arith.addi %arg2, %c32 : index
        %32 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = "disc_shape.linearize"(%31, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %35 = memref.load %reinterpret_cast[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        memref.store %36, %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %25 = arith.cmpi ult, %2, %c2 : index
      %26 = arith.addi %7, %c2 : index
      %27 = arith.cmpi ult, %26, %c8192 : index
      %28 = arith.andi %25, %27 : i1
      scf.if %28 {
        %31 = arith.addi %arg2, %c16 : index
        %32 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = "disc_shape.linearize"(%31, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %35 = memref.load %reinterpret_cast[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        memref.store %36, %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %29 = arith.cmpi eq, %2, %c0 : index
      %30 = arith.andi %29, %12 : i1
      scf.if %30 {
        %31 = arith.addi %arg2, %c8 : index
        %32 = "disc_shape.linearize"(%arg2, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%32] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = "disc_shape.linearize"(%31, %c256) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %35 = memref.load %reinterpret_cast[%34] : memref<256xf32, #gpu.address_space<workgroup>>
        %36 = arith.addf %33, %35 : f32
        %37 = memref.atomic_rmw addf %36, %alloc[%9] : (f32, memref<2560xf32, "gpu">) -> f32
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ConvertShapeToStandardPass (disc-convert-shape-to-std) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c2560) step (%c1) {
      %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%arg1] : memref<2560xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c81920, %c256) step (%c1, %c1) {
      %2 = arith.divui %arg2, %c8 : index
      %3 = arith.remui %arg2, %c8 : index
      %4 = arith.divui %arg1, %c320 : index
      %5 = arith.remui %arg1, %c320 : index
      %6 = arith.muli %4, %c32 : index
      %7 = arith.addi %6, %2 : index
      %8 = arith.muli %5, %c8 : index
      %9 = arith.addi %8, %3 : index
      %alloc_0 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
      %10 = arith.cmpi ult, %7, %c8192 : index
      %11 = arith.cmpi ult, %9, %c2560 : index
      %12 = arith.andi %10, %11 : i1
      scf.if %12 {
        %c0_1 = arith.constant 0 : index
        %31 = arith.muli %7, %c2560 : index
        %32 = arith.addi %31, %9 : index
        %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %33 = memref.load %reinterpret_cast[%32] : memref<20971520xf32, "gpu">
        %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %34 = memref.load %reinterpret_cast_2[%32] : memref<20971520xf32, "gpu">
        %35 = arith.subf %33, %34 : f32
        %36 = arith.mulf %35, %33 : f32
        %37 = arith.addf %36, %cst : f32
        %c0_3 = arith.constant 0 : index
        %reinterpret_cast_4 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %37, %reinterpret_cast_4[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      } else {
        %c0_1 = arith.constant 0 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %cst, %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %13 = arith.cmpi ult, %2, %c16 : index
      %14 = arith.addi %7, %c16 : index
      %15 = arith.cmpi ult, %14, %c8192 : index
      %16 = arith.andi %13, %15 : i1
      scf.if %16 {
        %31 = arith.addi %arg2, %c128 : index
        %c0_1 = arith.constant 0 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %32 = memref.load %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %c0_2 = arith.constant 0 : index
        %33 = memref.load %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %17 = arith.cmpi ult, %2, %c8 : index
      %18 = arith.addi %7, %c8 : index
      %19 = arith.cmpi ult, %18, %c8192 : index
      %20 = arith.andi %17, %19 : i1
      scf.if %20 {
        %31 = arith.addi %arg2, %c64 : index
        %c0_1 = arith.constant 0 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %32 = memref.load %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %c0_2 = arith.constant 0 : index
        %33 = memref.load %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %21 = arith.cmpi ult, %2, %c4 : index
      %22 = arith.addi %7, %c4 : index
      %23 = arith.cmpi ult, %22, %c8192 : index
      %24 = arith.andi %21, %23 : i1
      scf.if %24 {
        %31 = arith.addi %arg2, %c32 : index
        %c0_1 = arith.constant 0 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %32 = memref.load %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %c0_2 = arith.constant 0 : index
        %33 = memref.load %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %25 = arith.cmpi ult, %2, %c2 : index
      %26 = arith.addi %7, %c2 : index
      %27 = arith.cmpi ult, %26, %c8192 : index
      %28 = arith.andi %25, %27 : i1
      scf.if %28 {
        %31 = arith.addi %arg2, %c16 : index
        %c0_1 = arith.constant 0 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %32 = memref.load %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %c0_2 = arith.constant 0 : index
        %33 = memref.load %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %29 = arith.cmpi eq, %2, %c0 : index
      %30 = arith.andi %29, %12 : i1
      scf.if %30 {
        %31 = arith.addi %arg2, %c8 : index
        %c0_1 = arith.constant 0 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %32 = memref.load %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %c0_2 = arith.constant 0 : index
        %33 = memref.load %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        %35 = memref.atomic_rmw addf %34, %alloc[%9] : (f32, memref<2560xf32, "gpu">) -> f32
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After Canonicalizer (disc-canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c2560) step (%c1) {
      %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%arg1] : memref<2560xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c81920, %c256) step (%c1, %c1) {
      %2 = arith.divui %arg2, %c8 : index
      %3 = arith.remui %arg2, %c8 : index
      %4 = arith.divui %arg1, %c320 : index
      %5 = arith.remui %arg1, %c320 : index
      %6 = arith.muli %4, %c32 : index
      %7 = arith.addi %6, %2 : index
      %8 = arith.muli %5, %c8 : index
      %9 = arith.addi %8, %3 : index
      %alloc_0 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
      %10 = arith.cmpi ult, %7, %c8192 : index
      %11 = arith.cmpi ult, %9, %c2560 : index
      %12 = arith.andi %10, %11 : i1
      scf.if %12 {
        %31 = arith.muli %7, %c2560 : index
        %32 = arith.addi %31, %9 : index
        %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %33 = memref.load %reinterpret_cast[%32] : memref<20971520xf32, "gpu">
        %reinterpret_cast_1 = memref.reinterpret_cast %1 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %34 = memref.load %reinterpret_cast_1[%32] : memref<20971520xf32, "gpu">
        %35 = arith.subf %33, %34 : f32
        %36 = arith.mulf %35, %33 : f32
        %37 = arith.addf %36, %cst : f32
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %37, %reinterpret_cast_2[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      } else {
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %cst, %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %13 = arith.cmpi ult, %2, %c16 : index
      %14 = arith.addi %7, %c16 : index
      %15 = arith.cmpi ult, %14, %c8192 : index
      %16 = arith.andi %13, %15 : i1
      scf.if %16 {
        %31 = arith.addi %arg2, %c128 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %32 = memref.load %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %17 = arith.cmpi ult, %2, %c8 : index
      %18 = arith.addi %7, %c8 : index
      %19 = arith.cmpi ult, %18, %c8192 : index
      %20 = arith.andi %17, %19 : i1
      scf.if %20 {
        %31 = arith.addi %arg2, %c64 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %32 = memref.load %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %21 = arith.cmpi ult, %2, %c4 : index
      %22 = arith.addi %7, %c4 : index
      %23 = arith.cmpi ult, %22, %c8192 : index
      %24 = arith.andi %21, %23 : i1
      scf.if %24 {
        %31 = arith.addi %arg2, %c32 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %32 = memref.load %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %25 = arith.cmpi ult, %2, %c2 : index
      %26 = arith.addi %7, %c2 : index
      %27 = arith.cmpi ult, %26, %c8192 : index
      %28 = arith.andi %25, %27 : i1
      scf.if %28 {
        %31 = arith.addi %arg2, %c16 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %32 = memref.load %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        memref.store %34, %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %29 = arith.cmpi eq, %2, %c0 : index
      %30 = arith.andi %29, %12 : i1
      scf.if %30 {
        %31 = arith.addi %arg2, %c8 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_0 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %32 = memref.load %reinterpret_cast[%arg2] : memref<256xf32, #gpu.address_space<workgroup>>
        %33 = memref.load %reinterpret_cast[%31] : memref<256xf32, #gpu.address_space<workgroup>>
        %34 = arith.addf %32, %33 : f32
        %35 = memref.atomic_rmw addf %34, %alloc[%9] : (f32, memref<2560xf32, "gpu">) -> f32
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ParallelLoopCollapsing (disc-parallel-loop-collapsing) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c2560) step (%c1) {
      %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%arg1] : memref<2560xf32, "gpu">
      scf.yield
    }
    %c0_0 = arith.constant 0 : index
    %c1_1 = arith.constant 1 : index
    %c1_2 = arith.constant 1 : index
    %2 = arith.muli %c1_2, %c81920 : index
    %3 = arith.muli %2, %c256 : index
    scf.parallel (%arg1) = (%c0_0) to (%3) step (%c1_1) {
      %4 = arith.remsi %arg1, %c256 : index
      %5 = arith.divsi %arg1, %c256 : index
      %6 = arith.divui %4, %c8 : index
      %7 = arith.remui %4, %c8 : index
      %8 = arith.divui %5, %c320 : index
      %9 = arith.remui %5, %c320 : index
      %10 = arith.muli %8, %c32 : index
      %11 = arith.addi %10, %6 : index
      %12 = arith.muli %9, %c8 : index
      %13 = arith.addi %12, %7 : index
      %alloc_3 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
      %14 = arith.cmpi ult, %11, %c8192 : index
      %15 = arith.cmpi ult, %13, %c2560 : index
      %16 = arith.andi %14, %15 : i1
      scf.if %16 {
        %35 = arith.muli %11, %c2560 : index
        %36 = arith.addi %35, %13 : index
        %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %37 = memref.load %reinterpret_cast[%36] : memref<20971520xf32, "gpu">
        %reinterpret_cast_4 = memref.reinterpret_cast %1 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
        %38 = memref.load %reinterpret_cast_4[%36] : memref<20971520xf32, "gpu">
        %39 = arith.subf %37, %38 : f32
        %40 = arith.mulf %39, %37 : f32
        %41 = arith.addf %40, %cst : f32
        %reinterpret_cast_5 = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %41, %reinterpret_cast_5[%4] : memref<256xf32, #gpu.address_space<workgroup>>
      } else {
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        memref.store %cst, %reinterpret_cast[%4] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %17 = arith.cmpi ult, %6, %c16 : index
      %18 = arith.addi %11, %c16 : index
      %19 = arith.cmpi ult, %18, %c8192 : index
      %20 = arith.andi %17, %19 : i1
      scf.if %20 {
        %35 = arith.addi %4, %c128 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %36 = memref.load %reinterpret_cast[%4] : memref<256xf32, #gpu.address_space<workgroup>>
        %37 = memref.load %reinterpret_cast[%35] : memref<256xf32, #gpu.address_space<workgroup>>
        %38 = arith.addf %36, %37 : f32
        memref.store %38, %reinterpret_cast[%4] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %21 = arith.cmpi ult, %6, %c8 : index
      %22 = arith.addi %11, %c8 : index
      %23 = arith.cmpi ult, %22, %c8192 : index
      %24 = arith.andi %21, %23 : i1
      scf.if %24 {
        %35 = arith.addi %4, %c64 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %36 = memref.load %reinterpret_cast[%4] : memref<256xf32, #gpu.address_space<workgroup>>
        %37 = memref.load %reinterpret_cast[%35] : memref<256xf32, #gpu.address_space<workgroup>>
        %38 = arith.addf %36, %37 : f32
        memref.store %38, %reinterpret_cast[%4] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %25 = arith.cmpi ult, %6, %c4 : index
      %26 = arith.addi %11, %c4 : index
      %27 = arith.cmpi ult, %26, %c8192 : index
      %28 = arith.andi %25, %27 : i1
      scf.if %28 {
        %35 = arith.addi %4, %c32 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %36 = memref.load %reinterpret_cast[%4] : memref<256xf32, #gpu.address_space<workgroup>>
        %37 = memref.load %reinterpret_cast[%35] : memref<256xf32, #gpu.address_space<workgroup>>
        %38 = arith.addf %36, %37 : f32
        memref.store %38, %reinterpret_cast[%4] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %29 = arith.cmpi ult, %6, %c2 : index
      %30 = arith.addi %11, %c2 : index
      %31 = arith.cmpi ult, %30, %c8192 : index
      %32 = arith.andi %29, %31 : i1
      scf.if %32 {
        %35 = arith.addi %4, %c16 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %36 = memref.load %reinterpret_cast[%4] : memref<256xf32, #gpu.address_space<workgroup>>
        %37 = memref.load %reinterpret_cast[%35] : memref<256xf32, #gpu.address_space<workgroup>>
        %38 = arith.addf %36, %37 : f32
        memref.store %38, %reinterpret_cast[%4] : memref<256xf32, #gpu.address_space<workgroup>>
      }
      gpu.barrier
      %33 = arith.cmpi eq, %6, %c0 : index
      %34 = arith.andi %33, %16 : i1
      scf.if %34 {
        %35 = arith.addi %4, %c8 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc_3 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
        %36 = memref.load %reinterpret_cast[%4] : memref<256xf32, #gpu.address_space<workgroup>>
        %37 = memref.load %reinterpret_cast[%35] : memref<256xf32, #gpu.address_space<workgroup>>
        %38 = arith.addf %36, %37 : f32
        %39 = memref.atomic_rmw addf %38, %alloc[%13] : (f32, memref<2560xf32, "gpu">) -> f32
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After SCFParallelLoopTiling (disc-parallel-loop-tiling) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    %c0_0 = arith.constant 0 : index
    %c256_1 = arith.constant 256 : index
    %2 = arith.muli %c1, %c256_1 : index
    scf.parallel (%arg1) = (%c0) to (%c2560) step (%2) {
      scf.parallel (%arg2) = (%c0_0) to (%2) step (%c1) {
        %6 = arith.addi %arg2, %arg1 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
        memref.store %cst, %reinterpret_cast[%6] : memref<2560xf32, "gpu">
        scf.yield
      }
      scf.yield
    }
    %c0_2 = arith.constant 0 : index
    %c1_3 = arith.constant 1 : index
    %c1_4 = arith.constant 1 : index
    %3 = arith.muli %c1_4, %c81920 : index
    %4 = arith.muli %3, %c256 : index
    %c0_5 = arith.constant 0 : index
    %c256_6 = arith.constant 256 : index
    %5 = arith.muli %c1_3, %c256_6 : index
    scf.parallel (%arg1) = (%c0_2) to (%4) step (%5) {
      scf.parallel (%arg2) = (%c0_5) to (%5) step (%c1_3) {
        %6 = arith.addi %arg2, %arg1 : index
        %true = arith.constant true
        %7 = arith.muli %arg2, %c1_3 : index
        %8 = arith.addi %7, %arg1 : index
        %9 = arith.cmpi ult, %8, %4 : index
        %10 = arith.andi %true, %9 : i1
        scf.if %10 {
          %11 = arith.remsi %6, %c256 : index
          %12 = arith.divsi %6, %c256 : index
          %13 = arith.divui %11, %c8 : index
          %14 = arith.remui %11, %c8 : index
          %15 = arith.divui %12, %c320 : index
          %16 = arith.remui %12, %c320 : index
          %17 = arith.muli %15, %c32 : index
          %18 = arith.addi %17, %13 : index
          %19 = arith.muli %16, %c8 : index
          %20 = arith.addi %19, %14 : index
          %alloc_7 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
          %21 = arith.cmpi ult, %18, %c8192 : index
          %22 = arith.cmpi ult, %20, %c2560 : index
          %23 = arith.andi %21, %22 : i1
          scf.if %23 {
            %42 = arith.muli %18, %c2560 : index
            %43 = arith.addi %42, %20 : index
            %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
            %44 = memref.load %reinterpret_cast[%43] : memref<20971520xf32, "gpu">
            %reinterpret_cast_8 = memref.reinterpret_cast %1 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
            %45 = memref.load %reinterpret_cast_8[%43] : memref<20971520xf32, "gpu">
            %46 = arith.subf %44, %45 : f32
            %47 = arith.mulf %46, %44 : f32
            %48 = arith.addf %47, %cst : f32
            %reinterpret_cast_9 = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            memref.store %48, %reinterpret_cast_9[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          } else {
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            memref.store %cst, %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %24 = arith.cmpi ult, %13, %c16 : index
          %25 = arith.addi %18, %c16 : index
          %26 = arith.cmpi ult, %25, %c8192 : index
          %27 = arith.andi %24, %26 : i1
          scf.if %27 {
            %42 = arith.addi %11, %c128 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %43 = memref.load %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
            %44 = memref.load %reinterpret_cast[%42] : memref<256xf32, #gpu.address_space<workgroup>>
            %45 = arith.addf %43, %44 : f32
            memref.store %45, %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %28 = arith.cmpi ult, %13, %c8 : index
          %29 = arith.addi %18, %c8 : index
          %30 = arith.cmpi ult, %29, %c8192 : index
          %31 = arith.andi %28, %30 : i1
          scf.if %31 {
            %42 = arith.addi %11, %c64 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %43 = memref.load %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
            %44 = memref.load %reinterpret_cast[%42] : memref<256xf32, #gpu.address_space<workgroup>>
            %45 = arith.addf %43, %44 : f32
            memref.store %45, %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %32 = arith.cmpi ult, %13, %c4 : index
          %33 = arith.addi %18, %c4 : index
          %34 = arith.cmpi ult, %33, %c8192 : index
          %35 = arith.andi %32, %34 : i1
          scf.if %35 {
            %42 = arith.addi %11, %c32 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %43 = memref.load %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
            %44 = memref.load %reinterpret_cast[%42] : memref<256xf32, #gpu.address_space<workgroup>>
            %45 = arith.addf %43, %44 : f32
            memref.store %45, %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %36 = arith.cmpi ult, %13, %c2 : index
          %37 = arith.addi %18, %c2 : index
          %38 = arith.cmpi ult, %37, %c8192 : index
          %39 = arith.andi %36, %38 : i1
          scf.if %39 {
            %42 = arith.addi %11, %c16 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %43 = memref.load %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
            %44 = memref.load %reinterpret_cast[%42] : memref<256xf32, #gpu.address_space<workgroup>>
            %45 = arith.addf %43, %44 : f32
            memref.store %45, %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %40 = arith.cmpi eq, %13, %c0 : index
          %41 = arith.andi %40, %23 : i1
          scf.if %41 {
            %42 = arith.addi %11, %c8 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %43 = memref.load %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
            %44 = memref.load %reinterpret_cast[%42] : memref<256xf32, #gpu.address_space<workgroup>>
            %45 = arith.addf %43, %44 : f32
            %46 = memref.atomic_rmw addf %45, %alloc[%20] : (f32, memref<2560xf32, "gpu">) -> f32
          }
        }
        scf.yield
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After GpuMapParallelLoopsPass (gpu-map-parallel-loops) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    %c0_0 = arith.constant 0 : index
    %c256_1 = arith.constant 256 : index
    %2 = arith.muli %c1, %c256_1 : index
    scf.parallel (%arg1) = (%c0) to (%c2560) step (%2) {
      scf.parallel (%arg2) = (%c0_0) to (%2) step (%c1) {
        %6 = arith.addi %arg2, %arg1 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
        memref.store %cst, %reinterpret_cast[%6] : memref<2560xf32, "gpu">
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      scf.yield
    } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
    %c0_2 = arith.constant 0 : index
    %c1_3 = arith.constant 1 : index
    %c1_4 = arith.constant 1 : index
    %3 = arith.muli %c1_4, %c81920 : index
    %4 = arith.muli %3, %c256 : index
    %c0_5 = arith.constant 0 : index
    %c256_6 = arith.constant 256 : index
    %5 = arith.muli %c1_3, %c256_6 : index
    scf.parallel (%arg1) = (%c0_2) to (%4) step (%5) {
      scf.parallel (%arg2) = (%c0_5) to (%5) step (%c1_3) {
        %6 = arith.addi %arg2, %arg1 : index
        %true = arith.constant true
        %7 = arith.muli %arg2, %c1_3 : index
        %8 = arith.addi %7, %arg1 : index
        %9 = arith.cmpi ult, %8, %4 : index
        %10 = arith.andi %true, %9 : i1
        scf.if %10 {
          %11 = arith.remsi %6, %c256 : index
          %12 = arith.divsi %6, %c256 : index
          %13 = arith.divui %11, %c8 : index
          %14 = arith.remui %11, %c8 : index
          %15 = arith.divui %12, %c320 : index
          %16 = arith.remui %12, %c320 : index
          %17 = arith.muli %15, %c32 : index
          %18 = arith.addi %17, %13 : index
          %19 = arith.muli %16, %c8 : index
          %20 = arith.addi %19, %14 : index
          %alloc_7 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
          %21 = arith.cmpi ult, %18, %c8192 : index
          %22 = arith.cmpi ult, %20, %c2560 : index
          %23 = arith.andi %21, %22 : i1
          scf.if %23 {
            %42 = arith.muli %18, %c2560 : index
            %43 = arith.addi %42, %20 : index
            %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
            %44 = memref.load %reinterpret_cast[%43] : memref<20971520xf32, "gpu">
            %reinterpret_cast_8 = memref.reinterpret_cast %1 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
            %45 = memref.load %reinterpret_cast_8[%43] : memref<20971520xf32, "gpu">
            %46 = arith.subf %44, %45 : f32
            %47 = arith.mulf %46, %44 : f32
            %48 = arith.addf %47, %cst : f32
            %reinterpret_cast_9 = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            memref.store %48, %reinterpret_cast_9[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          } else {
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            memref.store %cst, %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %24 = arith.cmpi ult, %13, %c16 : index
          %25 = arith.addi %18, %c16 : index
          %26 = arith.cmpi ult, %25, %c8192 : index
          %27 = arith.andi %24, %26 : i1
          scf.if %27 {
            %42 = arith.addi %11, %c128 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %43 = memref.load %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
            %44 = memref.load %reinterpret_cast[%42] : memref<256xf32, #gpu.address_space<workgroup>>
            %45 = arith.addf %43, %44 : f32
            memref.store %45, %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %28 = arith.cmpi ult, %13, %c8 : index
          %29 = arith.addi %18, %c8 : index
          %30 = arith.cmpi ult, %29, %c8192 : index
          %31 = arith.andi %28, %30 : i1
          scf.if %31 {
            %42 = arith.addi %11, %c64 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %43 = memref.load %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
            %44 = memref.load %reinterpret_cast[%42] : memref<256xf32, #gpu.address_space<workgroup>>
            %45 = arith.addf %43, %44 : f32
            memref.store %45, %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %32 = arith.cmpi ult, %13, %c4 : index
          %33 = arith.addi %18, %c4 : index
          %34 = arith.cmpi ult, %33, %c8192 : index
          %35 = arith.andi %32, %34 : i1
          scf.if %35 {
            %42 = arith.addi %11, %c32 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %43 = memref.load %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
            %44 = memref.load %reinterpret_cast[%42] : memref<256xf32, #gpu.address_space<workgroup>>
            %45 = arith.addf %43, %44 : f32
            memref.store %45, %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %36 = arith.cmpi ult, %13, %c2 : index
          %37 = arith.addi %18, %c2 : index
          %38 = arith.cmpi ult, %37, %c8192 : index
          %39 = arith.andi %36, %38 : i1
          scf.if %39 {
            %42 = arith.addi %11, %c16 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %43 = memref.load %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
            %44 = memref.load %reinterpret_cast[%42] : memref<256xf32, #gpu.address_space<workgroup>>
            %45 = arith.addf %43, %44 : f32
            memref.store %45, %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %40 = arith.cmpi eq, %13, %c0 : index
          %41 = arith.andi %40, %23 : i1
          scf.if %41 {
            %42 = arith.addi %11, %c8 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %43 = memref.load %reinterpret_cast[%11] : memref<256xf32, #gpu.address_space<workgroup>>
            %44 = memref.load %reinterpret_cast[%42] : memref<256xf32, #gpu.address_space<workgroup>>
            %45 = arith.addf %43, %44 : f32
            %46 = memref.atomic_rmw addf %45, %alloc[%20] : (f32, memref<2560xf32, "gpu">) -> f32
          }
        }
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      scf.yield
    } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ConvertParallelLoopToGpu (convert-parallel-loops-to-gpu) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<2560xf32, "gpu">
  "lmhlo.fusion"() ({
    %c0_0 = arith.constant 0 : index
    %c256_1 = arith.constant 256 : index
    %2 = arith.muli %c1, %c256_1 : index
    %c1_2 = arith.constant 1 : index
    %3 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%c2560)[%c0, %2]
    %4 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%2)[%c0_0, %c1]
    gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %3, %arg8 = %c1_2, %arg9 = %c1_2) threads(%arg4, %arg5, %arg6) in (%arg10 = %4, %arg11 = %c1_2, %arg12 = %c1_2) {
      %10 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%2, %c0]
      %11 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1, %c0_0]
      %12 = arith.addi %11, %10 : index
      %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%12] : memref<2560xf32, "gpu">
      gpu.terminator
    } {SCFToGPU_visited}
    %c0_3 = arith.constant 0 : index
    %c1_4 = arith.constant 1 : index
    %c1_5 = arith.constant 1 : index
    %5 = arith.muli %c1_5, %c81920 : index
    %6 = arith.muli %5, %c256 : index
    %c0_6 = arith.constant 0 : index
    %c256_7 = arith.constant 256 : index
    %7 = arith.muli %c1_4, %c256_7 : index
    %c1_8 = arith.constant 1 : index
    %8 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%6)[%c0_3, %7]
    %9 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%7)[%c0_6, %c1_4]
    gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %8, %arg8 = %c1_8, %arg9 = %c1_8) threads(%arg4, %arg5, %arg6) in (%arg10 = %9, %arg11 = %c1_8, %arg12 = %c1_8) {
      %10 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%7, %c0_3]
      %11 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1_4, %c0_6]
      %12 = arith.addi %11, %10 : index
      %true = arith.constant true
      %13 = arith.muli %11, %c1_4 : index
      %14 = arith.addi %13, %10 : index
      %15 = arith.cmpi ult, %14, %6 : index
      %16 = arith.andi %true, %15 : i1
      scf.if %16 {
        %17 = arith.remsi %12, %c256 : index
        %18 = arith.divsi %12, %c256 : index
        %19 = arith.divui %17, %c8 : index
        %20 = arith.remui %17, %c8 : index
        %21 = arith.divui %18, %c320 : index
        %22 = arith.remui %18, %c320 : index
        %23 = arith.muli %21, %c32 : index
        %24 = arith.addi %23, %19 : index
        %25 = arith.muli %22, %c8 : index
        %26 = arith.addi %25, %20 : index
        %alloc_9 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
        %27 = arith.cmpi ult, %24, %c8192 : index
        %28 = arith.cmpi ult, %26, %c2560 : index
        %29 = arith.andi %27, %28 : i1
        scf.if %29 {
          %48 = arith.muli %24, %c2560 : index
          %49 = arith.addi %48, %26 : index
          %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
          %50 = memref.load %reinterpret_cast[%49] : memref<20971520xf32, "gpu">
          %reinterpret_cast_10 = memref.reinterpret_cast %1 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
          %51 = memref.load %reinterpret_cast_10[%49] : memref<20971520xf32, "gpu">
          %52 = arith.subf %50, %51 : f32
          %53 = arith.mulf %52, %50 : f32
          %54 = arith.addf %53, %cst : f32
          %reinterpret_cast_11 = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          memref.store %54, %reinterpret_cast_11[%17] : memref<256xf32, #gpu.address_space<workgroup>>
        } else {
          %reinterpret_cast = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          memref.store %cst, %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %30 = arith.cmpi ult, %19, %c16 : index
        %31 = arith.addi %24, %c16 : index
        %32 = arith.cmpi ult, %31, %c8192 : index
        %33 = arith.andi %30, %32 : i1
        scf.if %33 {
          %48 = arith.addi %17, %c128 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %49 = memref.load %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          %50 = memref.load %reinterpret_cast[%48] : memref<256xf32, #gpu.address_space<workgroup>>
          %51 = arith.addf %49, %50 : f32
          memref.store %51, %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %34 = arith.cmpi ult, %19, %c8 : index
        %35 = arith.addi %24, %c8 : index
        %36 = arith.cmpi ult, %35, %c8192 : index
        %37 = arith.andi %34, %36 : i1
        scf.if %37 {
          %48 = arith.addi %17, %c64 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %49 = memref.load %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          %50 = memref.load %reinterpret_cast[%48] : memref<256xf32, #gpu.address_space<workgroup>>
          %51 = arith.addf %49, %50 : f32
          memref.store %51, %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %38 = arith.cmpi ult, %19, %c4 : index
        %39 = arith.addi %24, %c4 : index
        %40 = arith.cmpi ult, %39, %c8192 : index
        %41 = arith.andi %38, %40 : i1
        scf.if %41 {
          %48 = arith.addi %17, %c32 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %49 = memref.load %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          %50 = memref.load %reinterpret_cast[%48] : memref<256xf32, #gpu.address_space<workgroup>>
          %51 = arith.addf %49, %50 : f32
          memref.store %51, %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %42 = arith.cmpi ult, %19, %c2 : index
        %43 = arith.addi %24, %c2 : index
        %44 = arith.cmpi ult, %43, %c8192 : index
        %45 = arith.andi %42, %44 : i1
        scf.if %45 {
          %48 = arith.addi %17, %c16 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %49 = memref.load %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          %50 = memref.load %reinterpret_cast[%48] : memref<256xf32, #gpu.address_space<workgroup>>
          %51 = arith.addf %49, %50 : f32
          memref.store %51, %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %46 = arith.cmpi eq, %19, %c0 : index
        %47 = arith.andi %46, %29 : i1
        scf.if %47 {
          %48 = arith.addi %17, %c8 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %49 = memref.load %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          %50 = memref.load %reinterpret_cast[%48] : memref<256xf32, #gpu.address_space<workgroup>>
          %51 = arith.addf %49, %50 : f32
          %52 = memref.atomic_rmw addf %51, %alloc[%26] : (f32, memref<2560xf32, "gpu">) -> f32
        }
      }
      gpu.terminator
    } {SCFToGPU_visited}
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After GpuLaunchSinkIndexComputations (gpu-launch-sink-index-computations) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %cst = arith.constant 0.000000e+00 : f32
    %c81920 = arith.constant 81920 : index
    %c8192 = arith.constant 8192 : index
    %c320 = arith.constant 320 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c8 = arith.constant 8 : index
    %c256 = arith.constant 256 : index
    %c2560 = arith.constant 2560 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %alloc = memref.alloc() : memref<2560xf32, "gpu">
    "lmhlo.fusion"() ({
      %c0_0 = arith.constant 0 : index
      %c256_1 = arith.constant 256 : index
      %2 = arith.muli %c1, %c256_1 : index
      %c1_2 = arith.constant 1 : index
      %3 = affine.apply #map(%c2560)[%c0, %2]
      %4 = affine.apply #map(%2)[%c0_0, %c1]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %3, %arg8 = %c1_2, %arg9 = %c1_2) threads(%arg4, %arg5, %arg6) in (%arg10 = %4, %arg11 = %c1_2, %arg12 = %c1_2) {
        %c0_9 = arith.constant 0 : index
        %c1_10 = arith.constant 1 : index
        %c0_11 = arith.constant 0 : index
        %cst_12 = arith.constant 0.000000e+00 : f32
        %10 = affine.apply #map1(%arg1)[%2, %c0_9]
        %11 = affine.apply #map1(%arg4)[%c1_10, %c0_11]
        %12 = arith.addi %11, %10 : index
        %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
        memref.store %cst_12, %reinterpret_cast[%12] : memref<2560xf32, "gpu">
        gpu.terminator
      } {SCFToGPU_visited}
      %c0_3 = arith.constant 0 : index
      %c1_4 = arith.constant 1 : index
      %c1_5 = arith.constant 1 : index
      %5 = arith.muli %c1_5, %c81920 : index
      %6 = arith.muli %5, %c256 : index
      %c0_6 = arith.constant 0 : index
      %c256_7 = arith.constant 256 : index
      %7 = arith.muli %c1_4, %c256_7 : index
      %c1_8 = arith.constant 1 : index
      %8 = affine.apply #map(%6)[%c0_3, %7]
      %9 = affine.apply #map(%7)[%c0_6, %c1_4]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %8, %arg8 = %c1_8, %arg9 = %c1_8) threads(%arg4, %arg5, %arg6) in (%arg10 = %9, %arg11 = %c1_8, %arg12 = %c1_8) {
        %c0_9 = arith.constant 0 : index
        %c1_10 = arith.constant 1 : index
        %c0_11 = arith.constant 0 : index
        %c256_12 = arith.constant 256 : index
        %c8_13 = arith.constant 8 : index
        %c320_14 = arith.constant 320 : index
        %c32_15 = arith.constant 32 : index
        %c8192_16 = arith.constant 8192 : index
        %c2560_17 = arith.constant 2560 : index
        %cst_18 = arith.constant 0.000000e+00 : f32
        %c16_19 = arith.constant 16 : index
        %c128_20 = arith.constant 128 : index
        %c64_21 = arith.constant 64 : index
        %c4_22 = arith.constant 4 : index
        %c2_23 = arith.constant 2 : index
        %c0_24 = arith.constant 0 : index
        %10 = affine.apply #map1(%arg1)[%7, %c0_9]
        %11 = affine.apply #map1(%arg4)[%c1_10, %c0_11]
        %12 = arith.addi %11, %10 : index
        %true = arith.constant true
        %13 = arith.muli %11, %c1_10 : index
        %14 = arith.addi %13, %10 : index
        %15 = arith.cmpi ult, %14, %6 : index
        %16 = arith.andi %true, %15 : i1
        scf.if %16 {
          %17 = arith.remsi %12, %c256_12 : index
          %18 = arith.divsi %12, %c256_12 : index
          %19 = arith.divui %17, %c8_13 : index
          %20 = arith.remui %17, %c8_13 : index
          %21 = arith.divui %18, %c320_14 : index
          %22 = arith.remui %18, %c320_14 : index
          %23 = arith.muli %21, %c32_15 : index
          %24 = arith.addi %23, %19 : index
          %25 = arith.muli %22, %c8_13 : index
          %26 = arith.addi %25, %20 : index
          %alloc_25 = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
          %27 = arith.cmpi ult, %24, %c8192_16 : index
          %28 = arith.cmpi ult, %26, %c2560_17 : index
          %29 = arith.andi %27, %28 : i1
          scf.if %29 {
            %48 = arith.muli %24, %c2560_17 : index
            %49 = arith.addi %48, %26 : index
            %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
            %50 = memref.load %reinterpret_cast[%49] : memref<20971520xf32, "gpu">
            %reinterpret_cast_26 = memref.reinterpret_cast %1 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
            %51 = memref.load %reinterpret_cast_26[%49] : memref<20971520xf32, "gpu">
            %52 = arith.subf %50, %51 : f32
            %53 = arith.mulf %52, %50 : f32
            %54 = arith.addf %53, %cst_18 : f32
            %reinterpret_cast_27 = memref.reinterpret_cast %alloc_25 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            memref.store %54, %reinterpret_cast_27[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          } else {
            %reinterpret_cast = memref.reinterpret_cast %alloc_25 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            memref.store %cst_18, %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %30 = arith.cmpi ult, %19, %c16_19 : index
          %31 = arith.addi %24, %c16_19 : index
          %32 = arith.cmpi ult, %31, %c8192_16 : index
          %33 = arith.andi %30, %32 : i1
          scf.if %33 {
            %48 = arith.addi %17, %c128_20 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_25 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %49 = memref.load %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
            %50 = memref.load %reinterpret_cast[%48] : memref<256xf32, #gpu.address_space<workgroup>>
            %51 = arith.addf %49, %50 : f32
            memref.store %51, %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %34 = arith.cmpi ult, %19, %c8_13 : index
          %35 = arith.addi %24, %c8_13 : index
          %36 = arith.cmpi ult, %35, %c8192_16 : index
          %37 = arith.andi %34, %36 : i1
          scf.if %37 {
            %48 = arith.addi %17, %c64_21 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_25 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %49 = memref.load %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
            %50 = memref.load %reinterpret_cast[%48] : memref<256xf32, #gpu.address_space<workgroup>>
            %51 = arith.addf %49, %50 : f32
            memref.store %51, %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %38 = arith.cmpi ult, %19, %c4_22 : index
          %39 = arith.addi %24, %c4_22 : index
          %40 = arith.cmpi ult, %39, %c8192_16 : index
          %41 = arith.andi %38, %40 : i1
          scf.if %41 {
            %48 = arith.addi %17, %c32_15 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_25 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %49 = memref.load %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
            %50 = memref.load %reinterpret_cast[%48] : memref<256xf32, #gpu.address_space<workgroup>>
            %51 = arith.addf %49, %50 : f32
            memref.store %51, %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %42 = arith.cmpi ult, %19, %c2_23 : index
          %43 = arith.addi %24, %c2_23 : index
          %44 = arith.cmpi ult, %43, %c8192_16 : index
          %45 = arith.andi %42, %44 : i1
          scf.if %45 {
            %48 = arith.addi %17, %c16_19 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_25 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %49 = memref.load %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
            %50 = memref.load %reinterpret_cast[%48] : memref<256xf32, #gpu.address_space<workgroup>>
            %51 = arith.addf %49, %50 : f32
            memref.store %51, %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
          }
          gpu.barrier
          %46 = arith.cmpi eq, %19, %c0_24 : index
          %47 = arith.andi %46, %29 : i1
          scf.if %47 {
            %48 = arith.addi %17, %c8_13 : index
            %reinterpret_cast = memref.reinterpret_cast %alloc_25 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
            %49 = memref.load %reinterpret_cast[%17] : memref<256xf32, #gpu.address_space<workgroup>>
            %50 = memref.load %reinterpret_cast[%48] : memref<256xf32, #gpu.address_space<workgroup>>
            %51 = arith.addf %49, %50 : f32
            %52 = memref.atomic_rmw addf %51, %alloc[%26] : (f32, memref<2560xf32, "gpu">) -> f32
          }
        }
        gpu.terminator
      } {SCFToGPU_visited}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
    "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
    return
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After GpuKernelOutlining (gpu-kernel-outlining) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %cst = arith.constant 0.000000e+00 : f32
    %c81920 = arith.constant 81920 : index
    %c8192 = arith.constant 8192 : index
    %c320 = arith.constant 320 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c8 = arith.constant 8 : index
    %c256 = arith.constant 256 : index
    %c2560 = arith.constant 2560 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %alloc = memref.alloc() : memref<2560xf32, "gpu">
    "lmhlo.fusion"() ({
      %c0_0 = arith.constant 0 : index
      %c256_1 = arith.constant 256 : index
      %2 = arith.muli %c1, %c256_1 : index
      %c1_2 = arith.constant 1 : index
      %3 = affine.apply #map(%c2560)[%c0, %2]
      %4 = affine.apply #map(%2)[%c0_0, %c1]
      gpu.launch_func  @main_kernel::@main_kernel blocks in (%3, %c1_2, %c1_2) threads in (%4, %c1_2, %c1_2) args(%2 : index, %alloc : memref<2560xf32, "gpu">)
      %c0_3 = arith.constant 0 : index
      %c1_4 = arith.constant 1 : index
      %c1_5 = arith.constant 1 : index
      %5 = arith.muli %c1_5, %c81920 : index
      %6 = arith.muli %5, %c256 : index
      %c0_6 = arith.constant 0 : index
      %c256_7 = arith.constant 256 : index
      %7 = arith.muli %c1_4, %c256_7 : index
      %c1_8 = arith.constant 1 : index
      %8 = affine.apply #map(%6)[%c0_3, %7]
      %9 = affine.apply #map(%7)[%c0_6, %c1_4]
      gpu.launch_func  @main_kernel_0::@main_kernel blocks in (%8, %c1_8, %c1_8) threads in (%9, %c1_8, %c1_8) args(%7 : index, %6 : index, %0 : memref<8192x2560xf32, "gpu">, %1 : memref<8192x2560xf32, "gpu">, %alloc : memref<2560xf32, "gpu">)
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
    "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel {
    gpu.func @main_kernel(%arg0: index, %arg1: memref<2560xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%14] : memref<2560xf32, "gpu">
      gpu.return
    }
  }
  gpu.module @main_kernel_0 {
    gpu.func @main_kernel(%arg0: index, %arg1: index, %arg2: memref<8192x2560xf32, "gpu">, %arg3: memref<8192x2560xf32, "gpu">, %arg4: memref<2560xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %c8 = arith.constant 8 : index
      %c320 = arith.constant 320 : index
      %c32 = arith.constant 32 : index
      %c8192 = arith.constant 8192 : index
      %c2560 = arith.constant 2560 : index
      %cst = arith.constant 0.000000e+00 : f32
      %c16 = arith.constant 16 : index
      %c128 = arith.constant 128 : index
      %c64 = arith.constant 64 : index
      %c4 = arith.constant 4 : index
      %c2 = arith.constant 2 : index
      %c0_1 = arith.constant 0 : index
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remsi %14, %c256 : index
        %20 = arith.divsi %14, %c256 : index
        %21 = arith.divui %19, %c8 : index
        %22 = arith.remui %19, %c8 : index
        %23 = arith.divui %20, %c320 : index
        %24 = arith.remui %20, %c320 : index
        %25 = arith.muli %23, %c32 : index
        %26 = arith.addi %25, %21 : index
        %27 = arith.muli %24, %c8 : index
        %28 = arith.addi %27, %22 : index
        %alloc = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
        %29 = arith.cmpi ult, %26, %c8192 : index
        %30 = arith.cmpi ult, %28, %c2560 : index
        %31 = arith.andi %29, %30 : i1
        scf.if %31 {
          %50 = arith.muli %26, %c2560 : index
          %51 = arith.addi %50, %28 : index
          %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
          %52 = memref.load %reinterpret_cast[%51] : memref<20971520xf32, "gpu">
          %reinterpret_cast_2 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
          %53 = memref.load %reinterpret_cast_2[%51] : memref<20971520xf32, "gpu">
          %54 = arith.subf %52, %53 : f32
          %55 = arith.mulf %54, %52 : f32
          %56 = arith.addf %55, %cst : f32
          %reinterpret_cast_3 = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          memref.store %56, %reinterpret_cast_3[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        } else {
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          memref.store %cst, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %32 = arith.cmpi ult, %21, %c16 : index
        %33 = arith.addi %26, %c16 : index
        %34 = arith.cmpi ult, %33, %c8192 : index
        %35 = arith.andi %32, %34 : i1
        scf.if %35 {
          %50 = arith.addi %19, %c128 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %36 = arith.cmpi ult, %21, %c8 : index
        %37 = arith.addi %26, %c8 : index
        %38 = arith.cmpi ult, %37, %c8192 : index
        %39 = arith.andi %36, %38 : i1
        scf.if %39 {
          %50 = arith.addi %19, %c64 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %40 = arith.cmpi ult, %21, %c4 : index
        %41 = arith.addi %26, %c4 : index
        %42 = arith.cmpi ult, %41, %c8192 : index
        %43 = arith.andi %40, %42 : i1
        scf.if %43 {
          %50 = arith.addi %19, %c32 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %44 = arith.cmpi ult, %21, %c2 : index
        %45 = arith.addi %26, %c2 : index
        %46 = arith.cmpi ult, %45, %c8192 : index
        %47 = arith.andi %44, %46 : i1
        scf.if %47 {
          %50 = arith.addi %19, %c16 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %48 = arith.cmpi eq, %21, %c0_1 : index
        %49 = arith.andi %48, %31 : i1
        scf.if %49 {
          %50 = arith.addi %19, %c8 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          %54 = memref.atomic_rmw addf %53, %arg4[%28] : (f32, memref<2560xf32, "gpu">) -> f32
        }
      }
      gpu.return
    }
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After AssignKernelNamePass (disc-assign-kernel-name) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %cst = arith.constant 0.000000e+00 : f32
    %c81920 = arith.constant 81920 : index
    %c8192 = arith.constant 8192 : index
    %c320 = arith.constant 320 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c8 = arith.constant 8 : index
    %c256 = arith.constant 256 : index
    %c2560 = arith.constant 2560 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %alloc = memref.alloc() : memref<2560xf32, "gpu">
    "lmhlo.fusion"() ({
      %c0_0 = arith.constant 0 : index
      %c256_1 = arith.constant 256 : index
      %2 = arith.muli %c1, %c256_1 : index
      %c1_2 = arith.constant 1 : index
      %3 = affine.apply #map(%c2560)[%c0, %2]
      %4 = affine.apply #map(%2)[%c0_0, %c1]
      gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%3, %c1_2, %c1_2) threads in (%4, %c1_2, %c1_2) args(%2 : index, %alloc : memref<2560xf32, "gpu">)
      %c0_3 = arith.constant 0 : index
      %c1_4 = arith.constant 1 : index
      %c1_5 = arith.constant 1 : index
      %5 = arith.muli %c1_5, %c81920 : index
      %6 = arith.muli %5, %c256 : index
      %c0_6 = arith.constant 0 : index
      %c256_7 = arith.constant 256 : index
      %7 = arith.muli %c1_4, %c256_7 : index
      %c1_8 = arith.constant 1 : index
      %8 = affine.apply #map(%6)[%c0_3, %7]
      %9 = affine.apply #map(%7)[%c0_6, %c1_4]
      gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%8, %c1_8, %c1_8) threads in (%9, %c1_8, %c1_8) args(%7 : index, %6 : index, %0 : memref<8192x2560xf32, "gpu">, %1 : memref<8192x2560xf32, "gpu">, %alloc : memref<2560xf32, "gpu">)
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
    "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel {
    gpu.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: index, %arg1: memref<2560xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%14] : memref<2560xf32, "gpu">
      gpu.return
    }
  }
  gpu.module @main_kernel_0 {
    gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: index, %arg1: index, %arg2: memref<8192x2560xf32, "gpu">, %arg3: memref<8192x2560xf32, "gpu">, %arg4: memref<2560xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %c8 = arith.constant 8 : index
      %c320 = arith.constant 320 : index
      %c32 = arith.constant 32 : index
      %c8192 = arith.constant 8192 : index
      %c2560 = arith.constant 2560 : index
      %cst = arith.constant 0.000000e+00 : f32
      %c16 = arith.constant 16 : index
      %c128 = arith.constant 128 : index
      %c64 = arith.constant 64 : index
      %c4 = arith.constant 4 : index
      %c2 = arith.constant 2 : index
      %c0_1 = arith.constant 0 : index
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remsi %14, %c256 : index
        %20 = arith.divsi %14, %c256 : index
        %21 = arith.divui %19, %c8 : index
        %22 = arith.remui %19, %c8 : index
        %23 = arith.divui %20, %c320 : index
        %24 = arith.remui %20, %c320 : index
        %25 = arith.muli %23, %c32 : index
        %26 = arith.addi %25, %21 : index
        %27 = arith.muli %24, %c8 : index
        %28 = arith.addi %27, %22 : index
        %alloc = memref.alloc() : memref<256xf32, #gpu.address_space<workgroup>>
        %29 = arith.cmpi ult, %26, %c8192 : index
        %30 = arith.cmpi ult, %28, %c2560 : index
        %31 = arith.andi %29, %30 : i1
        scf.if %31 {
          %50 = arith.muli %26, %c2560 : index
          %51 = arith.addi %50, %28 : index
          %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
          %52 = memref.load %reinterpret_cast[%51] : memref<20971520xf32, "gpu">
          %reinterpret_cast_2 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
          %53 = memref.load %reinterpret_cast_2[%51] : memref<20971520xf32, "gpu">
          %54 = arith.subf %52, %53 : f32
          %55 = arith.mulf %54, %52 : f32
          %56 = arith.addf %55, %cst : f32
          %reinterpret_cast_3 = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          memref.store %56, %reinterpret_cast_3[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        } else {
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          memref.store %cst, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %32 = arith.cmpi ult, %21, %c16 : index
        %33 = arith.addi %26, %c16 : index
        %34 = arith.cmpi ult, %33, %c8192 : index
        %35 = arith.andi %32, %34 : i1
        scf.if %35 {
          %50 = arith.addi %19, %c128 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %36 = arith.cmpi ult, %21, %c8 : index
        %37 = arith.addi %26, %c8 : index
        %38 = arith.cmpi ult, %37, %c8192 : index
        %39 = arith.andi %36, %38 : i1
        scf.if %39 {
          %50 = arith.addi %19, %c64 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %40 = arith.cmpi ult, %21, %c4 : index
        %41 = arith.addi %26, %c4 : index
        %42 = arith.cmpi ult, %41, %c8192 : index
        %43 = arith.andi %40, %42 : i1
        scf.if %43 {
          %50 = arith.addi %19, %c32 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %44 = arith.cmpi ult, %21, %c2 : index
        %45 = arith.addi %26, %c2 : index
        %46 = arith.cmpi ult, %45, %c8192 : index
        %47 = arith.andi %44, %46 : i1
        scf.if %47 {
          %50 = arith.addi %19, %c16 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %48 = arith.cmpi eq, %21, %c0_1 : index
        %49 = arith.andi %48, %31 : i1
        scf.if %49 {
          %50 = arith.addi %19, %c8 : index
          %reinterpret_cast = memref.reinterpret_cast %alloc to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          %54 = memref.atomic_rmw addf %53, %arg4[%28] : (f32, memref<2560xf32, "gpu">) -> f32
        }
      }
      gpu.return
    }
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After LhloFusionInlinerPass (lhlo-fusion-inliner) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %cst = arith.constant 0.000000e+00 : f32
  %c81920 = arith.constant 81920 : index
  %c8192 = arith.constant 8192 : index
  %c320 = arith.constant 320 : index
  %c128 = arith.constant 128 : index
  %c64 = arith.constant 64 : index
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c16 = arith.constant 16 : index
  %c32 = arith.constant 32 : index
  %c8 = arith.constant 8 : index
  %c256 = arith.constant 256 : index
  %c2560 = arith.constant 2560 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<2560xf32, "gpu">
  %c0_0 = arith.constant 0 : index
  %c256_1 = arith.constant 256 : index
  %2 = arith.muli %c1, %c256_1 : index
  %c1_2 = arith.constant 1 : index
  %3 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%c2560)[%c0, %2]
  %4 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%2)[%c0_0, %c1]
  gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%3, %c1_2, %c1_2) threads in (%4, %c1_2, %c1_2) args(%2 : index, %alloc : memref<2560xf32, "gpu">)
  %c0_3 = arith.constant 0 : index
  %c1_4 = arith.constant 1 : index
  %c1_5 = arith.constant 1 : index
  %5 = arith.muli %c1_5, %c81920 : index
  %6 = arith.muli %5, %c256 : index
  %c0_6 = arith.constant 0 : index
  %c256_7 = arith.constant 256 : index
  %7 = arith.muli %c1_4, %c256_7 : index
  %c1_8 = arith.constant 1 : index
  %8 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%6)[%c0_3, %7]
  %9 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%7)[%c0_6, %c1_4]
  gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%8, %c1_8, %c1_8) threads in (%9, %c1_8, %c1_8) args(%7 : index, %6 : index, %0 : memref<8192x2560xf32, "gpu">, %1 : memref<8192x2560xf32, "gpu">, %alloc : memref<2560xf32, "gpu">)
  "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ReviseGpuKernelOutliningPass (disc-revise-gpu-kernel-outlining) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %cst = arith.constant 0.000000e+00 : f32
    %c81920 = arith.constant 81920 : index
    %c8192 = arith.constant 8192 : index
    %c320 = arith.constant 320 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c16 = arith.constant 16 : index
    %c32 = arith.constant 32 : index
    %c8 = arith.constant 8 : index
    %c256 = arith.constant 256 : index
    %c2560 = arith.constant 2560 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %alloc = memref.alloc() : memref<2560xf32, "gpu">
    %c0_0 = arith.constant 0 : index
    %c256_1 = arith.constant 256 : index
    %2 = arith.muli %c1, %c256_1 : index
    %c1_2 = arith.constant 1 : index
    %3 = affine.apply #map(%c2560)[%c0, %2]
    %4 = affine.apply #map(%2)[%c0_0, %c1]
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%3, %c1_2, %c1_2) threads in (%4, %c1_2, %c1_2) args(%2 : index, %alloc : memref<2560xf32, "gpu">)
    %c0_3 = arith.constant 0 : index
    %c1_4 = arith.constant 1 : index
    %c1_5 = arith.constant 1 : index
    %5 = arith.muli %c1_5, %c81920 : index
    %6 = arith.muli %5, %c256 : index
    %c0_6 = arith.constant 0 : index
    %c256_7 = arith.constant 256 : index
    %7 = arith.muli %c1_4, %c256_7 : index
    %c1_8 = arith.constant 1 : index
    %8 = affine.apply #map(%6)[%c0_3, %7]
    %9 = affine.apply #map(%7)[%c0_6, %c1_4]
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%8, %c1_8, %c1_8) threads in (%9, %c1_8, %c1_8) args(%7 : index, %6 : index, %0 : memref<8192x2560xf32, "gpu">, %1 : memref<8192x2560xf32, "gpu">, %alloc : memref<2560xf32, "gpu">)
    "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel {
    gpu.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: index, %arg1: memref<2560xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %cst = arith.constant 0.000000e+00 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%14] : memref<2560xf32, "gpu">
      gpu.return
    }
  }
  gpu.module @main_kernel_0 {
    gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: index, %arg1: index, %arg2: memref<8192x2560xf32, "gpu">, %arg3: memref<8192x2560xf32, "gpu">, %arg4: memref<2560xf32, "gpu">) workgroup(%arg5 : memref<256xf32, #gpu.address_space<workgroup>>) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %c8 = arith.constant 8 : index
      %c320 = arith.constant 320 : index
      %c32 = arith.constant 32 : index
      %c8192 = arith.constant 8192 : index
      %c2560 = arith.constant 2560 : index
      %cst = arith.constant 0.000000e+00 : f32
      %c16 = arith.constant 16 : index
      %c128 = arith.constant 128 : index
      %c64 = arith.constant 64 : index
      %c4 = arith.constant 4 : index
      %c2 = arith.constant 2 : index
      %c0_1 = arith.constant 0 : index
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remsi %14, %c256 : index
        %20 = arith.divsi %14, %c256 : index
        %21 = arith.divui %19, %c8 : index
        %22 = arith.remui %19, %c8 : index
        %23 = arith.divui %20, %c320 : index
        %24 = arith.remui %20, %c320 : index
        %25 = arith.muli %23, %c32 : index
        %26 = arith.addi %25, %21 : index
        %27 = arith.muli %24, %c8 : index
        %28 = arith.addi %27, %22 : index
        %29 = arith.cmpi ult, %26, %c8192 : index
        %30 = arith.cmpi ult, %28, %c2560 : index
        %31 = arith.andi %29, %30 : i1
        scf.if %31 {
          %50 = arith.muli %26, %c2560 : index
          %51 = arith.addi %50, %28 : index
          %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
          %52 = memref.load %reinterpret_cast[%51] : memref<20971520xf32, "gpu">
          %reinterpret_cast_2 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
          %53 = memref.load %reinterpret_cast_2[%51] : memref<20971520xf32, "gpu">
          %54 = arith.subf %52, %53 : f32
          %55 = arith.mulf %54, %52 : f32
          %56 = arith.addf %55, %cst : f32
          %reinterpret_cast_3 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          memref.store %56, %reinterpret_cast_3[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        } else {
          %reinterpret_cast = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          memref.store %cst, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %32 = arith.cmpi ult, %21, %c16 : index
        %33 = arith.addi %26, %c16 : index
        %34 = arith.cmpi ult, %33, %c8192 : index
        %35 = arith.andi %32, %34 : i1
        scf.if %35 {
          %50 = arith.addi %19, %c128 : index
          %reinterpret_cast = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %36 = arith.cmpi ult, %21, %c8 : index
        %37 = arith.addi %26, %c8 : index
        %38 = arith.cmpi ult, %37, %c8192 : index
        %39 = arith.andi %36, %38 : i1
        scf.if %39 {
          %50 = arith.addi %19, %c64 : index
          %reinterpret_cast = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %40 = arith.cmpi ult, %21, %c4 : index
        %41 = arith.addi %26, %c4 : index
        %42 = arith.cmpi ult, %41, %c8192 : index
        %43 = arith.andi %40, %42 : i1
        scf.if %43 {
          %50 = arith.addi %19, %c32 : index
          %reinterpret_cast = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %44 = arith.cmpi ult, %21, %c2 : index
        %45 = arith.addi %26, %c2 : index
        %46 = arith.cmpi ult, %45, %c8192 : index
        %47 = arith.andi %44, %46 : i1
        scf.if %47 {
          %50 = arith.addi %19, %c16 : index
          %reinterpret_cast = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          memref.store %53, %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
        }
        gpu.barrier
        %48 = arith.cmpi eq, %21, %c0_1 : index
        %49 = arith.andi %48, %31 : i1
        scf.if %49 {
          %50 = arith.addi %19, %c8 : index
          %reinterpret_cast = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
          %51 = memref.load %reinterpret_cast[%19] : memref<256xf32, #gpu.address_space<workgroup>>
          %52 = memref.load %reinterpret_cast[%50] : memref<256xf32, #gpu.address_space<workgroup>>
          %53 = arith.addf %51, %52 : f32
          %54 = memref.atomic_rmw addf %53, %arg4[%28] : (f32, memref<2560xf32, "gpu">) -> f32
        }
      }
      gpu.return
    }
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: index, %arg1: memref<2560xf32, "gpu">) kernel {
    %0 = gpu.block_id  x
    %1 = gpu.block_id  y
    %2 = gpu.block_id  z
    %3 = gpu.thread_id  x
    %4 = gpu.thread_id  y
    %5 = gpu.thread_id  z
    %6 = gpu.grid_dim  x
    %7 = gpu.grid_dim  y
    %8 = gpu.grid_dim  z
    %9 = gpu.block_dim  x
    %10 = gpu.block_dim  y
    %11 = gpu.block_dim  z
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c0_0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %12 = arith.muli %0, %arg0 : index
    %13 = arith.addi %12, %c0 : index
    %14 = arith.muli %3, %c1 : index
    %15 = arith.addi %14, %c0_0 : index
    %16 = arith.addi %15, %13 : index
    %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%16] : memref<2560xf32, "gpu">
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: index, %arg1: memref<2560xf32, "gpu">) kernel {
    %0 = gpu.block_id  x
    %1 = gpu.block_id  y
    %2 = gpu.block_id  z
    %3 = gpu.thread_id  x
    %4 = gpu.thread_id  y
    %5 = gpu.thread_id  z
    %6 = gpu.grid_dim  x
    %7 = gpu.grid_dim  y
    %8 = gpu.grid_dim  z
    %9 = gpu.block_dim  x
    %10 = gpu.block_dim  y
    %11 = gpu.block_dim  z
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c0_0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %12 = arith.muli %0, %arg0 : index
    %13 = arith.addi %12, %c0 : index
    %14 = arith.muli %3, %c1 : index
    %15 = arith.addi %14, %c0_0 : index
    %16 = arith.addi %15, %13 : index
    %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [2560], strides: [1] : memref<2560xf32, "gpu"> to memref<2560xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%16] : memref<2560xf32, "gpu">
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel {
  llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: !llvm.ptr<f32>, %arg2: !llvm.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %1 = llvm.insertvalue %arg1, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %2 = llvm.insertvalue %arg2, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %3 = llvm.insertvalue %arg3, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %4 = llvm.insertvalue %arg4, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %5 = llvm.insertvalue %arg5, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %6 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %7 = nvvm.read.ptx.sreg.ctaid.x : i32
    %8 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %9 = llvm.mul %7, %arg0  : i32
    %10 = llvm.add %8, %9  : i32
    %11 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %12 = llvm.extractvalue %5[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %13 = llvm.extractvalue %5[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %14 = llvm.insertvalue %12, %11[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %15 = llvm.insertvalue %13, %14[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %16 = llvm.mlir.constant(0 : index) : i32
    %17 = llvm.insertvalue %16, %15[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %18 = llvm.mlir.constant(2560 : index) : i32
    %19 = llvm.insertvalue %18, %17[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %20 = llvm.mlir.constant(1 : index) : i32
    %21 = llvm.insertvalue %20, %19[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %22 = llvm.extractvalue %21[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %23 = llvm.getelementptr %22[%10] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %6, %23 : !llvm.ptr<f32>
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\C8\01\00\00\00\00\00\00\01\00\01\01H\00\00\00\80\01\00\00\00\00\00\00|\01\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\03\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64/\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\0Ee__4_1_0___8w32h(\0A.param .u326\00\16\11_4\006_0,>\00/64>\00\1D\1F1>\00*/2,\BA\00)\1F3>\00*\1F4>\00*\F4\075\0A)\0A{\0A.reg .b32 %r<6>;\11\00\E264 %rd<5>;\0A\0Aldg\00\01f\00o%r1, [l\00\1C70];F\00\02\\\00\0FG\00 \F4\032];\0Acvta.to.globalM\00!2,S\00S;\0Amov\A7\00\00\13\00xctaid.x\17\00S3, %t\15\00qad.lo.s\18\00#4,4\00\00\E0\00\D3%r3;\0Amul.wide!\002d3,'\00\824;\0Aadd.sz\00&4,\80\00\183i\00\855, 0;\0Ast\AA\00@32 [1\00\10],\00\C05;\0Aret;\0A\0A}\0A\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\C8\03\00\00\00\00\00\00\C5\03\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00F\05F\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04 \00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04.\00r\00\04\1C\04\00\80\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\D3\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\8F\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00j\02\01\01\01\22H\00\01\00\00l\01/\05\00\01\00\FF\C8A\02z\01\00w\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\E4\03\B1\00\0E\00\00\E2\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05v\04\000\00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00p\D0\0F\00\86s\00\02`\001\00\E9\10`\003My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0a\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00@\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\A4\03\0D\88\05\03\15\00*\90\00\C8\03\04\ED\03\22\18\00\01\00\1F\FET\00\00\03\8E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\94\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B8)\00*\E0\00\01\00\1B\08\08\00!\0B\01\F4\04\0D\01\00\13\98\F5\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A8@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00D\05\00\00\08\80\06\80\00\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\F8\03\00\00\00\00\00\00\02\00\01\01@\00\00\00\B8\03\00\00\00\00\00\00\B4\03\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00K\05K\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04\1C\00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\D2\F0\11\00\03\1B\FF\00\04\1C\04\00p\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\CB\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\87\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00b\02\01\F9\00\22H\00\01\00\00d\01/\05\00\01\00\FF\D0A\02z\01\00w\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05f\04\00 \00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00\80\D0\0F\00\86s\00\02\FF0\00\A3\E9\10\00\00\E2\0F\00My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0Q\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\AC\03\0D\88\05\03\15\00*\90\00\D0\03\04\F5\03\22\18\00\01\00\1F\FET\00\00\03\9E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\8C\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B0)\00*\E0\00\01\00\1B\08\08\00!\0B\01\FC\04\0D\01\00\13\90\FD\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A0@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00Q\05\00\00\08\80\0E\00\A0\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
  llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: !llvm.ptr<f32>, %arg2: !llvm.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %1 = llvm.insertvalue %arg1, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %2 = llvm.insertvalue %arg2, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %3 = llvm.insertvalue %arg3, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %4 = llvm.insertvalue %arg4, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %5 = llvm.insertvalue %arg5, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %6 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %7 = nvvm.read.ptx.sreg.ctaid.x : i32
    %8 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %9 = llvm.mul %7, %arg0  : i32
    %10 = llvm.add %8, %9  : i32
    %11 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %12 = llvm.extractvalue %5[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %13 = llvm.extractvalue %5[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %14 = llvm.insertvalue %12, %11[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %15 = llvm.insertvalue %13, %14[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %16 = llvm.mlir.constant(0 : index) : i32
    %17 = llvm.insertvalue %16, %15[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %18 = llvm.mlir.constant(2560 : index) : i32
    %19 = llvm.insertvalue %18, %17[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %20 = llvm.mlir.constant(1 : index) : i32
    %21 = llvm.insertvalue %20, %19[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %22 = llvm.extractvalue %21[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %23 = llvm.getelementptr %22[%10] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %6, %23 : !llvm.ptr<f32>
    llvm.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: index, %arg1: index, %arg2: memref<8192x2560xf32, "gpu">, %arg3: memref<8192x2560xf32, "gpu">, %arg4: memref<2560xf32, "gpu">) workgroup(%arg5 : memref<256xf32, #gpu.address_space<workgroup>>) kernel {
    %0 = gpu.block_id  x
    %1 = gpu.block_id  y
    %2 = gpu.block_id  z
    %3 = gpu.thread_id  x
    %4 = gpu.thread_id  y
    %5 = gpu.thread_id  z
    %6 = gpu.grid_dim  x
    %7 = gpu.grid_dim  y
    %8 = gpu.grid_dim  z
    %9 = gpu.block_dim  x
    %10 = gpu.block_dim  y
    %11 = gpu.block_dim  z
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c0_0 = arith.constant 0 : index
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c320 = arith.constant 320 : index
    %c32 = arith.constant 32 : index
    %c8192 = arith.constant 8192 : index
    %c2560 = arith.constant 2560 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %c0_1 = arith.constant 0 : index
    %12 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %13 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%3)[%c1, %c0_0]
    %14 = arith.addi %13, %12 : index
    %true = arith.constant true
    %15 = arith.muli %13, %c1 : index
    %16 = arith.addi %15, %12 : index
    %17 = arith.cmpi ult, %16, %arg1 : index
    %18 = arith.andi %true, %17 : i1
    cf.cond_br %18, ^bb2, ^bb16
  ^bb2:  // pred: ^bb1
    %19 = arith.remsi %14, %c256 : index
    %20 = arith.divsi %14, %c256 : index
    %21 = arith.divui %19, %c8 : index
    %22 = arith.remui %19, %c8 : index
    %23 = arith.divui %20, %c320 : index
    %24 = arith.remui %20, %c320 : index
    %25 = arith.muli %23, %c32 : index
    %26 = arith.addi %25, %21 : index
    %27 = arith.muli %24, %c8 : index
    %28 = arith.addi %27, %22 : index
    %29 = arith.cmpi ult, %26, %c8192 : index
    %30 = arith.cmpi ult, %28, %c2560 : index
    %31 = arith.andi %29, %30 : i1
    cf.cond_br %31, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %32 = arith.muli %26, %c2560 : index
    %33 = arith.addi %32, %28 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
    %34 = memref.load %reinterpret_cast[%33] : memref<20971520xf32, "gpu">
    %reinterpret_cast_2 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
    %35 = memref.load %reinterpret_cast_2[%33] : memref<20971520xf32, "gpu">
    %36 = arith.subf %34, %35 : f32
    %37 = arith.mulf %36, %34 : f32
    %38 = arith.addf %37, %cst : f32
    %reinterpret_cast_3 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    memref.store %38, %reinterpret_cast_3[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb5
  ^bb4:  // pred: ^bb2
    %reinterpret_cast_4 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    memref.store %cst, %reinterpret_cast_4[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb5
  ^bb5:  // 2 preds: ^bb3, ^bb4
    gpu.barrier
    %39 = arith.cmpi ult, %21, %c16 : index
    %40 = arith.addi %26, %c16 : index
    %41 = arith.cmpi ult, %40, %c8192 : index
    %42 = arith.andi %39, %41 : i1
    cf.cond_br %42, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %43 = arith.addi %19, %c128 : index
    %reinterpret_cast_5 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %44 = memref.load %reinterpret_cast_5[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    %45 = memref.load %reinterpret_cast_5[%43] : memref<256xf32, #gpu.address_space<workgroup>>
    %46 = arith.addf %44, %45 : f32
    memref.store %46, %reinterpret_cast_5[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    gpu.barrier
    %47 = arith.cmpi ult, %21, %c8 : index
    %48 = arith.addi %26, %c8 : index
    %49 = arith.cmpi ult, %48, %c8192 : index
    %50 = arith.andi %47, %49 : i1
    cf.cond_br %50, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %51 = arith.addi %19, %c64 : index
    %reinterpret_cast_6 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %52 = memref.load %reinterpret_cast_6[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    %53 = memref.load %reinterpret_cast_6[%51] : memref<256xf32, #gpu.address_space<workgroup>>
    %54 = arith.addf %52, %53 : f32
    memref.store %54, %reinterpret_cast_6[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb9
  ^bb9:  // 2 preds: ^bb7, ^bb8
    gpu.barrier
    %55 = arith.cmpi ult, %21, %c4 : index
    %56 = arith.addi %26, %c4 : index
    %57 = arith.cmpi ult, %56, %c8192 : index
    %58 = arith.andi %55, %57 : i1
    cf.cond_br %58, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %59 = arith.addi %19, %c32 : index
    %reinterpret_cast_7 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %60 = memref.load %reinterpret_cast_7[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    %61 = memref.load %reinterpret_cast_7[%59] : memref<256xf32, #gpu.address_space<workgroup>>
    %62 = arith.addf %60, %61 : f32
    memref.store %62, %reinterpret_cast_7[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb11
  ^bb11:  // 2 preds: ^bb9, ^bb10
    gpu.barrier
    %63 = arith.cmpi ult, %21, %c2 : index
    %64 = arith.addi %26, %c2 : index
    %65 = arith.cmpi ult, %64, %c8192 : index
    %66 = arith.andi %63, %65 : i1
    cf.cond_br %66, ^bb12, ^bb13
  ^bb12:  // pred: ^bb11
    %67 = arith.addi %19, %c16 : index
    %reinterpret_cast_8 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %68 = memref.load %reinterpret_cast_8[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    %69 = memref.load %reinterpret_cast_8[%67] : memref<256xf32, #gpu.address_space<workgroup>>
    %70 = arith.addf %68, %69 : f32
    memref.store %70, %reinterpret_cast_8[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb13
  ^bb13:  // 2 preds: ^bb11, ^bb12
    gpu.barrier
    %71 = arith.cmpi eq, %21, %c0_1 : index
    %72 = arith.andi %71, %31 : i1
    cf.cond_br %72, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %73 = arith.addi %19, %c8 : index
    %reinterpret_cast_9 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %74 = memref.load %reinterpret_cast_9[%19] : memref<256xf32, #gpu.address_space<workgroup>>
    %75 = memref.load %reinterpret_cast_9[%73] : memref<256xf32, #gpu.address_space<workgroup>>
    %76 = arith.addf %74, %75 : f32
    %77 = memref.atomic_rmw addf %76, %arg4[%28] : (f32, memref<2560xf32, "gpu">) -> f32
    cf.br ^bb15
  ^bb15:  // 2 preds: ^bb13, ^bb14
    cf.br ^bb16
  ^bb16:  // 2 preds: ^bb1, ^bb15
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: index, %arg1: index, %arg2: memref<8192x2560xf32, "gpu">, %arg3: memref<8192x2560xf32, "gpu">, %arg4: memref<2560xf32, "gpu">) workgroup(%arg5 : memref<256xf32, #gpu.address_space<workgroup>>) kernel {
    %0 = gpu.block_id  x
    %1 = gpu.block_id  y
    %2 = gpu.block_id  z
    %3 = gpu.thread_id  x
    %4 = gpu.thread_id  y
    %5 = gpu.thread_id  z
    %6 = gpu.grid_dim  x
    %7 = gpu.grid_dim  y
    %8 = gpu.grid_dim  z
    %9 = gpu.block_dim  x
    %10 = gpu.block_dim  y
    %11 = gpu.block_dim  z
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c0_0 = arith.constant 0 : index
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c320 = arith.constant 320 : index
    %c32 = arith.constant 32 : index
    %c8192 = arith.constant 8192 : index
    %c2560 = arith.constant 2560 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %c0_1 = arith.constant 0 : index
    %12 = arith.muli %0, %arg0 : index
    %13 = arith.addi %12, %c0 : index
    %14 = arith.muli %3, %c1 : index
    %15 = arith.addi %14, %c0_0 : index
    %16 = arith.addi %15, %13 : index
    %true = arith.constant true
    %17 = arith.muli %15, %c1 : index
    %18 = arith.addi %17, %13 : index
    %19 = arith.cmpi ult, %18, %arg1 : index
    %20 = arith.andi %true, %19 : i1
    cf.cond_br %20, ^bb2, ^bb16
  ^bb2:  // pred: ^bb1
    %21 = arith.remsi %16, %c256 : index
    %22 = arith.divsi %16, %c256 : index
    %23 = arith.divui %21, %c8 : index
    %24 = arith.remui %21, %c8 : index
    %25 = arith.divui %22, %c320 : index
    %26 = arith.remui %22, %c320 : index
    %27 = arith.muli %25, %c32 : index
    %28 = arith.addi %27, %23 : index
    %29 = arith.muli %26, %c8 : index
    %30 = arith.addi %29, %24 : index
    %31 = arith.cmpi ult, %28, %c8192 : index
    %32 = arith.cmpi ult, %30, %c2560 : index
    %33 = arith.andi %31, %32 : i1
    cf.cond_br %33, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %34 = arith.muli %28, %c2560 : index
    %35 = arith.addi %34, %30 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
    %36 = memref.load %reinterpret_cast[%35] : memref<20971520xf32, "gpu">
    %reinterpret_cast_2 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
    %37 = memref.load %reinterpret_cast_2[%35] : memref<20971520xf32, "gpu">
    %38 = arith.subf %36, %37 : f32
    %39 = arith.mulf %38, %36 : f32
    %40 = arith.addf %39, %cst : f32
    %reinterpret_cast_3 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    memref.store %40, %reinterpret_cast_3[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb5
  ^bb4:  // pred: ^bb2
    %reinterpret_cast_4 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    memref.store %cst, %reinterpret_cast_4[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb5
  ^bb5:  // 2 preds: ^bb3, ^bb4
    gpu.barrier
    %41 = arith.cmpi ult, %23, %c16 : index
    %42 = arith.addi %28, %c16 : index
    %43 = arith.cmpi ult, %42, %c8192 : index
    %44 = arith.andi %41, %43 : i1
    cf.cond_br %44, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %45 = arith.addi %21, %c128 : index
    %reinterpret_cast_5 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %46 = memref.load %reinterpret_cast_5[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    %47 = memref.load %reinterpret_cast_5[%45] : memref<256xf32, #gpu.address_space<workgroup>>
    %48 = arith.addf %46, %47 : f32
    memref.store %48, %reinterpret_cast_5[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    gpu.barrier
    %49 = arith.cmpi ult, %23, %c8 : index
    %50 = arith.addi %28, %c8 : index
    %51 = arith.cmpi ult, %50, %c8192 : index
    %52 = arith.andi %49, %51 : i1
    cf.cond_br %52, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %53 = arith.addi %21, %c64 : index
    %reinterpret_cast_6 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %54 = memref.load %reinterpret_cast_6[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    %55 = memref.load %reinterpret_cast_6[%53] : memref<256xf32, #gpu.address_space<workgroup>>
    %56 = arith.addf %54, %55 : f32
    memref.store %56, %reinterpret_cast_6[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb9
  ^bb9:  // 2 preds: ^bb7, ^bb8
    gpu.barrier
    %57 = arith.cmpi ult, %23, %c4 : index
    %58 = arith.addi %28, %c4 : index
    %59 = arith.cmpi ult, %58, %c8192 : index
    %60 = arith.andi %57, %59 : i1
    cf.cond_br %60, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %61 = arith.addi %21, %c32 : index
    %reinterpret_cast_7 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %62 = memref.load %reinterpret_cast_7[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    %63 = memref.load %reinterpret_cast_7[%61] : memref<256xf32, #gpu.address_space<workgroup>>
    %64 = arith.addf %62, %63 : f32
    memref.store %64, %reinterpret_cast_7[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb11
  ^bb11:  // 2 preds: ^bb9, ^bb10
    gpu.barrier
    %65 = arith.cmpi ult, %23, %c2 : index
    %66 = arith.addi %28, %c2 : index
    %67 = arith.cmpi ult, %66, %c8192 : index
    %68 = arith.andi %65, %67 : i1
    cf.cond_br %68, ^bb12, ^bb13
  ^bb12:  // pred: ^bb11
    %69 = arith.addi %21, %c16 : index
    %reinterpret_cast_8 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %70 = memref.load %reinterpret_cast_8[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    %71 = memref.load %reinterpret_cast_8[%69] : memref<256xf32, #gpu.address_space<workgroup>>
    %72 = arith.addf %70, %71 : f32
    memref.store %72, %reinterpret_cast_8[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb13
  ^bb13:  // 2 preds: ^bb11, ^bb12
    gpu.barrier
    %73 = arith.cmpi eq, %23, %c0_1 : index
    %74 = arith.andi %73, %33 : i1
    cf.cond_br %74, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %75 = arith.addi %21, %c8 : index
    %reinterpret_cast_9 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %76 = memref.load %reinterpret_cast_9[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    %77 = memref.load %reinterpret_cast_9[%75] : memref<256xf32, #gpu.address_space<workgroup>>
    %78 = arith.addf %76, %77 : f32
    %79 = memref.atomic_rmw addf %78, %arg4[%30] : (f32, memref<2560xf32, "gpu">) -> f32
    cf.br ^bb15
  ^bb15:  // 2 preds: ^bb13, ^bb14
    cf.br ^bb16
  ^bb16:  // 2 preds: ^bb1, ^bb15
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: index, %arg1: index, %arg2: memref<8192x2560xf32, "gpu">, %arg3: memref<8192x2560xf32, "gpu">, %arg4: memref<2560xf32, "gpu">) workgroup(%arg5 : memref<256xf32, #gpu.address_space<workgroup>>) kernel {
    %0 = gpu.block_id  x
    %1 = gpu.block_id  y
    %2 = gpu.block_id  z
    %3 = gpu.thread_id  x
    %4 = gpu.thread_id  y
    %5 = gpu.thread_id  z
    %6 = gpu.grid_dim  x
    %7 = gpu.grid_dim  y
    %8 = gpu.grid_dim  z
    %9 = gpu.block_dim  x
    %10 = gpu.block_dim  y
    %11 = gpu.block_dim  z
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c0_0 = arith.constant 0 : index
    %c256 = arith.constant 256 : index
    %c8 = arith.constant 8 : index
    %c320 = arith.constant 320 : index
    %c32 = arith.constant 32 : index
    %c8192 = arith.constant 8192 : index
    %c2560 = arith.constant 2560 : index
    %cst = arith.constant 0.000000e+00 : f32
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c64 = arith.constant 64 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %c0_1 = arith.constant 0 : index
    %12 = arith.muli %0, %arg0 : index
    %13 = arith.addi %12, %c0 : index
    %14 = arith.muli %3, %c1 : index
    %15 = arith.addi %14, %c0_0 : index
    %16 = arith.addi %15, %13 : index
    %true = arith.constant true
    %17 = arith.muli %15, %c1 : index
    %18 = arith.addi %17, %13 : index
    %19 = arith.cmpi ult, %18, %arg1 : index
    %20 = arith.andi %true, %19 : i1
    cf.cond_br %20, ^bb2, ^bb16
  ^bb2:  // pred: ^bb1
    %21 = arith.remsi %16, %c256 : index
    %22 = arith.divsi %16, %c256 : index
    %23 = arith.divui %21, %c8 : index
    %24 = arith.remui %21, %c8 : index
    %25 = arith.divui %22, %c320 : index
    %26 = arith.remui %22, %c320 : index
    %27 = arith.muli %25, %c32 : index
    %28 = arith.addi %27, %23 : index
    %29 = arith.muli %26, %c8 : index
    %30 = arith.addi %29, %24 : index
    %31 = arith.cmpi ult, %28, %c8192 : index
    %32 = arith.cmpi ult, %30, %c2560 : index
    %33 = arith.andi %31, %32 : i1
    cf.cond_br %33, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %34 = arith.muli %28, %c2560 : index
    %35 = arith.addi %34, %30 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
    %36 = memref.load %reinterpret_cast[%35] : memref<20971520xf32, "gpu">
    %reinterpret_cast_2 = memref.reinterpret_cast %arg3 to offset: [0], sizes: [20971520], strides: [1] : memref<8192x2560xf32, "gpu"> to memref<20971520xf32, "gpu">
    %37 = memref.load %reinterpret_cast_2[%35] : memref<20971520xf32, "gpu">
    %38 = arith.subf %36, %37 : f32
    %39 = arith.mulf %38, %36 : f32
    %40 = arith.addf %39, %cst : f32
    %reinterpret_cast_3 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    memref.store %40, %reinterpret_cast_3[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb5
  ^bb4:  // pred: ^bb2
    %reinterpret_cast_4 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    memref.store %cst, %reinterpret_cast_4[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb5
  ^bb5:  // 2 preds: ^bb3, ^bb4
    gpu.barrier
    %41 = arith.cmpi ult, %23, %c16 : index
    %42 = arith.addi %28, %c16 : index
    %43 = arith.cmpi ult, %42, %c8192 : index
    %44 = arith.andi %41, %43 : i1
    cf.cond_br %44, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %45 = arith.addi %21, %c128 : index
    %reinterpret_cast_5 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %46 = memref.load %reinterpret_cast_5[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    %47 = memref.load %reinterpret_cast_5[%45] : memref<256xf32, #gpu.address_space<workgroup>>
    %48 = arith.addf %46, %47 : f32
    memref.store %48, %reinterpret_cast_5[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    gpu.barrier
    %49 = arith.cmpi ult, %23, %c8 : index
    %50 = arith.addi %28, %c8 : index
    %51 = arith.cmpi ult, %50, %c8192 : index
    %52 = arith.andi %49, %51 : i1
    cf.cond_br %52, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %53 = arith.addi %21, %c64 : index
    %reinterpret_cast_6 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %54 = memref.load %reinterpret_cast_6[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    %55 = memref.load %reinterpret_cast_6[%53] : memref<256xf32, #gpu.address_space<workgroup>>
    %56 = arith.addf %54, %55 : f32
    memref.store %56, %reinterpret_cast_6[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb9
  ^bb9:  // 2 preds: ^bb7, ^bb8
    gpu.barrier
    %57 = arith.cmpi ult, %23, %c4 : index
    %58 = arith.addi %28, %c4 : index
    %59 = arith.cmpi ult, %58, %c8192 : index
    %60 = arith.andi %57, %59 : i1
    cf.cond_br %60, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %61 = arith.addi %21, %c32 : index
    %reinterpret_cast_7 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %62 = memref.load %reinterpret_cast_7[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    %63 = memref.load %reinterpret_cast_7[%61] : memref<256xf32, #gpu.address_space<workgroup>>
    %64 = arith.addf %62, %63 : f32
    memref.store %64, %reinterpret_cast_7[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb11
  ^bb11:  // 2 preds: ^bb9, ^bb10
    gpu.barrier
    %65 = arith.cmpi ult, %23, %c2 : index
    %66 = arith.addi %28, %c2 : index
    %67 = arith.cmpi ult, %66, %c8192 : index
    %68 = arith.andi %65, %67 : i1
    cf.cond_br %68, ^bb12, ^bb13
  ^bb12:  // pred: ^bb11
    %69 = arith.addi %21, %c16 : index
    %reinterpret_cast_8 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %70 = memref.load %reinterpret_cast_8[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    %71 = memref.load %reinterpret_cast_8[%69] : memref<256xf32, #gpu.address_space<workgroup>>
    %72 = arith.addf %70, %71 : f32
    memref.store %72, %reinterpret_cast_8[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    cf.br ^bb13
  ^bb13:  // 2 preds: ^bb11, ^bb12
    gpu.barrier
    %73 = arith.cmpi eq, %23, %c0_1 : index
    %74 = arith.andi %73, %33 : i1
    cf.cond_br %74, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %75 = arith.addi %21, %c8 : index
    %reinterpret_cast_9 = memref.reinterpret_cast %arg5 to offset: [0], sizes: [256], strides: [1] : memref<256xf32, #gpu.address_space<workgroup>> to memref<256xf32, #gpu.address_space<workgroup>>
    %76 = memref.load %reinterpret_cast_9[%21] : memref<256xf32, #gpu.address_space<workgroup>>
    %77 = memref.load %reinterpret_cast_9[%75] : memref<256xf32, #gpu.address_space<workgroup>>
    %78 = arith.addf %76, %77 : f32
    %79 = memref.atomic_rmw addf %78, %arg4[%30] : (f32, memref<2560xf32, "gpu">) -> f32
    cf.br ^bb15
  ^bb15:  // 2 preds: ^bb13, ^bb14
    cf.br ^bb16
  ^bb16:  // 2 preds: ^bb1, ^bb15
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel_0 {
  llvm.mlir.global internal @__wg_main_kColReduction_reduce__4_1_0___8w32h_1_0() {addr_space = 3 : i32} : !llvm.array<256 x f32>
  llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<f32>, %arg10: !llvm.ptr<f32>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: !llvm.ptr<f32>, %arg17: !llvm.ptr<f32>, %arg18: i32, %arg19: i32, %arg20: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)>
    %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %5 = llvm.insertvalue %arg7, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %6 = llvm.insertvalue %arg6, %5[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %7 = llvm.insertvalue %arg8, %6[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %8 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)>
    %9 = llvm.insertvalue %arg9, %8[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %10 = llvm.insertvalue %arg10, %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %11 = llvm.insertvalue %arg11, %10[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %12 = llvm.insertvalue %arg12, %11[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %13 = llvm.insertvalue %arg14, %12[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %14 = llvm.insertvalue %arg13, %13[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %15 = llvm.insertvalue %arg15, %14[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %16 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %17 = llvm.insertvalue %arg16, %16[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %18 = llvm.insertvalue %arg17, %17[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %19 = llvm.insertvalue %arg18, %18[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %20 = llvm.insertvalue %arg19, %19[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %21 = llvm.insertvalue %arg20, %20[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %22 = llvm.mlir.addressof @__wg_main_kColReduction_reduce__4_1_0___8w32h_1_0 : !llvm.ptr<array<256 x f32>, 3>
    %23 = llvm.getelementptr %22[0, 0] : (!llvm.ptr<array<256 x f32>, 3>) -> !llvm.ptr<f32, 3>
    %24 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %25 = llvm.insertvalue %23, %24[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %26 = llvm.insertvalue %23, %25[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %27 = llvm.mlir.constant(0 : index) : i32
    %28 = llvm.insertvalue %27, %26[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %29 = llvm.mlir.constant(256 : index) : i32
    %30 = llvm.insertvalue %29, %28[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %31 = llvm.mlir.constant(1 : index) : i32
    %32 = llvm.insertvalue %31, %30[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %33 = llvm.mlir.constant(2 : index) : i32
    %34 = llvm.mlir.constant(4 : index) : i32
    %35 = llvm.mlir.constant(64 : index) : i32
    %36 = llvm.mlir.constant(128 : index) : i32
    %37 = llvm.mlir.constant(16 : index) : i32
    %38 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %39 = llvm.mlir.constant(2560 : index) : i32
    %40 = llvm.mlir.constant(8192 : index) : i32
    %41 = llvm.mlir.constant(32 : index) : i32
    %42 = llvm.mlir.constant(320 : index) : i32
    %43 = llvm.mlir.constant(8 : index) : i32
    %44 = llvm.mlir.constant(256 : index) : i32
    %45 = llvm.mlir.constant(0 : index) : i32
    %46 = nvvm.read.ptx.sreg.ctaid.x : i32
    %47 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %48 = llvm.mul %46, %arg0  : i32
    %49 = llvm.add %47, %48  : i32
    %50 = llvm.add %47, %48  : i32
    %51 = llvm.icmp "ult" %50, %arg1 : i32
    llvm.cond_br %51, ^bb2, ^bb16
  ^bb2:  // pred: ^bb1
    %52 = llvm.srem %49, %44  : i32
    %53 = llvm.sdiv %49, %44  : i32
    %54 = llvm.udiv %52, %43  : i32
    %55 = llvm.urem %52, %43  : i32
    %56 = llvm.udiv %53, %42  : i32
    %57 = llvm.urem %53, %42  : i32
    %58 = llvm.mul %56, %41  : i32
    %59 = llvm.add %58, %54  : i32
    %60 = llvm.mul %57, %43  : i32
    %61 = llvm.add %60, %55  : i32
    %62 = llvm.icmp "ult" %59, %40 : i32
    %63 = llvm.icmp "ult" %61, %39 : i32
    %64 = llvm.and %62, %63  : i1
    llvm.cond_br %64, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %65 = llvm.mul %59, %39  : i32
    %66 = llvm.add %65, %61  : i32
    %67 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %68 = llvm.extractvalue %7[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %69 = llvm.extractvalue %7[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %70 = llvm.insertvalue %68, %67[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %71 = llvm.insertvalue %69, %70[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %72 = llvm.mlir.constant(0 : index) : i32
    %73 = llvm.insertvalue %72, %71[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %74 = llvm.mlir.constant(20971520 : index) : i32
    %75 = llvm.insertvalue %74, %73[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %76 = llvm.mlir.constant(1 : index) : i32
    %77 = llvm.insertvalue %76, %75[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %78 = llvm.extractvalue %77[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %79 = llvm.getelementptr %78[%66] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %80 = llvm.load %79 : !llvm.ptr<f32>
    %81 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %82 = llvm.extractvalue %15[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %83 = llvm.extractvalue %15[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %84 = llvm.insertvalue %82, %81[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %85 = llvm.insertvalue %83, %84[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %86 = llvm.mlir.constant(0 : index) : i32
    %87 = llvm.insertvalue %86, %85[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %88 = llvm.mlir.constant(20971520 : index) : i32
    %89 = llvm.insertvalue %88, %87[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %90 = llvm.mlir.constant(1 : index) : i32
    %91 = llvm.insertvalue %90, %89[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %92 = llvm.extractvalue %91[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %93 = llvm.getelementptr %92[%66] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %94 = llvm.load %93 : !llvm.ptr<f32>
    %95 = llvm.fsub %80, %94  : f32
    %96 = llvm.fmul %95, %80  : f32
    %97 = llvm.fadd %96, %38  : f32
    %98 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %99 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %100 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %101 = llvm.insertvalue %99, %98[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %102 = llvm.insertvalue %100, %101[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %103 = llvm.mlir.constant(0 : index) : i32
    %104 = llvm.insertvalue %103, %102[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %105 = llvm.mlir.constant(256 : index) : i32
    %106 = llvm.insertvalue %105, %104[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %107 = llvm.mlir.constant(1 : index) : i32
    %108 = llvm.insertvalue %107, %106[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %109 = llvm.extractvalue %108[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %110 = llvm.getelementptr %109[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %97, %110 : !llvm.ptr<f32, 3>
    llvm.br ^bb5
  ^bb4:  // pred: ^bb2
    %111 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %112 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %113 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %114 = llvm.insertvalue %112, %111[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %115 = llvm.insertvalue %113, %114[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %116 = llvm.mlir.constant(0 : index) : i32
    %117 = llvm.insertvalue %116, %115[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %118 = llvm.mlir.constant(256 : index) : i32
    %119 = llvm.insertvalue %118, %117[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %120 = llvm.mlir.constant(1 : index) : i32
    %121 = llvm.insertvalue %120, %119[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %122 = llvm.extractvalue %121[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %123 = llvm.getelementptr %122[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %38, %123 : !llvm.ptr<f32, 3>
    llvm.br ^bb5
  ^bb5:  // 2 preds: ^bb3, ^bb4
    nvvm.barrier0
    %124 = llvm.icmp "ult" %54, %37 : i32
    %125 = llvm.add %59, %37  : i32
    %126 = llvm.icmp "ult" %125, %40 : i32
    %127 = llvm.and %124, %126  : i1
    llvm.cond_br %127, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %128 = llvm.add %52, %36  : i32
    %129 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %130 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %131 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %132 = llvm.insertvalue %130, %129[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %133 = llvm.insertvalue %131, %132[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %134 = llvm.mlir.constant(0 : index) : i32
    %135 = llvm.insertvalue %134, %133[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %136 = llvm.mlir.constant(256 : index) : i32
    %137 = llvm.insertvalue %136, %135[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %138 = llvm.mlir.constant(1 : index) : i32
    %139 = llvm.insertvalue %138, %137[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %140 = llvm.extractvalue %139[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %141 = llvm.getelementptr %140[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %142 = llvm.load %141 : !llvm.ptr<f32, 3>
    %143 = llvm.extractvalue %139[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %144 = llvm.getelementptr %143[%128] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %145 = llvm.load %144 : !llvm.ptr<f32, 3>
    %146 = llvm.fadd %142, %145  : f32
    %147 = llvm.extractvalue %139[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %148 = llvm.getelementptr %147[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %146, %148 : !llvm.ptr<f32, 3>
    llvm.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    nvvm.barrier0
    %149 = llvm.icmp "ult" %54, %43 : i32
    %150 = llvm.add %59, %43  : i32
    %151 = llvm.icmp "ult" %150, %40 : i32
    %152 = llvm.and %149, %151  : i1
    llvm.cond_br %152, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %153 = llvm.add %52, %35  : i32
    %154 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %155 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %156 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %157 = llvm.insertvalue %155, %154[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %158 = llvm.insertvalue %156, %157[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %159 = llvm.mlir.constant(0 : index) : i32
    %160 = llvm.insertvalue %159, %158[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %161 = llvm.mlir.constant(256 : index) : i32
    %162 = llvm.insertvalue %161, %160[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %163 = llvm.mlir.constant(1 : index) : i32
    %164 = llvm.insertvalue %163, %162[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %165 = llvm.extractvalue %164[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %166 = llvm.getelementptr %165[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %167 = llvm.load %166 : !llvm.ptr<f32, 3>
    %168 = llvm.extractvalue %164[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %169 = llvm.getelementptr %168[%153] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %170 = llvm.load %169 : !llvm.ptr<f32, 3>
    %171 = llvm.fadd %167, %170  : f32
    %172 = llvm.extractvalue %164[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %173 = llvm.getelementptr %172[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %171, %173 : !llvm.ptr<f32, 3>
    llvm.br ^bb9
  ^bb9:  // 2 preds: ^bb7, ^bb8
    nvvm.barrier0
    %174 = llvm.icmp "ult" %54, %34 : i32
    %175 = llvm.add %59, %34  : i32
    %176 = llvm.icmp "ult" %175, %40 : i32
    %177 = llvm.and %174, %176  : i1
    llvm.cond_br %177, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %178 = llvm.add %52, %41  : i32
    %179 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %180 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %181 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %182 = llvm.insertvalue %180, %179[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %183 = llvm.insertvalue %181, %182[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %184 = llvm.mlir.constant(0 : index) : i32
    %185 = llvm.insertvalue %184, %183[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %186 = llvm.mlir.constant(256 : index) : i32
    %187 = llvm.insertvalue %186, %185[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %188 = llvm.mlir.constant(1 : index) : i32
    %189 = llvm.insertvalue %188, %187[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %190 = llvm.extractvalue %189[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %191 = llvm.getelementptr %190[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %192 = llvm.load %191 : !llvm.ptr<f32, 3>
    %193 = llvm.extractvalue %189[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %194 = llvm.getelementptr %193[%178] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %195 = llvm.load %194 : !llvm.ptr<f32, 3>
    %196 = llvm.fadd %192, %195  : f32
    %197 = llvm.extractvalue %189[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %198 = llvm.getelementptr %197[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %196, %198 : !llvm.ptr<f32, 3>
    llvm.br ^bb11
  ^bb11:  // 2 preds: ^bb9, ^bb10
    nvvm.barrier0
    %199 = llvm.icmp "ult" %54, %33 : i32
    %200 = llvm.add %59, %33  : i32
    %201 = llvm.icmp "ult" %200, %40 : i32
    %202 = llvm.and %199, %201  : i1
    llvm.cond_br %202, ^bb12, ^bb13
  ^bb12:  // pred: ^bb11
    %203 = llvm.add %52, %37  : i32
    %204 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %205 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %206 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %207 = llvm.insertvalue %205, %204[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %208 = llvm.insertvalue %206, %207[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %209 = llvm.mlir.constant(0 : index) : i32
    %210 = llvm.insertvalue %209, %208[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %211 = llvm.mlir.constant(256 : index) : i32
    %212 = llvm.insertvalue %211, %210[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %213 = llvm.mlir.constant(1 : index) : i32
    %214 = llvm.insertvalue %213, %212[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %215 = llvm.extractvalue %214[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %216 = llvm.getelementptr %215[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %217 = llvm.load %216 : !llvm.ptr<f32, 3>
    %218 = llvm.extractvalue %214[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %219 = llvm.getelementptr %218[%203] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %220 = llvm.load %219 : !llvm.ptr<f32, 3>
    %221 = llvm.fadd %217, %220  : f32
    %222 = llvm.extractvalue %214[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %223 = llvm.getelementptr %222[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %221, %223 : !llvm.ptr<f32, 3>
    llvm.br ^bb13
  ^bb13:  // 2 preds: ^bb11, ^bb12
    nvvm.barrier0
    %224 = llvm.icmp "eq" %54, %45 : i32
    %225 = llvm.and %224, %64  : i1
    llvm.cond_br %225, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %226 = llvm.add %52, %43  : i32
    %227 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %228 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %229 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %230 = llvm.insertvalue %228, %227[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %231 = llvm.insertvalue %229, %230[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %232 = llvm.mlir.constant(0 : index) : i32
    %233 = llvm.insertvalue %232, %231[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %234 = llvm.mlir.constant(256 : index) : i32
    %235 = llvm.insertvalue %234, %233[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %236 = llvm.mlir.constant(1 : index) : i32
    %237 = llvm.insertvalue %236, %235[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %238 = llvm.extractvalue %237[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %239 = llvm.getelementptr %238[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %240 = llvm.load %239 : !llvm.ptr<f32, 3>
    %241 = llvm.extractvalue %237[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %242 = llvm.getelementptr %241[%226] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %243 = llvm.load %242 : !llvm.ptr<f32, 3>
    %244 = llvm.fadd %240, %243  : f32
    %245 = llvm.extractvalue %21[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %246 = llvm.getelementptr %245[%61] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %247 = llvm.atomicrmw fadd %246, %244 acq_rel : !llvm.ptr<f32>, f32
    llvm.br ^bb15
  ^bb15:  // 2 preds: ^bb13, ^bb14
    llvm.br ^bb16
  ^bb16:  // 2 preds: ^bb1, ^bb15
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel_0 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\C0\05\00\00\00\00\00\00\01\00\01\01H\00\00\00x\05\00\00\00\00\00\00t\05\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\03\11\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2!\0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64\0A0\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\10e__4_1_0___8w32h_1(\0A.param .u328\00\18\11_6\00?_0,@\00+\171@\00/64@\00\1F\1F2@\00,\1F3\C0\00,\1F4@\00,\1F5@\00,\1F6@\00,\1F7@\00,\1F8\80\01,\1F9@\00,\1F1\81\02.\1F1A\00-\1F2A\00-\0F\84\02-\1F1\85\02-/15\86\01-\1F6A\00-\0F\88\02-/18A\00-\1F9A\00,\F3\0A20\0A)\0A{\0A.reg .pred %p<18>;\13\00\95b32 %r<24\12\00\10f\12\00\18f\12\00\F0\04b64 %rd<17>;\0A\0A\09.shaI\00\FF\03.align 4 .b8 __wg_\9E\00\18\B20[1024];\0Ald\E0\00\01\DF\00o%r5, [\E5\00\1E\1E0H\00\1F6H\00!s1];\0AmovC\00\B87, %ctaid.x\17\00S8, %t\15\00qad.lo.s\18\00#1,4\00\00\C4\00\C2%r8;\0Asetp.ge8\004p1,%\00\F4\0C6;\0A@%p1 bra $L__BB0_13;\0AshrL\00\130-\00\2231\17\00\02{\00311,\1D\00t24;\0Aadd/\00\132/\00\00#\00\09H\00#3,\1F\00c8;\0Aand\EF\01$14\17\00\93-256;\0Asub1\00\07I\00\194z\00\225,\1E\00\193H\00\136\16\00\947;\0Amul.hi/\00#7,~\00\A9-858993459O\00#8,&\00\128:\00\06F\01#9, \009320\9A\00&0,\D1\00\01M\00\13l\86\00$213\00\185\15\01&3,\1C\00\1950\00#2,P\00S3;\0Aor\16\00%4,\1B\00$16\BC\01\12t\B0\002p2,Q\00B8191\0C\02\02&\03s23, 0f0\01\00\01\D7\01\192\D7\01\183\99\02\02G\03\1F7\9A\02\22\00\E3\02\E4cvta.to.globalP\00\01\9C\00.d7i\00\1F8i\00!\1F3h\00\06\01P\01+d8\F6\02#23\1B\011256\A2\01\124\D1\013wid\F9\02Crd9,)\00\04\B5\02\02Q\00\02\E5\02\03X\00\119\C0\00\03r\00\02]\01A4, ['\00\1A]7\00&1,\F7\00\0F7\00\00\1357\00\221]?\02\02\16\00\226,R\00\B7%f5;\0Afma.rn\C4\01\03\1B\00\1A6\CE\01\05\C5\01\16:\D3\00\02\F6\003d12\FA\02\134\1B\04\02$\01\00\9F\02\0F\0A\05\1E\0A\DE\00$4,I\00\00\07\00S2;\0Astq\05\01\B0\00\01\DB\0014],\B9\00\CC;\0Abar.sync 0\B3\02\133\A1\00<127\1B\00\154\CE\02.75\AE\01\05\EB\03\0A\AE\01\0A\98\00\115:\03\03P\06#5,p\00!p4\03\03\195\03\03\115\A3\01\07\C3\002%f7\A3\01.4]\1B\00\138\1B\00C+512\F8\01\02\19\00\229,9\00?%f8\14\01\01\02\13\01\169\B5\01/5:\1D\01\08\04\B8\04,63\1A\00\157\1C\01(83\E4\00#8,7\00!p7\E4\00\198\E4\00\1E7\C9\00/10\E5\00\07$11\E6\009256\E6\00\01X\02\01<\00\00&\00\0F\E9\00\07&12\EA\00\1F7\EA\00\09\139\EA\00,31\1A\00&10\EB\00\187\EB\00\01a\03\019\00\22p1\D4\04\1A1\AC\06\1F9\D2\00\00\1F3\EE\00\08\144\EE\00:128\EE\00\00:\02\01<\00\00&\00\0F\EE\00\08\165\EE\00\1F9\EE\00\09\05\97\03-15\1B\00\163\EF\00\199\EF\00\00\DA\02\02:\002p13\F0\00\194\F0\00/11\D5\00\00/6,\F1\00\07\04\E0\02:+64\F0\00\00F\02\01;\00\00%\00\0F\F0\00\08\168\F0\00/11\F1\00\0A\166\82\07\07\C2\01$7,\1C\00\22p2\D2\00\1D7n\08\0C/\06\0F2\09#\1F70\06\06\02\A7\05\1F6a\04\00\01\B4\00\1C4a\04&5,6\00/16V\01\00\1F9r\01\07$20r\01\1A36\04\01\00\08\01;\00\00%\00d;\0Aatom\A8\00\07&\00\122?\00\115~\01'21~\01\C03:\0Aret;\0A\0A}\0A\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\C8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00\88\06\00\00\00\00\00\00\83\06\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\11\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00o\02\00\BE\00u\00\01\00\00\11\0E\06\00a\00F\05F\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00g2\00\00\00\12\10x\00\11\05\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13\F0\93\00\10\04\08\00R\04\18\00\00\00E\002\04\0C\01\18\00C/\08\00\06/\04\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00@\00\04\1C\0C&\01c\000\04\00\00\A0\D8\01#K\00\01\00q\02\02\08\10\0A/\22\BB\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\88\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00;\02\11,\90\01\11\00\09\01\22H\00\01\00\11\02t\01\0F\01\00\FF\F0@$v\01\FF\AF\05\D0\FF\00\8E\07\00\C4\0F\00\89\F3\FF\FF\FF\04\05\00\C2\04b\E2\0F\00\19y\00\01\00\10%\E3\02a\0E\00\19y\03\00\01\00\10!=\00`\0E\00$z\00\00[\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\DB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\04\FF\B9\02\10\03 \00q\E4\0F\00\12x\05\03\91\05\F1\00\C0\8E\07\00\C6\0F\00%x\02\04\CD\CC\CC\CC\B0\00a\C8\0F\00$x\00@\05b\05\0A\8E\07\00\E2`\00\01@\00\12\16`\00A\19x\02\FFa\00\14\16p\00 \09\03\FC\02!\FF(0\00\B2\04$x\03\03\C0\FE\FF\FF\04\02@\001\12x\02^\06\01p\00p\E4\0F\00\0Cx\00\09\B1\00@p@\F0\03\80\00Q$x\02\03\08\1F\04\92\8E\07\00\D2\0F\00\02\88\07\A6\06!\0F\000\01c$\88\06\09\00\0A \00\90\C8\0F\00%\86\04\06\00\\\F0\04\04\10\00F\06\06\00f\10\00!\81\83J\06\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\07\06\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03\B0\00#r\03\A0\01\04\F0\00\11\08\CC\03\10\FF6\00\01\D0\006\0A\00\04 \00\D4\04\0Cx\00\00\7F\00\00\00pDt\01\D0\00\11\F7P\00A\F2\03\00\C8\10\00!\00? \00\11\F2\C0\00\81!\82\0B\04\07\00\00\80\84\00\81\C8O\00#\82\03\04\0BP\00\02\E0\00\000\00\11\070\00\A1p\00\00\CE\0F\00\88s\00\08`\01\00\A6\04f\E8\0F\00\18y\00\01\00f\E2\0F\00\1D{\00\01\00b\EA\0F\00\84\A9\04\A5\07\12\180\000\84\A9\05.\01\02\10\00s$\0E\00!\A2\05\04\BB\07\AF\00\00\D0\1F\00\88\A3\00\0A\05`\00\19\17\99`\00\02\B0\00$\09\FB@\01\10\C6 \00!\07\0A2\02\00 \00\11\22`\01$\00\1F \01\00\00\01 \92\07\00\01\06\80\00O\93\00\0A\07\E0\00\1A\1D\03\80\00\14\FDp\01\13\C6\00\01)\80\00\80\00\18\0F\80\01Z\A2\03\03\04\00\00\01\1F\03\00\01%\00`\011\99\05\0A\B1\0C\04`\01\1B\92`\01\1F\93`\01\1B\0C\D0\03E\84y\00\0Ap\00W\E2\0F\00\02x\10\03\00\F0\00Wy\03\0A\00 \80\00!r\05\E0\08\01\01\00\93\E4\1F\00%v\02\02\00p\10\03q\D0\0F\00\8Ey\00\02\90\00!G\11P\00*Myp\00PGy\00\00\F0\10\04[\FF\83\03\00\C0\B0\00\0F\10\00 \0F\01\00-\00|\04.\03\00\01\00\02$\0E]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13\CC\07\0C\01\00\138U\00\11\A8\06\00\06\F0\07\00\E7\01\04\AF\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03#\00P\C5\02\04H\0B\04\E4\00*\04\00\01\00\1Fc@\00\04\13\80)\00&\8C\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\10\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\1C\09\0D\01\00\13\F0@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0D\84\01\03E\04\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\C8\0C\12\03\C0\01:\0E\80\00\01\00\13\97\94\00+\03\00\01\00\03\B0\10/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00x\06\00\00\00\00\00\00s\06\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\80\10\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\0D\07\00a\00K\05K\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00f2\00\00\00\12\10x\00\13\80;\00f\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\08\00R\04\14\00\00\00E\00#\04\F8\18\00\80/\08\00\06\00\00\00\0E\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\04\1C\0C\FE\00c\00\D0\03\00\00@\D0\01#K\00\01\00q\02\02\08\10\0A/\22\B3\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\003\02\11,\88\01\11\00\01\01\22H\00\01\00\11\02l\01\0F\01\00\FF\F8@$v\01\FF\AF\05\B2\FF\00\8E\07\00\C4\0F\00\19y\00\01\00\10%\DB\02a\0E\00\19y\03\00\01\00\10!-\00`\0E\00$z\00\00K\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\CB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\02\FF\B1\02\10\03 \00q\E4\0F\00\12x\03\03\81\05\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\CD\CC\CC\CC\A0\00a\C8\0F\00$x\000\05`\03\0A\8E\07\00\E2@\00\11\04@\00\22\04\16`\00\00p\00\01a\00\14\16p\00 \06\04\10\00!\FF(0\00\B2\04$x\03\04\C0\FE\FF\FF\02\02@\001\12x\02N\06\01p\00p\E4\0F\00\0Cx\00\06\B1\00@p@\F0\03\80\00Q$x\07\03\08\17\04\92\8E\07\00\D2\0F\00\02\88\05\96\060\0F\00\00@\00@$\88\04\06@\01\22\07\02\A0\00`%\86\02\04\00\\\C0\04\04\10\00F\04\04\00f\10\000\81\83\02\83\03\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\05\04\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03`\00Sr\08\FF\FF\00\A0\01\01\F0\00\11\0B\C4\03\10\FF\C5\03\80\E4\0F\04\0Cx\00\00\7F\98\064Dt\01\C0\00\11\F7@\00A\F2\03\00\C8\10\00!\00? \00\11\F2\B0\00\81!\82\09\02\05\00\00\80t\00\81\C8O\00#\82\08\02\09`\00\02\D0\00\000\00\11\070\00\22p\000\014\09\00\04\80\00\93\CC\0F\00\88s\00\0B\08\00\1E\05f\E8\0F\00\1D{\00\01\00Q\EA\0F\00\84\A9O\002\00\00\18 \00A\84\A9\03\09v\04\12\18@\02c!\A2\02\02\03\00\01\00\8F\D0\1F\00\88\A3\00\09\02P\00\095\99\03\09P\00\02\A0\00$\06\FB \01\10\C6 \00!\04\09\12\02\00 \00\11\22@\01$\00\1F\10\01\00\F0\00W\92\04\03\04\00p\00O\93\00\09\04\C0\00\0A\0Ep\00\14\FDP\01\00p\001\A9\08\09>\01\07p\00\18\0F`\01!\A2\080\02\08\E0\00\1F\08\E0\00\0A\0B0\01\00\F0\00&@\000\01\1B\920\01\1F\930\01\0B\0C\80\039\84y\00\D0\006\02x\02\C0\02\00\D0\00Wy\03\09\00 p\00!r\05\80\08\01\01\00p\E4\1F\00%v\02\07{\08\10\02\00\02`\D0\0F\00\8Ey\00@\02A\00\00G\11P\00*Myp\00PGy\00\00\F0\C0\03\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\01\0C\04\1E\00\01\00\02\A4\0D]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13T\07\0C\01\00\138U\00\11\A8\06\00\06x\07\00\B7\01\04\8F\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03!\00P\E5\01\10\00\86\09'\00\00\E4\00*\04\00\01\00\1Fc@\00\04\04@\0B&\84\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\08\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\A4\08\0D\01\00\13\E8@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0C\84\01\13\F8@\00\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\08\01\12\03\C0\01:\0E\80\00\01\00\13\97\94\00/\03\000\10\03/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00"} {
  llvm.mlir.global internal @__wg_main_kColReduction_reduce__4_1_0___8w32h_1_0() {addr_space = 3 : i32} : !llvm.array<256 x f32>
  llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<f32>, %arg10: !llvm.ptr<f32>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: !llvm.ptr<f32>, %arg17: !llvm.ptr<f32>, %arg18: i32, %arg19: i32, %arg20: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)>
    %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %5 = llvm.insertvalue %arg7, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %6 = llvm.insertvalue %arg6, %5[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %7 = llvm.insertvalue %arg8, %6[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %8 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)>
    %9 = llvm.insertvalue %arg9, %8[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %10 = llvm.insertvalue %arg10, %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %11 = llvm.insertvalue %arg11, %10[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %12 = llvm.insertvalue %arg12, %11[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %13 = llvm.insertvalue %arg14, %12[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %14 = llvm.insertvalue %arg13, %13[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %15 = llvm.insertvalue %arg15, %14[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %16 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %17 = llvm.insertvalue %arg16, %16[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %18 = llvm.insertvalue %arg17, %17[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %19 = llvm.insertvalue %arg18, %18[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %20 = llvm.insertvalue %arg19, %19[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %21 = llvm.insertvalue %arg20, %20[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %22 = llvm.mlir.addressof @__wg_main_kColReduction_reduce__4_1_0___8w32h_1_0 : !llvm.ptr<array<256 x f32>, 3>
    %23 = llvm.getelementptr %22[0, 0] : (!llvm.ptr<array<256 x f32>, 3>) -> !llvm.ptr<f32, 3>
    %24 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %25 = llvm.insertvalue %23, %24[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %26 = llvm.insertvalue %23, %25[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %27 = llvm.mlir.constant(0 : index) : i32
    %28 = llvm.insertvalue %27, %26[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %29 = llvm.mlir.constant(256 : index) : i32
    %30 = llvm.insertvalue %29, %28[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %31 = llvm.mlir.constant(1 : index) : i32
    %32 = llvm.insertvalue %31, %30[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %33 = llvm.mlir.constant(2 : index) : i32
    %34 = llvm.mlir.constant(4 : index) : i32
    %35 = llvm.mlir.constant(64 : index) : i32
    %36 = llvm.mlir.constant(128 : index) : i32
    %37 = llvm.mlir.constant(16 : index) : i32
    %38 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %39 = llvm.mlir.constant(2560 : index) : i32
    %40 = llvm.mlir.constant(8192 : index) : i32
    %41 = llvm.mlir.constant(32 : index) : i32
    %42 = llvm.mlir.constant(320 : index) : i32
    %43 = llvm.mlir.constant(8 : index) : i32
    %44 = llvm.mlir.constant(256 : index) : i32
    %45 = llvm.mlir.constant(0 : index) : i32
    %46 = nvvm.read.ptx.sreg.ctaid.x : i32
    %47 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %48 = llvm.mul %46, %arg0  : i32
    %49 = llvm.add %47, %48  : i32
    %50 = llvm.add %47, %48  : i32
    %51 = llvm.icmp "ult" %50, %arg1 : i32
    llvm.cond_br %51, ^bb2, ^bb16
  ^bb2:  // pred: ^bb1
    %52 = llvm.srem %49, %44  : i32
    %53 = llvm.sdiv %49, %44  : i32
    %54 = llvm.udiv %52, %43  : i32
    %55 = llvm.urem %52, %43  : i32
    %56 = llvm.udiv %53, %42  : i32
    %57 = llvm.urem %53, %42  : i32
    %58 = llvm.mul %56, %41  : i32
    %59 = llvm.add %58, %54  : i32
    %60 = llvm.mul %57, %43  : i32
    %61 = llvm.add %60, %55  : i32
    %62 = llvm.icmp "ult" %59, %40 : i32
    %63 = llvm.icmp "ult" %61, %39 : i32
    %64 = llvm.and %62, %63  : i1
    llvm.cond_br %64, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %65 = llvm.mul %59, %39  : i32
    %66 = llvm.add %65, %61  : i32
    %67 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %68 = llvm.extractvalue %7[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %69 = llvm.extractvalue %7[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %70 = llvm.insertvalue %68, %67[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %71 = llvm.insertvalue %69, %70[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %72 = llvm.mlir.constant(0 : index) : i32
    %73 = llvm.insertvalue %72, %71[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %74 = llvm.mlir.constant(20971520 : index) : i32
    %75 = llvm.insertvalue %74, %73[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %76 = llvm.mlir.constant(1 : index) : i32
    %77 = llvm.insertvalue %76, %75[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %78 = llvm.extractvalue %77[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %79 = llvm.getelementptr %78[%66] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %80 = llvm.load %79 : !llvm.ptr<f32>
    %81 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %82 = llvm.extractvalue %15[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %83 = llvm.extractvalue %15[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
    %84 = llvm.insertvalue %82, %81[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %85 = llvm.insertvalue %83, %84[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %86 = llvm.mlir.constant(0 : index) : i32
    %87 = llvm.insertvalue %86, %85[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %88 = llvm.mlir.constant(20971520 : index) : i32
    %89 = llvm.insertvalue %88, %87[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %90 = llvm.mlir.constant(1 : index) : i32
    %91 = llvm.insertvalue %90, %89[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %92 = llvm.extractvalue %91[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %93 = llvm.getelementptr %92[%66] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %94 = llvm.load %93 : !llvm.ptr<f32>
    %95 = llvm.fsub %80, %94  : f32
    %96 = llvm.fmul %95, %80  : f32
    %97 = llvm.fadd %96, %38  : f32
    %98 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %99 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %100 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %101 = llvm.insertvalue %99, %98[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %102 = llvm.insertvalue %100, %101[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %103 = llvm.mlir.constant(0 : index) : i32
    %104 = llvm.insertvalue %103, %102[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %105 = llvm.mlir.constant(256 : index) : i32
    %106 = llvm.insertvalue %105, %104[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %107 = llvm.mlir.constant(1 : index) : i32
    %108 = llvm.insertvalue %107, %106[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %109 = llvm.extractvalue %108[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %110 = llvm.getelementptr %109[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %97, %110 : !llvm.ptr<f32, 3>
    llvm.br ^bb5
  ^bb4:  // pred: ^bb2
    %111 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %112 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %113 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %114 = llvm.insertvalue %112, %111[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %115 = llvm.insertvalue %113, %114[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %116 = llvm.mlir.constant(0 : index) : i32
    %117 = llvm.insertvalue %116, %115[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %118 = llvm.mlir.constant(256 : index) : i32
    %119 = llvm.insertvalue %118, %117[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %120 = llvm.mlir.constant(1 : index) : i32
    %121 = llvm.insertvalue %120, %119[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %122 = llvm.extractvalue %121[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %123 = llvm.getelementptr %122[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %38, %123 : !llvm.ptr<f32, 3>
    llvm.br ^bb5
  ^bb5:  // 2 preds: ^bb3, ^bb4
    nvvm.barrier0
    %124 = llvm.icmp "ult" %54, %37 : i32
    %125 = llvm.add %59, %37  : i32
    %126 = llvm.icmp "ult" %125, %40 : i32
    %127 = llvm.and %124, %126  : i1
    llvm.cond_br %127, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %128 = llvm.add %52, %36  : i32
    %129 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %130 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %131 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %132 = llvm.insertvalue %130, %129[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %133 = llvm.insertvalue %131, %132[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %134 = llvm.mlir.constant(0 : index) : i32
    %135 = llvm.insertvalue %134, %133[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %136 = llvm.mlir.constant(256 : index) : i32
    %137 = llvm.insertvalue %136, %135[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %138 = llvm.mlir.constant(1 : index) : i32
    %139 = llvm.insertvalue %138, %137[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %140 = llvm.extractvalue %139[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %141 = llvm.getelementptr %140[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %142 = llvm.load %141 : !llvm.ptr<f32, 3>
    %143 = llvm.extractvalue %139[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %144 = llvm.getelementptr %143[%128] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %145 = llvm.load %144 : !llvm.ptr<f32, 3>
    %146 = llvm.fadd %142, %145  : f32
    %147 = llvm.extractvalue %139[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %148 = llvm.getelementptr %147[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %146, %148 : !llvm.ptr<f32, 3>
    llvm.br ^bb7
  ^bb7:  // 2 preds: ^bb5, ^bb6
    nvvm.barrier0
    %149 = llvm.icmp "ult" %54, %43 : i32
    %150 = llvm.add %59, %43  : i32
    %151 = llvm.icmp "ult" %150, %40 : i32
    %152 = llvm.and %149, %151  : i1
    llvm.cond_br %152, ^bb8, ^bb9
  ^bb8:  // pred: ^bb7
    %153 = llvm.add %52, %35  : i32
    %154 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %155 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %156 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %157 = llvm.insertvalue %155, %154[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %158 = llvm.insertvalue %156, %157[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %159 = llvm.mlir.constant(0 : index) : i32
    %160 = llvm.insertvalue %159, %158[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %161 = llvm.mlir.constant(256 : index) : i32
    %162 = llvm.insertvalue %161, %160[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %163 = llvm.mlir.constant(1 : index) : i32
    %164 = llvm.insertvalue %163, %162[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %165 = llvm.extractvalue %164[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %166 = llvm.getelementptr %165[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %167 = llvm.load %166 : !llvm.ptr<f32, 3>
    %168 = llvm.extractvalue %164[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %169 = llvm.getelementptr %168[%153] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %170 = llvm.load %169 : !llvm.ptr<f32, 3>
    %171 = llvm.fadd %167, %170  : f32
    %172 = llvm.extractvalue %164[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %173 = llvm.getelementptr %172[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %171, %173 : !llvm.ptr<f32, 3>
    llvm.br ^bb9
  ^bb9:  // 2 preds: ^bb7, ^bb8
    nvvm.barrier0
    %174 = llvm.icmp "ult" %54, %34 : i32
    %175 = llvm.add %59, %34  : i32
    %176 = llvm.icmp "ult" %175, %40 : i32
    %177 = llvm.and %174, %176  : i1
    llvm.cond_br %177, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %178 = llvm.add %52, %41  : i32
    %179 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %180 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %181 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %182 = llvm.insertvalue %180, %179[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %183 = llvm.insertvalue %181, %182[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %184 = llvm.mlir.constant(0 : index) : i32
    %185 = llvm.insertvalue %184, %183[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %186 = llvm.mlir.constant(256 : index) : i32
    %187 = llvm.insertvalue %186, %185[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %188 = llvm.mlir.constant(1 : index) : i32
    %189 = llvm.insertvalue %188, %187[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %190 = llvm.extractvalue %189[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %191 = llvm.getelementptr %190[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %192 = llvm.load %191 : !llvm.ptr<f32, 3>
    %193 = llvm.extractvalue %189[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %194 = llvm.getelementptr %193[%178] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %195 = llvm.load %194 : !llvm.ptr<f32, 3>
    %196 = llvm.fadd %192, %195  : f32
    %197 = llvm.extractvalue %189[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %198 = llvm.getelementptr %197[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %196, %198 : !llvm.ptr<f32, 3>
    llvm.br ^bb11
  ^bb11:  // 2 preds: ^bb9, ^bb10
    nvvm.barrier0
    %199 = llvm.icmp "ult" %54, %33 : i32
    %200 = llvm.add %59, %33  : i32
    %201 = llvm.icmp "ult" %200, %40 : i32
    %202 = llvm.and %199, %201  : i1
    llvm.cond_br %202, ^bb12, ^bb13
  ^bb12:  // pred: ^bb11
    %203 = llvm.add %52, %37  : i32
    %204 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %205 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %206 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %207 = llvm.insertvalue %205, %204[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %208 = llvm.insertvalue %206, %207[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %209 = llvm.mlir.constant(0 : index) : i32
    %210 = llvm.insertvalue %209, %208[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %211 = llvm.mlir.constant(256 : index) : i32
    %212 = llvm.insertvalue %211, %210[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %213 = llvm.mlir.constant(1 : index) : i32
    %214 = llvm.insertvalue %213, %212[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %215 = llvm.extractvalue %214[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %216 = llvm.getelementptr %215[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %217 = llvm.load %216 : !llvm.ptr<f32, 3>
    %218 = llvm.extractvalue %214[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %219 = llvm.getelementptr %218[%203] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %220 = llvm.load %219 : !llvm.ptr<f32, 3>
    %221 = llvm.fadd %217, %220  : f32
    %222 = llvm.extractvalue %214[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %223 = llvm.getelementptr %222[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    llvm.store %221, %223 : !llvm.ptr<f32, 3>
    llvm.br ^bb13
  ^bb13:  // 2 preds: ^bb11, ^bb12
    nvvm.barrier0
    %224 = llvm.icmp "eq" %54, %45 : i32
    %225 = llvm.and %224, %64  : i1
    llvm.cond_br %225, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %226 = llvm.add %52, %43  : i32
    %227 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
    %228 = llvm.extractvalue %32[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %229 = llvm.extractvalue %32[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %230 = llvm.insertvalue %228, %227[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %231 = llvm.insertvalue %229, %230[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %232 = llvm.mlir.constant(0 : index) : i32
    %233 = llvm.insertvalue %232, %231[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %234 = llvm.mlir.constant(256 : index) : i32
    %235 = llvm.insertvalue %234, %233[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %236 = llvm.mlir.constant(1 : index) : i32
    %237 = llvm.insertvalue %236, %235[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %238 = llvm.extractvalue %237[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %239 = llvm.getelementptr %238[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %240 = llvm.load %239 : !llvm.ptr<f32, 3>
    %241 = llvm.extractvalue %237[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
    %242 = llvm.getelementptr %241[%226] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
    %243 = llvm.load %242 : !llvm.ptr<f32, 3>
    %244 = llvm.fadd %240, %243  : f32
    %245 = llvm.extractvalue %21[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %246 = llvm.getelementptr %245[%61] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %247 = llvm.atomicrmw fadd %246, %244 acq_rel : !llvm.ptr<f32>, f32
    llvm.br ^bb15
  ^bb15:  // 2 preds: ^bb13, ^bb14
    llvm.br ^bb16
  ^bb16:  // 2 preds: ^bb1, ^bb15
    llvm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
  %c256 = arith.constant 256 : index
  %c81920 = arith.constant 81920 : index
  %c20971520 = arith.constant 20971520 : index
  %c10 = arith.constant 10 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
  %alloc = memref.alloc() : memref<2560xf32, "gpu">
  gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%c10, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %alloc : memref<2560xf32, "gpu">)
  gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%c81920, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %c20971520 : index, %0 : memref<8192x2560xf32, "gpu">, %1 : memref<8192x2560xf32, "gpu">, %alloc : memref<2560xf32, "gpu">)
  "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %c256 = arith.constant 256 : index
    %c81920 = arith.constant 81920 : index
    %c20971520 = arith.constant 20971520 : index
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %alloc = memref.alloc() : memref<2560xf32, "gpu">
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%c10, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %alloc : memref<2560xf32, "gpu">)
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%c81920, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %c20971520 : index, %0 : memref<8192x2560xf32, "gpu">, %1 : memref<8192x2560xf32, "gpu">, %alloc : memref<2560xf32, "gpu">)
    "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\C8\01\00\00\00\00\00\00\01\00\01\01H\00\00\00\80\01\00\00\00\00\00\00|\01\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\03\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64/\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\0Ee__4_1_0___8w32h(\0A.param .u326\00\16\11_4\006_0,>\00/64>\00\1D\1F1>\00*/2,\BA\00)\1F3>\00*\1F4>\00*\F4\075\0A)\0A{\0A.reg .b32 %r<6>;\11\00\E264 %rd<5>;\0A\0Aldg\00\01f\00o%r1, [l\00\1C70];F\00\02\\\00\0FG\00 \F4\032];\0Acvta.to.globalM\00!2,S\00S;\0Amov\A7\00\00\13\00xctaid.x\17\00S3, %t\15\00qad.lo.s\18\00#4,4\00\00\E0\00\D3%r3;\0Amul.wide!\002d3,'\00\824;\0Aadd.sz\00&4,\80\00\183i\00\855, 0;\0Ast\AA\00@32 [1\00\10],\00\C05;\0Aret;\0A\0A}\0A\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\C8\03\00\00\00\00\00\00\C5\03\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00F\05F\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04 \00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04.\00r\00\04\1C\04\00\80\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\D3\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\8F\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00j\02\01\01\01\22H\00\01\00\00l\01/\05\00\01\00\FF\C8A\02z\01\00w\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\E4\03\B1\00\0E\00\00\E2\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05v\04\000\00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00p\D0\0F\00\86s\00\02`\001\00\E9\10`\003My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0a\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00@\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\A4\03\0D\88\05\03\15\00*\90\00\C8\03\04\ED\03\22\18\00\01\00\1F\FET\00\00\03\8E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\94\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B8)\00*\E0\00\01\00\1B\08\08\00!\0B\01\F4\04\0D\01\00\13\98\F5\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A8@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00D\05\00\00\08\80\06\80\00\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\F8\03\00\00\00\00\00\00\02\00\01\01@\00\00\00\B8\03\00\00\00\00\00\00\B4\03\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00K\05K\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04\1C\00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\D2\F0\11\00\03\1B\FF\00\04\1C\04\00p\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\CB\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\87\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00b\02\01\F9\00\22H\00\01\00\00d\01/\05\00\01\00\FF\D0A\02z\01\00w\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05f\04\00 \00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00\80\D0\0F\00\86s\00\02\FF0\00\A3\E9\10\00\00\E2\0F\00My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0Q\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\AC\03\0D\88\05\03\15\00*\90\00\D0\03\04\F5\03\22\18\00\01\00\1F\FET\00\00\03\9E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\8C\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B0)\00*\E0\00\01\00\1B\08\08\00!\0B\01\FC\04\0D\01\00\13\90\FD\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A0@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00Q\05\00\00\08\80\0E\00\A0\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: !llvm.ptr<f32>, %arg2: !llvm.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %1 = llvm.insertvalue %arg1, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %2 = llvm.insertvalue %arg2, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %3 = llvm.insertvalue %arg3, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %4 = llvm.insertvalue %arg4, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %5 = llvm.insertvalue %arg5, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %6 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %7 = nvvm.read.ptx.sreg.ctaid.x : i32
      %8 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %9 = llvm.mul %7, %arg0  : i32
      %10 = llvm.add %8, %9  : i32
      %11 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %12 = llvm.insertvalue %arg1, %11[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %13 = llvm.insertvalue %arg2, %12[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %14 = llvm.mlir.constant(0 : index) : i32
      %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %16 = llvm.mlir.constant(2560 : index) : i32
      %17 = llvm.insertvalue %16, %15[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %18 = llvm.mlir.constant(1 : index) : i32
      %19 = llvm.insertvalue %18, %17[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %20 = llvm.getelementptr %arg2[%10] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %6, %20 : !llvm.ptr<f32>
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\C0\05\00\00\00\00\00\00\01\00\01\01H\00\00\00x\05\00\00\00\00\00\00t\05\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\03\11\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2!\0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64\0A0\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\10e__4_1_0___8w32h_1(\0A.param .u328\00\18\11_6\00?_0,@\00+\171@\00/64@\00\1F\1F2@\00,\1F3\C0\00,\1F4@\00,\1F5@\00,\1F6@\00,\1F7@\00,\1F8\80\01,\1F9@\00,\1F1\81\02.\1F1A\00-\1F2A\00-\0F\84\02-\1F1\85\02-/15\86\01-\1F6A\00-\0F\88\02-/18A\00-\1F9A\00,\F3\0A20\0A)\0A{\0A.reg .pred %p<18>;\13\00\95b32 %r<24\12\00\10f\12\00\18f\12\00\F0\04b64 %rd<17>;\0A\0A\09.shaI\00\FF\03.align 4 .b8 __wg_\9E\00\18\B20[1024];\0Ald\E0\00\01\DF\00o%r5, [\E5\00\1E\1E0H\00\1F6H\00!s1];\0AmovC\00\B87, %ctaid.x\17\00S8, %t\15\00qad.lo.s\18\00#1,4\00\00\C4\00\C2%r8;\0Asetp.ge8\004p1,%\00\F4\0C6;\0A@%p1 bra $L__BB0_13;\0AshrL\00\130-\00\2231\17\00\02{\00311,\1D\00t24;\0Aadd/\00\132/\00\00#\00\09H\00#3,\1F\00c8;\0Aand\EF\01$14\17\00\93-256;\0Asub1\00\07I\00\194z\00\225,\1E\00\193H\00\136\16\00\947;\0Amul.hi/\00#7,~\00\A9-858993459O\00#8,&\00\128:\00\06F\01#9, \009320\9A\00&0,\D1\00\01M\00\13l\86\00$213\00\185\15\01&3,\1C\00\1950\00#2,P\00S3;\0Aor\16\00%4,\1B\00$16\BC\01\12t\B0\002p2,Q\00B8191\0C\02\02&\03s23, 0f0\01\00\01\D7\01\192\D7\01\183\99\02\02G\03\1F7\9A\02\22\00\E3\02\E4cvta.to.globalP\00\01\9C\00.d7i\00\1F8i\00!\1F3h\00\06\01P\01+d8\F6\02#23\1B\011256\A2\01\124\D1\013wid\F9\02Crd9,)\00\04\B5\02\02Q\00\02\E5\02\03X\00\119\C0\00\03r\00\02]\01A4, ['\00\1A]7\00&1,\F7\00\0F7\00\00\1357\00\221]?\02\02\16\00\226,R\00\B7%f5;\0Afma.rn\C4\01\03\1B\00\1A6\CE\01\05\C5\01\16:\D3\00\02\F6\003d12\FA\02\134\1B\04\02$\01\00\9F\02\0F\0A\05\1E\0A\DE\00$4,I\00\00\07\00S2;\0Astq\05\01\B0\00\01\DB\0014],\B9\00\CC;\0Abar.sync 0\B3\02\133\A1\00<127\1B\00\154\CE\02.75\AE\01\05\EB\03\0A\AE\01\0A\98\00\115:\03\03P\06#5,p\00!p4\03\03\195\03\03\115\A3\01\07\C3\002%f7\A3\01.4]\1B\00\138\1B\00C+512\F8\01\02\19\00\229,9\00?%f8\14\01\01\02\13\01\169\B5\01/5:\1D\01\08\04\B8\04,63\1A\00\157\1C\01(83\E4\00#8,7\00!p7\E4\00\198\E4\00\1E7\C9\00/10\E5\00\07$11\E6\009256\E6\00\01X\02\01<\00\00&\00\0F\E9\00\07&12\EA\00\1F7\EA\00\09\139\EA\00,31\1A\00&10\EB\00\187\EB\00\01a\03\019\00\22p1\D4\04\1A1\AC\06\1F9\D2\00\00\1F3\EE\00\08\144\EE\00:128\EE\00\00:\02\01<\00\00&\00\0F\EE\00\08\165\EE\00\1F9\EE\00\09\05\97\03-15\1B\00\163\EF\00\199\EF\00\00\DA\02\02:\002p13\F0\00\194\F0\00/11\D5\00\00/6,\F1\00\07\04\E0\02:+64\F0\00\00F\02\01;\00\00%\00\0F\F0\00\08\168\F0\00/11\F1\00\0A\166\82\07\07\C2\01$7,\1C\00\22p2\D2\00\1D7n\08\0C/\06\0F2\09#\1F70\06\06\02\A7\05\1F6a\04\00\01\B4\00\1C4a\04&5,6\00/16V\01\00\1F9r\01\07$20r\01\1A36\04\01\00\08\01;\00\00%\00d;\0Aatom\A8\00\07&\00\122?\00\115~\01'21~\01\C03:\0Aret;\0A\0A}\0A\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\C8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00\88\06\00\00\00\00\00\00\83\06\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\11\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00o\02\00\BE\00u\00\01\00\00\11\0E\06\00a\00F\05F\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00g2\00\00\00\12\10x\00\11\05\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13\F0\93\00\10\04\08\00R\04\18\00\00\00E\002\04\0C\01\18\00C/\08\00\06/\04\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00@\00\04\1C\0C&\01c\000\04\00\00\A0\D8\01#K\00\01\00q\02\02\08\10\0A/\22\BB\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\88\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00;\02\11,\90\01\11\00\09\01\22H\00\01\00\11\02t\01\0F\01\00\FF\F0@$v\01\FF\AF\05\D0\FF\00\8E\07\00\C4\0F\00\89\F3\FF\FF\FF\04\05\00\C2\04b\E2\0F\00\19y\00\01\00\10%\E3\02a\0E\00\19y\03\00\01\00\10!=\00`\0E\00$z\00\00[\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\DB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\04\FF\B9\02\10\03 \00q\E4\0F\00\12x\05\03\91\05\F1\00\C0\8E\07\00\C6\0F\00%x\02\04\CD\CC\CC\CC\B0\00a\C8\0F\00$x\00@\05b\05\0A\8E\07\00\E2`\00\01@\00\12\16`\00A\19x\02\FFa\00\14\16p\00 \09\03\FC\02!\FF(0\00\B2\04$x\03\03\C0\FE\FF\FF\04\02@\001\12x\02^\06\01p\00p\E4\0F\00\0Cx\00\09\B1\00@p@\F0\03\80\00Q$x\02\03\08\1F\04\92\8E\07\00\D2\0F\00\02\88\07\A6\06!\0F\000\01c$\88\06\09\00\0A \00\90\C8\0F\00%\86\04\06\00\\\F0\04\04\10\00F\06\06\00f\10\00!\81\83J\06\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\07\06\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03\B0\00#r\03\A0\01\04\F0\00\11\08\CC\03\10\FF6\00\01\D0\006\0A\00\04 \00\D4\04\0Cx\00\00\7F\00\00\00pDt\01\D0\00\11\F7P\00A\F2\03\00\C8\10\00!\00? \00\11\F2\C0\00\81!\82\0B\04\07\00\00\80\84\00\81\C8O\00#\82\03\04\0BP\00\02\E0\00\000\00\11\070\00\A1p\00\00\CE\0F\00\88s\00\08`\01\00\A6\04f\E8\0F\00\18y\00\01\00f\E2\0F\00\1D{\00\01\00b\EA\0F\00\84\A9\04\A5\07\12\180\000\84\A9\05.\01\02\10\00s$\0E\00!\A2\05\04\BB\07\AF\00\00\D0\1F\00\88\A3\00\0A\05`\00\19\17\99`\00\02\B0\00$\09\FB@\01\10\C6 \00!\07\0A2\02\00 \00\11\22`\01$\00\1F \01\00\00\01 \92\07\00\01\06\80\00O\93\00\0A\07\E0\00\1A\1D\03\80\00\14\FDp\01\13\C6\00\01)\80\00\80\00\18\0F\80\01Z\A2\03\03\04\00\00\01\1F\03\00\01%\00`\011\99\05\0A\B1\0C\04`\01\1B\92`\01\1F\93`\01\1B\0C\D0\03E\84y\00\0Ap\00W\E2\0F\00\02x\10\03\00\F0\00Wy\03\0A\00 \80\00!r\05\E0\08\01\01\00\93\E4\1F\00%v\02\02\00p\10\03q\D0\0F\00\8Ey\00\02\90\00!G\11P\00*Myp\00PGy\00\00\F0\10\04[\FF\83\03\00\C0\B0\00\0F\10\00 \0F\01\00-\00|\04.\03\00\01\00\02$\0E]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13\CC\07\0C\01\00\138U\00\11\A8\06\00\06\F0\07\00\E7\01\04\AF\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03#\00P\C5\02\04H\0B\04\E4\00*\04\00\01\00\1Fc@\00\04\13\80)\00&\8C\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\10\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\1C\09\0D\01\00\13\F0@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0D\84\01\03E\04\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\C8\0C\12\03\C0\01:\0E\80\00\01\00\13\97\94\00+\03\00\01\00\03\B0\10/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00x\06\00\00\00\00\00\00s\06\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\80\10\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\0D\07\00a\00K\05K\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00f2\00\00\00\12\10x\00\13\80;\00f\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\08\00R\04\14\00\00\00E\00#\04\F8\18\00\80/\08\00\06\00\00\00\0E\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\04\1C\0C\FE\00c\00\D0\03\00\00@\D0\01#K\00\01\00q\02\02\08\10\0A/\22\B3\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\003\02\11,\88\01\11\00\01\01\22H\00\01\00\11\02l\01\0F\01\00\FF\F8@$v\01\FF\AF\05\B2\FF\00\8E\07\00\C4\0F\00\19y\00\01\00\10%\DB\02a\0E\00\19y\03\00\01\00\10!-\00`\0E\00$z\00\00K\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\CB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\02\FF\B1\02\10\03 \00q\E4\0F\00\12x\03\03\81\05\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\CD\CC\CC\CC\A0\00a\C8\0F\00$x\000\05`\03\0A\8E\07\00\E2@\00\11\04@\00\22\04\16`\00\00p\00\01a\00\14\16p\00 \06\04\10\00!\FF(0\00\B2\04$x\03\04\C0\FE\FF\FF\02\02@\001\12x\02N\06\01p\00p\E4\0F\00\0Cx\00\06\B1\00@p@\F0\03\80\00Q$x\07\03\08\17\04\92\8E\07\00\D2\0F\00\02\88\05\96\060\0F\00\00@\00@$\88\04\06@\01\22\07\02\A0\00`%\86\02\04\00\\\C0\04\04\10\00F\04\04\00f\10\000\81\83\02\83\03\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\05\04\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03`\00Sr\08\FF\FF\00\A0\01\01\F0\00\11\0B\C4\03\10\FF\C5\03\80\E4\0F\04\0Cx\00\00\7F\98\064Dt\01\C0\00\11\F7@\00A\F2\03\00\C8\10\00!\00? \00\11\F2\B0\00\81!\82\09\02\05\00\00\80t\00\81\C8O\00#\82\08\02\09`\00\02\D0\00\000\00\11\070\00\22p\000\014\09\00\04\80\00\93\CC\0F\00\88s\00\0B\08\00\1E\05f\E8\0F\00\1D{\00\01\00Q\EA\0F\00\84\A9O\002\00\00\18 \00A\84\A9\03\09v\04\12\18@\02c!\A2\02\02\03\00\01\00\8F\D0\1F\00\88\A3\00\09\02P\00\095\99\03\09P\00\02\A0\00$\06\FB \01\10\C6 \00!\04\09\12\02\00 \00\11\22@\01$\00\1F\10\01\00\F0\00W\92\04\03\04\00p\00O\93\00\09\04\C0\00\0A\0Ep\00\14\FDP\01\00p\001\A9\08\09>\01\07p\00\18\0F`\01!\A2\080\02\08\E0\00\1F\08\E0\00\0A\0B0\01\00\F0\00&@\000\01\1B\920\01\1F\930\01\0B\0C\80\039\84y\00\D0\006\02x\02\C0\02\00\D0\00Wy\03\09\00 p\00!r\05\80\08\01\01\00p\E4\1F\00%v\02\07{\08\10\02\00\02`\D0\0F\00\8Ey\00@\02A\00\00G\11P\00*Myp\00PGy\00\00\F0\C0\03\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\01\0C\04\1E\00\01\00\02\A4\0D]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13T\07\0C\01\00\138U\00\11\A8\06\00\06x\07\00\B7\01\04\8F\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03!\00P\E5\01\10\00\86\09'\00\00\E4\00*\04\00\01\00\1Fc@\00\04\04@\0B&\84\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\08\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\A4\08\0D\01\00\13\E8@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0C\84\01\13\F8@\00\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\08\01\12\03\C0\01:\0E\80\00\01\00\13\97\94\00/\03\000\10\03/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00"} {
    llvm.mlir.global internal @__wg_main_kColReduction_reduce__4_1_0___8w32h_1_0() {addr_space = 3 : i32} : !llvm.array<256 x f32>
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<f32>, %arg10: !llvm.ptr<f32>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: !llvm.ptr<f32>, %arg17: !llvm.ptr<f32>, %arg18: i32, %arg19: i32, %arg20: i32) attributes {gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)>
      %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %5 = llvm.insertvalue %arg7, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %6 = llvm.insertvalue %arg6, %5[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %7 = llvm.insertvalue %arg8, %6[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %8 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)>
      %9 = llvm.insertvalue %arg9, %8[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %10 = llvm.insertvalue %arg10, %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %11 = llvm.insertvalue %arg11, %10[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %12 = llvm.insertvalue %arg12, %11[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %13 = llvm.insertvalue %arg14, %12[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %14 = llvm.insertvalue %arg13, %13[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %15 = llvm.insertvalue %arg15, %14[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %16 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %17 = llvm.insertvalue %arg16, %16[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %18 = llvm.insertvalue %arg17, %17[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %19 = llvm.insertvalue %arg18, %18[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %20 = llvm.insertvalue %arg19, %19[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %21 = llvm.insertvalue %arg20, %20[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %22 = llvm.mlir.addressof @__wg_main_kColReduction_reduce__4_1_0___8w32h_1_0 : !llvm.ptr<array<256 x f32>, 3>
      %23 = llvm.getelementptr %22[0, 0] : (!llvm.ptr<array<256 x f32>, 3>) -> !llvm.ptr<f32, 3>
      %24 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %25 = llvm.insertvalue %23, %24[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %26 = llvm.insertvalue %23, %25[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %27 = llvm.mlir.constant(0 : index) : i32
      %28 = llvm.insertvalue %27, %26[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %29 = llvm.mlir.constant(256 : index) : i32
      %30 = llvm.insertvalue %29, %28[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %31 = llvm.mlir.constant(1 : index) : i32
      %32 = llvm.insertvalue %31, %30[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %33 = llvm.mlir.constant(2 : index) : i32
      %34 = llvm.mlir.constant(4 : index) : i32
      %35 = llvm.mlir.constant(64 : index) : i32
      %36 = llvm.mlir.constant(128 : index) : i32
      %37 = llvm.mlir.constant(16 : index) : i32
      %38 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %39 = llvm.mlir.constant(2560 : index) : i32
      %40 = llvm.mlir.constant(8192 : index) : i32
      %41 = llvm.mlir.constant(32 : index) : i32
      %42 = llvm.mlir.constant(320 : index) : i32
      %43 = llvm.mlir.constant(8 : index) : i32
      %44 = llvm.mlir.constant(256 : index) : i32
      %45 = llvm.mlir.constant(0 : index) : i32
      %46 = nvvm.read.ptx.sreg.ctaid.x : i32
      %47 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %48 = llvm.mul %46, %arg0  : i32
      %49 = llvm.add %47, %48  : i32
      %50 = llvm.add %47, %48  : i32
      %51 = llvm.icmp "ult" %50, %arg1 : i32
      llvm.cond_br %51, ^bb2, ^bb16
    ^bb2:  // pred: ^bb1
      %52 = llvm.srem %49, %44  : i32
      %53 = llvm.sdiv %49, %44  : i32
      %54 = llvm.udiv %52, %43  : i32
      %55 = llvm.urem %52, %43  : i32
      %56 = llvm.udiv %53, %42  : i32
      %57 = llvm.urem %53, %42  : i32
      %58 = llvm.mul %56, %41  : i32
      %59 = llvm.add %58, %54  : i32
      %60 = llvm.mul %57, %43  : i32
      %61 = llvm.add %60, %55  : i32
      %62 = llvm.icmp "ult" %59, %40 : i32
      %63 = llvm.icmp "ult" %61, %39 : i32
      %64 = llvm.and %62, %63  : i1
      llvm.cond_br %64, ^bb3, ^bb4
    ^bb3:  // pred: ^bb2
      %65 = llvm.mul %59, %39  : i32
      %66 = llvm.add %65, %61  : i32
      %67 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %68 = llvm.insertvalue %arg2, %67[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %69 = llvm.insertvalue %arg3, %68[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %70 = llvm.mlir.constant(0 : index) : i32
      %71 = llvm.insertvalue %70, %69[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %72 = llvm.mlir.constant(20971520 : index) : i32
      %73 = llvm.insertvalue %72, %71[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %74 = llvm.mlir.constant(1 : index) : i32
      %75 = llvm.insertvalue %74, %73[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %76 = llvm.getelementptr %arg3[%66] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %77 = llvm.load %76 : !llvm.ptr<f32>
      %78 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %79 = llvm.insertvalue %arg9, %78[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %80 = llvm.insertvalue %arg10, %79[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %81 = llvm.mlir.constant(0 : index) : i32
      %82 = llvm.insertvalue %81, %80[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %83 = llvm.mlir.constant(20971520 : index) : i32
      %84 = llvm.insertvalue %83, %82[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %85 = llvm.mlir.constant(1 : index) : i32
      %86 = llvm.insertvalue %85, %84[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %87 = llvm.getelementptr %arg10[%66] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %88 = llvm.load %87 : !llvm.ptr<f32>
      %89 = llvm.fsub %77, %88  : f32
      %90 = llvm.fmul %89, %77  : f32
      %91 = llvm.fadd %90, %38  : f32
      %92 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %93 = llvm.insertvalue %23, %92[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %94 = llvm.insertvalue %23, %93[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %95 = llvm.mlir.constant(0 : index) : i32
      %96 = llvm.insertvalue %95, %94[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %97 = llvm.mlir.constant(256 : index) : i32
      %98 = llvm.insertvalue %97, %96[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %99 = llvm.mlir.constant(1 : index) : i32
      %100 = llvm.insertvalue %99, %98[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %101 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %91, %101 : !llvm.ptr<f32, 3>
      llvm.br ^bb5
    ^bb4:  // pred: ^bb2
      %102 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %103 = llvm.insertvalue %23, %102[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %104 = llvm.insertvalue %23, %103[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %105 = llvm.mlir.constant(0 : index) : i32
      %106 = llvm.insertvalue %105, %104[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %107 = llvm.mlir.constant(256 : index) : i32
      %108 = llvm.insertvalue %107, %106[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %109 = llvm.mlir.constant(1 : index) : i32
      %110 = llvm.insertvalue %109, %108[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %111 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %38, %111 : !llvm.ptr<f32, 3>
      llvm.br ^bb5
    ^bb5:  // 2 preds: ^bb3, ^bb4
      nvvm.barrier0
      %112 = llvm.icmp "ult" %54, %37 : i32
      %113 = llvm.add %59, %37  : i32
      %114 = llvm.icmp "ult" %113, %40 : i32
      %115 = llvm.and %112, %114  : i1
      llvm.cond_br %115, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      %116 = llvm.add %52, %36  : i32
      %117 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %118 = llvm.insertvalue %23, %117[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %119 = llvm.insertvalue %23, %118[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %120 = llvm.mlir.constant(0 : index) : i32
      %121 = llvm.insertvalue %120, %119[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %122 = llvm.mlir.constant(256 : index) : i32
      %123 = llvm.insertvalue %122, %121[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %124 = llvm.mlir.constant(1 : index) : i32
      %125 = llvm.insertvalue %124, %123[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %126 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %127 = llvm.load %126 : !llvm.ptr<f32, 3>
      %128 = llvm.getelementptr %23[%116] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %129 = llvm.load %128 : !llvm.ptr<f32, 3>
      %130 = llvm.fadd %127, %129  : f32
      %131 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %130, %131 : !llvm.ptr<f32, 3>
      llvm.br ^bb7
    ^bb7:  // 2 preds: ^bb5, ^bb6
      nvvm.barrier0
      %132 = llvm.icmp "ult" %54, %43 : i32
      %133 = llvm.add %59, %43  : i32
      %134 = llvm.icmp "ult" %133, %40 : i32
      %135 = llvm.and %132, %134  : i1
      llvm.cond_br %135, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %136 = llvm.add %52, %35  : i32
      %137 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %138 = llvm.insertvalue %23, %137[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %139 = llvm.insertvalue %23, %138[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %140 = llvm.mlir.constant(0 : index) : i32
      %141 = llvm.insertvalue %140, %139[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %142 = llvm.mlir.constant(256 : index) : i32
      %143 = llvm.insertvalue %142, %141[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %144 = llvm.mlir.constant(1 : index) : i32
      %145 = llvm.insertvalue %144, %143[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %146 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %147 = llvm.load %146 : !llvm.ptr<f32, 3>
      %148 = llvm.getelementptr %23[%136] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %149 = llvm.load %148 : !llvm.ptr<f32, 3>
      %150 = llvm.fadd %147, %149  : f32
      %151 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %150, %151 : !llvm.ptr<f32, 3>
      llvm.br ^bb9
    ^bb9:  // 2 preds: ^bb7, ^bb8
      nvvm.barrier0
      %152 = llvm.icmp "ult" %54, %34 : i32
      %153 = llvm.add %59, %34  : i32
      %154 = llvm.icmp "ult" %153, %40 : i32
      %155 = llvm.and %152, %154  : i1
      llvm.cond_br %155, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %156 = llvm.add %52, %41  : i32
      %157 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %158 = llvm.insertvalue %23, %157[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %159 = llvm.insertvalue %23, %158[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %160 = llvm.mlir.constant(0 : index) : i32
      %161 = llvm.insertvalue %160, %159[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %162 = llvm.mlir.constant(256 : index) : i32
      %163 = llvm.insertvalue %162, %161[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %164 = llvm.mlir.constant(1 : index) : i32
      %165 = llvm.insertvalue %164, %163[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %166 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %167 = llvm.load %166 : !llvm.ptr<f32, 3>
      %168 = llvm.getelementptr %23[%156] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %169 = llvm.load %168 : !llvm.ptr<f32, 3>
      %170 = llvm.fadd %167, %169  : f32
      %171 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %170, %171 : !llvm.ptr<f32, 3>
      llvm.br ^bb11
    ^bb11:  // 2 preds: ^bb9, ^bb10
      nvvm.barrier0
      %172 = llvm.icmp "ult" %54, %33 : i32
      %173 = llvm.add %59, %33  : i32
      %174 = llvm.icmp "ult" %173, %40 : i32
      %175 = llvm.and %172, %174  : i1
      llvm.cond_br %175, ^bb12, ^bb13
    ^bb12:  // pred: ^bb11
      %176 = llvm.add %52, %37  : i32
      %177 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %178 = llvm.insertvalue %23, %177[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %179 = llvm.insertvalue %23, %178[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %180 = llvm.mlir.constant(0 : index) : i32
      %181 = llvm.insertvalue %180, %179[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %182 = llvm.mlir.constant(256 : index) : i32
      %183 = llvm.insertvalue %182, %181[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %184 = llvm.mlir.constant(1 : index) : i32
      %185 = llvm.insertvalue %184, %183[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %186 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %187 = llvm.load %186 : !llvm.ptr<f32, 3>
      %188 = llvm.getelementptr %23[%176] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %189 = llvm.load %188 : !llvm.ptr<f32, 3>
      %190 = llvm.fadd %187, %189  : f32
      %191 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %190, %191 : !llvm.ptr<f32, 3>
      llvm.br ^bb13
    ^bb13:  // 2 preds: ^bb11, ^bb12
      nvvm.barrier0
      %192 = llvm.icmp "eq" %54, %45 : i32
      %193 = llvm.and %192, %64  : i1
      llvm.cond_br %193, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %194 = llvm.add %52, %43  : i32
      %195 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %196 = llvm.insertvalue %23, %195[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %197 = llvm.insertvalue %23, %196[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %198 = llvm.mlir.constant(0 : index) : i32
      %199 = llvm.insertvalue %198, %197[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %200 = llvm.mlir.constant(256 : index) : i32
      %201 = llvm.insertvalue %200, %199[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %202 = llvm.mlir.constant(1 : index) : i32
      %203 = llvm.insertvalue %202, %201[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %204 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %205 = llvm.load %204 : !llvm.ptr<f32, 3>
      %206 = llvm.getelementptr %23[%194] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %207 = llvm.load %206 : !llvm.ptr<f32, 3>
      %208 = llvm.fadd %205, %207  : f32
      %209 = llvm.getelementptr %arg17[%61] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %210 = llvm.atomicrmw fadd %209, %208 acq_rel : !llvm.ptr<f32>, f32
      llvm.br ^bb15
    ^bb15:  // 2 preds: ^bb13, ^bb14
      llvm.br ^bb16
    ^bb16:  // 2 preds: ^bb1, ^bb15
      llvm.return
    }
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %c256 = arith.constant 256 : index
    %c81920 = arith.constant 81920 : index
    %c20971520 = arith.constant 20971520 : index
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %alloc = memref.alloc() : memref<2560xf32, "gpu">
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%c10, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %alloc : memref<2560xf32, "gpu">)
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%c81920, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %c20971520 : index, %0 : memref<8192x2560xf32, "gpu">, %1 : memref<8192x2560xf32, "gpu">, %alloc : memref<2560xf32, "gpu">)
    "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\C8\01\00\00\00\00\00\00\01\00\01\01H\00\00\00\80\01\00\00\00\00\00\00|\01\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\03\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64/\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\0Ee__4_1_0___8w32h(\0A.param .u326\00\16\11_4\006_0,>\00/64>\00\1D\1F1>\00*/2,\BA\00)\1F3>\00*\1F4>\00*\F4\075\0A)\0A{\0A.reg .b32 %r<6>;\11\00\E264 %rd<5>;\0A\0Aldg\00\01f\00o%r1, [l\00\1C70];F\00\02\\\00\0FG\00 \F4\032];\0Acvta.to.globalM\00!2,S\00S;\0Amov\A7\00\00\13\00xctaid.x\17\00S3, %t\15\00qad.lo.s\18\00#4,4\00\00\E0\00\D3%r3;\0Amul.wide!\002d3,'\00\824;\0Aadd.sz\00&4,\80\00\183i\00\855, 0;\0Ast\AA\00@32 [1\00\10],\00\C05;\0Aret;\0A\0A}\0A\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\C8\03\00\00\00\00\00\00\C5\03\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00F\05F\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04 \00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04.\00r\00\04\1C\04\00\80\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\D3\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\8F\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00j\02\01\01\01\22H\00\01\00\00l\01/\05\00\01\00\FF\C8A\02z\01\00w\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\E4\03\B1\00\0E\00\00\E2\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05v\04\000\00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00p\D0\0F\00\86s\00\02`\001\00\E9\10`\003My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0a\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00@\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\A4\03\0D\88\05\03\15\00*\90\00\C8\03\04\ED\03\22\18\00\01\00\1F\FET\00\00\03\8E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\94\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B8)\00*\E0\00\01\00\1B\08\08\00!\0B\01\F4\04\0D\01\00\13\98\F5\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A8@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00D\05\00\00\08\80\06\80\00\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\F8\03\00\00\00\00\00\00\02\00\01\01@\00\00\00\B8\03\00\00\00\00\00\00\B4\03\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00K\05K\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04\1C\00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\D2\F0\11\00\03\1B\FF\00\04\1C\04\00p\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\CB\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\87\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00b\02\01\F9\00\22H\00\01\00\00d\01/\05\00\01\00\FF\D0A\02z\01\00w\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05f\04\00 \00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00\80\D0\0F\00\86s\00\02\FF0\00\A3\E9\10\00\00\E2\0F\00My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0Q\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\AC\03\0D\88\05\03\15\00*\90\00\D0\03\04\F5\03\22\18\00\01\00\1F\FET\00\00\03\9E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\8C\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B0)\00*\E0\00\01\00\1B\08\08\00!\0B\01\FC\04\0D\01\00\13\90\FD\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A0@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00Q\05\00\00\08\80\0E\00\A0\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: !llvm.ptr<f32>, %arg2: !llvm.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %1 = llvm.insertvalue %arg1, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %2 = llvm.insertvalue %arg2, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %3 = llvm.insertvalue %arg3, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %4 = llvm.insertvalue %arg4, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %5 = llvm.insertvalue %arg5, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %6 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %7 = nvvm.read.ptx.sreg.ctaid.x : i32
      %8 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %9 = llvm.mul %7, %arg0  : i32
      %10 = llvm.add %8, %9  : i32
      %11 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %12 = llvm.insertvalue %arg1, %11[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %13 = llvm.insertvalue %arg2, %12[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %14 = llvm.mlir.constant(0 : index) : i32
      %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %16 = llvm.mlir.constant(2560 : index) : i32
      %17 = llvm.insertvalue %16, %15[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %18 = llvm.mlir.constant(1 : index) : i32
      %19 = llvm.insertvalue %18, %17[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %20 = llvm.getelementptr %arg2[%10] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %6, %20 : !llvm.ptr<f32>
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\C0\05\00\00\00\00\00\00\01\00\01\01H\00\00\00x\05\00\00\00\00\00\00t\05\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\03\11\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2!\0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64\0A0\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\10e__4_1_0___8w32h_1(\0A.param .u328\00\18\11_6\00?_0,@\00+\171@\00/64@\00\1F\1F2@\00,\1F3\C0\00,\1F4@\00,\1F5@\00,\1F6@\00,\1F7@\00,\1F8\80\01,\1F9@\00,\1F1\81\02.\1F1A\00-\1F2A\00-\0F\84\02-\1F1\85\02-/15\86\01-\1F6A\00-\0F\88\02-/18A\00-\1F9A\00,\F3\0A20\0A)\0A{\0A.reg .pred %p<18>;\13\00\95b32 %r<24\12\00\10f\12\00\18f\12\00\F0\04b64 %rd<17>;\0A\0A\09.shaI\00\FF\03.align 4 .b8 __wg_\9E\00\18\B20[1024];\0Ald\E0\00\01\DF\00o%r5, [\E5\00\1E\1E0H\00\1F6H\00!s1];\0AmovC\00\B87, %ctaid.x\17\00S8, %t\15\00qad.lo.s\18\00#1,4\00\00\C4\00\C2%r8;\0Asetp.ge8\004p1,%\00\F4\0C6;\0A@%p1 bra $L__BB0_13;\0AshrL\00\130-\00\2231\17\00\02{\00311,\1D\00t24;\0Aadd/\00\132/\00\00#\00\09H\00#3,\1F\00c8;\0Aand\EF\01$14\17\00\93-256;\0Asub1\00\07I\00\194z\00\225,\1E\00\193H\00\136\16\00\947;\0Amul.hi/\00#7,~\00\A9-858993459O\00#8,&\00\128:\00\06F\01#9, \009320\9A\00&0,\D1\00\01M\00\13l\86\00$213\00\185\15\01&3,\1C\00\1950\00#2,P\00S3;\0Aor\16\00%4,\1B\00$16\BC\01\12t\B0\002p2,Q\00B8191\0C\02\02&\03s23, 0f0\01\00\01\D7\01\192\D7\01\183\99\02\02G\03\1F7\9A\02\22\00\E3\02\E4cvta.to.globalP\00\01\9C\00.d7i\00\1F8i\00!\1F3h\00\06\01P\01+d8\F6\02#23\1B\011256\A2\01\124\D1\013wid\F9\02Crd9,)\00\04\B5\02\02Q\00\02\E5\02\03X\00\119\C0\00\03r\00\02]\01A4, ['\00\1A]7\00&1,\F7\00\0F7\00\00\1357\00\221]?\02\02\16\00\226,R\00\B7%f5;\0Afma.rn\C4\01\03\1B\00\1A6\CE\01\05\C5\01\16:\D3\00\02\F6\003d12\FA\02\134\1B\04\02$\01\00\9F\02\0F\0A\05\1E\0A\DE\00$4,I\00\00\07\00S2;\0Astq\05\01\B0\00\01\DB\0014],\B9\00\CC;\0Abar.sync 0\B3\02\133\A1\00<127\1B\00\154\CE\02.75\AE\01\05\EB\03\0A\AE\01\0A\98\00\115:\03\03P\06#5,p\00!p4\03\03\195\03\03\115\A3\01\07\C3\002%f7\A3\01.4]\1B\00\138\1B\00C+512\F8\01\02\19\00\229,9\00?%f8\14\01\01\02\13\01\169\B5\01/5:\1D\01\08\04\B8\04,63\1A\00\157\1C\01(83\E4\00#8,7\00!p7\E4\00\198\E4\00\1E7\C9\00/10\E5\00\07$11\E6\009256\E6\00\01X\02\01<\00\00&\00\0F\E9\00\07&12\EA\00\1F7\EA\00\09\139\EA\00,31\1A\00&10\EB\00\187\EB\00\01a\03\019\00\22p1\D4\04\1A1\AC\06\1F9\D2\00\00\1F3\EE\00\08\144\EE\00:128\EE\00\00:\02\01<\00\00&\00\0F\EE\00\08\165\EE\00\1F9\EE\00\09\05\97\03-15\1B\00\163\EF\00\199\EF\00\00\DA\02\02:\002p13\F0\00\194\F0\00/11\D5\00\00/6,\F1\00\07\04\E0\02:+64\F0\00\00F\02\01;\00\00%\00\0F\F0\00\08\168\F0\00/11\F1\00\0A\166\82\07\07\C2\01$7,\1C\00\22p2\D2\00\1D7n\08\0C/\06\0F2\09#\1F70\06\06\02\A7\05\1F6a\04\00\01\B4\00\1C4a\04&5,6\00/16V\01\00\1F9r\01\07$20r\01\1A36\04\01\00\08\01;\00\00%\00d;\0Aatom\A8\00\07&\00\122?\00\115~\01'21~\01\C03:\0Aret;\0A\0A}\0A\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\C8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00\88\06\00\00\00\00\00\00\83\06\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\11\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00o\02\00\BE\00u\00\01\00\00\11\0E\06\00a\00F\05F\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00g2\00\00\00\12\10x\00\11\05\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13\F0\93\00\10\04\08\00R\04\18\00\00\00E\002\04\0C\01\18\00C/\08\00\06/\04\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00@\00\04\1C\0C&\01c\000\04\00\00\A0\D8\01#K\00\01\00q\02\02\08\10\0A/\22\BB\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\88\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00;\02\11,\90\01\11\00\09\01\22H\00\01\00\11\02t\01\0F\01\00\FF\F0@$v\01\FF\AF\05\D0\FF\00\8E\07\00\C4\0F\00\89\F3\FF\FF\FF\04\05\00\C2\04b\E2\0F\00\19y\00\01\00\10%\E3\02a\0E\00\19y\03\00\01\00\10!=\00`\0E\00$z\00\00[\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\DB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\04\FF\B9\02\10\03 \00q\E4\0F\00\12x\05\03\91\05\F1\00\C0\8E\07\00\C6\0F\00%x\02\04\CD\CC\CC\CC\B0\00a\C8\0F\00$x\00@\05b\05\0A\8E\07\00\E2`\00\01@\00\12\16`\00A\19x\02\FFa\00\14\16p\00 \09\03\FC\02!\FF(0\00\B2\04$x\03\03\C0\FE\FF\FF\04\02@\001\12x\02^\06\01p\00p\E4\0F\00\0Cx\00\09\B1\00@p@\F0\03\80\00Q$x\02\03\08\1F\04\92\8E\07\00\D2\0F\00\02\88\07\A6\06!\0F\000\01c$\88\06\09\00\0A \00\90\C8\0F\00%\86\04\06\00\\\F0\04\04\10\00F\06\06\00f\10\00!\81\83J\06\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\07\06\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03\B0\00#r\03\A0\01\04\F0\00\11\08\CC\03\10\FF6\00\01\D0\006\0A\00\04 \00\D4\04\0Cx\00\00\7F\00\00\00pDt\01\D0\00\11\F7P\00A\F2\03\00\C8\10\00!\00? \00\11\F2\C0\00\81!\82\0B\04\07\00\00\80\84\00\81\C8O\00#\82\03\04\0BP\00\02\E0\00\000\00\11\070\00\A1p\00\00\CE\0F\00\88s\00\08`\01\00\A6\04f\E8\0F\00\18y\00\01\00f\E2\0F\00\1D{\00\01\00b\EA\0F\00\84\A9\04\A5\07\12\180\000\84\A9\05.\01\02\10\00s$\0E\00!\A2\05\04\BB\07\AF\00\00\D0\1F\00\88\A3\00\0A\05`\00\19\17\99`\00\02\B0\00$\09\FB@\01\10\C6 \00!\07\0A2\02\00 \00\11\22`\01$\00\1F \01\00\00\01 \92\07\00\01\06\80\00O\93\00\0A\07\E0\00\1A\1D\03\80\00\14\FDp\01\13\C6\00\01)\80\00\80\00\18\0F\80\01Z\A2\03\03\04\00\00\01\1F\03\00\01%\00`\011\99\05\0A\B1\0C\04`\01\1B\92`\01\1F\93`\01\1B\0C\D0\03E\84y\00\0Ap\00W\E2\0F\00\02x\10\03\00\F0\00Wy\03\0A\00 \80\00!r\05\E0\08\01\01\00\93\E4\1F\00%v\02\02\00p\10\03q\D0\0F\00\8Ey\00\02\90\00!G\11P\00*Myp\00PGy\00\00\F0\10\04[\FF\83\03\00\C0\B0\00\0F\10\00 \0F\01\00-\00|\04.\03\00\01\00\02$\0E]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13\CC\07\0C\01\00\138U\00\11\A8\06\00\06\F0\07\00\E7\01\04\AF\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03#\00P\C5\02\04H\0B\04\E4\00*\04\00\01\00\1Fc@\00\04\13\80)\00&\8C\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\10\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\1C\09\0D\01\00\13\F0@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0D\84\01\03E\04\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\C8\0C\12\03\C0\01:\0E\80\00\01\00\13\97\94\00+\03\00\01\00\03\B0\10/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00x\06\00\00\00\00\00\00s\06\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\80\10\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\0D\07\00a\00K\05K\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00f2\00\00\00\12\10x\00\13\80;\00f\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\08\00R\04\14\00\00\00E\00#\04\F8\18\00\80/\08\00\06\00\00\00\0E\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\04\1C\0C\FE\00c\00\D0\03\00\00@\D0\01#K\00\01\00q\02\02\08\10\0A/\22\B3\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\003\02\11,\88\01\11\00\01\01\22H\00\01\00\11\02l\01\0F\01\00\FF\F8@$v\01\FF\AF\05\B2\FF\00\8E\07\00\C4\0F\00\19y\00\01\00\10%\DB\02a\0E\00\19y\03\00\01\00\10!-\00`\0E\00$z\00\00K\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\CB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\02\FF\B1\02\10\03 \00q\E4\0F\00\12x\03\03\81\05\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\CD\CC\CC\CC\A0\00a\C8\0F\00$x\000\05`\03\0A\8E\07\00\E2@\00\11\04@\00\22\04\16`\00\00p\00\01a\00\14\16p\00 \06\04\10\00!\FF(0\00\B2\04$x\03\04\C0\FE\FF\FF\02\02@\001\12x\02N\06\01p\00p\E4\0F\00\0Cx\00\06\B1\00@p@\F0\03\80\00Q$x\07\03\08\17\04\92\8E\07\00\D2\0F\00\02\88\05\96\060\0F\00\00@\00@$\88\04\06@\01\22\07\02\A0\00`%\86\02\04\00\\\C0\04\04\10\00F\04\04\00f\10\000\81\83\02\83\03\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\05\04\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03`\00Sr\08\FF\FF\00\A0\01\01\F0\00\11\0B\C4\03\10\FF\C5\03\80\E4\0F\04\0Cx\00\00\7F\98\064Dt\01\C0\00\11\F7@\00A\F2\03\00\C8\10\00!\00? \00\11\F2\B0\00\81!\82\09\02\05\00\00\80t\00\81\C8O\00#\82\08\02\09`\00\02\D0\00\000\00\11\070\00\22p\000\014\09\00\04\80\00\93\CC\0F\00\88s\00\0B\08\00\1E\05f\E8\0F\00\1D{\00\01\00Q\EA\0F\00\84\A9O\002\00\00\18 \00A\84\A9\03\09v\04\12\18@\02c!\A2\02\02\03\00\01\00\8F\D0\1F\00\88\A3\00\09\02P\00\095\99\03\09P\00\02\A0\00$\06\FB \01\10\C6 \00!\04\09\12\02\00 \00\11\22@\01$\00\1F\10\01\00\F0\00W\92\04\03\04\00p\00O\93\00\09\04\C0\00\0A\0Ep\00\14\FDP\01\00p\001\A9\08\09>\01\07p\00\18\0F`\01!\A2\080\02\08\E0\00\1F\08\E0\00\0A\0B0\01\00\F0\00&@\000\01\1B\920\01\1F\930\01\0B\0C\80\039\84y\00\D0\006\02x\02\C0\02\00\D0\00Wy\03\09\00 p\00!r\05\80\08\01\01\00p\E4\1F\00%v\02\07{\08\10\02\00\02`\D0\0F\00\8Ey\00@\02A\00\00G\11P\00*Myp\00PGy\00\00\F0\C0\03\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\01\0C\04\1E\00\01\00\02\A4\0D]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13T\07\0C\01\00\138U\00\11\A8\06\00\06x\07\00\B7\01\04\8F\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03!\00P\E5\01\10\00\86\09'\00\00\E4\00*\04\00\01\00\1Fc@\00\04\04@\0B&\84\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\08\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\A4\08\0D\01\00\13\E8@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0C\84\01\13\F8@\00\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\08\01\12\03\C0\01:\0E\80\00\01\00\13\97\94\00/\03\000\10\03/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00"} {
    llvm.mlir.global internal @__wg_main_kColReduction_reduce__4_1_0___8w32h_1_0() {addr_space = 3 : i32} : !llvm.array<256 x f32>
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<f32>, %arg10: !llvm.ptr<f32>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: !llvm.ptr<f32>, %arg17: !llvm.ptr<f32>, %arg18: i32, %arg19: i32, %arg20: i32) attributes {gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)>
      %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %5 = llvm.insertvalue %arg7, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %6 = llvm.insertvalue %arg6, %5[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %7 = llvm.insertvalue %arg8, %6[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %8 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)>
      %9 = llvm.insertvalue %arg9, %8[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %10 = llvm.insertvalue %arg10, %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %11 = llvm.insertvalue %arg11, %10[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %12 = llvm.insertvalue %arg12, %11[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %13 = llvm.insertvalue %arg14, %12[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %14 = llvm.insertvalue %arg13, %13[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %15 = llvm.insertvalue %arg15, %14[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %16 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %17 = llvm.insertvalue %arg16, %16[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %18 = llvm.insertvalue %arg17, %17[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %19 = llvm.insertvalue %arg18, %18[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %20 = llvm.insertvalue %arg19, %19[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %21 = llvm.insertvalue %arg20, %20[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %22 = llvm.mlir.addressof @__wg_main_kColReduction_reduce__4_1_0___8w32h_1_0 : !llvm.ptr<array<256 x f32>, 3>
      %23 = llvm.getelementptr %22[0, 0] : (!llvm.ptr<array<256 x f32>, 3>) -> !llvm.ptr<f32, 3>
      %24 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %25 = llvm.insertvalue %23, %24[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %26 = llvm.insertvalue %23, %25[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %27 = llvm.mlir.constant(0 : index) : i32
      %28 = llvm.insertvalue %27, %26[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %29 = llvm.mlir.constant(256 : index) : i32
      %30 = llvm.insertvalue %29, %28[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %31 = llvm.mlir.constant(1 : index) : i32
      %32 = llvm.insertvalue %31, %30[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %33 = llvm.mlir.constant(2 : index) : i32
      %34 = llvm.mlir.constant(4 : index) : i32
      %35 = llvm.mlir.constant(64 : index) : i32
      %36 = llvm.mlir.constant(128 : index) : i32
      %37 = llvm.mlir.constant(16 : index) : i32
      %38 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %39 = llvm.mlir.constant(2560 : index) : i32
      %40 = llvm.mlir.constant(8192 : index) : i32
      %41 = llvm.mlir.constant(32 : index) : i32
      %42 = llvm.mlir.constant(320 : index) : i32
      %43 = llvm.mlir.constant(8 : index) : i32
      %44 = llvm.mlir.constant(256 : index) : i32
      %45 = llvm.mlir.constant(0 : index) : i32
      %46 = nvvm.read.ptx.sreg.ctaid.x : i32
      %47 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %48 = llvm.mul %46, %arg0  : i32
      %49 = llvm.add %47, %48  : i32
      %50 = llvm.add %47, %48  : i32
      %51 = llvm.icmp "ult" %50, %arg1 : i32
      llvm.cond_br %51, ^bb2, ^bb16
    ^bb2:  // pred: ^bb1
      %52 = llvm.srem %49, %44  : i32
      %53 = llvm.sdiv %49, %44  : i32
      %54 = llvm.udiv %52, %43  : i32
      %55 = llvm.urem %52, %43  : i32
      %56 = llvm.udiv %53, %42  : i32
      %57 = llvm.urem %53, %42  : i32
      %58 = llvm.mul %56, %41  : i32
      %59 = llvm.add %58, %54  : i32
      %60 = llvm.mul %57, %43  : i32
      %61 = llvm.add %60, %55  : i32
      %62 = llvm.icmp "ult" %59, %40 : i32
      %63 = llvm.icmp "ult" %61, %39 : i32
      %64 = llvm.and %62, %63  : i1
      llvm.cond_br %64, ^bb3, ^bb4
    ^bb3:  // pred: ^bb2
      %65 = llvm.mul %59, %39  : i32
      %66 = llvm.add %65, %61  : i32
      %67 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %68 = llvm.insertvalue %arg2, %67[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %69 = llvm.insertvalue %arg3, %68[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %70 = llvm.mlir.constant(0 : index) : i32
      %71 = llvm.insertvalue %70, %69[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %72 = llvm.mlir.constant(20971520 : index) : i32
      %73 = llvm.insertvalue %72, %71[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %74 = llvm.mlir.constant(1 : index) : i32
      %75 = llvm.insertvalue %74, %73[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %76 = llvm.getelementptr %arg3[%66] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %77 = llvm.load %76 : !llvm.ptr<f32>
      %78 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %79 = llvm.insertvalue %arg9, %78[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %80 = llvm.insertvalue %arg10, %79[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %81 = llvm.mlir.constant(0 : index) : i32
      %82 = llvm.insertvalue %81, %80[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %83 = llvm.mlir.constant(20971520 : index) : i32
      %84 = llvm.insertvalue %83, %82[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %85 = llvm.mlir.constant(1 : index) : i32
      %86 = llvm.insertvalue %85, %84[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %87 = llvm.getelementptr %arg10[%66] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %88 = llvm.load %87 : !llvm.ptr<f32>
      %89 = llvm.fsub %77, %88  : f32
      %90 = llvm.fmul %89, %77  : f32
      %91 = llvm.fadd %90, %38  : f32
      %92 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %93 = llvm.insertvalue %23, %92[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %94 = llvm.insertvalue %23, %93[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %95 = llvm.mlir.constant(0 : index) : i32
      %96 = llvm.insertvalue %95, %94[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %97 = llvm.mlir.constant(256 : index) : i32
      %98 = llvm.insertvalue %97, %96[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %99 = llvm.mlir.constant(1 : index) : i32
      %100 = llvm.insertvalue %99, %98[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %101 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %91, %101 : !llvm.ptr<f32, 3>
      llvm.br ^bb5
    ^bb4:  // pred: ^bb2
      %102 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %103 = llvm.insertvalue %23, %102[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %104 = llvm.insertvalue %23, %103[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %105 = llvm.mlir.constant(0 : index) : i32
      %106 = llvm.insertvalue %105, %104[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %107 = llvm.mlir.constant(256 : index) : i32
      %108 = llvm.insertvalue %107, %106[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %109 = llvm.mlir.constant(1 : index) : i32
      %110 = llvm.insertvalue %109, %108[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %111 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %38, %111 : !llvm.ptr<f32, 3>
      llvm.br ^bb5
    ^bb5:  // 2 preds: ^bb3, ^bb4
      nvvm.barrier0
      %112 = llvm.icmp "ult" %54, %37 : i32
      %113 = llvm.add %59, %37  : i32
      %114 = llvm.icmp "ult" %113, %40 : i32
      %115 = llvm.and %112, %114  : i1
      llvm.cond_br %115, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      %116 = llvm.add %52, %36  : i32
      %117 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %118 = llvm.insertvalue %23, %117[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %119 = llvm.insertvalue %23, %118[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %120 = llvm.mlir.constant(0 : index) : i32
      %121 = llvm.insertvalue %120, %119[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %122 = llvm.mlir.constant(256 : index) : i32
      %123 = llvm.insertvalue %122, %121[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %124 = llvm.mlir.constant(1 : index) : i32
      %125 = llvm.insertvalue %124, %123[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %126 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %127 = llvm.load %126 : !llvm.ptr<f32, 3>
      %128 = llvm.getelementptr %23[%116] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %129 = llvm.load %128 : !llvm.ptr<f32, 3>
      %130 = llvm.fadd %127, %129  : f32
      %131 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %130, %131 : !llvm.ptr<f32, 3>
      llvm.br ^bb7
    ^bb7:  // 2 preds: ^bb5, ^bb6
      nvvm.barrier0
      %132 = llvm.icmp "ult" %54, %43 : i32
      %133 = llvm.add %59, %43  : i32
      %134 = llvm.icmp "ult" %133, %40 : i32
      %135 = llvm.and %132, %134  : i1
      llvm.cond_br %135, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %136 = llvm.add %52, %35  : i32
      %137 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %138 = llvm.insertvalue %23, %137[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %139 = llvm.insertvalue %23, %138[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %140 = llvm.mlir.constant(0 : index) : i32
      %141 = llvm.insertvalue %140, %139[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %142 = llvm.mlir.constant(256 : index) : i32
      %143 = llvm.insertvalue %142, %141[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %144 = llvm.mlir.constant(1 : index) : i32
      %145 = llvm.insertvalue %144, %143[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %146 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %147 = llvm.load %146 : !llvm.ptr<f32, 3>
      %148 = llvm.getelementptr %23[%136] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %149 = llvm.load %148 : !llvm.ptr<f32, 3>
      %150 = llvm.fadd %147, %149  : f32
      %151 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %150, %151 : !llvm.ptr<f32, 3>
      llvm.br ^bb9
    ^bb9:  // 2 preds: ^bb7, ^bb8
      nvvm.barrier0
      %152 = llvm.icmp "ult" %54, %34 : i32
      %153 = llvm.add %59, %34  : i32
      %154 = llvm.icmp "ult" %153, %40 : i32
      %155 = llvm.and %152, %154  : i1
      llvm.cond_br %155, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %156 = llvm.add %52, %41  : i32
      %157 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %158 = llvm.insertvalue %23, %157[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %159 = llvm.insertvalue %23, %158[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %160 = llvm.mlir.constant(0 : index) : i32
      %161 = llvm.insertvalue %160, %159[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %162 = llvm.mlir.constant(256 : index) : i32
      %163 = llvm.insertvalue %162, %161[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %164 = llvm.mlir.constant(1 : index) : i32
      %165 = llvm.insertvalue %164, %163[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %166 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %167 = llvm.load %166 : !llvm.ptr<f32, 3>
      %168 = llvm.getelementptr %23[%156] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %169 = llvm.load %168 : !llvm.ptr<f32, 3>
      %170 = llvm.fadd %167, %169  : f32
      %171 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %170, %171 : !llvm.ptr<f32, 3>
      llvm.br ^bb11
    ^bb11:  // 2 preds: ^bb9, ^bb10
      nvvm.barrier0
      %172 = llvm.icmp "ult" %54, %33 : i32
      %173 = llvm.add %59, %33  : i32
      %174 = llvm.icmp "ult" %173, %40 : i32
      %175 = llvm.and %172, %174  : i1
      llvm.cond_br %175, ^bb12, ^bb13
    ^bb12:  // pred: ^bb11
      %176 = llvm.add %52, %37  : i32
      %177 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %178 = llvm.insertvalue %23, %177[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %179 = llvm.insertvalue %23, %178[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %180 = llvm.mlir.constant(0 : index) : i32
      %181 = llvm.insertvalue %180, %179[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %182 = llvm.mlir.constant(256 : index) : i32
      %183 = llvm.insertvalue %182, %181[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %184 = llvm.mlir.constant(1 : index) : i32
      %185 = llvm.insertvalue %184, %183[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %186 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %187 = llvm.load %186 : !llvm.ptr<f32, 3>
      %188 = llvm.getelementptr %23[%176] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %189 = llvm.load %188 : !llvm.ptr<f32, 3>
      %190 = llvm.fadd %187, %189  : f32
      %191 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %190, %191 : !llvm.ptr<f32, 3>
      llvm.br ^bb13
    ^bb13:  // 2 preds: ^bb11, ^bb12
      nvvm.barrier0
      %192 = llvm.icmp "eq" %54, %45 : i32
      %193 = llvm.and %192, %64  : i1
      llvm.cond_br %193, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %194 = llvm.add %52, %43  : i32
      %195 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %196 = llvm.insertvalue %23, %195[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %197 = llvm.insertvalue %23, %196[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %198 = llvm.mlir.constant(0 : index) : i32
      %199 = llvm.insertvalue %198, %197[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %200 = llvm.mlir.constant(256 : index) : i32
      %201 = llvm.insertvalue %200, %199[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %202 = llvm.mlir.constant(1 : index) : i32
      %203 = llvm.insertvalue %202, %201[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %204 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %205 = llvm.load %204 : !llvm.ptr<f32, 3>
      %206 = llvm.getelementptr %23[%194] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %207 = llvm.load %206 : !llvm.ptr<f32, 3>
      %208 = llvm.fadd %205, %207  : f32
      %209 = llvm.getelementptr %arg17[%61] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %210 = llvm.atomicrmw fadd %209, %208 acq_rel : !llvm.ptr<f32>, f32
      llvm.br ^bb15
    ^bb15:  // 2 preds: ^bb13, ^bb14
      llvm.br ^bb16
    ^bb16:  // 2 preds: ^bb1, ^bb15
      llvm.return
    }
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscStripShapeConstraintOpsPass (disc-strip-shape-constraint-ops) //----- //
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %c256 = arith.constant 256 : index
    %c81920 = arith.constant 81920 : index
    %c20971520 = arith.constant 20971520 : index
    %c10 = arith.constant 10 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %1 = "disc_ral.dispatch"(%arg0, %c1) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<8192x2560xf32, "gpu">
    %alloc = memref.alloc() : memref<2560xf32, "gpu">
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%c10, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %alloc : memref<2560xf32, "gpu">)
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%c81920, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %c20971520 : index, %0 : memref<8192x2560xf32, "gpu">, %1 : memref<8192x2560xf32, "gpu">, %alloc : memref<2560xf32, "gpu">)
    "disc_ral.dispatch"(%arg0, %c0, %alloc) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<2560xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\C8\01\00\00\00\00\00\00\01\00\01\01H\00\00\00\80\01\00\00\00\00\00\00|\01\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\03\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64/\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\0Ee__4_1_0___8w32h(\0A.param .u326\00\16\11_4\006_0,>\00/64>\00\1D\1F1>\00*/2,\BA\00)\1F3>\00*\1F4>\00*\F4\075\0A)\0A{\0A.reg .b32 %r<6>;\11\00\E264 %rd<5>;\0A\0Aldg\00\01f\00o%r1, [l\00\1C70];F\00\02\\\00\0FG\00 \F4\032];\0Acvta.to.globalM\00!2,S\00S;\0Amov\A7\00\00\13\00xctaid.x\17\00S3, %t\15\00qad.lo.s\18\00#4,4\00\00\E0\00\D3%r3;\0Amul.wide!\002d3,'\00\824;\0Aadd.sz\00&4,\80\00\183i\00\855, 0;\0Ast\AA\00@32 [1\00\10],\00\C05;\0Aret;\0A\0A}\0A\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\C8\03\00\00\00\00\00\00\C5\03\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00F\05F\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04 \00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04.\00r\00\04\1C\04\00\80\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\D3\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\8F\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00j\02\01\01\01\22H\00\01\00\00l\01/\05\00\01\00\FF\C8A\02z\01\00w\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\E4\03\B1\00\0E\00\00\E2\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05v\04\000\00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00p\D0\0F\00\86s\00\02`\001\00\E9\10`\003My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0a\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00@\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\A4\03\0D\88\05\03\15\00*\90\00\C8\03\04\ED\03\22\18\00\01\00\1F\FET\00\00\03\8E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\94\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B8)\00*\E0\00\01\00\1B\08\08\00!\0B\01\F4\04\0D\01\00\13\98\F5\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A8@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00D\05\00\00\08\80\06\80\00\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\F8\03\00\00\00\00\00\00\02\00\01\01@\00\00\00\B8\03\00\00\00\00\00\00\B4\03\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00K\05K\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04\1C\00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\D2\F0\11\00\03\1B\FF\00\04\1C\04\00p\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\CB\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\87\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00b\02\01\F9\00\22H\00\01\00\00d\01/\05\00\01\00\FF\D0A\02z\01\00w\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05f\04\00 \00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00\80\D0\0F\00\86s\00\02\FF0\00\A3\E9\10\00\00\E2\0F\00My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0Q\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\AC\03\0D\88\05\03\15\00*\90\00\D0\03\04\F5\03\22\18\00\01\00\1F\FET\00\00\03\9E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\8C\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B0)\00*\E0\00\01\00\1B\08\08\00!\0B\01\FC\04\0D\01\00\13\90\FD\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A0@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00Q\05\00\00\08\80\0E\00\A0\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: !llvm.ptr<f32>, %arg2: !llvm.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %1 = llvm.insertvalue %arg1, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %2 = llvm.insertvalue %arg2, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %3 = llvm.insertvalue %arg3, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %4 = llvm.insertvalue %arg4, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %5 = llvm.insertvalue %arg5, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %6 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %7 = nvvm.read.ptx.sreg.ctaid.x : i32
      %8 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %9 = llvm.mul %7, %arg0  : i32
      %10 = llvm.add %8, %9  : i32
      %11 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %12 = llvm.insertvalue %arg1, %11[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %13 = llvm.insertvalue %arg2, %12[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %14 = llvm.mlir.constant(0 : index) : i32
      %15 = llvm.insertvalue %14, %13[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %16 = llvm.mlir.constant(2560 : index) : i32
      %17 = llvm.insertvalue %16, %15[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %18 = llvm.mlir.constant(1 : index) : i32
      %19 = llvm.insertvalue %18, %17[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %20 = llvm.getelementptr %arg2[%10] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %6, %20 : !llvm.ptr<f32>
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary_compute_60 = "P\EDU\BA\01\00\10\00\C0\05\00\00\00\00\00\00\01\00\01\01H\00\00\00x\05\00\00\00\00\00\00t\05\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\03\11\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2!\0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64\0A0\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\10e__4_1_0___8w32h_1(\0A.param .u328\00\18\11_6\00?_0,@\00+\171@\00/64@\00\1F\1F2@\00,\1F3\C0\00,\1F4@\00,\1F5@\00,\1F6@\00,\1F7@\00,\1F8\80\01,\1F9@\00,\1F1\81\02.\1F1A\00-\1F2A\00-\0F\84\02-\1F1\85\02-/15\86\01-\1F6A\00-\0F\88\02-/18A\00-\1F9A\00,\F3\0A20\0A)\0A{\0A.reg .pred %p<18>;\13\00\95b32 %r<24\12\00\10f\12\00\18f\12\00\F0\04b64 %rd<17>;\0A\0A\09.shaI\00\FF\03.align 4 .b8 __wg_\9E\00\18\B20[1024];\0Ald\E0\00\01\DF\00o%r5, [\E5\00\1E\1E0H\00\1F6H\00!s1];\0AmovC\00\B87, %ctaid.x\17\00S8, %t\15\00qad.lo.s\18\00#1,4\00\00\C4\00\C2%r8;\0Asetp.ge8\004p1,%\00\F4\0C6;\0A@%p1 bra $L__BB0_13;\0AshrL\00\130-\00\2231\17\00\02{\00311,\1D\00t24;\0Aadd/\00\132/\00\00#\00\09H\00#3,\1F\00c8;\0Aand\EF\01$14\17\00\93-256;\0Asub1\00\07I\00\194z\00\225,\1E\00\193H\00\136\16\00\947;\0Amul.hi/\00#7,~\00\A9-858993459O\00#8,&\00\128:\00\06F\01#9, \009320\9A\00&0,\D1\00\01M\00\13l\86\00$213\00\185\15\01&3,\1C\00\1950\00#2,P\00S3;\0Aor\16\00%4,\1B\00$16\BC\01\12t\B0\002p2,Q\00B8191\0C\02\02&\03s23, 0f0\01\00\01\D7\01\192\D7\01\183\99\02\02G\03\1F7\9A\02\22\00\E3\02\E4cvta.to.globalP\00\01\9C\00.d7i\00\1F8i\00!\1F3h\00\06\01P\01+d8\F6\02#23\1B\011256\A2\01\124\D1\013wid\F9\02Crd9,)\00\04\B5\02\02Q\00\02\E5\02\03X\00\119\C0\00\03r\00\02]\01A4, ['\00\1A]7\00&1,\F7\00\0F7\00\00\1357\00\221]?\02\02\16\00\226,R\00\B7%f5;\0Afma.rn\C4\01\03\1B\00\1A6\CE\01\05\C5\01\16:\D3\00\02\F6\003d12\FA\02\134\1B\04\02$\01\00\9F\02\0F\0A\05\1E\0A\DE\00$4,I\00\00\07\00S2;\0Astq\05\01\B0\00\01\DB\0014],\B9\00\CC;\0Abar.sync 0\B3\02\133\A1\00<127\1B\00\154\CE\02.75\AE\01\05\EB\03\0A\AE\01\0A\98\00\115:\03\03P\06#5,p\00!p4\03\03\195\03\03\115\A3\01\07\C3\002%f7\A3\01.4]\1B\00\138\1B\00C+512\F8\01\02\19\00\229,9\00?%f8\14\01\01\02\13\01\169\B5\01/5:\1D\01\08\04\B8\04,63\1A\00\157\1C\01(83\E4\00#8,7\00!p7\E4\00\198\E4\00\1E7\C9\00/10\E5\00\07$11\E6\009256\E6\00\01X\02\01<\00\00&\00\0F\E9\00\07&12\EA\00\1F7\EA\00\09\139\EA\00,31\1A\00&10\EB\00\187\EB\00\01a\03\019\00\22p1\D4\04\1A1\AC\06\1F9\D2\00\00\1F3\EE\00\08\144\EE\00:128\EE\00\00:\02\01<\00\00&\00\0F\EE\00\08\165\EE\00\1F9\EE\00\09\05\97\03-15\1B\00\163\EF\00\199\EF\00\00\DA\02\02:\002p13\F0\00\194\F0\00/11\D5\00\00/6,\F1\00\07\04\E0\02:+64\F0\00\00F\02\01;\00\00%\00\0F\F0\00\08\168\F0\00/11\F1\00\0A\166\82\07\07\C2\01$7,\1C\00\22p2\D2\00\1D7n\08\0C/\06\0F2\09#\1F70\06\06\02\A7\05\1F6a\04\00\01\B4\00\1C4a\04&5,6\00/16V\01\00\1F9r\01\07$20r\01\1A36\04\01\00\08\01;\00\00%\00d;\0Aatom\A8\00\07&\00\122?\00\115~\01'21~\01\C03:\0Aret;\0A\0A}\0A\00\00\00\00\00", gpu.binary_sm_70 = "P\EDU\BA\01\00\10\00\C8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00\88\06\00\00\00\00\00\00\83\06\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\11\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00o\02\00\BE\00u\00\01\00\00\11\0E\06\00a\00F\05F\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00g2\00\00\00\12\10x\00\11\05\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13\F0\93\00\10\04\08\00R\04\18\00\00\00E\002\04\0C\01\18\00C/\08\00\06/\04\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00@\00\04\1C\0C&\01c\000\04\00\00\A0\D8\01#K\00\01\00q\02\02\08\10\0A/\22\BB\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\88\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00;\02\11,\90\01\11\00\09\01\22H\00\01\00\11\02t\01\0F\01\00\FF\F0@$v\01\FF\AF\05\D0\FF\00\8E\07\00\C4\0F\00\89\F3\FF\FF\FF\04\05\00\C2\04b\E2\0F\00\19y\00\01\00\10%\E3\02a\0E\00\19y\03\00\01\00\10!=\00`\0E\00$z\00\00[\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\DB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\04\FF\B9\02\10\03 \00q\E4\0F\00\12x\05\03\91\05\F1\00\C0\8E\07\00\C6\0F\00%x\02\04\CD\CC\CC\CC\B0\00a\C8\0F\00$x\00@\05b\05\0A\8E\07\00\E2`\00\01@\00\12\16`\00A\19x\02\FFa\00\14\16p\00 \09\03\FC\02!\FF(0\00\B2\04$x\03\03\C0\FE\FF\FF\04\02@\001\12x\02^\06\01p\00p\E4\0F\00\0Cx\00\09\B1\00@p@\F0\03\80\00Q$x\02\03\08\1F\04\92\8E\07\00\D2\0F\00\02\88\07\A6\06!\0F\000\01c$\88\06\09\00\0A \00\90\C8\0F\00%\86\04\06\00\\\F0\04\04\10\00F\06\06\00f\10\00!\81\83J\06\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\07\06\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03\B0\00#r\03\A0\01\04\F0\00\11\08\CC\03\10\FF6\00\01\D0\006\0A\00\04 \00\D4\04\0Cx\00\00\7F\00\00\00pDt\01\D0\00\11\F7P\00A\F2\03\00\C8\10\00!\00? \00\11\F2\C0\00\81!\82\0B\04\07\00\00\80\84\00\81\C8O\00#\82\03\04\0BP\00\02\E0\00\000\00\11\070\00\A1p\00\00\CE\0F\00\88s\00\08`\01\00\A6\04f\E8\0F\00\18y\00\01\00f\E2\0F\00\1D{\00\01\00b\EA\0F\00\84\A9\04\A5\07\12\180\000\84\A9\05.\01\02\10\00s$\0E\00!\A2\05\04\BB\07\AF\00\00\D0\1F\00\88\A3\00\0A\05`\00\19\17\99`\00\02\B0\00$\09\FB@\01\10\C6 \00!\07\0A2\02\00 \00\11\22`\01$\00\1F \01\00\00\01 \92\07\00\01\06\80\00O\93\00\0A\07\E0\00\1A\1D\03\80\00\14\FDp\01\13\C6\00\01)\80\00\80\00\18\0F\80\01Z\A2\03\03\04\00\00\01\1F\03\00\01%\00`\011\99\05\0A\B1\0C\04`\01\1B\92`\01\1F\93`\01\1B\0C\D0\03E\84y\00\0Ap\00W\E2\0F\00\02x\10\03\00\F0\00Wy\03\0A\00 \80\00!r\05\E0\08\01\01\00\93\E4\1F\00%v\02\02\00p\10\03q\D0\0F\00\8Ey\00\02\90\00!G\11P\00*Myp\00PGy\00\00\F0\10\04[\FF\83\03\00\C0\B0\00\0F\10\00 \0F\01\00-\00|\04.\03\00\01\00\02$\0E]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13\CC\07\0C\01\00\138U\00\11\A8\06\00\06\F0\07\00\E7\01\04\AF\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03#\00P\C5\02\04H\0B\04\E4\00*\04\00\01\00\1Fc@\00\04\13\80)\00&\8C\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\10\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\1C\09\0D\01\00\13\F0@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0D\84\01\03E\04\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\C8\0C\12\03\C0\01:\0E\80\00\01\00\13\97\94\00+\03\00\01\00\03\B0\10/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00", gpu.binary_sm_75 = "P\EDU\BA\01\00\10\00\B8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00x\06\00\00\00\00\00\00s\06\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\80\10\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\0D\07\00a\00K\05K\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00f2\00\00\00\12\10x\00\13\80;\00f\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\08\00R\04\14\00\00\00E\00#\04\F8\18\00\80/\08\00\06\00\00\00\0E\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\04\1C\0C\FE\00c\00\D0\03\00\00@\D0\01#K\00\01\00q\02\02\08\10\0A/\22\B3\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\003\02\11,\88\01\11\00\01\01\22H\00\01\00\11\02l\01\0F\01\00\FF\F8@$v\01\FF\AF\05\B2\FF\00\8E\07\00\C4\0F\00\19y\00\01\00\10%\DB\02a\0E\00\19y\03\00\01\00\10!-\00`\0E\00$z\00\00K\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\CB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\02\FF\B1\02\10\03 \00q\E4\0F\00\12x\03\03\81\05\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\CD\CC\CC\CC\A0\00a\C8\0F\00$x\000\05`\03\0A\8E\07\00\E2@\00\11\04@\00\22\04\16`\00\00p\00\01a\00\14\16p\00 \06\04\10\00!\FF(0\00\B2\04$x\03\04\C0\FE\FF\FF\02\02@\001\12x\02N\06\01p\00p\E4\0F\00\0Cx\00\06\B1\00@p@\F0\03\80\00Q$x\07\03\08\17\04\92\8E\07\00\D2\0F\00\02\88\05\96\060\0F\00\00@\00@$\88\04\06@\01\22\07\02\A0\00`%\86\02\04\00\\\C0\04\04\10\00F\04\04\00f\10\000\81\83\02\83\03\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\05\04\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03`\00Sr\08\FF\FF\00\A0\01\01\F0\00\11\0B\C4\03\10\FF\C5\03\80\E4\0F\04\0Cx\00\00\7F\98\064Dt\01\C0\00\11\F7@\00A\F2\03\00\C8\10\00!\00? \00\11\F2\B0\00\81!\82\09\02\05\00\00\80t\00\81\C8O\00#\82\08\02\09`\00\02\D0\00\000\00\11\070\00\22p\000\014\09\00\04\80\00\93\CC\0F\00\88s\00\0B\08\00\1E\05f\E8\0F\00\1D{\00\01\00Q\EA\0F\00\84\A9O\002\00\00\18 \00A\84\A9\03\09v\04\12\18@\02c!\A2\02\02\03\00\01\00\8F\D0\1F\00\88\A3\00\09\02P\00\095\99\03\09P\00\02\A0\00$\06\FB \01\10\C6 \00!\04\09\12\02\00 \00\11\22@\01$\00\1F\10\01\00\F0\00W\92\04\03\04\00p\00O\93\00\09\04\C0\00\0A\0Ep\00\14\FDP\01\00p\001\A9\08\09>\01\07p\00\18\0F`\01!\A2\080\02\08\E0\00\1F\08\E0\00\0A\0B0\01\00\F0\00&@\000\01\1B\920\01\1F\930\01\0B\0C\80\039\84y\00\D0\006\02x\02\C0\02\00\D0\00Wy\03\09\00 p\00!r\05\80\08\01\01\00p\E4\1F\00%v\02\07{\08\10\02\00\02`\D0\0F\00\8Ey\00@\02A\00\00G\11P\00*Myp\00PGy\00\00\F0\C0\03\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\01\0C\04\1E\00\01\00\02\A4\0D]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13T\07\0C\01\00\138U\00\11\A8\06\00\06x\07\00\B7\01\04\8F\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03!\00P\E5\01\10\00\86\09'\00\00\E4\00*\04\00\01\00\1Fc@\00\04\04@\0B&\84\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\08\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\A4\08\0D\01\00\13\E8@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0C\84\01\13\F8@\00\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\08\01\12\03\C0\01:\0E\80\00\01\00\13\97\94\00/\03\000\10\03/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00"} {
    llvm.mlir.global internal @__wg_main_kColReduction_reduce__4_1_0___8w32h_1_0() {addr_space = 3 : i32} : !llvm.array<256 x f32>
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: !llvm.ptr<f32>, %arg10: !llvm.ptr<f32>, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: !llvm.ptr<f32>, %arg17: !llvm.ptr<f32>, %arg18: i32, %arg19: i32, %arg20: i32) attributes {gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)>
      %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %5 = llvm.insertvalue %arg7, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %6 = llvm.insertvalue %arg6, %5[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %7 = llvm.insertvalue %arg8, %6[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %8 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)>
      %9 = llvm.insertvalue %arg9, %8[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %10 = llvm.insertvalue %arg10, %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %11 = llvm.insertvalue %arg11, %10[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %12 = llvm.insertvalue %arg12, %11[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %13 = llvm.insertvalue %arg14, %12[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %14 = llvm.insertvalue %arg13, %13[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %15 = llvm.insertvalue %arg15, %14[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<2 x i32>, array<2 x i32>)> 
      %16 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %17 = llvm.insertvalue %arg16, %16[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %18 = llvm.insertvalue %arg17, %17[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %19 = llvm.insertvalue %arg18, %18[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %20 = llvm.insertvalue %arg19, %19[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %21 = llvm.insertvalue %arg20, %20[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %22 = llvm.mlir.addressof @__wg_main_kColReduction_reduce__4_1_0___8w32h_1_0 : !llvm.ptr<array<256 x f32>, 3>
      %23 = llvm.getelementptr %22[0, 0] : (!llvm.ptr<array<256 x f32>, 3>) -> !llvm.ptr<f32, 3>
      %24 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %25 = llvm.insertvalue %23, %24[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %26 = llvm.insertvalue %23, %25[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %27 = llvm.mlir.constant(0 : index) : i32
      %28 = llvm.insertvalue %27, %26[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %29 = llvm.mlir.constant(256 : index) : i32
      %30 = llvm.insertvalue %29, %28[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %31 = llvm.mlir.constant(1 : index) : i32
      %32 = llvm.insertvalue %31, %30[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %33 = llvm.mlir.constant(2 : index) : i32
      %34 = llvm.mlir.constant(4 : index) : i32
      %35 = llvm.mlir.constant(64 : index) : i32
      %36 = llvm.mlir.constant(128 : index) : i32
      %37 = llvm.mlir.constant(16 : index) : i32
      %38 = llvm.mlir.constant(0.000000e+00 : f32) : f32
      %39 = llvm.mlir.constant(2560 : index) : i32
      %40 = llvm.mlir.constant(8192 : index) : i32
      %41 = llvm.mlir.constant(32 : index) : i32
      %42 = llvm.mlir.constant(320 : index) : i32
      %43 = llvm.mlir.constant(8 : index) : i32
      %44 = llvm.mlir.constant(256 : index) : i32
      %45 = llvm.mlir.constant(0 : index) : i32
      %46 = nvvm.read.ptx.sreg.ctaid.x : i32
      %47 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %48 = llvm.mul %46, %arg0  : i32
      %49 = llvm.add %47, %48  : i32
      %50 = llvm.add %47, %48  : i32
      %51 = llvm.icmp "ult" %50, %arg1 : i32
      llvm.cond_br %51, ^bb2, ^bb16
    ^bb2:  // pred: ^bb1
      %52 = llvm.srem %49, %44  : i32
      %53 = llvm.sdiv %49, %44  : i32
      %54 = llvm.udiv %52, %43  : i32
      %55 = llvm.urem %52, %43  : i32
      %56 = llvm.udiv %53, %42  : i32
      %57 = llvm.urem %53, %42  : i32
      %58 = llvm.mul %56, %41  : i32
      %59 = llvm.add %58, %54  : i32
      %60 = llvm.mul %57, %43  : i32
      %61 = llvm.add %60, %55  : i32
      %62 = llvm.icmp "ult" %59, %40 : i32
      %63 = llvm.icmp "ult" %61, %39 : i32
      %64 = llvm.and %62, %63  : i1
      llvm.cond_br %64, ^bb3, ^bb4
    ^bb3:  // pred: ^bb2
      %65 = llvm.mul %59, %39  : i32
      %66 = llvm.add %65, %61  : i32
      %67 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %68 = llvm.insertvalue %arg2, %67[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %69 = llvm.insertvalue %arg3, %68[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %70 = llvm.mlir.constant(0 : index) : i32
      %71 = llvm.insertvalue %70, %69[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %72 = llvm.mlir.constant(20971520 : index) : i32
      %73 = llvm.insertvalue %72, %71[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %74 = llvm.mlir.constant(1 : index) : i32
      %75 = llvm.insertvalue %74, %73[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %76 = llvm.getelementptr %arg3[%66] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %77 = llvm.load %76 : !llvm.ptr<f32>
      %78 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
      %79 = llvm.insertvalue %arg9, %78[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %80 = llvm.insertvalue %arg10, %79[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %81 = llvm.mlir.constant(0 : index) : i32
      %82 = llvm.insertvalue %81, %80[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %83 = llvm.mlir.constant(20971520 : index) : i32
      %84 = llvm.insertvalue %83, %82[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %85 = llvm.mlir.constant(1 : index) : i32
      %86 = llvm.insertvalue %85, %84[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
      %87 = llvm.getelementptr %arg10[%66] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %88 = llvm.load %87 : !llvm.ptr<f32>
      %89 = llvm.fsub %77, %88  : f32
      %90 = llvm.fmul %89, %77  : f32
      %91 = llvm.fadd %90, %38  : f32
      %92 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %93 = llvm.insertvalue %23, %92[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %94 = llvm.insertvalue %23, %93[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %95 = llvm.mlir.constant(0 : index) : i32
      %96 = llvm.insertvalue %95, %94[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %97 = llvm.mlir.constant(256 : index) : i32
      %98 = llvm.insertvalue %97, %96[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %99 = llvm.mlir.constant(1 : index) : i32
      %100 = llvm.insertvalue %99, %98[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %101 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %91, %101 : !llvm.ptr<f32, 3>
      llvm.br ^bb5
    ^bb4:  // pred: ^bb2
      %102 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %103 = llvm.insertvalue %23, %102[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %104 = llvm.insertvalue %23, %103[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %105 = llvm.mlir.constant(0 : index) : i32
      %106 = llvm.insertvalue %105, %104[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %107 = llvm.mlir.constant(256 : index) : i32
      %108 = llvm.insertvalue %107, %106[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %109 = llvm.mlir.constant(1 : index) : i32
      %110 = llvm.insertvalue %109, %108[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %111 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %38, %111 : !llvm.ptr<f32, 3>
      llvm.br ^bb5
    ^bb5:  // 2 preds: ^bb3, ^bb4
      nvvm.barrier0
      %112 = llvm.icmp "ult" %54, %37 : i32
      %113 = llvm.add %59, %37  : i32
      %114 = llvm.icmp "ult" %113, %40 : i32
      %115 = llvm.and %112, %114  : i1
      llvm.cond_br %115, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      %116 = llvm.add %52, %36  : i32
      %117 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %118 = llvm.insertvalue %23, %117[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %119 = llvm.insertvalue %23, %118[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %120 = llvm.mlir.constant(0 : index) : i32
      %121 = llvm.insertvalue %120, %119[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %122 = llvm.mlir.constant(256 : index) : i32
      %123 = llvm.insertvalue %122, %121[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %124 = llvm.mlir.constant(1 : index) : i32
      %125 = llvm.insertvalue %124, %123[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %126 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %127 = llvm.load %126 : !llvm.ptr<f32, 3>
      %128 = llvm.getelementptr %23[%116] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %129 = llvm.load %128 : !llvm.ptr<f32, 3>
      %130 = llvm.fadd %127, %129  : f32
      %131 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %130, %131 : !llvm.ptr<f32, 3>
      llvm.br ^bb7
    ^bb7:  // 2 preds: ^bb5, ^bb6
      nvvm.barrier0
      %132 = llvm.icmp "ult" %54, %43 : i32
      %133 = llvm.add %59, %43  : i32
      %134 = llvm.icmp "ult" %133, %40 : i32
      %135 = llvm.and %132, %134  : i1
      llvm.cond_br %135, ^bb8, ^bb9
    ^bb8:  // pred: ^bb7
      %136 = llvm.add %52, %35  : i32
      %137 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %138 = llvm.insertvalue %23, %137[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %139 = llvm.insertvalue %23, %138[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %140 = llvm.mlir.constant(0 : index) : i32
      %141 = llvm.insertvalue %140, %139[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %142 = llvm.mlir.constant(256 : index) : i32
      %143 = llvm.insertvalue %142, %141[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %144 = llvm.mlir.constant(1 : index) : i32
      %145 = llvm.insertvalue %144, %143[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %146 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %147 = llvm.load %146 : !llvm.ptr<f32, 3>
      %148 = llvm.getelementptr %23[%136] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %149 = llvm.load %148 : !llvm.ptr<f32, 3>
      %150 = llvm.fadd %147, %149  : f32
      %151 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %150, %151 : !llvm.ptr<f32, 3>
      llvm.br ^bb9
    ^bb9:  // 2 preds: ^bb7, ^bb8
      nvvm.barrier0
      %152 = llvm.icmp "ult" %54, %34 : i32
      %153 = llvm.add %59, %34  : i32
      %154 = llvm.icmp "ult" %153, %40 : i32
      %155 = llvm.and %152, %154  : i1
      llvm.cond_br %155, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %156 = llvm.add %52, %41  : i32
      %157 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %158 = llvm.insertvalue %23, %157[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %159 = llvm.insertvalue %23, %158[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %160 = llvm.mlir.constant(0 : index) : i32
      %161 = llvm.insertvalue %160, %159[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %162 = llvm.mlir.constant(256 : index) : i32
      %163 = llvm.insertvalue %162, %161[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %164 = llvm.mlir.constant(1 : index) : i32
      %165 = llvm.insertvalue %164, %163[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %166 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %167 = llvm.load %166 : !llvm.ptr<f32, 3>
      %168 = llvm.getelementptr %23[%156] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %169 = llvm.load %168 : !llvm.ptr<f32, 3>
      %170 = llvm.fadd %167, %169  : f32
      %171 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %170, %171 : !llvm.ptr<f32, 3>
      llvm.br ^bb11
    ^bb11:  // 2 preds: ^bb9, ^bb10
      nvvm.barrier0
      %172 = llvm.icmp "ult" %54, %33 : i32
      %173 = llvm.add %59, %33  : i32
      %174 = llvm.icmp "ult" %173, %40 : i32
      %175 = llvm.and %172, %174  : i1
      llvm.cond_br %175, ^bb12, ^bb13
    ^bb12:  // pred: ^bb11
      %176 = llvm.add %52, %37  : i32
      %177 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %178 = llvm.insertvalue %23, %177[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %179 = llvm.insertvalue %23, %178[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %180 = llvm.mlir.constant(0 : index) : i32
      %181 = llvm.insertvalue %180, %179[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %182 = llvm.mlir.constant(256 : index) : i32
      %183 = llvm.insertvalue %182, %181[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %184 = llvm.mlir.constant(1 : index) : i32
      %185 = llvm.insertvalue %184, %183[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %186 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %187 = llvm.load %186 : !llvm.ptr<f32, 3>
      %188 = llvm.getelementptr %23[%176] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %189 = llvm.load %188 : !llvm.ptr<f32, 3>
      %190 = llvm.fadd %187, %189  : f32
      %191 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      llvm.store %190, %191 : !llvm.ptr<f32, 3>
      llvm.br ^bb13
    ^bb13:  // 2 preds: ^bb11, ^bb12
      nvvm.barrier0
      %192 = llvm.icmp "eq" %54, %45 : i32
      %193 = llvm.and %192, %64  : i1
      llvm.cond_br %193, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %194 = llvm.add %52, %43  : i32
      %195 = llvm.mlir.undef : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)>
      %196 = llvm.insertvalue %23, %195[0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %197 = llvm.insertvalue %23, %196[1] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %198 = llvm.mlir.constant(0 : index) : i32
      %199 = llvm.insertvalue %198, %197[2] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %200 = llvm.mlir.constant(256 : index) : i32
      %201 = llvm.insertvalue %200, %199[3, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %202 = llvm.mlir.constant(1 : index) : i32
      %203 = llvm.insertvalue %202, %201[4, 0] : !llvm.struct<(ptr<f32, 3>, ptr<f32, 3>, i32, array<1 x i32>, array<1 x i32>)> 
      %204 = llvm.getelementptr %23[%52] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %205 = llvm.load %204 : !llvm.ptr<f32, 3>
      %206 = llvm.getelementptr %23[%194] : (!llvm.ptr<f32, 3>, i32) -> !llvm.ptr<f32, 3>
      %207 = llvm.load %206 : !llvm.ptr<f32, 3>
      %208 = llvm.fadd %205, %207  : f32
      %209 = llvm.getelementptr %arg17[%61] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %210 = llvm.atomicrmw fadd %209, %208 acq_rel : !llvm.ptr<f32>, f32
      llvm.br ^bb15
    ^bb15:  // 2 preds: ^bb13, ^bb14
      llvm.br ^bb16
    ^bb16:  // 2 preds: ^bb1, ^bb15
      llvm.return
    }
  }
}


// -----// IR Dump After DiscToLLVMPass (disc-to-llvm) //----- //
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @ral_send_output___cpu___pvoid_i64_m1df32___void("ral_send_output___cpu___pvoid_i64_m1df32___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name("main_kColReduction_reduce__4_1_0___8w32h_1\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_0_blob_gpu.binary_sm_75("P\EDU\BA\01\00\10\00\B8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00x\06\00\00\00\00\00\00s\06\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\80\10\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\0D\07\00a\00K\05K\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00f2\00\00\00\12\10x\00\13\80;\00f\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\08\00R\04\14\00\00\00E\00#\04\F8\18\00\80/\08\00\06\00\00\00\0E\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\04\1C\0C\FE\00c\00\D0\03\00\00@\D0\01#K\00\01\00q\02\02\08\10\0A/\22\B3\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\003\02\11,\88\01\11\00\01\01\22H\00\01\00\11\02l\01\0F\01\00\FF\F8@$v\01\FF\AF\05\B2\FF\00\8E\07\00\C4\0F\00\19y\00\01\00\10%\DB\02a\0E\00\19y\03\00\01\00\10!-\00`\0E\00$z\00\00K\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\CB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\02\FF\B1\02\10\03 \00q\E4\0F\00\12x\03\03\81\05\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\CD\CC\CC\CC\A0\00a\C8\0F\00$x\000\05`\03\0A\8E\07\00\E2@\00\11\04@\00\22\04\16`\00\00p\00\01a\00\14\16p\00 \06\04\10\00!\FF(0\00\B2\04$x\03\04\C0\FE\FF\FF\02\02@\001\12x\02N\06\01p\00p\E4\0F\00\0Cx\00\06\B1\00@p@\F0\03\80\00Q$x\07\03\08\17\04\92\8E\07\00\D2\0F\00\02\88\05\96\060\0F\00\00@\00@$\88\04\06@\01\22\07\02\A0\00`%\86\02\04\00\\\C0\04\04\10\00F\04\04\00f\10\000\81\83\02\83\03\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\05\04\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03`\00Sr\08\FF\FF\00\A0\01\01\F0\00\11\0B\C4\03\10\FF\C5\03\80\E4\0F\04\0Cx\00\00\7F\98\064Dt\01\C0\00\11\F7@\00A\F2\03\00\C8\10\00!\00? \00\11\F2\B0\00\81!\82\09\02\05\00\00\80t\00\81\C8O\00#\82\08\02\09`\00\02\D0\00\000\00\11\070\00\22p\000\014\09\00\04\80\00\93\CC\0F\00\88s\00\0B\08\00\1E\05f\E8\0F\00\1D{\00\01\00Q\EA\0F\00\84\A9O\002\00\00\18 \00A\84\A9\03\09v\04\12\18@\02c!\A2\02\02\03\00\01\00\8F\D0\1F\00\88\A3\00\09\02P\00\095\99\03\09P\00\02\A0\00$\06\FB \01\10\C6 \00!\04\09\12\02\00 \00\11\22@\01$\00\1F\10\01\00\F0\00W\92\04\03\04\00p\00O\93\00\09\04\C0\00\0A\0Ep\00\14\FDP\01\00p\001\A9\08\09>\01\07p\00\18\0F`\01!\A2\080\02\08\E0\00\1F\08\E0\00\0A\0B0\01\00\F0\00&@\000\01\1B\920\01\1F\930\01\0B\0C\80\039\84y\00\D0\006\02x\02\C0\02\00\D0\00Wy\03\09\00 p\00!r\05\80\08\01\01\00p\E4\1F\00%v\02\07{\08\10\02\00\02`\D0\0F\00\8Ey\00@\02A\00\00G\11P\00*Myp\00PGy\00\00\F0\C0\03\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\01\0C\04\1E\00\01\00\02\A4\0D]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13T\07\0C\01\00\138U\00\11\A8\06\00\06x\07\00\B7\01\04\8F\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03!\00P\E5\01\10\00\86\09'\00\00\E4\00*\04\00\01\00\1Fc@\00\04\04@\0B&\84\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\08\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\A4\08\0D\01\00\13\E8@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0C\84\01\13\F8@\00\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\08\01\12\03\C0\01:\0E\80\00\01\00\13\97\94\00/\03\000\10\03/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_0_blob_gpu.binary_sm_70("P\EDU\BA\01\00\10\00\C8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00\88\06\00\00\00\00\00\00\83\06\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\11\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00o\02\00\BE\00u\00\01\00\00\11\0E\06\00a\00F\05F\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00g2\00\00\00\12\10x\00\11\05\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13\F0\93\00\10\04\08\00R\04\18\00\00\00E\002\04\0C\01\18\00C/\08\00\06/\04\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00@\00\04\1C\0C&\01c\000\04\00\00\A0\D8\01#K\00\01\00q\02\02\08\10\0A/\22\BB\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\88\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00;\02\11,\90\01\11\00\09\01\22H\00\01\00\11\02t\01\0F\01\00\FF\F0@$v\01\FF\AF\05\D0\FF\00\8E\07\00\C4\0F\00\89\F3\FF\FF\FF\04\05\00\C2\04b\E2\0F\00\19y\00\01\00\10%\E3\02a\0E\00\19y\03\00\01\00\10!=\00`\0E\00$z\00\00[\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\DB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\04\FF\B9\02\10\03 \00q\E4\0F\00\12x\05\03\91\05\F1\00\C0\8E\07\00\C6\0F\00%x\02\04\CD\CC\CC\CC\B0\00a\C8\0F\00$x\00@\05b\05\0A\8E\07\00\E2`\00\01@\00\12\16`\00A\19x\02\FFa\00\14\16p\00 \09\03\FC\02!\FF(0\00\B2\04$x\03\03\C0\FE\FF\FF\04\02@\001\12x\02^\06\01p\00p\E4\0F\00\0Cx\00\09\B1\00@p@\F0\03\80\00Q$x\02\03\08\1F\04\92\8E\07\00\D2\0F\00\02\88\07\A6\06!\0F\000\01c$\88\06\09\00\0A \00\90\C8\0F\00%\86\04\06\00\\\F0\04\04\10\00F\06\06\00f\10\00!\81\83J\06\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\07\06\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03\B0\00#r\03\A0\01\04\F0\00\11\08\CC\03\10\FF6\00\01\D0\006\0A\00\04 \00\D4\04\0Cx\00\00\7F\00\00\00pDt\01\D0\00\11\F7P\00A\F2\03\00\C8\10\00!\00? \00\11\F2\C0\00\81!\82\0B\04\07\00\00\80\84\00\81\C8O\00#\82\03\04\0BP\00\02\E0\00\000\00\11\070\00\A1p\00\00\CE\0F\00\88s\00\08`\01\00\A6\04f\E8\0F\00\18y\00\01\00f\E2\0F\00\1D{\00\01\00b\EA\0F\00\84\A9\04\A5\07\12\180\000\84\A9\05.\01\02\10\00s$\0E\00!\A2\05\04\BB\07\AF\00\00\D0\1F\00\88\A3\00\0A\05`\00\19\17\99`\00\02\B0\00$\09\FB@\01\10\C6 \00!\07\0A2\02\00 \00\11\22`\01$\00\1F \01\00\00\01 \92\07\00\01\06\80\00O\93\00\0A\07\E0\00\1A\1D\03\80\00\14\FDp\01\13\C6\00\01)\80\00\80\00\18\0F\80\01Z\A2\03\03\04\00\00\01\1F\03\00\01%\00`\011\99\05\0A\B1\0C\04`\01\1B\92`\01\1F\93`\01\1B\0C\D0\03E\84y\00\0Ap\00W\E2\0F\00\02x\10\03\00\F0\00Wy\03\0A\00 \80\00!r\05\E0\08\01\01\00\93\E4\1F\00%v\02\02\00p\10\03q\D0\0F\00\8Ey\00\02\90\00!G\11P\00*Myp\00PGy\00\00\F0\10\04[\FF\83\03\00\C0\B0\00\0F\10\00 \0F\01\00-\00|\04.\03\00\01\00\02$\0E]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13\CC\07\0C\01\00\138U\00\11\A8\06\00\06\F0\07\00\E7\01\04\AF\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03#\00P\C5\02\04H\0B\04\E4\00*\04\00\01\00\1Fc@\00\04\13\80)\00&\8C\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\10\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\1C\09\0D\01\00\13\F0@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0D\84\01\03E\04\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\C8\0C\12\03\C0\01:\0E\80\00\01\00\13\97\94\00+\03\00\01\00\03\B0\10/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_0_blob_gpu.binary_compute_60("P\EDU\BA\01\00\10\00\C0\05\00\00\00\00\00\00\01\00\01\01H\00\00\00x\05\00\00\00\00\00\00t\05\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\03\11\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2!\0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64\0A0\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\10e__4_1_0___8w32h_1(\0A.param .u328\00\18\11_6\00?_0,@\00+\171@\00/64@\00\1F\1F2@\00,\1F3\C0\00,\1F4@\00,\1F5@\00,\1F6@\00,\1F7@\00,\1F8\80\01,\1F9@\00,\1F1\81\02.\1F1A\00-\1F2A\00-\0F\84\02-\1F1\85\02-/15\86\01-\1F6A\00-\0F\88\02-/18A\00-\1F9A\00,\F3\0A20\0A)\0A{\0A.reg .pred %p<18>;\13\00\95b32 %r<24\12\00\10f\12\00\18f\12\00\F0\04b64 %rd<17>;\0A\0A\09.shaI\00\FF\03.align 4 .b8 __wg_\9E\00\18\B20[1024];\0Ald\E0\00\01\DF\00o%r5, [\E5\00\1E\1E0H\00\1F6H\00!s1];\0AmovC\00\B87, %ctaid.x\17\00S8, %t\15\00qad.lo.s\18\00#1,4\00\00\C4\00\C2%r8;\0Asetp.ge8\004p1,%\00\F4\0C6;\0A@%p1 bra $L__BB0_13;\0AshrL\00\130-\00\2231\17\00\02{\00311,\1D\00t24;\0Aadd/\00\132/\00\00#\00\09H\00#3,\1F\00c8;\0Aand\EF\01$14\17\00\93-256;\0Asub1\00\07I\00\194z\00\225,\1E\00\193H\00\136\16\00\947;\0Amul.hi/\00#7,~\00\A9-858993459O\00#8,&\00\128:\00\06F\01#9, \009320\9A\00&0,\D1\00\01M\00\13l\86\00$213\00\185\15\01&3,\1C\00\1950\00#2,P\00S3;\0Aor\16\00%4,\1B\00$16\BC\01\12t\B0\002p2,Q\00B8191\0C\02\02&\03s23, 0f0\01\00\01\D7\01\192\D7\01\183\99\02\02G\03\1F7\9A\02\22\00\E3\02\E4cvta.to.globalP\00\01\9C\00.d7i\00\1F8i\00!\1F3h\00\06\01P\01+d8\F6\02#23\1B\011256\A2\01\124\D1\013wid\F9\02Crd9,)\00\04\B5\02\02Q\00\02\E5\02\03X\00\119\C0\00\03r\00\02]\01A4, ['\00\1A]7\00&1,\F7\00\0F7\00\00\1357\00\221]?\02\02\16\00\226,R\00\B7%f5;\0Afma.rn\C4\01\03\1B\00\1A6\CE\01\05\C5\01\16:\D3\00\02\F6\003d12\FA\02\134\1B\04\02$\01\00\9F\02\0F\0A\05\1E\0A\DE\00$4,I\00\00\07\00S2;\0Astq\05\01\B0\00\01\DB\0014],\B9\00\CC;\0Abar.sync 0\B3\02\133\A1\00<127\1B\00\154\CE\02.75\AE\01\05\EB\03\0A\AE\01\0A\98\00\115:\03\03P\06#5,p\00!p4\03\03\195\03\03\115\A3\01\07\C3\002%f7\A3\01.4]\1B\00\138\1B\00C+512\F8\01\02\19\00\229,9\00?%f8\14\01\01\02\13\01\169\B5\01/5:\1D\01\08\04\B8\04,63\1A\00\157\1C\01(83\E4\00#8,7\00!p7\E4\00\198\E4\00\1E7\C9\00/10\E5\00\07$11\E6\009256\E6\00\01X\02\01<\00\00&\00\0F\E9\00\07&12\EA\00\1F7\EA\00\09\139\EA\00,31\1A\00&10\EB\00\187\EB\00\01a\03\019\00\22p1\D4\04\1A1\AC\06\1F9\D2\00\00\1F3\EE\00\08\144\EE\00:128\EE\00\00:\02\01<\00\00&\00\0F\EE\00\08\165\EE\00\1F9\EE\00\09\05\97\03-15\1B\00\163\EF\00\199\EF\00\00\DA\02\02:\002p13\F0\00\194\F0\00/11\D5\00\00/6,\F1\00\07\04\E0\02:+64\F0\00\00F\02\01;\00\00%\00\0F\F0\00\08\168\F0\00/11\F1\00\0A\166\82\07\07\C2\01$7,\1C\00\22p2\D2\00\1D7n\08\0C/\06\0F2\09#\1F70\06\06\02\A7\05\1F6a\04\00\01\B4\00\1C4a\04&5,6\00/16V\01\00\1F9r\01\07$20r\01\1A36\04\01\00\08\01;\00\00%\00d;\0Aatom\A8\00\07&\00\122?\00\115~\01'21~\01\C03:\0Aret;\0A\0A}\0A\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void("ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name("main_kColReduction_reduce__4_1_0___8w32h\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_blob_gpu.binary_sm_75("P\EDU\BA\01\00\10\00\F8\03\00\00\00\00\00\00\02\00\01\01@\00\00\00\B8\03\00\00\00\00\00\00\B4\03\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00K\05K\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04\1C\00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\D2\F0\11\00\03\1B\FF\00\04\1C\04\00p\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\CB\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\87\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00b\02\01\F9\00\22H\00\01\00\00d\01/\05\00\01\00\FF\D0A\02z\01\00w\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05f\04\00 \00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00\80\D0\0F\00\86s\00\02\FF0\00\A3\E9\10\00\00\E2\0F\00My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0Q\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\AC\03\0D\88\05\03\15\00*\90\00\D0\03\04\F5\03\22\18\00\01\00\1F\FET\00\00\03\9E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\8C\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B0)\00*\E0\00\01\00\1B\08\08\00!\0B\01\FC\04\0D\01\00\13\90\FD\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A0@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00Q\05\00\00\08\80\0E\00\A0\00\00\00\00\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_blob_gpu.binary_sm_70("P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\C8\03\00\00\00\00\00\00\C5\03\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00F\05F\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04 \00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04.\00r\00\04\1C\04\00\80\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\D3\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\8F\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00j\02\01\01\01\22H\00\01\00\00l\01/\05\00\01\00\FF\C8A\02z\01\00w\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\E4\03\B1\00\0E\00\00\E2\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05v\04\000\00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00p\D0\0F\00\86s\00\02`\001\00\E9\10`\003My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0a\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00@\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\A4\03\0D\88\05\03\15\00*\90\00\C8\03\04\ED\03\22\18\00\01\00\1F\FET\00\00\03\8E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\94\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B8)\00*\E0\00\01\00\1B\08\08\00!\0B\01\F4\04\0D\01\00\13\98\F5\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A8@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00D\05\00\00\08\80\06\80\00\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_blob_gpu.binary_compute_60("P\EDU\BA\01\00\10\00\C8\01\00\00\00\00\00\00\01\00\01\01H\00\00\00\80\01\00\00\00\00\00\00|\01\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\03\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64/\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\0Ee__4_1_0___8w32h(\0A.param .u326\00\16\11_4\006_0,>\00/64>\00\1D\1F1>\00*/2,\BA\00)\1F3>\00*\1F4>\00*\F4\075\0A)\0A{\0A.reg .b32 %r<6>;\11\00\E264 %rd<5>;\0A\0Aldg\00\01f\00o%r1, [l\00\1C70];F\00\02\\\00\0FG\00 \F4\032];\0Acvta.to.globalM\00!2,S\00S;\0Amov\A7\00\00\13\00xctaid.x\17\00S3, %t\15\00qad.lo.s\18\00#4,4\00\00\E0\00\D3%r3;\0Amul.wide!\002d3,'\00\824;\0Aadd.sz\00&4,\80\00\183i\00\855, 0;\0Ast\AA\00@32 [1\00\10],\00\C05;\0Aret;\0A\0A}\0A\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @alloc___gpu___pvoid_i64___pvoid("alloc___gpu___pvoid_i64___pvoid\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_recv_input___cpu___pvoid_i64___m2df32("ral_recv_input___cpu___pvoid_i64___m2df32\00") {addr_space = 0 : i32}
  llvm.func @disc_ral_call(!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>)
  llvm.func @main(%arg0: !llvm.ptr<i8>) attributes {tf.entry_function = {input_placements = "gpu,gpu", inputs = "arg0_1.1_,arg1_1.1_", output_placements = "gpu", outputs = "sum_1.1"}} {
    %0 = llvm.mlir.constant(256 : index) : i64
    %1 = llvm.mlir.constant(81920 : index) : i64
    %2 = llvm.mlir.constant(20971520 : index) : i64
    %3 = llvm.mlir.constant(10 : index) : i64
    %4 = llvm.mlir.constant(1 : index) : i64
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = llvm.mlir.constant(0 : i32) : i32
    %7 = llvm.mlir.constant(1 : i32) : i32
    %8 = llvm.alloca %7 x !llvm.struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)> : (i32) -> !llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>
    %9 = llvm.mlir.constant(3 : i32) : i32
    %10 = llvm.alloca %9 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %11 = llvm.mlir.constant(0 : i32) : i32
    %12 = llvm.getelementptr %8[%6, 0] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %12 : !llvm.ptr<ptr<i8>>
    %13 = llvm.getelementptr %10[%11] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %14 = llvm.bitcast %12 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %14, %13 : !llvm.ptr<ptr<i8>>
    %15 = llvm.mlir.constant(1 : i32) : i32
    %16 = llvm.getelementptr %8[%6, 1] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %5, %16 : !llvm.ptr<i64>
    %17 = llvm.getelementptr %10[%15] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %18 = llvm.bitcast %16 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %18, %17 : !llvm.ptr<ptr<i8>>
    %19 = llvm.mlir.constant(2 : i32) : i32
    %20 = llvm.getelementptr %8[%6, 2] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>>
    %21 = llvm.getelementptr %10[%19] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %22 = llvm.bitcast %20 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>> to !llvm.ptr<i8>
    llvm.store %22, %21 : !llvm.ptr<ptr<i8>>
    %23 = llvm.mlir.addressof @ral_recv_input___cpu___pvoid_i64___m2df32 : !llvm.ptr<array<42 x i8>>
    %24 = llvm.mlir.constant(0 : index) : i64
    %25 = llvm.getelementptr %23[%24, %24] : (!llvm.ptr<array<42 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %25, %10) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %26 = llvm.load %20 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>>
    %27 = llvm.mlir.constant(0 : i32) : i32
    %28 = llvm.mlir.constant(1 : i32) : i32
    %29 = llvm.alloca %28 x !llvm.struct<".1", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)> : (i32) -> !llvm.ptr<struct<".1", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>
    %30 = llvm.mlir.constant(3 : i32) : i32
    %31 = llvm.alloca %30 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %32 = llvm.mlir.constant(0 : i32) : i32
    %33 = llvm.getelementptr %29[%27, 0] : (!llvm.ptr<struct<".1", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %33 : !llvm.ptr<ptr<i8>>
    %34 = llvm.getelementptr %31[%32] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %35 = llvm.bitcast %33 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %35, %34 : !llvm.ptr<ptr<i8>>
    %36 = llvm.mlir.constant(1 : i32) : i32
    %37 = llvm.getelementptr %29[%27, 1] : (!llvm.ptr<struct<".1", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %37 : !llvm.ptr<i64>
    %38 = llvm.getelementptr %31[%36] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %39 = llvm.bitcast %37 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %39, %38 : !llvm.ptr<ptr<i8>>
    %40 = llvm.mlir.constant(2 : i32) : i32
    %41 = llvm.getelementptr %29[%27, 2] : (!llvm.ptr<struct<".1", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>>
    %42 = llvm.getelementptr %31[%40] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %43 = llvm.bitcast %41 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>> to !llvm.ptr<i8>
    llvm.store %43, %42 : !llvm.ptr<ptr<i8>>
    %44 = llvm.mlir.addressof @ral_recv_input___cpu___pvoid_i64___m2df32 : !llvm.ptr<array<42 x i8>>
    %45 = llvm.mlir.constant(0 : index) : i64
    %46 = llvm.getelementptr %44[%45, %45] : (!llvm.ptr<array<42 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %46, %31) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %47 = llvm.load %41 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>>
    %48 = llvm.mlir.constant(2560 : index) : i64
    %49 = llvm.mlir.constant(1 : index) : i64
    %50 = llvm.mlir.null : !llvm.ptr<f32>
    %51 = llvm.getelementptr %50[%48] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %52 = llvm.ptrtoint %51 : !llvm.ptr<f32> to i64
    %53 = llvm.mlir.constant(0 : i32) : i32
    %54 = llvm.mlir.constant(1 : i32) : i32
    %55 = llvm.alloca %54 x !llvm.struct<".2", (ptr<i8>, i64, ptr<i8>)> : (i32) -> !llvm.ptr<struct<".2", (ptr<i8>, i64, ptr<i8>)>>
    %56 = llvm.mlir.constant(3 : i32) : i32
    %57 = llvm.alloca %56 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %58 = llvm.mlir.constant(0 : i32) : i32
    %59 = llvm.getelementptr %55[%53, 0] : (!llvm.ptr<struct<".2", (ptr<i8>, i64, ptr<i8>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %59 : !llvm.ptr<ptr<i8>>
    %60 = llvm.getelementptr %57[%58] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %61 = llvm.bitcast %59 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %61, %60 : !llvm.ptr<ptr<i8>>
    %62 = llvm.mlir.constant(1 : i32) : i32
    %63 = llvm.getelementptr %55[%53, 1] : (!llvm.ptr<struct<".2", (ptr<i8>, i64, ptr<i8>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %52, %63 : !llvm.ptr<i64>
    %64 = llvm.getelementptr %57[%62] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %65 = llvm.bitcast %63 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %65, %64 : !llvm.ptr<ptr<i8>>
    %66 = llvm.mlir.constant(2 : i32) : i32
    %67 = llvm.getelementptr %55[%53, 2] : (!llvm.ptr<struct<".2", (ptr<i8>, i64, ptr<i8>)>>, i32) -> !llvm.ptr<ptr<i8>>
    %68 = llvm.getelementptr %57[%66] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %69 = llvm.bitcast %67 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %69, %68 : !llvm.ptr<ptr<i8>>
    %70 = llvm.mlir.addressof @alloc___gpu___pvoid_i64___pvoid : !llvm.ptr<array<32 x i8>>
    %71 = llvm.mlir.constant(0 : index) : i64
    %72 = llvm.getelementptr %70[%71, %71] : (!llvm.ptr<array<32 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %72, %57) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %73 = llvm.load %67 : !llvm.ptr<ptr<i8>>
    %74 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>
    %75 = llvm.bitcast %73 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %76 = llvm.insertvalue %75, %74[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %77 = llvm.insertvalue %75, %76[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %78 = llvm.mlir.constant(0 : index) : i64
    %79 = llvm.insertvalue %78, %77[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %80 = llvm.mlir.constant(1 : index) : i64
    %81 = llvm.insertvalue %48, %79[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %82 = llvm.insertvalue %80, %81[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %83 = llvm.mlir.addressof @main_kernel_blob_gpu.binary_compute_60 : !llvm.ptr<array<472 x i8>>
    %84 = llvm.mlir.constant(0 : index) : i64
    %85 = llvm.getelementptr %83[%84, %84] : (!llvm.ptr<array<472 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %86 = llvm.mlir.addressof @main_kernel_blob_gpu.binary_sm_70 : !llvm.ptr<array<1048 x i8>>
    %87 = llvm.mlir.constant(0 : index) : i64
    %88 = llvm.getelementptr %86[%87, %87] : (!llvm.ptr<array<1048 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %89 = llvm.mlir.addressof @main_kernel_blob_gpu.binary_sm_75 : !llvm.ptr<array<1032 x i8>>
    %90 = llvm.mlir.constant(0 : index) : i64
    %91 = llvm.getelementptr %89[%90, %90] : (!llvm.ptr<array<1032 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %92 = llvm.mlir.constant(3 : i32) : i32
    %93 = llvm.alloca %92 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %94 = llvm.mlir.constant(0 : i32) : i32
    %95 = llvm.getelementptr %93[%94] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %85, %95 : !llvm.ptr<ptr<i8>>
    %96 = llvm.mlir.constant(1 : i32) : i32
    %97 = llvm.getelementptr %93[%96] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %88, %97 : !llvm.ptr<ptr<i8>>
    %98 = llvm.mlir.constant(2 : i32) : i32
    %99 = llvm.getelementptr %93[%98] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %91, %99 : !llvm.ptr<ptr<i8>>
    %100 = llvm.mlir.constant(3 : i64) : i64
    %101 = llvm.mlir.addressof @main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name : !llvm.ptr<array<41 x i8>>
    %102 = llvm.mlir.constant(0 : index) : i64
    %103 = llvm.getelementptr %101[%102, %102] : (!llvm.ptr<array<41 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %104 = llvm.extractvalue %82[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %105 = llvm.extractvalue %82[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %106 = llvm.extractvalue %82[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %107 = llvm.extractvalue %82[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %108 = llvm.extractvalue %82[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %109 = llvm.mlir.constant(1 : i32) : i32
    %110 = llvm.alloca %109 x !llvm.struct<".3", (i64, ptr<f32>, ptr<f32>, i64, i64, i64)> : (i32) -> !llvm.ptr<struct<".3", (i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>
    %111 = llvm.mlir.constant(6 : i32) : i32
    %112 = llvm.alloca %111 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %113 = llvm.mlir.constant(0 : i32) : i32
    %114 = llvm.mlir.constant(0 : i32) : i32
    %115 = llvm.getelementptr %110[%113, 0] : (!llvm.ptr<struct<".3", (i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %115 : !llvm.ptr<i64>
    %116 = llvm.getelementptr %112[%114] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %117 = llvm.bitcast %115 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %117, %116 : !llvm.ptr<ptr<i8>>
    %118 = llvm.mlir.constant(1 : i32) : i32
    %119 = llvm.getelementptr %110[%113, 1] : (!llvm.ptr<struct<".3", (i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %104, %119 : !llvm.ptr<ptr<f32>>
    %120 = llvm.getelementptr %112[%118] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %121 = llvm.bitcast %119 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %121, %120 : !llvm.ptr<ptr<i8>>
    %122 = llvm.mlir.constant(2 : i32) : i32
    %123 = llvm.getelementptr %110[%113, 2] : (!llvm.ptr<struct<".3", (i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %105, %123 : !llvm.ptr<ptr<f32>>
    %124 = llvm.getelementptr %112[%122] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %125 = llvm.bitcast %123 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %125, %124 : !llvm.ptr<ptr<i8>>
    %126 = llvm.mlir.constant(3 : i32) : i32
    %127 = llvm.getelementptr %110[%113, 3] : (!llvm.ptr<struct<".3", (i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %106, %127 : !llvm.ptr<i64>
    %128 = llvm.getelementptr %112[%126] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %129 = llvm.bitcast %127 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %129, %128 : !llvm.ptr<ptr<i8>>
    %130 = llvm.mlir.constant(4 : i32) : i32
    %131 = llvm.getelementptr %110[%113, 4] : (!llvm.ptr<struct<".3", (i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %107, %131 : !llvm.ptr<i64>
    %132 = llvm.getelementptr %112[%130] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %133 = llvm.bitcast %131 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %133, %132 : !llvm.ptr<ptr<i8>>
    %134 = llvm.mlir.constant(5 : i32) : i32
    %135 = llvm.getelementptr %110[%113, 5] : (!llvm.ptr<struct<".3", (i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %108, %135 : !llvm.ptr<i64>
    %136 = llvm.getelementptr %112[%134] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %137 = llvm.bitcast %135 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %137, %136 : !llvm.ptr<ptr<i8>>
    %138 = llvm.mlir.constant(0 : i32) : i32
    %139 = llvm.mlir.constant(6 : i32) : i32
    %140 = llvm.inttoptr %138 : i32 to !llvm.ptr<i8>
    %141 = llvm.mlir.constant(0 : i32) : i32
    %142 = llvm.mlir.constant(1 : i32) : i32
    %143 = llvm.alloca %142 x !llvm.struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %144 = llvm.mlir.constant(14 : i32) : i32
    %145 = llvm.alloca %144 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %146 = llvm.mlir.constant(0 : i32) : i32
    %147 = llvm.getelementptr %143[%141, 0] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %147 : !llvm.ptr<ptr<i8>>
    %148 = llvm.getelementptr %145[%146] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %149 = llvm.bitcast %147 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %149, %148 : !llvm.ptr<ptr<i8>>
    %150 = llvm.mlir.constant(1 : i32) : i32
    %151 = llvm.getelementptr %143[%141, 1] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %93, %151 : !llvm.ptr<ptr<ptr<i8>>>
    %152 = llvm.getelementptr %145[%150] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %153 = llvm.bitcast %151 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %153, %152 : !llvm.ptr<ptr<i8>>
    %154 = llvm.mlir.constant(2 : i32) : i32
    %155 = llvm.getelementptr %143[%141, 2] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %100, %155 : !llvm.ptr<i64>
    %156 = llvm.getelementptr %145[%154] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %157 = llvm.bitcast %155 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %157, %156 : !llvm.ptr<ptr<i8>>
    %158 = llvm.mlir.constant(3 : i32) : i32
    %159 = llvm.getelementptr %143[%141, 3] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %103, %159 : !llvm.ptr<ptr<i8>>
    %160 = llvm.getelementptr %145[%158] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %161 = llvm.bitcast %159 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %161, %160 : !llvm.ptr<ptr<i8>>
    %162 = llvm.mlir.constant(4 : i32) : i32
    %163 = llvm.getelementptr %143[%141, 4] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %3, %163 : !llvm.ptr<i64>
    %164 = llvm.getelementptr %145[%162] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %165 = llvm.bitcast %163 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %165, %164 : !llvm.ptr<ptr<i8>>
    %166 = llvm.mlir.constant(5 : i32) : i32
    %167 = llvm.getelementptr %143[%141, 5] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %167 : !llvm.ptr<i64>
    %168 = llvm.getelementptr %145[%166] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %169 = llvm.bitcast %167 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %169, %168 : !llvm.ptr<ptr<i8>>
    %170 = llvm.mlir.constant(6 : i32) : i32
    %171 = llvm.getelementptr %143[%141, 6] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %171 : !llvm.ptr<i64>
    %172 = llvm.getelementptr %145[%170] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %173 = llvm.bitcast %171 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %173, %172 : !llvm.ptr<ptr<i8>>
    %174 = llvm.mlir.constant(7 : i32) : i32
    %175 = llvm.getelementptr %143[%141, 7] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %175 : !llvm.ptr<i64>
    %176 = llvm.getelementptr %145[%174] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %177 = llvm.bitcast %175 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %177, %176 : !llvm.ptr<ptr<i8>>
    %178 = llvm.mlir.constant(8 : i32) : i32
    %179 = llvm.getelementptr %143[%141, 8] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %179 : !llvm.ptr<i64>
    %180 = llvm.getelementptr %145[%178] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %181 = llvm.bitcast %179 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %181, %180 : !llvm.ptr<ptr<i8>>
    %182 = llvm.mlir.constant(9 : i32) : i32
    %183 = llvm.getelementptr %143[%141, 9] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %183 : !llvm.ptr<i64>
    %184 = llvm.getelementptr %145[%182] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %185 = llvm.bitcast %183 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %185, %184 : !llvm.ptr<ptr<i8>>
    %186 = llvm.mlir.constant(10 : i32) : i32
    %187 = llvm.getelementptr %143[%141, 10] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %138, %187 : !llvm.ptr<i32>
    %188 = llvm.getelementptr %145[%186] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %189 = llvm.bitcast %187 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %189, %188 : !llvm.ptr<ptr<i8>>
    %190 = llvm.mlir.constant(11 : i32) : i32
    %191 = llvm.getelementptr %143[%141, 11] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %140, %191 : !llvm.ptr<ptr<i8>>
    %192 = llvm.getelementptr %145[%190] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %193 = llvm.bitcast %191 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %193, %192 : !llvm.ptr<ptr<i8>>
    %194 = llvm.mlir.constant(12 : i32) : i32
    %195 = llvm.getelementptr %143[%141, 12] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %139, %195 : !llvm.ptr<i32>
    %196 = llvm.getelementptr %145[%194] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %197 = llvm.bitcast %195 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %197, %196 : !llvm.ptr<ptr<i8>>
    %198 = llvm.mlir.constant(13 : i32) : i32
    %199 = llvm.getelementptr %143[%141, 13] : (!llvm.ptr<struct<".4", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %112, %199 : !llvm.ptr<ptr<ptr<i8>>>
    %200 = llvm.getelementptr %145[%198] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %201 = llvm.bitcast %199 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %201, %200 : !llvm.ptr<ptr<i8>>
    %202 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %203 = llvm.mlir.constant(0 : index) : i64
    %204 = llvm.getelementptr %202[%203, %203] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %204, %145) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %205 = llvm.mlir.addressof @main_kernel_0_blob_gpu.binary_compute_60 : !llvm.ptr<array<1488 x i8>>
    %206 = llvm.mlir.constant(0 : index) : i64
    %207 = llvm.getelementptr %205[%206, %206] : (!llvm.ptr<array<1488 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %208 = llvm.mlir.addressof @main_kernel_0_blob_gpu.binary_sm_70 : !llvm.ptr<array<1752 x i8>>
    %209 = llvm.mlir.constant(0 : index) : i64
    %210 = llvm.getelementptr %208[%209, %209] : (!llvm.ptr<array<1752 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %211 = llvm.mlir.addressof @main_kernel_0_blob_gpu.binary_sm_75 : !llvm.ptr<array<1736 x i8>>
    %212 = llvm.mlir.constant(0 : index) : i64
    %213 = llvm.getelementptr %211[%212, %212] : (!llvm.ptr<array<1736 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %214 = llvm.mlir.constant(3 : i32) : i32
    %215 = llvm.alloca %214 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %216 = llvm.mlir.constant(0 : i32) : i32
    %217 = llvm.getelementptr %215[%216] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %207, %217 : !llvm.ptr<ptr<i8>>
    %218 = llvm.mlir.constant(1 : i32) : i32
    %219 = llvm.getelementptr %215[%218] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %210, %219 : !llvm.ptr<ptr<i8>>
    %220 = llvm.mlir.constant(2 : i32) : i32
    %221 = llvm.getelementptr %215[%220] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %213, %221 : !llvm.ptr<ptr<i8>>
    %222 = llvm.mlir.constant(3 : i64) : i64
    %223 = llvm.mlir.addressof @main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name : !llvm.ptr<array<43 x i8>>
    %224 = llvm.mlir.constant(0 : index) : i64
    %225 = llvm.getelementptr %223[%224, %224] : (!llvm.ptr<array<43 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %226 = llvm.extractvalue %26[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %227 = llvm.extractvalue %26[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %228 = llvm.extractvalue %26[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %229 = llvm.extractvalue %26[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %230 = llvm.extractvalue %26[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %231 = llvm.extractvalue %26[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %232 = llvm.extractvalue %26[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %233 = llvm.extractvalue %47[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %234 = llvm.extractvalue %47[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %235 = llvm.extractvalue %47[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %236 = llvm.extractvalue %47[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %237 = llvm.extractvalue %47[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %238 = llvm.extractvalue %47[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %239 = llvm.extractvalue %47[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %240 = llvm.extractvalue %82[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %241 = llvm.extractvalue %82[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %242 = llvm.extractvalue %82[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %243 = llvm.extractvalue %82[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %244 = llvm.extractvalue %82[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %245 = llvm.mlir.constant(1 : i32) : i32
    %246 = llvm.alloca %245 x !llvm.struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)> : (i32) -> !llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>
    %247 = llvm.mlir.constant(21 : i32) : i32
    %248 = llvm.alloca %247 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %249 = llvm.mlir.constant(0 : i32) : i32
    %250 = llvm.mlir.constant(0 : i32) : i32
    %251 = llvm.getelementptr %246[%249, 0] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %251 : !llvm.ptr<i64>
    %252 = llvm.getelementptr %248[%250] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %253 = llvm.bitcast %251 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %253, %252 : !llvm.ptr<ptr<i8>>
    %254 = llvm.mlir.constant(1 : i32) : i32
    %255 = llvm.getelementptr %246[%249, 1] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %2, %255 : !llvm.ptr<i64>
    %256 = llvm.getelementptr %248[%254] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %257 = llvm.bitcast %255 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %257, %256 : !llvm.ptr<ptr<i8>>
    %258 = llvm.mlir.constant(2 : i32) : i32
    %259 = llvm.getelementptr %246[%249, 2] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %226, %259 : !llvm.ptr<ptr<f32>>
    %260 = llvm.getelementptr %248[%258] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %261 = llvm.bitcast %259 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %261, %260 : !llvm.ptr<ptr<i8>>
    %262 = llvm.mlir.constant(3 : i32) : i32
    %263 = llvm.getelementptr %246[%249, 3] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %227, %263 : !llvm.ptr<ptr<f32>>
    %264 = llvm.getelementptr %248[%262] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %265 = llvm.bitcast %263 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %265, %264 : !llvm.ptr<ptr<i8>>
    %266 = llvm.mlir.constant(4 : i32) : i32
    %267 = llvm.getelementptr %246[%249, 4] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %228, %267 : !llvm.ptr<i64>
    %268 = llvm.getelementptr %248[%266] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %269 = llvm.bitcast %267 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %269, %268 : !llvm.ptr<ptr<i8>>
    %270 = llvm.mlir.constant(5 : i32) : i32
    %271 = llvm.getelementptr %246[%249, 5] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %229, %271 : !llvm.ptr<i64>
    %272 = llvm.getelementptr %248[%270] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %273 = llvm.bitcast %271 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %273, %272 : !llvm.ptr<ptr<i8>>
    %274 = llvm.mlir.constant(6 : i32) : i32
    %275 = llvm.getelementptr %246[%249, 6] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %230, %275 : !llvm.ptr<i64>
    %276 = llvm.getelementptr %248[%274] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %277 = llvm.bitcast %275 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %277, %276 : !llvm.ptr<ptr<i8>>
    %278 = llvm.mlir.constant(7 : i32) : i32
    %279 = llvm.getelementptr %246[%249, 7] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %231, %279 : !llvm.ptr<i64>
    %280 = llvm.getelementptr %248[%278] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %281 = llvm.bitcast %279 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %281, %280 : !llvm.ptr<ptr<i8>>
    %282 = llvm.mlir.constant(8 : i32) : i32
    %283 = llvm.getelementptr %246[%249, 8] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %232, %283 : !llvm.ptr<i64>
    %284 = llvm.getelementptr %248[%282] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %285 = llvm.bitcast %283 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %285, %284 : !llvm.ptr<ptr<i8>>
    %286 = llvm.mlir.constant(9 : i32) : i32
    %287 = llvm.getelementptr %246[%249, 9] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %233, %287 : !llvm.ptr<ptr<f32>>
    %288 = llvm.getelementptr %248[%286] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %289 = llvm.bitcast %287 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %289, %288 : !llvm.ptr<ptr<i8>>
    %290 = llvm.mlir.constant(10 : i32) : i32
    %291 = llvm.getelementptr %246[%249, 10] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %234, %291 : !llvm.ptr<ptr<f32>>
    %292 = llvm.getelementptr %248[%290] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %293 = llvm.bitcast %291 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %293, %292 : !llvm.ptr<ptr<i8>>
    %294 = llvm.mlir.constant(11 : i32) : i32
    %295 = llvm.getelementptr %246[%249, 11] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %235, %295 : !llvm.ptr<i64>
    %296 = llvm.getelementptr %248[%294] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %297 = llvm.bitcast %295 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %297, %296 : !llvm.ptr<ptr<i8>>
    %298 = llvm.mlir.constant(12 : i32) : i32
    %299 = llvm.getelementptr %246[%249, 12] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %236, %299 : !llvm.ptr<i64>
    %300 = llvm.getelementptr %248[%298] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %301 = llvm.bitcast %299 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %301, %300 : !llvm.ptr<ptr<i8>>
    %302 = llvm.mlir.constant(13 : i32) : i32
    %303 = llvm.getelementptr %246[%249, 13] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %237, %303 : !llvm.ptr<i64>
    %304 = llvm.getelementptr %248[%302] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %305 = llvm.bitcast %303 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %305, %304 : !llvm.ptr<ptr<i8>>
    %306 = llvm.mlir.constant(14 : i32) : i32
    %307 = llvm.getelementptr %246[%249, 14] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %238, %307 : !llvm.ptr<i64>
    %308 = llvm.getelementptr %248[%306] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %309 = llvm.bitcast %307 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %309, %308 : !llvm.ptr<ptr<i8>>
    %310 = llvm.mlir.constant(15 : i32) : i32
    %311 = llvm.getelementptr %246[%249, 15] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %239, %311 : !llvm.ptr<i64>
    %312 = llvm.getelementptr %248[%310] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %313 = llvm.bitcast %311 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %313, %312 : !llvm.ptr<ptr<i8>>
    %314 = llvm.mlir.constant(16 : i32) : i32
    %315 = llvm.getelementptr %246[%249, 16] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %240, %315 : !llvm.ptr<ptr<f32>>
    %316 = llvm.getelementptr %248[%314] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %317 = llvm.bitcast %315 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %317, %316 : !llvm.ptr<ptr<i8>>
    %318 = llvm.mlir.constant(17 : i32) : i32
    %319 = llvm.getelementptr %246[%249, 17] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %241, %319 : !llvm.ptr<ptr<f32>>
    %320 = llvm.getelementptr %248[%318] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %321 = llvm.bitcast %319 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %321, %320 : !llvm.ptr<ptr<i8>>
    %322 = llvm.mlir.constant(18 : i32) : i32
    %323 = llvm.getelementptr %246[%249, 18] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %242, %323 : !llvm.ptr<i64>
    %324 = llvm.getelementptr %248[%322] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %325 = llvm.bitcast %323 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %325, %324 : !llvm.ptr<ptr<i8>>
    %326 = llvm.mlir.constant(19 : i32) : i32
    %327 = llvm.getelementptr %246[%249, 19] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %243, %327 : !llvm.ptr<i64>
    %328 = llvm.getelementptr %248[%326] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %329 = llvm.bitcast %327 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %329, %328 : !llvm.ptr<ptr<i8>>
    %330 = llvm.mlir.constant(20 : i32) : i32
    %331 = llvm.getelementptr %246[%249, 20] : (!llvm.ptr<struct<".5", (i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %244, %331 : !llvm.ptr<i64>
    %332 = llvm.getelementptr %248[%330] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %333 = llvm.bitcast %331 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %333, %332 : !llvm.ptr<ptr<i8>>
    %334 = llvm.mlir.constant(0 : i32) : i32
    %335 = llvm.mlir.constant(21 : i32) : i32
    %336 = llvm.inttoptr %334 : i32 to !llvm.ptr<i8>
    %337 = llvm.mlir.constant(0 : i32) : i32
    %338 = llvm.mlir.constant(1 : i32) : i32
    %339 = llvm.alloca %338 x !llvm.struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %340 = llvm.mlir.constant(14 : i32) : i32
    %341 = llvm.alloca %340 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %342 = llvm.mlir.constant(0 : i32) : i32
    %343 = llvm.getelementptr %339[%337, 0] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %343 : !llvm.ptr<ptr<i8>>
    %344 = llvm.getelementptr %341[%342] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %345 = llvm.bitcast %343 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %345, %344 : !llvm.ptr<ptr<i8>>
    %346 = llvm.mlir.constant(1 : i32) : i32
    %347 = llvm.getelementptr %339[%337, 1] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %215, %347 : !llvm.ptr<ptr<ptr<i8>>>
    %348 = llvm.getelementptr %341[%346] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %349 = llvm.bitcast %347 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %349, %348 : !llvm.ptr<ptr<i8>>
    %350 = llvm.mlir.constant(2 : i32) : i32
    %351 = llvm.getelementptr %339[%337, 2] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %222, %351 : !llvm.ptr<i64>
    %352 = llvm.getelementptr %341[%350] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %353 = llvm.bitcast %351 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %353, %352 : !llvm.ptr<ptr<i8>>
    %354 = llvm.mlir.constant(3 : i32) : i32
    %355 = llvm.getelementptr %339[%337, 3] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %225, %355 : !llvm.ptr<ptr<i8>>
    %356 = llvm.getelementptr %341[%354] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %357 = llvm.bitcast %355 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %357, %356 : !llvm.ptr<ptr<i8>>
    %358 = llvm.mlir.constant(4 : i32) : i32
    %359 = llvm.getelementptr %339[%337, 4] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1, %359 : !llvm.ptr<i64>
    %360 = llvm.getelementptr %341[%358] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %361 = llvm.bitcast %359 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %361, %360 : !llvm.ptr<ptr<i8>>
    %362 = llvm.mlir.constant(5 : i32) : i32
    %363 = llvm.getelementptr %339[%337, 5] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %363 : !llvm.ptr<i64>
    %364 = llvm.getelementptr %341[%362] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %365 = llvm.bitcast %363 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %365, %364 : !llvm.ptr<ptr<i8>>
    %366 = llvm.mlir.constant(6 : i32) : i32
    %367 = llvm.getelementptr %339[%337, 6] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %367 : !llvm.ptr<i64>
    %368 = llvm.getelementptr %341[%366] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %369 = llvm.bitcast %367 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %369, %368 : !llvm.ptr<ptr<i8>>
    %370 = llvm.mlir.constant(7 : i32) : i32
    %371 = llvm.getelementptr %339[%337, 7] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %371 : !llvm.ptr<i64>
    %372 = llvm.getelementptr %341[%370] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %373 = llvm.bitcast %371 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %373, %372 : !llvm.ptr<ptr<i8>>
    %374 = llvm.mlir.constant(8 : i32) : i32
    %375 = llvm.getelementptr %339[%337, 8] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %375 : !llvm.ptr<i64>
    %376 = llvm.getelementptr %341[%374] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %377 = llvm.bitcast %375 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %377, %376 : !llvm.ptr<ptr<i8>>
    %378 = llvm.mlir.constant(9 : i32) : i32
    %379 = llvm.getelementptr %339[%337, 9] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %379 : !llvm.ptr<i64>
    %380 = llvm.getelementptr %341[%378] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %381 = llvm.bitcast %379 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %381, %380 : !llvm.ptr<ptr<i8>>
    %382 = llvm.mlir.constant(10 : i32) : i32
    %383 = llvm.getelementptr %339[%337, 10] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %334, %383 : !llvm.ptr<i32>
    %384 = llvm.getelementptr %341[%382] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %385 = llvm.bitcast %383 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %385, %384 : !llvm.ptr<ptr<i8>>
    %386 = llvm.mlir.constant(11 : i32) : i32
    %387 = llvm.getelementptr %339[%337, 11] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %336, %387 : !llvm.ptr<ptr<i8>>
    %388 = llvm.getelementptr %341[%386] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %389 = llvm.bitcast %387 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %389, %388 : !llvm.ptr<ptr<i8>>
    %390 = llvm.mlir.constant(12 : i32) : i32
    %391 = llvm.getelementptr %339[%337, 12] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %335, %391 : !llvm.ptr<i32>
    %392 = llvm.getelementptr %341[%390] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %393 = llvm.bitcast %391 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %393, %392 : !llvm.ptr<ptr<i8>>
    %394 = llvm.mlir.constant(13 : i32) : i32
    %395 = llvm.getelementptr %339[%337, 13] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %248, %395 : !llvm.ptr<ptr<ptr<i8>>>
    %396 = llvm.getelementptr %341[%394] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %397 = llvm.bitcast %395 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %397, %396 : !llvm.ptr<ptr<i8>>
    %398 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %399 = llvm.mlir.constant(0 : index) : i64
    %400 = llvm.getelementptr %398[%399, %399] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %400, %341) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %401 = llvm.mlir.constant(0 : i32) : i32
    %402 = llvm.mlir.constant(1 : i32) : i32
    %403 = llvm.extractvalue %82[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %404 = llvm.extractvalue %82[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %405 = llvm.extractvalue %82[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %406 = llvm.extractvalue %82[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %407 = llvm.extractvalue %82[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %408 = llvm.alloca %402 x !llvm.struct<".7", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64)> : (i32) -> !llvm.ptr<struct<".7", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>
    %409 = llvm.mlir.constant(7 : i32) : i32
    %410 = llvm.alloca %409 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %411 = llvm.mlir.constant(0 : i32) : i32
    %412 = llvm.getelementptr %408[%401, 0] : (!llvm.ptr<struct<".7", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %412 : !llvm.ptr<ptr<i8>>
    %413 = llvm.getelementptr %410[%411] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %414 = llvm.bitcast %412 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %414, %413 : !llvm.ptr<ptr<i8>>
    %415 = llvm.mlir.constant(1 : i32) : i32
    %416 = llvm.getelementptr %408[%401, 1] : (!llvm.ptr<struct<".7", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %5, %416 : !llvm.ptr<i64>
    %417 = llvm.getelementptr %410[%415] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %418 = llvm.bitcast %416 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %418, %417 : !llvm.ptr<ptr<i8>>
    %419 = llvm.mlir.constant(2 : i32) : i32
    %420 = llvm.getelementptr %408[%401, 2] : (!llvm.ptr<struct<".7", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %403, %420 : !llvm.ptr<ptr<f32>>
    %421 = llvm.getelementptr %410[%419] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %422 = llvm.bitcast %420 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %422, %421 : !llvm.ptr<ptr<i8>>
    %423 = llvm.mlir.constant(3 : i32) : i32
    %424 = llvm.getelementptr %408[%401, 3] : (!llvm.ptr<struct<".7", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %404, %424 : !llvm.ptr<ptr<f32>>
    %425 = llvm.getelementptr %410[%423] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %426 = llvm.bitcast %424 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %426, %425 : !llvm.ptr<ptr<i8>>
    %427 = llvm.mlir.constant(4 : i32) : i32
    %428 = llvm.getelementptr %408[%401, 4] : (!llvm.ptr<struct<".7", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %405, %428 : !llvm.ptr<i64>
    %429 = llvm.getelementptr %410[%427] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %430 = llvm.bitcast %428 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %430, %429 : !llvm.ptr<ptr<i8>>
    %431 = llvm.mlir.constant(5 : i32) : i32
    %432 = llvm.getelementptr %408[%401, 5] : (!llvm.ptr<struct<".7", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %406, %432 : !llvm.ptr<i64>
    %433 = llvm.getelementptr %410[%431] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %434 = llvm.bitcast %432 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %434, %433 : !llvm.ptr<ptr<i8>>
    %435 = llvm.mlir.constant(6 : i32) : i32
    %436 = llvm.getelementptr %408[%401, 6] : (!llvm.ptr<struct<".7", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %407, %436 : !llvm.ptr<i64>
    %437 = llvm.getelementptr %410[%435] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %438 = llvm.bitcast %436 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %438, %437 : !llvm.ptr<ptr<i8>>
    %439 = llvm.mlir.addressof @ral_send_output___cpu___pvoid_i64_m1df32___void : !llvm.ptr<array<48 x i8>>
    %440 = llvm.mlir.constant(0 : index) : i64
    %441 = llvm.getelementptr %439[%440, %440] : (!llvm.ptr<array<48 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %441, %410) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    llvm.return
  }
}


===-------------------------------------------------------------------------===
                         ... Execution time report ...
===-------------------------------------------------------------------------===
  Total Execution Time: 0.4872 seconds

  ----Wall Time----  ----Name----
    0.0018 (  0.4%)  Inliner
    0.0000 (  0.0%)    (A) CallGraph
    0.0009 (  0.2%)  'func.func' Pipeline
    0.0009 (  0.2%)    Canonicalizer
    0.0026 (  0.5%)  'func.func' Pipeline
    0.0001 (  0.0%)    MhloDecompositionRewriterPass
    0.0006 (  0.1%)    RemoveShapeConstraintsPass
    0.0006 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    DiscCustomCallRewriterPass
    0.0000 (  0.0%)    DiscConvertFakeQuantOpPass
    0.0000 (  0.0%)    DiscLowerGpuQuantizeAndDequantizePass
    0.0011 (  0.2%)    ConvertShapeToStandardPass
    0.0019 (  0.4%)  DiscShapeOptimizationPass
    0.0004 (  0.1%)  'builtin.func' Pipeline
    0.0004 (  0.1%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0004 (  0.1%)  'func.func' Pipeline
    0.0000 (  0.0%)    ConvertTensorToStandardPass
    0.0000 (  0.0%)    ConvertHloToStandardPass
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    DiscAlgebraicSimplifierPass
    0.0000 (  0.0%)    SplitLargeOpsPass
    0.0000 (  0.0%)    DotRewriterPass
    0.0010 (  0.2%)  DiscShapeOptimizationPass
    0.0001 (  0.0%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscDotMergePass
    0.0010 (  0.2%)  DiscShapeOptimizationPass
    0.0000 (  0.0%)  'func.func' Pipeline
    0.0000 (  0.0%)    HloCanonicalizeReductionPass
    0.0011 (  0.2%)  DiscShapeOptimizationPass
    0.0000 (  0.0%)  DiscMarkShapeCalculationPass
    0.0003 (  0.1%)  PlaceOpsPass
    0.0003 (  0.1%)  'func.func' Pipeline
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    ElementTypeConverterPass
    0.0010 (  0.2%)  DiscShapeOptimizationPass
    0.0001 (  0.0%)  'func.func' Pipeline
    0.0000 (  0.0%)    ReductionRewriterPass
    0.0000 (  0.0%)    ConvRewriterPass
    0.0000 (  0.0%)    ConvRewriterPass
    0.0000 (  0.0%)    QuantizedDotRewriterPass
    0.0010 (  0.2%)  DiscShapeOptimizationPass
    0.0015 (  0.3%)  'func.func' Pipeline
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0012 (  0.3%)    TransposeSimplifierPass
    0.0000 (  0.0%)    GpuConvPaddingLegalizationPass
    0.0010 (  0.2%)  DiscShapeOptimizationPass
    0.0000 (  0.0%)  'func.func' Pipeline
    0.0000 (  0.0%)    DiscAlgebraicSimplifierPass
    0.0015 (  0.3%)  DiscShapeOptimizationPass
    0.0006 (  0.1%)  'func.func' Pipeline
    0.0004 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0005 (  0.1%)  FuncBufferize
    0.0000 (  0.0%)  DiscHloLegalizeToLhloPass
    0.0010 (  0.2%)  HloLegalizeToLhloPass
    0.0009 (  0.2%)  'func.func' Pipeline
    0.0009 (  0.2%)    Canonicalizer
    0.0000 (  0.0%)  DiscLhloRewriterPass
    0.0005 (  0.1%)  'func.func' Pipeline
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    ConvertShapeToStandardPass
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    LegalizeToTensorOpPass
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    StdBufferizePass
    0.0000 (  0.0%)  ArithBufferize
    0.0003 (  0.1%)  'func.func' Pipeline
    0.0000 (  0.0%)    TensorBufferize
    0.0000 (  0.0%)    FinalizingBufferize
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    DiscMemrefCanonicalizer
    0.0008 (  0.2%)  DiscAssignMemorySpacePass
    0.0052 (  1.1%)  'func.func' Pipeline
    0.0000 (  0.0%)    DiscDuplicateComputationForFusionPass
    0.0000 (  0.0%)    PromoteBuffersToStack
    0.0000 (  0.0%)    DiscMemRefLoadStoreSimplifierPass
    0.0010 (  0.2%)    DiscFusionPass
    0.0000 (  0.0%)    DiscFuseSplatConstPass
    0.0017 (  0.4%)    DiscSpecializeFusionWithSpeculationPass
    0.0010 (  0.2%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0009 (  0.2%)    BufferDeallocation
    0.0000 (  0.0%)    DiscBufferDeallocationPass
    0.0011 (  0.2%)  RalInjectExecutionContextPass
    0.0012 (  0.2%)  'func.func' Pipeline
    0.0012 (  0.2%)    DiscLowerToLibraryCallPass
    0.0001 (  0.0%)  DiscConstToRALPass
    0.0434 (  8.9%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscMemRefLoadStoreSimplifierPass
    0.0033 (  0.7%)    DiscLhloLegalizeRootsToParallelLoopsPass
    0.0001 (  0.0%)    ExpandOps
    0.0002 (  0.0%)    UnhandledAtomicRMWConverterPass
    0.0030 (  0.6%)    InputInlineFusionPass
    0.0001 (  0.0%)    ArithExpandOps
    0.0002 (  0.0%)    DiscBF16ExpansionPass
    0.0002 (  0.0%)    FoldMemRefAliasOps
    0.0052 (  1.1%)    DiscFlattenMemrefAccessPass
    0.0052 (  1.1%)    Canonicalizer
    0.0041 (  0.8%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0004 (  0.1%)    Canonicalizer
    0.0003 (  0.1%)    DiscMemRefCSEPass
    0.0032 (  0.7%)    ConvertShapeToStandardPass
    0.0033 (  0.7%)    Canonicalizer
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0003 (  0.1%)    Canonicalizer
    0.0032 (  0.7%)    ParallelLoopCollapsing
    0.0034 (  0.7%)    SCFParallelLoopTiling
    0.0035 (  0.7%)    GpuMapParallelLoopsPass
    0.0040 (  0.8%)    ConvertParallelLoopToGpu
    0.0002 (  0.0%)  'func' Pipeline
    0.0002 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0041 (  0.8%)  GpuLaunchSinkIndexComputations
    0.0048 (  1.0%)  GpuKernelOutlining
    0.0045 (  0.9%)  AssignKernelNamePass
    0.0011 (  0.2%)  'func.func' Pipeline
    0.0011 (  0.2%)    LhloFusionInlinerPass
    0.0002 (  0.0%)  DiscCompIntensFusionToCUDASourcePass
    0.0044 (  0.9%)  ReviseGpuKernelOutliningPass
    0.2807 ( 57.6%)  'gpu.module' Pipeline
    0.0033 (  0.7%)    SCFToControlFlow
    0.0037 (  0.8%)    ConvertAffineToStandard
    0.0034 (  0.7%)    StripDebugInfo
    0.0085 (  1.7%)    DiscLowerGpuOpsToNVVMOpsPass
    0.2618 ( 53.7%)    GpuKernelToBlobPass
    0.0003 (  0.1%)  DiscGPUSourceToLibPass
    0.0011 (  0.2%)  'func.func' Pipeline
    0.0009 (  0.2%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    RemoveDeadBufferPass
    0.0000 (  0.0%)    LinalgLowerToLoops
    0.0003 (  0.1%)  SCFToControlFlow
    0.0003 (  0.1%)  'func.func' Pipeline
    0.0000 (  0.0%)    ExpandStridedMetadata
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0242 (  5.0%)  ConvertAffineToStandard
    0.0240 (  4.9%)  StripDebugInfo
    0.0240 (  4.9%)  DiscStripShapeConstraintOpsPass
    0.0334 (  6.9%)  DiscToLLVMPass
    0.0055 (  1.1%)  Rest
    0.4872 (100.0%)  Total
[DISC] LowerHLOToLLVM takes: 4.880450e-01 s.
before optimize llvm module:
; ModuleID = 'LLVMDialectModule'
source_filename = "LLVMDialectModule"

%0 = type { ptr, i64, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.1 = type { ptr, i64, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.2 = type { ptr, i64, ptr }
%.3 = type { i64, ptr, ptr, i64, i64, i64 }
%.4 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.5 = type { i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64 }
%.6 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.7 = type { ptr, i64, ptr, ptr, i64, i64, i64 }

@ral_send_output___cpu___pvoid_i64_m1df32___void = internal constant [48 x i8] c"ral_send_output___cpu___pvoid_i64_m1df32___void\00"
@main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name = internal constant [43 x i8] c"main_kColReduction_reduce__4_1_0___8w32h_1\00"
@main_kernel_0_blob_gpu.binary_sm_75 = internal constant [1736 x i8] c"P\EDU\BA\01\00\10\00\B8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00x\06\00\00\00\00\00\00s\06\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\80\10\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\0D\07\00a\00K\05K\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00f2\00\00\00\12\10x\00\13\80;\00f\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\08\00R\04\14\00\00\00E\00#\04\F8\18\00\80/\08\00\06\00\00\00\0E\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\04\1C\0C\FE\00c\00\D0\03\00\00@\D0\01#K\00\01\00q\02\02\08\10\0A/\22\B3\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\003\02\11,\88\01\11\00\01\01\22H\00\01\00\11\02l\01\0F\01\00\FF\F8@$v\01\FF\AF\05\B2\FF\00\8E\07\00\C4\0F\00\19y\00\01\00\10%\DB\02a\0E\00\19y\03\00\01\00\10!-\00`\0E\00$z\00\00K\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\CB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\02\FF\B1\02\10\03 \00q\E4\0F\00\12x\03\03\81\05\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\CD\CC\CC\CC\A0\00a\C8\0F\00$x\000\05`\03\0A\8E\07\00\E2@\00\11\04@\00\22\04\16`\00\00p\00\01a\00\14\16p\00 \06\04\10\00!\FF(0\00\B2\04$x\03\04\C0\FE\FF\FF\02\02@\001\12x\02N\06\01p\00p\E4\0F\00\0Cx\00\06\B1\00@p@\F0\03\80\00Q$x\07\03\08\17\04\92\8E\07\00\D2\0F\00\02\88\05\96\060\0F\00\00@\00@$\88\04\06@\01\22\07\02\A0\00`%\86\02\04\00\\\C0\04\04\10\00F\04\04\00f\10\000\81\83\02\83\03\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\05\04\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03`\00Sr\08\FF\FF\00\A0\01\01\F0\00\11\0B\C4\03\10\FF\C5\03\80\E4\0F\04\0Cx\00\00\7F\98\064Dt\01\C0\00\11\F7@\00A\F2\03\00\C8\10\00!\00? \00\11\F2\B0\00\81!\82\09\02\05\00\00\80t\00\81\C8O\00#\82\08\02\09`\00\02\D0\00\000\00\11\070\00\22p\000\014\09\00\04\80\00\93\CC\0F\00\88s\00\0B\08\00\1E\05f\E8\0F\00\1D{\00\01\00Q\EA\0F\00\84\A9O\002\00\00\18 \00A\84\A9\03\09v\04\12\18@\02c!\A2\02\02\03\00\01\00\8F\D0\1F\00\88\A3\00\09\02P\00\095\99\03\09P\00\02\A0\00$\06\FB \01\10\C6 \00!\04\09\12\02\00 \00\11\22@\01$\00\1F\10\01\00\F0\00W\92\04\03\04\00p\00O\93\00\09\04\C0\00\0A\0Ep\00\14\FDP\01\00p\001\A9\08\09>\01\07p\00\18\0F`\01!\A2\080\02\08\E0\00\1F\08\E0\00\0A\0B0\01\00\F0\00&@\000\01\1B\920\01\1F\930\01\0B\0C\80\039\84y\00\D0\006\02x\02\C0\02\00\D0\00Wy\03\09\00 p\00!r\05\80\08\01\01\00p\E4\1F\00%v\02\07{\08\10\02\00\02`\D0\0F\00\8Ey\00@\02A\00\00G\11P\00*Myp\00PGy\00\00\F0\C0\03\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\01\0C\04\1E\00\01\00\02\A4\0D]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13T\07\0C\01\00\138U\00\11\A8\06\00\06x\07\00\B7\01\04\8F\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03!\00P\E5\01\10\00\86\09'\00\00\E4\00*\04\00\01\00\1Fc@\00\04\04@\0B&\84\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\08\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\A4\08\0D\01\00\13\E8@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0C\84\01\13\F8@\00\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\08\01\12\03\C0\01:\0E\80\00\01\00\13\97\94\00/\03\000\10\03/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00"
@main_kernel_0_blob_gpu.binary_sm_70 = internal constant [1752 x i8] c"P\EDU\BA\01\00\10\00\C8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00\88\06\00\00\00\00\00\00\83\06\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\11\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00o\02\00\BE\00u\00\01\00\00\11\0E\06\00a\00F\05F\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00g2\00\00\00\12\10x\00\11\05\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13\F0\93\00\10\04\08\00R\04\18\00\00\00E\002\04\0C\01\18\00C/\08\00\06/\04\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00@\00\04\1C\0C&\01c\000\04\00\00\A0\D8\01#K\00\01\00q\02\02\08\10\0A/\22\BB\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\88\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00;\02\11,\90\01\11\00\09\01\22H\00\01\00\11\02t\01\0F\01\00\FF\F0@$v\01\FF\AF\05\D0\FF\00\8E\07\00\C4\0F\00\89\F3\FF\FF\FF\04\05\00\C2\04b\E2\0F\00\19y\00\01\00\10%\E3\02a\0E\00\19y\03\00\01\00\10!=\00`\0E\00$z\00\00[\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\DB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\04\FF\B9\02\10\03 \00q\E4\0F\00\12x\05\03\91\05\F1\00\C0\8E\07\00\C6\0F\00%x\02\04\CD\CC\CC\CC\B0\00a\C8\0F\00$x\00@\05b\05\0A\8E\07\00\E2`\00\01@\00\12\16`\00A\19x\02\FFa\00\14\16p\00 \09\03\FC\02!\FF(0\00\B2\04$x\03\03\C0\FE\FF\FF\04\02@\001\12x\02^\06\01p\00p\E4\0F\00\0Cx\00\09\B1\00@p@\F0\03\80\00Q$x\02\03\08\1F\04\92\8E\07\00\D2\0F\00\02\88\07\A6\06!\0F\000\01c$\88\06\09\00\0A \00\90\C8\0F\00%\86\04\06\00\\\F0\04\04\10\00F\06\06\00f\10\00!\81\83J\06\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\07\06\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03\B0\00#r\03\A0\01\04\F0\00\11\08\CC\03\10\FF6\00\01\D0\006\0A\00\04 \00\D4\04\0Cx\00\00\7F\00\00\00pDt\01\D0\00\11\F7P\00A\F2\03\00\C8\10\00!\00? \00\11\F2\C0\00\81!\82\0B\04\07\00\00\80\84\00\81\C8O\00#\82\03\04\0BP\00\02\E0\00\000\00\11\070\00\A1p\00\00\CE\0F\00\88s\00\08`\01\00\A6\04f\E8\0F\00\18y\00\01\00f\E2\0F\00\1D{\00\01\00b\EA\0F\00\84\A9\04\A5\07\12\180\000\84\A9\05.\01\02\10\00s$\0E\00!\A2\05\04\BB\07\AF\00\00\D0\1F\00\88\A3\00\0A\05`\00\19\17\99`\00\02\B0\00$\09\FB@\01\10\C6 \00!\07\0A2\02\00 \00\11\22`\01$\00\1F \01\00\00\01 \92\07\00\01\06\80\00O\93\00\0A\07\E0\00\1A\1D\03\80\00\14\FDp\01\13\C6\00\01)\80\00\80\00\18\0F\80\01Z\A2\03\03\04\00\00\01\1F\03\00\01%\00`\011\99\05\0A\B1\0C\04`\01\1B\92`\01\1F\93`\01\1B\0C\D0\03E\84y\00\0Ap\00W\E2\0F\00\02x\10\03\00\F0\00Wy\03\0A\00 \80\00!r\05\E0\08\01\01\00\93\E4\1F\00%v\02\02\00p\10\03q\D0\0F\00\8Ey\00\02\90\00!G\11P\00*Myp\00PGy\00\00\F0\10\04[\FF\83\03\00\C0\B0\00\0F\10\00 \0F\01\00-\00|\04.\03\00\01\00\02$\0E]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13\CC\07\0C\01\00\138U\00\11\A8\06\00\06\F0\07\00\E7\01\04\AF\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03#\00P\C5\02\04H\0B\04\E4\00*\04\00\01\00\1Fc@\00\04\13\80)\00&\8C\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\10\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\1C\09\0D\01\00\13\F0@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0D\84\01\03E\04\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\C8\0C\12\03\C0\01:\0E\80\00\01\00\13\97\94\00+\03\00\01\00\03\B0\10/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00"
@main_kernel_0_blob_gpu.binary_compute_60 = internal constant [1488 x i8] c"P\EDU\BA\01\00\10\00\C0\05\00\00\00\00\00\00\01\00\01\01H\00\00\00x\05\00\00\00\00\00\00t\05\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\03\11\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2!\0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64\0A0\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\10e__4_1_0___8w32h_1(\0A.param .u328\00\18\11_6\00?_0,@\00+\171@\00/64@\00\1F\1F2@\00,\1F3\C0\00,\1F4@\00,\1F5@\00,\1F6@\00,\1F7@\00,\1F8\80\01,\1F9@\00,\1F1\81\02.\1F1A\00-\1F2A\00-\0F\84\02-\1F1\85\02-/15\86\01-\1F6A\00-\0F\88\02-/18A\00-\1F9A\00,\F3\0A20\0A)\0A{\0A.reg .pred %p<18>;\13\00\95b32 %r<24\12\00\10f\12\00\18f\12\00\F0\04b64 %rd<17>;\0A\0A\09.shaI\00\FF\03.align 4 .b8 __wg_\9E\00\18\B20[1024];\0Ald\E0\00\01\DF\00o%r5, [\E5\00\1E\1E0H\00\1F6H\00!s1];\0AmovC\00\B87, %ctaid.x\17\00S8, %t\15\00qad.lo.s\18\00#1,4\00\00\C4\00\C2%r8;\0Asetp.ge8\004p1,%\00\F4\0C6;\0A@%p1 bra $L__BB0_13;\0AshrL\00\130-\00\2231\17\00\02{\00311,\1D\00t24;\0Aadd/\00\132/\00\00#\00\09H\00#3,\1F\00c8;\0Aand\EF\01$14\17\00\93-256;\0Asub1\00\07I\00\194z\00\225,\1E\00\193H\00\136\16\00\947;\0Amul.hi/\00#7,~\00\A9-858993459O\00#8,&\00\128:\00\06F\01#9, \009320\9A\00&0,\D1\00\01M\00\13l\86\00$213\00\185\15\01&3,\1C\00\1950\00#2,P\00S3;\0Aor\16\00%4,\1B\00$16\BC\01\12t\B0\002p2,Q\00B8191\0C\02\02&\03s23, 0f0\01\00\01\D7\01\192\D7\01\183\99\02\02G\03\1F7\9A\02\22\00\E3\02\E4cvta.to.globalP\00\01\9C\00.d7i\00\1F8i\00!\1F3h\00\06\01P\01+d8\F6\02#23\1B\011256\A2\01\124\D1\013wid\F9\02Crd9,)\00\04\B5\02\02Q\00\02\E5\02\03X\00\119\C0\00\03r\00\02]\01A4, ['\00\1A]7\00&1,\F7\00\0F7\00\00\1357\00\221]?\02\02\16\00\226,R\00\B7%f5;\0Afma.rn\C4\01\03\1B\00\1A6\CE\01\05\C5\01\16:\D3\00\02\F6\003d12\FA\02\134\1B\04\02$\01\00\9F\02\0F\0A\05\1E\0A\DE\00$4,I\00\00\07\00S2;\0Astq\05\01\B0\00\01\DB\0014],\B9\00\CC;\0Abar.sync 0\B3\02\133\A1\00<127\1B\00\154\CE\02.75\AE\01\05\EB\03\0A\AE\01\0A\98\00\115:\03\03P\06#5,p\00!p4\03\03\195\03\03\115\A3\01\07\C3\002%f7\A3\01.4]\1B\00\138\1B\00C+512\F8\01\02\19\00\229,9\00?%f8\14\01\01\02\13\01\169\B5\01/5:\1D\01\08\04\B8\04,63\1A\00\157\1C\01(83\E4\00#8,7\00!p7\E4\00\198\E4\00\1E7\C9\00/10\E5\00\07$11\E6\009256\E6\00\01X\02\01<\00\00&\00\0F\E9\00\07&12\EA\00\1F7\EA\00\09\139\EA\00,31\1A\00&10\EB\00\187\EB\00\01a\03\019\00\22p1\D4\04\1A1\AC\06\1F9\D2\00\00\1F3\EE\00\08\144\EE\00:128\EE\00\00:\02\01<\00\00&\00\0F\EE\00\08\165\EE\00\1F9\EE\00\09\05\97\03-15\1B\00\163\EF\00\199\EF\00\00\DA\02\02:\002p13\F0\00\194\F0\00/11\D5\00\00/6,\F1\00\07\04\E0\02:+64\F0\00\00F\02\01;\00\00%\00\0F\F0\00\08\168\F0\00/11\F1\00\0A\166\82\07\07\C2\01$7,\1C\00\22p2\D2\00\1D7n\08\0C/\06\0F2\09#\1F70\06\06\02\A7\05\1F6a\04\00\01\B4\00\1C4a\04&5,6\00/16V\01\00\1F9r\01\07$20r\01\1A36\04\01\00\08\01;\00\00%\00d;\0Aatom\A8\00\07&\00\122?\00\115~\01'21~\01\C03:\0Aret;\0A\0A}\0A\00\00\00\00\00"
@ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void = internal constant [101 x i8] c"ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00"
@main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name = internal constant [41 x i8] c"main_kColReduction_reduce__4_1_0___8w32h\00"
@main_kernel_blob_gpu.binary_sm_75 = internal constant [1032 x i8] c"P\EDU\BA\01\00\10\00\F8\03\00\00\00\00\00\00\02\00\01\01@\00\00\00\B8\03\00\00\00\00\00\00\B4\03\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00K\05K\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04\1C\00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\D2\F0\11\00\03\1B\FF\00\04\1C\04\00p\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\CB\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\87\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00b\02\01\F9\00\22H\00\01\00\00d\01/\05\00\01\00\FF\D0A\02z\01\00w\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05f\04\00 \00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00\80\D0\0F\00\86s\00\02\FF0\00\A3\E9\10\00\00\E2\0F\00My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0Q\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\AC\03\0D\88\05\03\15\00*\90\00\D0\03\04\F5\03\22\18\00\01\00\1F\FET\00\00\03\9E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\8C\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B0)\00*\E0\00\01\00\1B\08\08\00!\0B\01\FC\04\0D\01\00\13\90\FD\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A0@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00Q\05\00\00\08\80\0E\00\A0\00\00\00\00\00\00\00\00\00\00\00\00\00\00"
@main_kernel_blob_gpu.binary_sm_70 = internal constant [1048 x i8] c"P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\C8\03\00\00\00\00\00\00\C5\03\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00F\05F\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04 \00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04.\00r\00\04\1C\04\00\80\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\D3\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\8F\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00j\02\01\01\01\22H\00\01\00\00l\01/\05\00\01\00\FF\C8A\02z\01\00w\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\E4\03\B1\00\0E\00\00\E2\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05v\04\000\00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00p\D0\0F\00\86s\00\02`\001\00\E9\10`\003My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0a\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00@\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\A4\03\0D\88\05\03\15\00*\90\00\C8\03\04\ED\03\22\18\00\01\00\1F\FET\00\00\03\8E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\94\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B8)\00*\E0\00\01\00\1B\08\08\00!\0B\01\F4\04\0D\01\00\13\98\F5\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A8@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00D\05\00\00\08\80\06\80\00\00\00\00\00\00\00\00\00\00\00"
@main_kernel_blob_gpu.binary_compute_60 = internal constant [472 x i8] c"P\EDU\BA\01\00\10\00\C8\01\00\00\00\00\00\00\01\00\01\01H\00\00\00\80\01\00\00\00\00\00\00|\01\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\03\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64/\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\0Ee__4_1_0___8w32h(\0A.param .u326\00\16\11_4\006_0,>\00/64>\00\1D\1F1>\00*/2,\BA\00)\1F3>\00*\1F4>\00*\F4\075\0A)\0A{\0A.reg .b32 %r<6>;\11\00\E264 %rd<5>;\0A\0Aldg\00\01f\00o%r1, [l\00\1C70];F\00\02\\\00\0FG\00 \F4\032];\0Acvta.to.globalM\00!2,S\00S;\0Amov\A7\00\00\13\00xctaid.x\17\00S3, %t\15\00qad.lo.s\18\00#4,4\00\00\E0\00\D3%r3;\0Amul.wide!\002d3,'\00\824;\0Aadd.sz\00&4,\80\00\183i\00\855, 0;\0Ast\AA\00@32 [1\00\10],\00\C05;\0Aret;\0A\0A}\0A\00\00\00\00\00"
@alloc___gpu___pvoid_i64___pvoid = internal constant [32 x i8] c"alloc___gpu___pvoid_i64___pvoid\00"
@ral_recv_input___cpu___pvoid_i64___m2df32 = internal constant [42 x i8] c"ral_recv_input___cpu___pvoid_i64___m2df32\00"

declare ptr @malloc(i64)

declare void @free(ptr)

declare void @disc_ral_call(ptr, ptr, ptr)

define void @main(ptr %0) {
  %2 = alloca %0, align 8
  %3 = alloca ptr, i32 3, align 8
  %4 = getelementptr %0, ptr %2, i32 0, i32 0
  store ptr %0, ptr %4, align 8
  %5 = getelementptr ptr, ptr %3, i32 0
  store ptr %4, ptr %5, align 8
  %6 = getelementptr %0, ptr %2, i32 0, i32 1
  store i64 0, ptr %6, align 4
  %7 = getelementptr ptr, ptr %3, i32 1
  store ptr %6, ptr %7, align 8
  %8 = getelementptr %0, ptr %2, i32 0, i32 2
  %9 = getelementptr ptr, ptr %3, i32 2
  store ptr %8, ptr %9, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_recv_input___cpu___pvoid_i64___m2df32, ptr %3)
  %10 = load { ptr, ptr, i64, [2 x i64], [2 x i64] }, ptr %8, align 8
  %11 = alloca %.1, align 8
  %12 = alloca ptr, i32 3, align 8
  %13 = getelementptr %.1, ptr %11, i32 0, i32 0
  store ptr %0, ptr %13, align 8
  %14 = getelementptr ptr, ptr %12, i32 0
  store ptr %13, ptr %14, align 8
  %15 = getelementptr %.1, ptr %11, i32 0, i32 1
  store i64 1, ptr %15, align 4
  %16 = getelementptr ptr, ptr %12, i32 1
  store ptr %15, ptr %16, align 8
  %17 = getelementptr %.1, ptr %11, i32 0, i32 2
  %18 = getelementptr ptr, ptr %12, i32 2
  store ptr %17, ptr %18, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_recv_input___cpu___pvoid_i64___m2df32, ptr %12)
  %19 = load { ptr, ptr, i64, [2 x i64], [2 x i64] }, ptr %17, align 8
  %20 = alloca %.2, align 8
  %21 = alloca ptr, i32 3, align 8
  %22 = getelementptr %.2, ptr %20, i32 0, i32 0
  store ptr %0, ptr %22, align 8
  %23 = getelementptr ptr, ptr %21, i32 0
  store ptr %22, ptr %23, align 8
  %24 = getelementptr %.2, ptr %20, i32 0, i32 1
  store i64 ptrtoint (ptr getelementptr (float, ptr null, i64 2560) to i64), ptr %24, align 4
  %25 = getelementptr ptr, ptr %21, i32 1
  store ptr %24, ptr %25, align 8
  %26 = getelementptr %.2, ptr %20, i32 0, i32 2
  %27 = getelementptr ptr, ptr %21, i32 2
  store ptr %26, ptr %27, align 8
  call void @disc_ral_call(ptr %0, ptr @alloc___gpu___pvoid_i64___pvoid, ptr %21)
  %28 = load ptr, ptr %26, align 8
  %29 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } undef, ptr %28, 0
  %30 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %29, ptr %28, 1
  %31 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %30, i64 0, 2
  %32 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %31, i64 2560, 3, 0
  %33 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %32, i64 1, 4, 0
  %34 = alloca ptr, i32 3, align 8
  %35 = getelementptr ptr, ptr %34, i32 0
  store ptr @main_kernel_blob_gpu.binary_compute_60, ptr %35, align 8
  %36 = getelementptr ptr, ptr %34, i32 1
  store ptr @main_kernel_blob_gpu.binary_sm_70, ptr %36, align 8
  %37 = getelementptr ptr, ptr %34, i32 2
  store ptr @main_kernel_blob_gpu.binary_sm_75, ptr %37, align 8
  %38 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 0
  %39 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 1
  %40 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 2
  %41 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 3, 0
  %42 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 4, 0
  %43 = alloca %.3, align 8
  %44 = alloca ptr, i32 6, align 8
  %45 = getelementptr %.3, ptr %43, i32 0, i32 0
  store i64 256, ptr %45, align 4
  %46 = getelementptr ptr, ptr %44, i32 0
  store ptr %45, ptr %46, align 8
  %47 = getelementptr %.3, ptr %43, i32 0, i32 1
  store ptr %38, ptr %47, align 8
  %48 = getelementptr ptr, ptr %44, i32 1
  store ptr %47, ptr %48, align 8
  %49 = getelementptr %.3, ptr %43, i32 0, i32 2
  store ptr %39, ptr %49, align 8
  %50 = getelementptr ptr, ptr %44, i32 2
  store ptr %49, ptr %50, align 8
  %51 = getelementptr %.3, ptr %43, i32 0, i32 3
  store i64 %40, ptr %51, align 4
  %52 = getelementptr ptr, ptr %44, i32 3
  store ptr %51, ptr %52, align 8
  %53 = getelementptr %.3, ptr %43, i32 0, i32 4
  store i64 %41, ptr %53, align 4
  %54 = getelementptr ptr, ptr %44, i32 4
  store ptr %53, ptr %54, align 8
  %55 = getelementptr %.3, ptr %43, i32 0, i32 5
  store i64 %42, ptr %55, align 4
  %56 = getelementptr ptr, ptr %44, i32 5
  store ptr %55, ptr %56, align 8
  %57 = alloca %.4, align 8
  %58 = alloca ptr, i32 14, align 8
  %59 = getelementptr %.4, ptr %57, i32 0, i32 0
  store ptr %0, ptr %59, align 8
  %60 = getelementptr ptr, ptr %58, i32 0
  store ptr %59, ptr %60, align 8
  %61 = getelementptr %.4, ptr %57, i32 0, i32 1
  store ptr %34, ptr %61, align 8
  %62 = getelementptr ptr, ptr %58, i32 1
  store ptr %61, ptr %62, align 8
  %63 = getelementptr %.4, ptr %57, i32 0, i32 2
  store i64 3, ptr %63, align 4
  %64 = getelementptr ptr, ptr %58, i32 2
  store ptr %63, ptr %64, align 8
  %65 = getelementptr %.4, ptr %57, i32 0, i32 3
  store ptr @main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name, ptr %65, align 8
  %66 = getelementptr ptr, ptr %58, i32 3
  store ptr %65, ptr %66, align 8
  %67 = getelementptr %.4, ptr %57, i32 0, i32 4
  store i64 10, ptr %67, align 4
  %68 = getelementptr ptr, ptr %58, i32 4
  store ptr %67, ptr %68, align 8
  %69 = getelementptr %.4, ptr %57, i32 0, i32 5
  store i64 1, ptr %69, align 4
  %70 = getelementptr ptr, ptr %58, i32 5
  store ptr %69, ptr %70, align 8
  %71 = getelementptr %.4, ptr %57, i32 0, i32 6
  store i64 1, ptr %71, align 4
  %72 = getelementptr ptr, ptr %58, i32 6
  store ptr %71, ptr %72, align 8
  %73 = getelementptr %.4, ptr %57, i32 0, i32 7
  store i64 256, ptr %73, align 4
  %74 = getelementptr ptr, ptr %58, i32 7
  store ptr %73, ptr %74, align 8
  %75 = getelementptr %.4, ptr %57, i32 0, i32 8
  store i64 1, ptr %75, align 4
  %76 = getelementptr ptr, ptr %58, i32 8
  store ptr %75, ptr %76, align 8
  %77 = getelementptr %.4, ptr %57, i32 0, i32 9
  store i64 1, ptr %77, align 4
  %78 = getelementptr ptr, ptr %58, i32 9
  store ptr %77, ptr %78, align 8
  %79 = getelementptr %.4, ptr %57, i32 0, i32 10
  store i32 0, ptr %79, align 4
  %80 = getelementptr ptr, ptr %58, i32 10
  store ptr %79, ptr %80, align 8
  %81 = getelementptr %.4, ptr %57, i32 0, i32 11
  store ptr null, ptr %81, align 8
  %82 = getelementptr ptr, ptr %58, i32 11
  store ptr %81, ptr %82, align 8
  %83 = getelementptr %.4, ptr %57, i32 0, i32 12
  store i32 6, ptr %83, align 4
  %84 = getelementptr ptr, ptr %58, i32 12
  store ptr %83, ptr %84, align 8
  %85 = getelementptr %.4, ptr %57, i32 0, i32 13
  store ptr %44, ptr %85, align 8
  %86 = getelementptr ptr, ptr %58, i32 13
  store ptr %85, ptr %86, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %58)
  %87 = alloca ptr, i32 3, align 8
  %88 = getelementptr ptr, ptr %87, i32 0
  store ptr @main_kernel_0_blob_gpu.binary_compute_60, ptr %88, align 8
  %89 = getelementptr ptr, ptr %87, i32 1
  store ptr @main_kernel_0_blob_gpu.binary_sm_70, ptr %89, align 8
  %90 = getelementptr ptr, ptr %87, i32 2
  store ptr @main_kernel_0_blob_gpu.binary_sm_75, ptr %90, align 8
  %91 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %10, 0
  %92 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %10, 1
  %93 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %10, 2
  %94 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %10, 3, 0
  %95 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %10, 3, 1
  %96 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %10, 4, 0
  %97 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %10, 4, 1
  %98 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %19, 0
  %99 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %19, 1
  %100 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %19, 2
  %101 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %19, 3, 0
  %102 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %19, 3, 1
  %103 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %19, 4, 0
  %104 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %19, 4, 1
  %105 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 0
  %106 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 1
  %107 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 2
  %108 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 3, 0
  %109 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 4, 0
  %110 = alloca %.5, align 8
  %111 = alloca ptr, i32 21, align 8
  %112 = getelementptr %.5, ptr %110, i32 0, i32 0
  store i64 256, ptr %112, align 4
  %113 = getelementptr ptr, ptr %111, i32 0
  store ptr %112, ptr %113, align 8
  %114 = getelementptr %.5, ptr %110, i32 0, i32 1
  store i64 20971520, ptr %114, align 4
  %115 = getelementptr ptr, ptr %111, i32 1
  store ptr %114, ptr %115, align 8
  %116 = getelementptr %.5, ptr %110, i32 0, i32 2
  store ptr %91, ptr %116, align 8
  %117 = getelementptr ptr, ptr %111, i32 2
  store ptr %116, ptr %117, align 8
  %118 = getelementptr %.5, ptr %110, i32 0, i32 3
  store ptr %92, ptr %118, align 8
  %119 = getelementptr ptr, ptr %111, i32 3
  store ptr %118, ptr %119, align 8
  %120 = getelementptr %.5, ptr %110, i32 0, i32 4
  store i64 %93, ptr %120, align 4
  %121 = getelementptr ptr, ptr %111, i32 4
  store ptr %120, ptr %121, align 8
  %122 = getelementptr %.5, ptr %110, i32 0, i32 5
  store i64 %94, ptr %122, align 4
  %123 = getelementptr ptr, ptr %111, i32 5
  store ptr %122, ptr %123, align 8
  %124 = getelementptr %.5, ptr %110, i32 0, i32 6
  store i64 %95, ptr %124, align 4
  %125 = getelementptr ptr, ptr %111, i32 6
  store ptr %124, ptr %125, align 8
  %126 = getelementptr %.5, ptr %110, i32 0, i32 7
  store i64 %96, ptr %126, align 4
  %127 = getelementptr ptr, ptr %111, i32 7
  store ptr %126, ptr %127, align 8
  %128 = getelementptr %.5, ptr %110, i32 0, i32 8
  store i64 %97, ptr %128, align 4
  %129 = getelementptr ptr, ptr %111, i32 8
  store ptr %128, ptr %129, align 8
  %130 = getelementptr %.5, ptr %110, i32 0, i32 9
  store ptr %98, ptr %130, align 8
  %131 = getelementptr ptr, ptr %111, i32 9
  store ptr %130, ptr %131, align 8
  %132 = getelementptr %.5, ptr %110, i32 0, i32 10
  store ptr %99, ptr %132, align 8
  %133 = getelementptr ptr, ptr %111, i32 10
  store ptr %132, ptr %133, align 8
  %134 = getelementptr %.5, ptr %110, i32 0, i32 11
  store i64 %100, ptr %134, align 4
  %135 = getelementptr ptr, ptr %111, i32 11
  store ptr %134, ptr %135, align 8
  %136 = getelementptr %.5, ptr %110, i32 0, i32 12
  store i64 %101, ptr %136, align 4
  %137 = getelementptr ptr, ptr %111, i32 12
  store ptr %136, ptr %137, align 8
  %138 = getelementptr %.5, ptr %110, i32 0, i32 13
  store i64 %102, ptr %138, align 4
  %139 = getelementptr ptr, ptr %111, i32 13
  store ptr %138, ptr %139, align 8
  %140 = getelementptr %.5, ptr %110, i32 0, i32 14
  store i64 %103, ptr %140, align 4
  %141 = getelementptr ptr, ptr %111, i32 14
  store ptr %140, ptr %141, align 8
  %142 = getelementptr %.5, ptr %110, i32 0, i32 15
  store i64 %104, ptr %142, align 4
  %143 = getelementptr ptr, ptr %111, i32 15
  store ptr %142, ptr %143, align 8
  %144 = getelementptr %.5, ptr %110, i32 0, i32 16
  store ptr %105, ptr %144, align 8
  %145 = getelementptr ptr, ptr %111, i32 16
  store ptr %144, ptr %145, align 8
  %146 = getelementptr %.5, ptr %110, i32 0, i32 17
  store ptr %106, ptr %146, align 8
  %147 = getelementptr ptr, ptr %111, i32 17
  store ptr %146, ptr %147, align 8
  %148 = getelementptr %.5, ptr %110, i32 0, i32 18
  store i64 %107, ptr %148, align 4
  %149 = getelementptr ptr, ptr %111, i32 18
  store ptr %148, ptr %149, align 8
  %150 = getelementptr %.5, ptr %110, i32 0, i32 19
  store i64 %108, ptr %150, align 4
  %151 = getelementptr ptr, ptr %111, i32 19
  store ptr %150, ptr %151, align 8
  %152 = getelementptr %.5, ptr %110, i32 0, i32 20
  store i64 %109, ptr %152, align 4
  %153 = getelementptr ptr, ptr %111, i32 20
  store ptr %152, ptr %153, align 8
  %154 = alloca %.6, align 8
  %155 = alloca ptr, i32 14, align 8
  %156 = getelementptr %.6, ptr %154, i32 0, i32 0
  store ptr %0, ptr %156, align 8
  %157 = getelementptr ptr, ptr %155, i32 0
  store ptr %156, ptr %157, align 8
  %158 = getelementptr %.6, ptr %154, i32 0, i32 1
  store ptr %87, ptr %158, align 8
  %159 = getelementptr ptr, ptr %155, i32 1
  store ptr %158, ptr %159, align 8
  %160 = getelementptr %.6, ptr %154, i32 0, i32 2
  store i64 3, ptr %160, align 4
  %161 = getelementptr ptr, ptr %155, i32 2
  store ptr %160, ptr %161, align 8
  %162 = getelementptr %.6, ptr %154, i32 0, i32 3
  store ptr @main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name, ptr %162, align 8
  %163 = getelementptr ptr, ptr %155, i32 3
  store ptr %162, ptr %163, align 8
  %164 = getelementptr %.6, ptr %154, i32 0, i32 4
  store i64 81920, ptr %164, align 4
  %165 = getelementptr ptr, ptr %155, i32 4
  store ptr %164, ptr %165, align 8
  %166 = getelementptr %.6, ptr %154, i32 0, i32 5
  store i64 1, ptr %166, align 4
  %167 = getelementptr ptr, ptr %155, i32 5
  store ptr %166, ptr %167, align 8
  %168 = getelementptr %.6, ptr %154, i32 0, i32 6
  store i64 1, ptr %168, align 4
  %169 = getelementptr ptr, ptr %155, i32 6
  store ptr %168, ptr %169, align 8
  %170 = getelementptr %.6, ptr %154, i32 0, i32 7
  store i64 256, ptr %170, align 4
  %171 = getelementptr ptr, ptr %155, i32 7
  store ptr %170, ptr %171, align 8
  %172 = getelementptr %.6, ptr %154, i32 0, i32 8
  store i64 1, ptr %172, align 4
  %173 = getelementptr ptr, ptr %155, i32 8
  store ptr %172, ptr %173, align 8
  %174 = getelementptr %.6, ptr %154, i32 0, i32 9
  store i64 1, ptr %174, align 4
  %175 = getelementptr ptr, ptr %155, i32 9
  store ptr %174, ptr %175, align 8
  %176 = getelementptr %.6, ptr %154, i32 0, i32 10
  store i32 0, ptr %176, align 4
  %177 = getelementptr ptr, ptr %155, i32 10
  store ptr %176, ptr %177, align 8
  %178 = getelementptr %.6, ptr %154, i32 0, i32 11
  store ptr null, ptr %178, align 8
  %179 = getelementptr ptr, ptr %155, i32 11
  store ptr %178, ptr %179, align 8
  %180 = getelementptr %.6, ptr %154, i32 0, i32 12
  store i32 21, ptr %180, align 4
  %181 = getelementptr ptr, ptr %155, i32 12
  store ptr %180, ptr %181, align 8
  %182 = getelementptr %.6, ptr %154, i32 0, i32 13
  store ptr %111, ptr %182, align 8
  %183 = getelementptr ptr, ptr %155, i32 13
  store ptr %182, ptr %183, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %155)
  %184 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 0
  %185 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 1
  %186 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 2
  %187 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 3, 0
  %188 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 4, 0
  %189 = alloca %.7, align 8
  %190 = alloca ptr, i32 7, align 8
  %191 = getelementptr %.7, ptr %189, i32 0, i32 0
  store ptr %0, ptr %191, align 8
  %192 = getelementptr ptr, ptr %190, i32 0
  store ptr %191, ptr %192, align 8
  %193 = getelementptr %.7, ptr %189, i32 0, i32 1
  store i64 0, ptr %193, align 4
  %194 = getelementptr ptr, ptr %190, i32 1
  store ptr %193, ptr %194, align 8
  %195 = getelementptr %.7, ptr %189, i32 0, i32 2
  store ptr %184, ptr %195, align 8
  %196 = getelementptr ptr, ptr %190, i32 2
  store ptr %195, ptr %196, align 8
  %197 = getelementptr %.7, ptr %189, i32 0, i32 3
  store ptr %185, ptr %197, align 8
  %198 = getelementptr ptr, ptr %190, i32 3
  store ptr %197, ptr %198, align 8
  %199 = getelementptr %.7, ptr %189, i32 0, i32 4
  store i64 %186, ptr %199, align 4
  %200 = getelementptr ptr, ptr %190, i32 4
  store ptr %199, ptr %200, align 8
  %201 = getelementptr %.7, ptr %189, i32 0, i32 5
  store i64 %187, ptr %201, align 4
  %202 = getelementptr ptr, ptr %190, i32 5
  store ptr %201, ptr %202, align 8
  %203 = getelementptr %.7, ptr %189, i32 0, i32 6
  store i64 %188, ptr %203, align 4
  %204 = getelementptr ptr, ptr %190, i32 6
  store ptr %203, ptr %204, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_send_output___cpu___pvoid_i64_m1df32___void, ptr %190)
  ret void
}

host default target triple: x86_64-unknown-linux-gnu
host cpu name: icelake-server
host cpu features: -avx512pf,-tsxldtrk,+cx16,+sahf,-tbm,+avx512ifma,+sha,+crc32,-fma4,+vpclmulqdq,+prfchw,+bmi2,-cldemote,+fsgsbase,-avx512bf16,-amx-tile,-raoint,-uintr,+gfni,+popcnt,-ptwrite,+aes,+avx512bitalg,-movdiri,-widekl,+xsaves,-avx512er,-avxvnni,-avx512fp16,+avx512vnni,-amx-bf16,-avxvnniint8,+avx512vpopcntdq,-pconfig,+clwb,-cmpccxadd,+avx512f,+xsavec,-clzero,-pku,-amx-fp16,+mmx,-lwp,+rdpid,-xop,+rdseed,-waitpkg,-prefetchi,-kl,-movdir64b,-sse4a,+avx512bw,-avxneconvert,+clflushopt,+xsave,+avx512vbmi2,+64bit,+avx512vl,-serialize,-hreset,+invpcid,+avx512cd,+avx,+vaes,-amx-int8,+cx8,+fma,-rtm,+bmi,-enqcmd,+rdrnd,-mwaitx,+sse4.1,+sse4.2,+avx2,+fxsr,+wbnoinvd,+sse,+lzcnt,+pclmul,-rdpru,-avxifma,+f16c,+ssse3,-sgx,-prefetchwt1,+cmov,+avx512vbmi,-shstk,+movbe,-avx512vp2intersect,+xsaveopt,+avx512dq,+sse2,+adx,+sse3
after optimize llvm module:
; ModuleID = 'LLVMDialectModule'
source_filename = "LLVMDialectModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%0 = type { ptr, i64, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.1 = type { ptr, i64, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.2 = type { ptr, i64, ptr }
%.3 = type { i64, ptr, ptr, i64, i64, i64 }
%.4 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.5 = type { i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64, i64, i64, ptr, ptr, i64, i64, i64 }
%.6 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.7 = type { ptr, i64, ptr, ptr, i64, i64, i64 }

@ral_send_output___cpu___pvoid_i64_m1df32___void = internal constant [48 x i8] c"ral_send_output___cpu___pvoid_i64_m1df32___void\00"
@main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name = internal constant [43 x i8] c"main_kColReduction_reduce__4_1_0___8w32h_1\00"
@main_kernel_0_blob_gpu.binary_sm_75 = internal constant [1736 x i8] c"P\EDU\BA\01\00\10\00\B8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00x\06\00\00\00\00\00\00s\06\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\80\10\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\0D\07\00a\00K\05K\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00f2\00\00\00\12\10x\00\13\80;\00f\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\08\00R\04\14\00\00\00E\00#\04\F8\18\00\80/\08\00\06\00\00\00\0E\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\04\1C\0C\FE\00c\00\D0\03\00\00@\D0\01#K\00\01\00q\02\02\08\10\0A/\22\B3\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\80\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\003\02\11,\88\01\11\00\01\01\22H\00\01\00\11\02l\01\0F\01\00\FF\F8@$v\01\FF\AF\05\B2\FF\00\8E\07\00\C4\0F\00\19y\00\01\00\10%\DB\02a\0E\00\19y\03\00\01\00\10!-\00`\0E\00$z\00\00K\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\CB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\02\FF\B1\02\10\03 \00q\E4\0F\00\12x\03\03\81\05\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\CD\CC\CC\CC\A0\00a\C8\0F\00$x\000\05`\03\0A\8E\07\00\E2@\00\11\04@\00\22\04\16`\00\00p\00\01a\00\14\16p\00 \06\04\10\00!\FF(0\00\B2\04$x\03\04\C0\FE\FF\FF\02\02@\001\12x\02N\06\01p\00p\E4\0F\00\0Cx\00\06\B1\00@p@\F0\03\80\00Q$x\07\03\08\17\04\92\8E\07\00\D2\0F\00\02\88\05\96\060\0F\00\00@\00@$\88\04\06@\01\22\07\02\A0\00`%\86\02\04\00\\\C0\04\04\10\00F\04\04\00f\10\000\81\83\02\83\03\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\05\04\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03`\00Sr\08\FF\FF\00\A0\01\01\F0\00\11\0B\C4\03\10\FF\C5\03\80\E4\0F\04\0Cx\00\00\7F\98\064Dt\01\C0\00\11\F7@\00A\F2\03\00\C8\10\00!\00? \00\11\F2\B0\00\81!\82\09\02\05\00\00\80t\00\81\C8O\00#\82\08\02\09`\00\02\D0\00\000\00\11\070\00\22p\000\014\09\00\04\80\00\93\CC\0F\00\88s\00\0B\08\00\1E\05f\E8\0F\00\1D{\00\01\00Q\EA\0F\00\84\A9O\002\00\00\18 \00A\84\A9\03\09v\04\12\18@\02c!\A2\02\02\03\00\01\00\8F\D0\1F\00\88\A3\00\09\02P\00\095\99\03\09P\00\02\A0\00$\06\FB \01\10\C6 \00!\04\09\12\02\00 \00\11\22@\01$\00\1F\10\01\00\F0\00W\92\04\03\04\00p\00O\93\00\09\04\C0\00\0A\0Ep\00\14\FDP\01\00p\001\A9\08\09>\01\07p\00\18\0F`\01!\A2\080\02\08\E0\00\1F\08\E0\00\0A\0B0\01\00\F0\00&@\000\01\1B\920\01\1F\930\01\0B\0C\80\039\84y\00\D0\006\02x\02\C0\02\00\D0\00Wy\03\09\00 p\00!r\05\80\08\01\01\00p\E4\1F\00%v\02\07{\08\10\02\00\02`\D0\0F\00\8Ey\00@\02A\00\00G\11P\00*Myp\00PGy\00\00\F0\C0\03\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\00\0F\01\00-\01\0C\04\1E\00\01\00\02\A4\0D]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13T\07\0C\01\00\138U\00\11\A8\06\00\06x\07\00\B7\01\04\8F\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03!\00P\E5\01\10\00\86\09'\00\00\E4\00*\04\00\01\00\1Fc@\00\04\04@\0B&\84\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\08\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\A4\08\0D\01\00\13\E8@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0C\84\01\13\F8@\00\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\08\01\12\03\C0\01:\0E\80\00\01\00\13\97\94\00/\03\000\10\03/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00"
@main_kernel_0_blob_gpu.binary_sm_70 = internal constant [1752 x i8] c"P\EDU\BA\01\00\10\00\C8\06\00\00\00\00\00\00\02\00\01\01@\00\00\00\88\06\00\00\00\00\00\00\83\06\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\11\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00o\02\00\BE\00u\00\01\00\00\11\0E\06\00a\00F\05F\00@\0A\00\F5\03@\00\0C\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1D\9Fconstant09\00\1A\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aW\00\0FE\01 \0F\9C\00\17\0Fp\01\89\8F$____wg_3\00\17\00\0C\00\1F4\A9\01(o_param\B0\01.\0F\01\00\07\8C]\00\00\00\03\00\0A\00\01\00\11\C2\18\00,\0B\00\01\00 1\01\18\00,\09\00\01\00\11q\18\00,\04\00\01\00\11\A1\18\00,\07\00\01\00g2\00\00\00\12\10x\00\11\05\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13\F0\93\00\10\04\08\00R\04\18\00\00\00E\002\04\0C\01\18\00C/\08\00\06/\04\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00 6\04F\04A\00\047\04x\04\F1\04\04\0A\08\00\03\00\00\00`\01t\00\03\19t\00\04\17\0C(\00u\14\00p\00\00\F0\11\10\009\13\00l\10\009\12\00h\10\00u\11\00`\00\00\F0!\10\009\10\00X\10\009\0F\00P0\009\0E\00L\10\009\0D\00H\10\009\0C\00D\10\009\0B\00@\10\009\0A\008`\009\09\000\10\009\08\00(0\009\07\00$\10\009\06\00 \10\009\05\00\1C\10\009\04\00\18\10\009\03\00\10`\009\02\00\08\10\009\01\00\040\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04>\00@\00\04\1C\0C&\01c\000\04\00\00\A0\D8\01#K\00\01\00q\02\02\08\10\0A/\22\BB\00\01\01\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\88\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\00;\02\11,\90\01\11\00\09\01\22H\00\01\00\11\02t\01\0F\01\00\FF\F0@$v\01\FF\AF\05\D0\FF\00\8E\07\00\C4\0F\00\89\F3\FF\FF\FF\04\05\00\C2\04b\E2\0F\00\19y\00\01\00\10%\E3\02a\0E\00\19y\03\00\01\00\10!=\00`\0E\00$z\00\00[\04\90\03\02\8E\07\00\CA\1F\00\0C\10\00\C5Y\00\00p`\F0\03\00\D8\0F\00M\DB\05\B0\80\03\00\EA\0F\00\19x\03\FF\1F\0F\00\A1\14\01\00\00\C8\0F\00\11r\03Q\00@\FF@\8F\07\10\00@\19x\04\FF\B9\02\10\03 \00q\E4\0F\00\12x\05\03\91\05\F1\00\C0\8E\07\00\C6\0F\00%x\02\04\CD\CC\CC\CC\B0\00a\C8\0F\00$x\00@\05b\05\0A\8E\07\00\E2`\00\01@\00\12\16`\00A\19x\02\FFa\00\14\16p\00 \09\03\FC\02!\FF(0\00\B2\04$x\03\03\C0\FE\FF\FF\04\02@\001\12x\02^\06\01p\00p\E4\0F\00\0Cx\00\09\B1\00@p@\F0\03\80\00Q$x\02\03\08\1F\04\92\8E\07\00\D2\0F\00\02\88\07\A6\06!\0F\000\01c$\88\06\09\00\0A \00\90\C8\0F\00%\86\04\06\00\\\F0\04\04\10\00F\06\06\00f\10\00!\81\83J\06\D5\00\00\E9\1E\00\00\A8\0E\00\81\83\07\06\10\00!\A2\0E\80\00\11\EF\80\00!\F4\03\B0\00#r\03\A0\01\04\F0\00\11\08\CC\03\10\FF6\00\01\D0\006\0A\00\04 \00\D4\04\0Cx\00\00\7F\00\00\00pDt\01\D0\00\11\F7P\00A\F2\03\00\C8\10\00!\00? \00\11\F2\C0\00\81!\82\0B\04\07\00\00\80\84\00\81\C8O\00#\82\03\04\0BP\00\02\E0\00\000\00\11\070\00\A1p\00\00\CE\0F\00\88s\00\08`\01\00\A6\04f\E8\0F\00\18y\00\01\00f\E2\0F\00\1D{\00\01\00b\EA\0F\00\84\A9\04\A5\07\12\180\000\84\A9\05.\01\02\10\00s$\0E\00!\A2\05\04\BB\07\AF\00\00\D0\1F\00\88\A3\00\0A\05`\00\19\17\99`\00\02\B0\00$\09\FB@\01\10\C6 \00!\07\0A2\02\00 \00\11\22`\01$\00\1F \01\00\00\01 \92\07\00\01\06\80\00O\93\00\0A\07\E0\00\1A\1D\03\80\00\14\FDp\01\13\C6\00\01)\80\00\80\00\18\0F\80\01Z\A2\03\03\04\00\00\01\1F\03\00\01%\00`\011\99\05\0A\B1\0C\04`\01\1B\92`\01\1F\93`\01\1B\0C\D0\03E\84y\00\0Ap\00W\E2\0F\00\02x\10\03\00\F0\00Wy\03\0A\00 \80\00!r\05\E0\08\01\01\00\93\E4\1F\00%v\02\02\00p\10\03q\D0\0F\00\8Ey\00\02\90\00!G\11P\00*Myp\00PGy\00\00\F0\10\04[\FF\83\03\00\C0\B0\00\0F\10\00 \0F\01\00-\00|\04.\03\00\01\00\02$\0E]\00\00E\01\000\00\08\01\00\1F\0B@\00\04\13\85)\00\1F\B0@\00\0C\13\13\CC\07\0C\01\00\138U\00\11\A8\06\00\06\F0\07\00\E7\01\04\AF\01\00\01\00.\06\01T\00\00\01\00\13\E0@\00/p\00\80\00\0B\1F)'\00\03#\00P\C5\02\04H\0B\04\E4\00*\04\00\01\00\1Fc@\00\04\13\80)\00&\8C\01@\00\1F\0A@\00\00!6\01D\01\0D@\001\10\06\00\01\00*\E0\00\01\00\1B\08\08\00!\13\01\1C\09\0D\01\00\13\F0@\00&\10\00\80\00\17\048\00\04\18\00\13\CD\14\01\0D\84\01\03E\04\13\D4\C0\00\1F\00\C0\00\04\132@\00\15\06R\00\03\01\00\1A\09\C8\0C\12\03\C0\01:\0E\80\00\01\00\13\97\94\00+\03\00\01\00\03\B0\10/\00\04\80\00\06P\00\00\00\00\00\00\00\00\00\00"
@main_kernel_0_blob_gpu.binary_compute_60 = internal constant [1488 x i8] c"P\EDU\BA\01\00\10\00\C0\05\00\00\00\00\00\00\01\00\01\01H\00\00\00x\05\00\00\00\00\00\00t\05\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\03\11\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2!\0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64\0A0\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\10e__4_1_0___8w32h_1(\0A.param .u328\00\18\11_6\00?_0,@\00+\171@\00/64@\00\1F\1F2@\00,\1F3\C0\00,\1F4@\00,\1F5@\00,\1F6@\00,\1F7@\00,\1F8\80\01,\1F9@\00,\1F1\81\02.\1F1A\00-\1F2A\00-\0F\84\02-\1F1\85\02-/15\86\01-\1F6A\00-\0F\88\02-/18A\00-\1F9A\00,\F3\0A20\0A)\0A{\0A.reg .pred %p<18>;\13\00\95b32 %r<24\12\00\10f\12\00\18f\12\00\F0\04b64 %rd<17>;\0A\0A\09.shaI\00\FF\03.align 4 .b8 __wg_\9E\00\18\B20[1024];\0Ald\E0\00\01\DF\00o%r5, [\E5\00\1E\1E0H\00\1F6H\00!s1];\0AmovC\00\B87, %ctaid.x\17\00S8, %t\15\00qad.lo.s\18\00#1,4\00\00\C4\00\C2%r8;\0Asetp.ge8\004p1,%\00\F4\0C6;\0A@%p1 bra $L__BB0_13;\0AshrL\00\130-\00\2231\17\00\02{\00311,\1D\00t24;\0Aadd/\00\132/\00\00#\00\09H\00#3,\1F\00c8;\0Aand\EF\01$14\17\00\93-256;\0Asub1\00\07I\00\194z\00\225,\1E\00\193H\00\136\16\00\947;\0Amul.hi/\00#7,~\00\A9-858993459O\00#8,&\00\128:\00\06F\01#9, \009320\9A\00&0,\D1\00\01M\00\13l\86\00$213\00\185\15\01&3,\1C\00\1950\00#2,P\00S3;\0Aor\16\00%4,\1B\00$16\BC\01\12t\B0\002p2,Q\00B8191\0C\02\02&\03s23, 0f0\01\00\01\D7\01\192\D7\01\183\99\02\02G\03\1F7\9A\02\22\00\E3\02\E4cvta.to.globalP\00\01\9C\00.d7i\00\1F8i\00!\1F3h\00\06\01P\01+d8\F6\02#23\1B\011256\A2\01\124\D1\013wid\F9\02Crd9,)\00\04\B5\02\02Q\00\02\E5\02\03X\00\119\C0\00\03r\00\02]\01A4, ['\00\1A]7\00&1,\F7\00\0F7\00\00\1357\00\221]?\02\02\16\00\226,R\00\B7%f5;\0Afma.rn\C4\01\03\1B\00\1A6\CE\01\05\C5\01\16:\D3\00\02\F6\003d12\FA\02\134\1B\04\02$\01\00\9F\02\0F\0A\05\1E\0A\DE\00$4,I\00\00\07\00S2;\0Astq\05\01\B0\00\01\DB\0014],\B9\00\CC;\0Abar.sync 0\B3\02\133\A1\00<127\1B\00\154\CE\02.75\AE\01\05\EB\03\0A\AE\01\0A\98\00\115:\03\03P\06#5,p\00!p4\03\03\195\03\03\115\A3\01\07\C3\002%f7\A3\01.4]\1B\00\138\1B\00C+512\F8\01\02\19\00\229,9\00?%f8\14\01\01\02\13\01\169\B5\01/5:\1D\01\08\04\B8\04,63\1A\00\157\1C\01(83\E4\00#8,7\00!p7\E4\00\198\E4\00\1E7\C9\00/10\E5\00\07$11\E6\009256\E6\00\01X\02\01<\00\00&\00\0F\E9\00\07&12\EA\00\1F7\EA\00\09\139\EA\00,31\1A\00&10\EB\00\187\EB\00\01a\03\019\00\22p1\D4\04\1A1\AC\06\1F9\D2\00\00\1F3\EE\00\08\144\EE\00:128\EE\00\00:\02\01<\00\00&\00\0F\EE\00\08\165\EE\00\1F9\EE\00\09\05\97\03-15\1B\00\163\EF\00\199\EF\00\00\DA\02\02:\002p13\F0\00\194\F0\00/11\D5\00\00/6,\F1\00\07\04\E0\02:+64\F0\00\00F\02\01;\00\00%\00\0F\F0\00\08\168\F0\00/11\F1\00\0A\166\82\07\07\C2\01$7,\1C\00\22p2\D2\00\1D7n\08\0C/\06\0F2\09#\1F70\06\06\02\A7\05\1F6a\04\00\01\B4\00\1C4a\04&5,6\00/16V\01\00\1F9r\01\07$20r\01\1A36\04\01\00\08\01;\00\00%\00d;\0Aatom\A8\00\07&\00\122?\00\115~\01'21~\01\C03:\0Aret;\0A\0A}\0A\00\00\00\00\00"
@ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void = internal constant [101 x i8] c"ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00"
@main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name = internal constant [41 x i8] c"main_kColReduction_reduce__4_1_0___8w32h\00"
@main_kernel_blob_gpu.binary_sm_75 = internal constant [1032 x i8] c"P\EDU\BA\01\00\10\00\F8\03\00\00\00\00\00\00\02\00\01\01@\00\00\00\B8\03\00\00\00\00\00\00\B4\03\00\00\00\00\00\00\07\00\01\00K\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00K\05K\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04\1C\00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\D2\F0\11\00\03\1B\FF\00\04\1C\04\00p\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\CB\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\87\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00b\02\01\F9\00\22H\00\01\00\00d\01/\05\00\01\00\FF\D0A\02z\01\00w\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05f\04\00 \00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00\80\D0\0F\00\86s\00\02\FF0\00\A3\E9\10\00\00\E2\0F\00My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0Q\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00P\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\AC\03\0D\88\05\03\15\00*\90\00\D0\03\04\F5\03\22\18\00\01\00\1F\FET\00\00\03\9E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\8C\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B0)\00*\E0\00\01\00\1B\08\08\00!\0B\01\FC\04\0D\01\00\13\90\FD\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A0@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00Q\05\00\00\08\80\0E\00\A0\00\00\00\00\00\00\00\00\00\00\00\00\00\00"
@main_kernel_blob_gpu.binary_sm_70 = internal constant [1048 x i8] c"P\EDU\BA\01\00\10\00\08\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\C8\03\00\00\00\00\00\00\C5\03\00\00\00\00\00\00\07\00\01\00F\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00@\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00n\02\00\BE\00u\00\01\00!\80\08\07\00a\00F\05F\00@\0A\00\F5\03@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FD\01debug_frame\00.rel\11\00\1Aa\12\00!nv&\00\11aU\00\0F=\01 \0F\9A\00\15\0Ff\01\BAo_paramm\01.\0F\01\00\0A\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11^\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\01\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\22\F0\00\01\00\10\04\9B\00R\04 \00\00\00E\00P\04\FC\FF\FF?\13\00p/\08\00\05\00\00\00\CF\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!6\04\AB\001\047\04\18\04\F1\04\04\0A\08\00\02\00\00\00`\01$\00\03\19$\00\04\17\0C(\00u\05\00 \00\00\F0\11\10\009\04\00\1C\10\009\03\00\18\10\00u\02\00\10\00\00\F0!\10\009\01\00\08\10\00\01\01\00\A0\F0\11\00\03\1B\FF\00\041\04.\00r\00\04\1C\04\00\80\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\D3\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08\8F\01\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00p\00\00\00\14,\00\00j\02\01\01\01\22H\00\01\00\00l\01/\05\00\01\00\FF\C8A\02z\01\00w\04\C0\0F\00\00\00\C4\0F\00\89\F3\FF\FF\FF\E4\03\B1\00\0E\00\00\E2\0F\00\19y\02\00\01\00\A2%\00\00\00\22\0E\00\02x\05v\04\000\00\10\C6 \00!\03\00\01\00\F0\11!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\C8\1F\00%v\02\02\00\\\00\00\05\10\00p\D0\0F\00\86s\00\02`\001\00\E9\10`\003My\00\01\00\B0\80\03\00\EA\0F\00Gy\00\00\F0a\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00@\0F\01\00-\00\9C\04.\03\00\01\00\02\A4\08]\00\00=\01\000\00\08\01\00\1F\0B@\00\04\13})\00\1Fm@\00\0C\13\13\A4\03\0D\88\05\03\15\00*\90\00\C8\03\04\ED\03\22\18\00\01\00\1F\FET\00\00\03\8E\01\01\01\00/p\00\80\00\0B\1F)'\00\03#\00\F0@\00\04(\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13 )\00&\94\00@\00\1F\0A@\00\00\00\08\07\1F\0B@\00\00\13\B8)\00*\E0\00\01\00\1B\08\08\00!\0B\01\F4\04\0D\01\00\13\98\F5\04&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01\13\A8@\00\17\841\01\0F\C0\00\01\132@\00*\06\00\01\00\14\80\C3\07\16\01\80\00D\05\00\00\08\80\06\80\00\00\00\00\00\00\00\00\00\00\00"
@main_kernel_blob_gpu.binary_compute_60 = internal constant [472 x i8] c"P\EDU\BA\01\00\10\00\C8\01\00\00\00\00\00\00\01\00\01\01H\00\00\00\80\01\00\00\00\00\00\00|\01\00\00@\00\00\00\00\00\06\00<\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\03\00\00\00\00\00\00\00\00\00\00\00\00\00\00\F2 \0A\0A\0A\0A.version 6.0\0A.target sm_60\0A.address_size 64/\00\F0\13isible .entry main_kColReduction_r\0A\00\FF\0Ee__4_1_0___8w32h(\0A.param .u326\00\16\11_4\006_0,>\00/64>\00\1D\1F1>\00*/2,\BA\00)\1F3>\00*\1F4>\00*\F4\075\0A)\0A{\0A.reg .b32 %r<6>;\11\00\E264 %rd<5>;\0A\0Aldg\00\01f\00o%r1, [l\00\1C70];F\00\02\\\00\0FG\00 \F4\032];\0Acvta.to.globalM\00!2,S\00S;\0Amov\A7\00\00\13\00xctaid.x\17\00S3, %t\15\00qad.lo.s\18\00#4,4\00\00\E0\00\D3%r3;\0Amul.wide!\002d3,'\00\824;\0Aadd.sz\00&4,\80\00\183i\00\855, 0;\0Ast\AA\00@32 [1\00\10],\00\C05;\0Aret;\0A\0A}\0A\00\00\00\00\00"
@alloc___gpu___pvoid_i64___pvoid = internal constant [32 x i8] c"alloc___gpu___pvoid_i64___pvoid\00"
@ral_recv_input___cpu___pvoid_i64___m2df32 = internal constant [42 x i8] c"ral_recv_input___cpu___pvoid_i64___m2df32\00"

define void @disc_ral_call(ptr nocapture readonly %0, ptr %1, ptr %2) local_unnamed_addr {
entry:
  %3 = load ptr, ptr %0, align 8
  %4 = getelementptr ptr, ptr %0, i64 1
  %5 = load ptr, ptr %4, align 8
  %6 = load ptr, ptr %2, align 8
  store ptr %3, ptr %6, align 8
  tail call void %5(ptr %3, ptr %1, ptr nonnull %2)
  ret void
}

define void @main(ptr %0) local_unnamed_addr {
  %2 = alloca %0, align 8
  %3 = alloca [3 x ptr], align 8
  store ptr %2, ptr %3, align 8
  %4 = getelementptr inbounds %0, ptr %2, i64 0, i32 1
  store i64 0, ptr %4, align 8
  %5 = getelementptr inbounds ptr, ptr %3, i64 1
  store ptr %4, ptr %5, align 8
  %6 = getelementptr inbounds %0, ptr %2, i64 0, i32 2
  %7 = getelementptr inbounds ptr, ptr %3, i64 2
  store ptr %6, ptr %7, align 8
  %8 = load ptr, ptr %0, align 8
  %9 = getelementptr ptr, ptr %0, i64 1
  %10 = load ptr, ptr %9, align 8
  store ptr %8, ptr %2, align 8
  call void %10(ptr %8, ptr nonnull @ral_recv_input___cpu___pvoid_i64___m2df32, ptr nonnull %3)
  %.fca.0.load2 = load ptr, ptr %6, align 8
  %.fca.1.gep4 = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 1
  %.fca.1.load5 = load ptr, ptr %.fca.1.gep4, align 8
  %.fca.2.gep7 = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 2
  %.fca.2.load8 = load i64, ptr %.fca.2.gep7, align 8
  %.fca.3.0.gep10 = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 3
  %.fca.3.0.load11 = load i64, ptr %.fca.3.0.gep10, align 8
  %.fca.3.1.gep13 = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 3, i64 1
  %.fca.3.1.load14 = load i64, ptr %.fca.3.1.gep13, align 8
  %.fca.4.0.gep16 = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 4
  %.fca.4.0.load17 = load i64, ptr %.fca.4.0.gep16, align 8
  %.fca.4.1.gep19 = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 4, i64 1
  %.fca.4.1.load20 = load i64, ptr %.fca.4.1.gep19, align 8
  %11 = alloca %.1, align 8
  %12 = alloca [3 x ptr], align 8
  store ptr %11, ptr %12, align 8
  %13 = getelementptr inbounds %.1, ptr %11, i64 0, i32 1
  store i64 1, ptr %13, align 8
  %14 = getelementptr inbounds ptr, ptr %12, i64 1
  store ptr %13, ptr %14, align 8
  %15 = getelementptr inbounds %.1, ptr %11, i64 0, i32 2
  %16 = getelementptr inbounds ptr, ptr %12, i64 2
  store ptr %15, ptr %16, align 8
  %17 = load ptr, ptr %0, align 8
  %18 = load ptr, ptr %9, align 8
  store ptr %17, ptr %11, align 8
  call void %18(ptr %17, ptr nonnull @ral_recv_input___cpu___pvoid_i64___m2df32, ptr nonnull %12)
  %.fca.0.load = load ptr, ptr %15, align 8
  %.fca.1.gep = getelementptr inbounds %.1, ptr %11, i64 0, i32 2, i32 1
  %.fca.1.load = load ptr, ptr %.fca.1.gep, align 8
  %.fca.2.gep = getelementptr inbounds %.1, ptr %11, i64 0, i32 2, i32 2
  %.fca.2.load = load i64, ptr %.fca.2.gep, align 8
  %.fca.3.0.gep = getelementptr inbounds %.1, ptr %11, i64 0, i32 2, i32 3
  %.fca.3.0.load = load i64, ptr %.fca.3.0.gep, align 8
  %.fca.3.1.gep = getelementptr inbounds %.1, ptr %11, i64 0, i32 2, i32 3, i64 1
  %.fca.3.1.load = load i64, ptr %.fca.3.1.gep, align 8
  %.fca.4.0.gep = getelementptr inbounds %.1, ptr %11, i64 0, i32 2, i32 4
  %.fca.4.0.load = load i64, ptr %.fca.4.0.gep, align 8
  %.fca.4.1.gep = getelementptr inbounds %.1, ptr %11, i64 0, i32 2, i32 4, i64 1
  %.fca.4.1.load = load i64, ptr %.fca.4.1.gep, align 8
  %19 = alloca %.2, align 8
  %20 = alloca [3 x ptr], align 8
  store ptr %19, ptr %20, align 8
  %21 = getelementptr inbounds %.2, ptr %19, i64 0, i32 1
  store i64 10240, ptr %21, align 8
  %22 = getelementptr inbounds ptr, ptr %20, i64 1
  store ptr %21, ptr %22, align 8
  %23 = getelementptr inbounds %.2, ptr %19, i64 0, i32 2
  %24 = getelementptr inbounds ptr, ptr %20, i64 2
  store ptr %23, ptr %24, align 8
  %25 = load ptr, ptr %0, align 8
  %26 = load ptr, ptr %9, align 8
  store ptr %25, ptr %19, align 8
  call void %26(ptr %25, ptr nonnull @alloc___gpu___pvoid_i64___pvoid, ptr nonnull %20)
  %27 = load ptr, ptr %23, align 8
  %28 = alloca [3 x ptr], align 8
  store ptr @main_kernel_blob_gpu.binary_compute_60, ptr %28, align 8
  %29 = getelementptr inbounds ptr, ptr %28, i64 1
  store ptr @main_kernel_blob_gpu.binary_sm_70, ptr %29, align 8
  %30 = getelementptr inbounds ptr, ptr %28, i64 2
  store ptr @main_kernel_blob_gpu.binary_sm_75, ptr %30, align 8
  %31 = alloca %.3, align 8
  %32 = alloca [6 x ptr], align 8
  store i64 256, ptr %31, align 8
  store ptr %31, ptr %32, align 8
  %33 = getelementptr inbounds %.3, ptr %31, i64 0, i32 1
  store ptr %27, ptr %33, align 8
  %34 = getelementptr inbounds ptr, ptr %32, i64 1
  store ptr %33, ptr %34, align 8
  %35 = getelementptr inbounds %.3, ptr %31, i64 0, i32 2
  store ptr %27, ptr %35, align 8
  %36 = getelementptr inbounds ptr, ptr %32, i64 2
  store ptr %35, ptr %36, align 8
  %37 = getelementptr inbounds %.3, ptr %31, i64 0, i32 3
  store i64 0, ptr %37, align 8
  %38 = getelementptr inbounds ptr, ptr %32, i64 3
  store ptr %37, ptr %38, align 8
  %39 = getelementptr inbounds %.3, ptr %31, i64 0, i32 4
  store i64 2560, ptr %39, align 8
  %40 = getelementptr inbounds ptr, ptr %32, i64 4
  store ptr %39, ptr %40, align 8
  %41 = getelementptr inbounds %.3, ptr %31, i64 0, i32 5
  store i64 1, ptr %41, align 8
  %42 = getelementptr inbounds ptr, ptr %32, i64 5
  store ptr %41, ptr %42, align 8
  %43 = alloca %.4, align 8
  %44 = alloca [14 x ptr], align 8
  store ptr %43, ptr %44, align 8
  %45 = getelementptr inbounds %.4, ptr %43, i64 0, i32 1
  store ptr %28, ptr %45, align 8
  %46 = getelementptr inbounds ptr, ptr %44, i64 1
  store ptr %45, ptr %46, align 8
  %47 = getelementptr inbounds %.4, ptr %43, i64 0, i32 2
  store i64 3, ptr %47, align 8
  %48 = getelementptr inbounds ptr, ptr %44, i64 2
  store ptr %47, ptr %48, align 8
  %49 = getelementptr inbounds %.4, ptr %43, i64 0, i32 3
  store ptr @main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name, ptr %49, align 8
  %50 = getelementptr inbounds ptr, ptr %44, i64 3
  store ptr %49, ptr %50, align 8
  %51 = getelementptr inbounds %.4, ptr %43, i64 0, i32 4
  store i64 10, ptr %51, align 8
  %52 = getelementptr inbounds ptr, ptr %44, i64 4
  store ptr %51, ptr %52, align 8
  %53 = getelementptr inbounds %.4, ptr %43, i64 0, i32 5
  store i64 1, ptr %53, align 8
  %54 = getelementptr inbounds ptr, ptr %44, i64 5
  store ptr %53, ptr %54, align 8
  %55 = getelementptr inbounds %.4, ptr %43, i64 0, i32 6
  store i64 1, ptr %55, align 8
  %56 = getelementptr inbounds ptr, ptr %44, i64 6
  store ptr %55, ptr %56, align 8
  %57 = getelementptr inbounds %.4, ptr %43, i64 0, i32 7
  store i64 256, ptr %57, align 8
  %58 = getelementptr inbounds ptr, ptr %44, i64 7
  store ptr %57, ptr %58, align 8
  %59 = getelementptr inbounds %.4, ptr %43, i64 0, i32 8
  store i64 1, ptr %59, align 8
  %60 = getelementptr inbounds ptr, ptr %44, i64 8
  store ptr %59, ptr %60, align 8
  %61 = getelementptr inbounds %.4, ptr %43, i64 0, i32 9
  store i64 1, ptr %61, align 8
  %62 = getelementptr inbounds ptr, ptr %44, i64 9
  store ptr %61, ptr %62, align 8
  %63 = getelementptr inbounds %.4, ptr %43, i64 0, i32 10
  store i32 0, ptr %63, align 8
  %64 = getelementptr inbounds ptr, ptr %44, i64 10
  store ptr %63, ptr %64, align 8
  %65 = getelementptr inbounds %.4, ptr %43, i64 0, i32 11
  store ptr null, ptr %65, align 8
  %66 = getelementptr inbounds ptr, ptr %44, i64 11
  store ptr %65, ptr %66, align 8
  %67 = getelementptr inbounds %.4, ptr %43, i64 0, i32 12
  store i32 6, ptr %67, align 8
  %68 = getelementptr inbounds ptr, ptr %44, i64 12
  store ptr %67, ptr %68, align 8
  %69 = getelementptr inbounds %.4, ptr %43, i64 0, i32 13
  store ptr %32, ptr %69, align 8
  %70 = getelementptr inbounds ptr, ptr %44, i64 13
  store ptr %69, ptr %70, align 8
  %71 = load ptr, ptr %0, align 8
  %72 = load ptr, ptr %9, align 8
  store ptr %71, ptr %43, align 8
  call void %72(ptr %71, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %44)
  %73 = alloca [3 x ptr], align 8
  store ptr @main_kernel_0_blob_gpu.binary_compute_60, ptr %73, align 8
  %74 = getelementptr inbounds ptr, ptr %73, i64 1
  store ptr @main_kernel_0_blob_gpu.binary_sm_70, ptr %74, align 8
  %75 = getelementptr inbounds ptr, ptr %73, i64 2
  store ptr @main_kernel_0_blob_gpu.binary_sm_75, ptr %75, align 8
  %76 = alloca %.5, align 8
  %77 = alloca [21 x ptr], align 8
  store i64 256, ptr %76, align 8
  store ptr %76, ptr %77, align 8
  %78 = getelementptr inbounds %.5, ptr %76, i64 0, i32 1
  store i64 20971520, ptr %78, align 8
  %79 = getelementptr inbounds ptr, ptr %77, i64 1
  store ptr %78, ptr %79, align 8
  %80 = getelementptr inbounds %.5, ptr %76, i64 0, i32 2
  store ptr %.fca.0.load2, ptr %80, align 8
  %81 = getelementptr inbounds ptr, ptr %77, i64 2
  store ptr %80, ptr %81, align 8
  %82 = getelementptr inbounds %.5, ptr %76, i64 0, i32 3
  store ptr %.fca.1.load5, ptr %82, align 8
  %83 = getelementptr inbounds ptr, ptr %77, i64 3
  store ptr %82, ptr %83, align 8
  %84 = getelementptr inbounds %.5, ptr %76, i64 0, i32 4
  store i64 %.fca.2.load8, ptr %84, align 8
  %85 = getelementptr inbounds ptr, ptr %77, i64 4
  store ptr %84, ptr %85, align 8
  %86 = getelementptr inbounds %.5, ptr %76, i64 0, i32 5
  store i64 %.fca.3.0.load11, ptr %86, align 8
  %87 = getelementptr inbounds ptr, ptr %77, i64 5
  store ptr %86, ptr %87, align 8
  %88 = getelementptr inbounds %.5, ptr %76, i64 0, i32 6
  store i64 %.fca.3.1.load14, ptr %88, align 8
  %89 = getelementptr inbounds ptr, ptr %77, i64 6
  store ptr %88, ptr %89, align 8
  %90 = getelementptr inbounds %.5, ptr %76, i64 0, i32 7
  store i64 %.fca.4.0.load17, ptr %90, align 8
  %91 = getelementptr inbounds ptr, ptr %77, i64 7
  store ptr %90, ptr %91, align 8
  %92 = getelementptr inbounds %.5, ptr %76, i64 0, i32 8
  store i64 %.fca.4.1.load20, ptr %92, align 8
  %93 = getelementptr inbounds ptr, ptr %77, i64 8
  store ptr %92, ptr %93, align 8
  %94 = getelementptr inbounds %.5, ptr %76, i64 0, i32 9
  store ptr %.fca.0.load, ptr %94, align 8
  %95 = getelementptr inbounds ptr, ptr %77, i64 9
  store ptr %94, ptr %95, align 8
  %96 = getelementptr inbounds %.5, ptr %76, i64 0, i32 10
  store ptr %.fca.1.load, ptr %96, align 8
  %97 = getelementptr inbounds ptr, ptr %77, i64 10
  store ptr %96, ptr %97, align 8
  %98 = getelementptr inbounds %.5, ptr %76, i64 0, i32 11
  store i64 %.fca.2.load, ptr %98, align 8
  %99 = getelementptr inbounds ptr, ptr %77, i64 11
  store ptr %98, ptr %99, align 8
  %100 = getelementptr inbounds %.5, ptr %76, i64 0, i32 12
  store i64 %.fca.3.0.load, ptr %100, align 8
  %101 = getelementptr inbounds ptr, ptr %77, i64 12
  store ptr %100, ptr %101, align 8
  %102 = getelementptr inbounds %.5, ptr %76, i64 0, i32 13
  store i64 %.fca.3.1.load, ptr %102, align 8
  %103 = getelementptr inbounds ptr, ptr %77, i64 13
  store ptr %102, ptr %103, align 8
  %104 = getelementptr inbounds %.5, ptr %76, i64 0, i32 14
  store i64 %.fca.4.0.load, ptr %104, align 8
  %105 = getelementptr inbounds ptr, ptr %77, i64 14
  store ptr %104, ptr %105, align 8
  %106 = getelementptr inbounds %.5, ptr %76, i64 0, i32 15
  store i64 %.fca.4.1.load, ptr %106, align 8
  %107 = getelementptr inbounds ptr, ptr %77, i64 15
  store ptr %106, ptr %107, align 8
  %108 = getelementptr inbounds %.5, ptr %76, i64 0, i32 16
  store ptr %27, ptr %108, align 8
  %109 = getelementptr inbounds ptr, ptr %77, i64 16
  store ptr %108, ptr %109, align 8
  %110 = getelementptr inbounds %.5, ptr %76, i64 0, i32 17
  store ptr %27, ptr %110, align 8
  %111 = getelementptr inbounds ptr, ptr %77, i64 17
  store ptr %110, ptr %111, align 8
  %112 = getelementptr inbounds %.5, ptr %76, i64 0, i32 18
  store i64 0, ptr %112, align 8
  %113 = getelementptr inbounds ptr, ptr %77, i64 18
  store ptr %112, ptr %113, align 8
  %114 = getelementptr inbounds %.5, ptr %76, i64 0, i32 19
  store i64 2560, ptr %114, align 8
  %115 = getelementptr inbounds ptr, ptr %77, i64 19
  store ptr %114, ptr %115, align 8
  %116 = getelementptr inbounds %.5, ptr %76, i64 0, i32 20
  store i64 1, ptr %116, align 8
  %117 = getelementptr inbounds ptr, ptr %77, i64 20
  store ptr %116, ptr %117, align 8
  %118 = alloca %.6, align 8
  %119 = alloca [14 x ptr], align 8
  store ptr %118, ptr %119, align 8
  %120 = getelementptr inbounds %.6, ptr %118, i64 0, i32 1
  store ptr %73, ptr %120, align 8
  %121 = getelementptr inbounds ptr, ptr %119, i64 1
  store ptr %120, ptr %121, align 8
  %122 = getelementptr inbounds %.6, ptr %118, i64 0, i32 2
  store i64 3, ptr %122, align 8
  %123 = getelementptr inbounds ptr, ptr %119, i64 2
  store ptr %122, ptr %123, align 8
  %124 = getelementptr inbounds %.6, ptr %118, i64 0, i32 3
  store ptr @main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name, ptr %124, align 8
  %125 = getelementptr inbounds ptr, ptr %119, i64 3
  store ptr %124, ptr %125, align 8
  %126 = getelementptr inbounds %.6, ptr %118, i64 0, i32 4
  store i64 81920, ptr %126, align 8
  %127 = getelementptr inbounds ptr, ptr %119, i64 4
  store ptr %126, ptr %127, align 8
  %128 = getelementptr inbounds %.6, ptr %118, i64 0, i32 5
  store i64 1, ptr %128, align 8
  %129 = getelementptr inbounds ptr, ptr %119, i64 5
  store ptr %128, ptr %129, align 8
  %130 = getelementptr inbounds %.6, ptr %118, i64 0, i32 6
  store i64 1, ptr %130, align 8
  %131 = getelementptr inbounds ptr, ptr %119, i64 6
  store ptr %130, ptr %131, align 8
  %132 = getelementptr inbounds %.6, ptr %118, i64 0, i32 7
  store i64 256, ptr %132, align 8
  %133 = getelementptr inbounds ptr, ptr %119, i64 7
  store ptr %132, ptr %133, align 8
  %134 = getelementptr inbounds %.6, ptr %118, i64 0, i32 8
  store i64 1, ptr %134, align 8
  %135 = getelementptr inbounds ptr, ptr %119, i64 8
  store ptr %134, ptr %135, align 8
  %136 = getelementptr inbounds %.6, ptr %118, i64 0, i32 9
  store i64 1, ptr %136, align 8
  %137 = getelementptr inbounds ptr, ptr %119, i64 9
  store ptr %136, ptr %137, align 8
  %138 = getelementptr inbounds %.6, ptr %118, i64 0, i32 10
  store i32 0, ptr %138, align 8
  %139 = getelementptr inbounds ptr, ptr %119, i64 10
  store ptr %138, ptr %139, align 8
  %140 = getelementptr inbounds %.6, ptr %118, i64 0, i32 11
  store ptr null, ptr %140, align 8
  %141 = getelementptr inbounds ptr, ptr %119, i64 11
  store ptr %140, ptr %141, align 8
  %142 = getelementptr inbounds %.6, ptr %118, i64 0, i32 12
  store i32 21, ptr %142, align 8
  %143 = getelementptr inbounds ptr, ptr %119, i64 12
  store ptr %142, ptr %143, align 8
  %144 = getelementptr inbounds %.6, ptr %118, i64 0, i32 13
  store ptr %77, ptr %144, align 8
  %145 = getelementptr inbounds ptr, ptr %119, i64 13
  store ptr %144, ptr %145, align 8
  %146 = load ptr, ptr %0, align 8
  %147 = load ptr, ptr %9, align 8
  store ptr %146, ptr %118, align 8
  call void %147(ptr %146, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %119)
  %148 = alloca %.7, align 8
  %149 = alloca [7 x ptr], align 8
  store ptr %148, ptr %149, align 8
  %150 = getelementptr inbounds %.7, ptr %148, i64 0, i32 1
  store i64 0, ptr %150, align 8
  %151 = getelementptr inbounds ptr, ptr %149, i64 1
  store ptr %150, ptr %151, align 8
  %152 = getelementptr inbounds %.7, ptr %148, i64 0, i32 2
  store ptr %27, ptr %152, align 8
  %153 = getelementptr inbounds ptr, ptr %149, i64 2
  store ptr %152, ptr %153, align 8
  %154 = getelementptr inbounds %.7, ptr %148, i64 0, i32 3
  store ptr %27, ptr %154, align 8
  %155 = getelementptr inbounds ptr, ptr %149, i64 3
  store ptr %154, ptr %155, align 8
  %156 = getelementptr inbounds %.7, ptr %148, i64 0, i32 4
  store i64 0, ptr %156, align 8
  %157 = getelementptr inbounds ptr, ptr %149, i64 4
  store ptr %156, ptr %157, align 8
  %158 = getelementptr inbounds %.7, ptr %148, i64 0, i32 5
  store i64 2560, ptr %158, align 8
  %159 = getelementptr inbounds ptr, ptr %149, i64 5
  store ptr %158, ptr %159, align 8
  %160 = getelementptr inbounds %.7, ptr %148, i64 0, i32 6
  store i64 1, ptr %160, align 8
  %161 = getelementptr inbounds ptr, ptr %149, i64 6
  store ptr %160, ptr %161, align 8
  %162 = load ptr, ptr %0, align 8
  %163 = load ptr, ptr %9, align 8
  store ptr %162, ptr %148, align 8
  call void %163(ptr %162, ptr nonnull @ral_send_output___cpu___pvoid_i64_m1df32___void, ptr nonnull %149)
  ret void
}

[DISC] LowerLLVMToBinary takes: 1.712700e-02 s.
object file to shared library command: gcc --shared -o /tmp/tmph4zfk7pw/tmpw2h27_5r.so /tmp/tmph4zfk7pw/tmpw2h27_5r.so.o
save shared lib file to : /tmp/tmph4zfk7pw/tmpw2h27_5r.so
[DISC] BinaryStrToSharedLibrary takes: 3.794400e-02 s.
[DISC] LowerHLOToSharedLibrary takes: 9.725590e-01 s.
