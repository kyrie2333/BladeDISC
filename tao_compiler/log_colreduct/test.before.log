exec ${PAGER:-/usr/bin/less} "$0" || exit 1
Executing tests from //mlir/disc/tests/tensorflow_ops:max.cpp.test
-----------------------------------------------------------------------------
[==========] Running 1 test from 1 test suite.
[----------] Global test environment set-up.
[----------] 1 test from TFMaxOpTest
[ RUN      ] TFMaxOpTest.ColReduceFullyDynamicShape3DF32
2023-06-08 04:48:05.309156: I ./mlir/disc/tests/mlir_feature_test.h:29] Apply env setting:
2023-06-08 04:48:05.309204: I ./mlir/disc/tests/mlir_feature_test.h:31] 	DISC_MEM_INTENSIVE_OPT_EXPERIMENTAL = true
2023-06-08 04:48:05.309207: I ./mlir/disc/tests/mlir_feature_test.h:31] 	DISC_ENABLE_STITCH = true
2023-06-08 04:48:05.309211: I mlir/disc/tests/mlir_feature_test.cc:271] Testing for CUDA backend
2023-06-08 04:48:05.309262: I mlir/disc/tests/mlir_feature_test.cc:145] Original TF code: func.func @main(%arg0: tensor<?x?x?xf32>) -> tensor<?x?xf32> attributes {tf.entry_function = {inputs = "{{INPUTS}}", outputs = "{{OUTPUTS}}", input_placements="{{INPUT_PLACEMENTS}}", output_placements="{{OUTPUT_PLACEMENTS}}"}} {
  %graph = tf_executor.graph {
    %1:2 = tf_executor.island wraps "tf.Const"() {value = dense<[0]> : tensor<1xi32>} : () -> tensor<1xi32>
    %2:2 = tf_executor.island wraps "tf.Abs"(%arg0) : (tensor<?x?x?xf32>) -> tensor<?x?x?xf32>
    %3:2 = tf_executor.island wraps "tf.Max"(%2, %1) : (tensor<?x?x?xf32>, tensor<1xi32>) -> tensor<?x?xf32>
    tf_executor.fetch %3 : tensor<?x?xf32>
  }
  return %graph : tensor<?x?xf32>
}
2023-06-08 04:48:05.309280: I mlir/disc/tests/mlir_feature_test.cc:149] New TF code: func.func @main(%arg0: tensor<?x?x?xf32>) -> tensor<?x?xf32> attributes {tf.entry_function = {inputs = "input0", outputs = "output0", input_placements="gpu", output_placements="gpu"}} {
  %graph = tf_executor.graph {
    %1:2 = tf_executor.island wraps "tf.Const"() {value = dense<[0]> : tensor<1xi32>} : () -> tensor<1xi32>
    %2:2 = tf_executor.island wraps "tf.Abs"(%arg0) : (tensor<?x?x?xf32>) -> tensor<?x?x?xf32>
    %3:2 = tf_executor.island wraps "tf.Max"(%2, %1) : (tensor<?x?x?xf32>, tensor<1xi32>) -> tensor<?x?xf32>
    tf_executor.fetch %3 : tensor<?x?xf32>
  }
  return %graph : tensor<?x?xf32>
}
2023-06-08 04:48:05.309371: I mlir/disc/tests/mlir_test.cc:233] tf_opt_pat: external/org_tensorflow/tensorflow/compiler/mlir/tf-opt
2023-06-08 04:48:05.309375: I mlir/disc/tests/mlir_test.cc:234] mlir_file_path: /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617bea/tempfile-adf59ec6ac82-11dd47f9-244707-5fd96f5436371
2023-06-08 04:48:05.309378: I mlir/disc/tests/mlir_test.cc:235] tmp_dir: /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617bea
2023-06-08 04:48:05.309381: I mlir/disc/tests/mlir_test.cc:236] test_name: ColReduceFullyDynamicShape3DF32_0
2023-06-08 04:48:05.309388: I mlir/disc/tests/mlir_test.cc:284] tf_opt_path: external/org_tensorflow/tensorflow/compiler/mlir/tf-opt

2023-06-08 04:48:05.309393: I mlir/disc/tests/mlir_test.cc:257] program_path: external/org_tensorflow/tensorflow/compiler/mlir/tf-opt

2023-06-08 04:48:05.369174: I mlir/disc/tests/mlir_test.cc:269] Executed: external/org_tensorflow/tensorflow/compiler/mlir/tf-opt --tf-standard-pipeline /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617bea/tempfile-adf59ec6ac82-11dd47f9-244707-5fd96f5436371 -o /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceFullyDynamicShape3DF32_0_tf_dialect.mlir 
2023-06-08 04:48:05.369191: I mlir/disc/tests/mlir_test.cc:270] external/org_tensorflow/tensorflow/compiler/mlir/tf-opt: 0
2023-06-08 04:48:05.369194: I mlir/disc/tests/mlir_test.cc:271] -- stdout:

============ END ============

2023-06-08 04:48:05.369198: I mlir/disc/tests/mlir_test.cc:273] -- stderr:
2023-06-08 04:48:05.355435: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.

============ END ============

2023-06-08 04:48:05.369207: I mlir/disc/tests/mlir_test.cc:275] ret: 0

2023-06-08 04:48:05.369222: I mlir/disc/tests/mlir_test.cc:257] program_path: mlir/disc/disc_compiler_main

2023-06-08 04:48:06.280831: I mlir/disc/tests/mlir_test.cc:269] Executed: mlir/disc/disc_compiler_main --mlir-print-elementsattrs-with-hex-if-larger -1 --mlir-elide-elementsattrs-if-larger 8 /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceFullyDynamicShape3DF32_0_tf_dialect.mlir /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceFullyDynamicShape3DF32_0.so 
2023-06-08 04:48:06.280857: I mlir/disc/tests/mlir_test.cc:270] mlir/disc/disc_compiler_main: 0
2023-06-08 04:48:06.280861: I mlir/disc/tests/mlir_test.cc:271] -- stdout:

============ END ============

2023-06-08 04:48:06.282226: I mlir/disc/tests/mlir_test.cc:273] -- stderr:
======== BEGIN Original Module =========
module {
  func.func @main(%arg0: tensor<?x?x?xf32>) -> tensor<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %cst = "tf.Const"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
    %0 = "tf.Abs"(%arg0) : (tensor<?x?x?xf32>) -> tensor<?x?x?xf32>
    %1 = "tf.Max"(%0, %cst) : (tensor<?x?x?xf32>, tensor<1xi32>) -> tensor<?x?xf32>
    return %1 : tensor<?x?xf32>
  }
}

======= END Original Module ==========
[DISC] Load Input IR takes: 2.035000e-03 s.
[[ INFO ]] Running TF2XLA
2023-06-08 04:48:05.417869: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
// -----// IR Dump After SCCP (sccp) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32>) -> tensor<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %cst = "tf.Const"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
    %0 = "tf.Abs"(%arg0) : (tensor<?x?x?xf32>) -> tensor<?x?x?xf32>
    %1 = "tf.Max"(%0, %cst) : (tensor<?x?x?xf32>, tensor<1xi32>) -> tensor<?x?xf32>
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After SCCP (sccp) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32>) -> tensor<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %cst = "tf.Const"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
    %0 = "tf.Abs"(%arg0) : (tensor<?x?x?xf32>) -> tensor<?x?x?xf32>
    %1 = "tf.Max"(%0, %cst) : (tensor<?x?x?xf32>, tensor<1xi32>) -> tensor<?x?xf32>
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After LegalizeTF (xla-legalize-tf) //----- //
func.func @main(%arg0: tensor<?x?x?xf32>) -> tensor<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %0 = mhlo.constant dense<0> : tensor<1xi32>
  %1 = mhlo.abs %arg0 : tensor<?x?x?xf32>
  %2 = mhlo.convert %1 : tensor<?x?x?xf32>
  %3 = mhlo.constant dense<0xFF800000> : tensor<f32>
  %4 = mhlo.reduce(%2 init: %3) applies mhlo.maximum across dimensions = [0] : (tensor<?x?x?xf32>, tensor<f32>) -> tensor<?x?xf32>
  %5 = mhlo.convert %4 : tensor<?x?xf32>
  return %5 : tensor<?x?xf32>
}

// -----// IR Dump After DiscLowerTfPass (disc-lower-tf) //----- //
func.func @main(%arg0: tensor<?x?x?xf32>) -> tensor<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
  %1 = mhlo.abs %arg0 : tensor<?x?x?xf32>
  %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?x?xf32>, tensor<f32>) -> tensor<?x?xf32>
  return %2 : tensor<?x?xf32>
}

===-------------------------------------------------------------------------===
                         ... Execution time report ...
===-------------------------------------------------------------------------===
  Total Execution Time: 0.0082 seconds

  ----Wall Time----  ----Name----
    0.0000 (  0.5%)  ReviseArgumentsForStaticRankPass
    0.0000 (  0.1%)  FunctionalControlFlowToRegionsPass
    0.0042 ( 51.0%)  Inliner
    0.0000 (  0.1%)    (A) CallGraph
    0.0040 ( 48.4%)  'func.func' Pipeline
    0.0040 ( 48.4%)    Canonicalizer
    0.0001 (  1.0%)  'func.func' Pipeline
    0.0000 (  0.1%)    DropWhileShapeInvariantPass
    0.0000 (  0.0%)    ReplicateTensorListInitOpsPass
    0.0001 (  0.9%)    Canonicalizer
    0.0002 (  2.5%)  SCCP
    0.0000 (  0.2%)  GuaranteeAllFuncsOneUsePass
    0.0000 (  0.0%)    (A) CallGraph
    0.0000 (  0.1%)  TensorFlowShapeInferencePass
    0.0002 (  2.0%)  SCCP
    0.0000 (  0.1%)  TensorListOpsDecompositionPass
    0.0000 (  0.1%)  StackOpsDecompositionPass
    0.0000 (  0.1%)  TensorArrayOpsDecompositionPass
    0.0000 (  0.6%)  'func.func' Pipeline
    0.0000 (  0.6%)    DecomposeResourceOpsPass
    0.0000 (  0.2%)  PromoteResourcesToArgsPass
    0.0000 (  0.1%)  SymbolDCE
    0.0000 (  0.1%)  'func.func' Pipeline
    0.0000 (  0.1%)    SinkConstantsToControlFlowPass
    0.0000 (  0.1%)  TensorFlowShapeInferencePass
    0.0002 (  2.7%)  StablehloLegalizeToHloPass
    0.0001 (  0.6%)  'func.func' Pipeline
    0.0000 (  0.4%)    DiscLowerTfPass
    0.0000 (  0.2%)    LowerQuantizedPass
    0.0000 (  0.2%)  LegalizeTfTypesPass
    0.0010 ( 11.7%)  'func.func' Pipeline
    0.0008 (  9.6%)    LegalizeTF
    0.0002 (  1.9%)    DiscLowerTfPass
    0.0000 (  0.1%)    mlir::mhlo::{anonymous}::AdjustLayout
    0.0000 (  0.3%)  LegalizeTFCollective
    0.0001 (  0.8%)  'func.func' Pipeline
    0.0001 (  0.8%)    Canonicalizer
    0.0000 (  0.1%)  TensorFlowShapeInferencePass
    0.0003 (  4.2%)  'func.func' Pipeline
    0.0003 (  4.2%)    LegalizeTF
    0.0000 (  0.2%)  LegalizeTFCommunicationPass
    0.0000 (  0.5%)  'func.func' Pipeline
    0.0000 (  0.4%)    DiscDynamicSliceConverterPass
    0.0000 (  0.1%)    SinkConstantsToControlFlowPass
   -0.0024 (-28.8%)  Rest
    0.0082 (100.0%)  Total
======== BEGIN After TF2HLO =========
module {
  func.func @main(%arg0: tensor<?x?x?xf32>) -> tensor<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %1 = mhlo.abs %arg0 : tensor<?x?x?xf32>
    %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?x?xf32>, tensor<f32>) -> tensor<?x?xf32>
    return %2 : tensor<?x?xf32>
  }
}

======= END After TF2HLO ==========
[DISC] tf2hlo takes: 8.531000e-03 s.
SymbolicDimMgr::save walkRankedTensorValue takes: 5 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 11 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 4 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 4 us
SymbolicDimMgr::save replace the name takes: 3 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %1 = mhlo.abs %arg0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<f32>) -> tensor<?x?xf32, [@S1, @S2]>
    return %2 : tensor<?x?xf32, [@S1, @S2]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 4 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 4 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 12 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 3 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 2 us
SymbolicDimMgr::save replace the name takes: 3 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %1 = mhlo.abs %arg0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<f32>) -> tensor<?x?xf32, [@S1, @S2]>
    return %2 : tensor<?x?xf32, [@S1, @S2]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 3 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 14 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 3 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 3 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %1 = mhlo.abs %arg0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<f32>) -> tensor<?x?xf32, [@S1, @S2]>
    return %2 : tensor<?x?xf32, [@S1, @S2]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After HloCanonicalizeReductionPass (hlo-canonicalize-reduction) //----- //
func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
  %1 = mhlo.abs %arg0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
  %c1_i32 = arith.constant 1 : i32
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %1, %c0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
  %2 = arith.index_cast %dim : index to i32
  %3 = arith.muli %c1_i32, %2 : i32
  %c1 = arith.constant 1 : index
  %dim_0 = tensor.dim %1, %c1 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
  %4 = arith.index_cast %dim_0 : index to i32
  %5 = arith.muli %c1_i32, %4 : i32
  %c2 = arith.constant 2 : index
  %dim_1 = tensor.dim %1, %c2 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
  %6 = arith.index_cast %dim_1 : index to i32
  %7 = arith.muli %5, %6 : i32
  %from_elements = tensor.from_elements %3, %7 : tensor<2xi32>
  %8 = mhlo.dynamic_reshape %1, %from_elements : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<2xi32>) -> tensor<?x?xf32>
  %9 = mhlo.reduce(%8 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
  %c1_2 = arith.constant 1 : index
  %dim_3 = tensor.dim %1, %c1_2 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
  %10 = arith.index_cast %dim_3 : index to i32
  %c2_4 = arith.constant 2 : index
  %dim_5 = tensor.dim %1, %c2_4 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
  %11 = arith.index_cast %dim_5 : index to i32
  %from_elements_6 = tensor.from_elements %10, %11 : tensor<2xi32>
  %12 = mhlo.dynamic_reshape %9, %from_elements_6 : (tensor<?xf32>, tensor<2xi32>) -> tensor<?x?xf32, [@S1, @S2]>
  return %12 : tensor<?x?xf32, [@S1, @S2]>
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_1 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %1 = "disc_shape.tie_shape"(%arg0, %dim, %dim_0, %dim_1) : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, index, index, index) -> tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %2 = mhlo.abs %1 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %3 = "disc_shape.tie_shape"(%2, %dim, %dim_0, %dim_1) : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, index, index, index) -> tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %4 = arith.index_cast %dim : index to i32
    %5 = arith.index_cast %dim_0 : index to i32
    %6 = arith.index_cast %dim_1 : index to i32
    %7 = arith.muli %5, %6 : i32
    %from_elements = tensor.from_elements %4, %7 : tensor<2xi32>
    %8 = "disc_shape.tie_shape"(%from_elements, %c2) : (tensor<2xi32>, index) -> tensor<2xi32>
    %9 = mhlo.dynamic_reshape %3, %8 : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<2xi32>) -> tensor<?x?xf32>
    %10 = arith.index_cast %7 : i32 to index
    %11 = "disc_shape.tie_shape"(%9, %dim, %10) : (tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %12 = mhlo.reduce(%11 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
    %13 = "disc_shape.tie_shape"(%12, %10) : (tensor<?xf32>, index) -> tensor<?xf32>
    %from_elements_2 = tensor.from_elements %5, %6 : tensor<2xi32>
    %14 = "disc_shape.tie_shape"(%from_elements_2, %c2) : (tensor<2xi32>, index) -> tensor<2xi32>
    %15 = mhlo.dynamic_reshape %13, %14 : (tensor<?xf32>, tensor<2xi32>) -> tensor<?x?xf32, [@S1, @S2]>
    %16 = "disc_shape.tie_shape"(%15, %dim_0, %dim_1) : (tensor<?x?xf32, [@S1, @S2]>, index, index) -> tensor<?x?xf32, [@S1, @S2]>
    return %16 : tensor<?x?xf32, [@S1, @S2]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 6 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 24 us
productSet.size() = 4
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 6 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 36 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 3 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 2 us
SymbolicDimMgr::save updateProductEqualityMap takes: 85 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 5 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 1 us
SymbolicDimMgr::save canonicalize the name takes: 4 us
SymbolicDimMgr::save replace the name takes: 7 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_1 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %1 = mhlo.abs %arg0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %2 = arith.index_cast %dim : index to i32
    %3 = arith.index_cast %dim_0 : index to i32
    %4 = arith.index_cast %dim_1 : index to i32
    %5 = arith.muli %3, %4 : i32
    %from_elements = tensor.from_elements %2, %5 : tensor<2xi32>
    %6 = mhlo.dynamic_reshape %1, %from_elements : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<2xi32>) -> tensor<?x?xf32, [@S0, @S3]>
    %7 = mhlo.reduce(%6 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32, [@S0, @S3]>, tensor<f32>) -> tensor<?xf32, [@S3]>
    %from_elements_2 = tensor.from_elements %3, %4 : tensor<2xi32>
    %8 = mhlo.dynamic_reshape %7, %from_elements_2 : (tensor<?xf32, [@S3]>, tensor<2xi32>) -> tensor<?x?xf32, [@S1, @S2]>
    return %8 : tensor<?x?xf32, [@S1, @S2]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After DiscMarkShapeCalculationPass (disc-mhlo-mark-shape-calc) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_1 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %1 = mhlo.abs %arg0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %2 = arith.index_cast %dim : index to i32
    %3 = arith.index_cast %dim_0 : index to i32
    %4 = arith.index_cast %dim_1 : index to i32
    %5 = arith.muli %3, %4 : i32
    %from_elements = tensor.from_elements %2, %5 {disc.shape_op = true} : tensor<2xi32>
    %6 = mhlo.dynamic_reshape %1, %from_elements : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<2xi32>) -> tensor<?x?xf32, [@S0, @S3]>
    %7 = mhlo.reduce(%6 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32, [@S0, @S3]>, tensor<f32>) -> tensor<?xf32, [@S3]>
    %from_elements_2 = tensor.from_elements %3, %4 {disc.shape_op = true} : tensor<2xi32>
    %8 = mhlo.dynamic_reshape %7, %from_elements_2 : (tensor<?xf32, [@S3]>, tensor<2xi32>) -> tensor<?x?xf32, [@S1, @S2]>
    return %8 : tensor<?x?xf32, [@S1, @S2]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After PlaceOpsPass (mhlo-place-ops) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_1 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %1 = mhlo.abs %arg0 {disc.device = "gpu"} : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %2 = arith.index_cast %dim : index to i32
    %3 = arith.index_cast %dim_0 : index to i32
    %4 = arith.index_cast %dim_1 : index to i32
    %5 = arith.muli %3, %4 : i32
    %from_elements = tensor.from_elements %2, %5 {disc.shape_op = true} : tensor<2xi32>
    %6 = mhlo.dynamic_reshape %1, %from_elements {disc.device = "gpu"} : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<2xi32>) -> tensor<?x?xf32, [@S0, @S3]>
    %7 = mhlo.reduce(%6 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32, [@S0, @S3]>, tensor<f32>) -> tensor<?xf32, [@S3]>
    %from_elements_2 = tensor.from_elements %3, %4 {disc.shape_op = true} : tensor<2xi32>
    %8 = mhlo.dynamic_reshape %7, %from_elements_2 {disc.device = "gpu"} : (tensor<?xf32, [@S3]>, tensor<2xi32>) -> tensor<?x?xf32, [@S1, @S2]>
    return %8 : tensor<?x?xf32, [@S1, @S2]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 6 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 13 us
productSet.size() = 4
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 5 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 36 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 2 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 1 us
SymbolicDimMgr::save updateProductEqualityMap takes: 72 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 6 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 1 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 5 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_1 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %1 = mhlo.abs %arg0 {disc.device = "gpu"} : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %2 = arith.index_cast %dim : index to i32
    %3 = arith.index_cast %dim_0 : index to i32
    %4 = arith.index_cast %dim_1 : index to i32
    %5 = arith.muli %3, %4 : i32
    %from_elements = tensor.from_elements %2, %5 {disc.shape_op = true} : tensor<2xi32>
    %6 = mhlo.dynamic_reshape %1, %from_elements {disc.device = "gpu"} : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<2xi32>) -> tensor<?x?xf32, [@S0, @S3]>
    %7 = mhlo.reduce(%6 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32, [@S0, @S3]>, tensor<f32>) -> tensor<?xf32, [@S3]>
    %from_elements_2 = tensor.from_elements %3, %4 {disc.shape_op = true} : tensor<2xi32>
    %8 = mhlo.dynamic_reshape %7, %from_elements_2 {disc.device = "gpu"} : (tensor<?xf32, [@S3]>, tensor<2xi32>) -> tensor<?x?xf32, [@S1, @S2]>
    return %8 : tensor<?x?xf32, [@S1, @S2]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 6 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 25 us
productSet.size() = 4
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 5 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 36 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 2 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 2 us
SymbolicDimMgr::save updateProductEqualityMap takes: 85 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 5 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 1 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 5 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_1 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %1 = mhlo.abs %arg0 {disc.device = "gpu"} : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %2 = arith.index_cast %dim : index to i32
    %3 = arith.index_cast %dim_0 : index to i32
    %4 = arith.index_cast %dim_1 : index to i32
    %5 = arith.muli %3, %4 : i32
    %from_elements = tensor.from_elements %2, %5 {disc.shape_op = true} : tensor<2xi32>
    %6 = mhlo.dynamic_reshape %1, %from_elements {disc.device = "gpu"} : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<2xi32>) -> tensor<?x?xf32, [@S0, @S3]>
    %7 = mhlo.reduce(%6 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32, [@S0, @S3]>, tensor<f32>) -> tensor<?xf32, [@S3]>
    %from_elements_2 = tensor.from_elements %3, %4 {disc.shape_op = true} : tensor<2xi32>
    %8 = mhlo.dynamic_reshape %7, %from_elements_2 {disc.device = "gpu"} : (tensor<?xf32, [@S3]>, tensor<2xi32>) -> tensor<?x?xf32, [@S1, @S2]>
    return %8 : tensor<?x?xf32, [@S1, @S2]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 6 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 19 us
productSet.size() = 4
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 5 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 35 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 3 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 2 us
SymbolicDimMgr::save updateProductEqualityMap takes: 77 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 6 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 1 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 5 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32, [@S0, @S1, @S2]>) -> tensor<?x?xf32, [@S1, @S2]> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %dim_1 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %1 = mhlo.abs %arg0 {disc.device = "gpu"} : tensor<?x?x?xf32, [@S0, @S1, @S2]>
    %2 = arith.index_cast %dim : index to i32
    %3 = arith.index_cast %dim_0 : index to i32
    %4 = arith.index_cast %dim_1 : index to i32
    %5 = arith.muli %3, %4 : i32
    %from_elements = tensor.from_elements %2, %5 {disc.shape_op = true} : tensor<2xi32>
    %6 = mhlo.dynamic_reshape %1, %from_elements {disc.device = "gpu"} : (tensor<?x?x?xf32, [@S0, @S1, @S2]>, tensor<2xi32>) -> tensor<?x?xf32, [@S0, @S3]>
    %7 = mhlo.reduce(%6 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32, [@S0, @S3]>, tensor<f32>) -> tensor<?xf32, [@S3]>
    %from_elements_2 = tensor.from_elements %3, %4 {disc.shape_op = true} : tensor<2xi32>
    %8 = mhlo.dynamic_reshape %7, %from_elements_2 {disc.device = "gpu"} : (tensor<?xf32, [@S3]>, tensor<2xi32>) -> tensor<?x?xf32, [@S1, @S2]>
    return %8 : tensor<?x?xf32, [@S1, @S2]>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 5 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 15 us
productSet.size() = 4
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 5 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 34 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 2 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 2 us
SymbolicDimMgr::save updateProductEqualityMap takes: 73 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 5 us
SymbolicDimMgr::save remove symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 1 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 5 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<?x?x?xf32>) -> tensor<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %dim = tensor.dim %arg0, %c0 : tensor<?x?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32>
    %dim_1 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32>
    %1 = "disc_shape.tie_shape"(%arg0, %dim, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : (tensor<?x?x?xf32>, index, index, index) -> tensor<?x?x?xf32>
    %2 = mhlo.abs %1 {disc.device = "gpu"} : tensor<?x?x?xf32>
    %3 = "disc_shape.tie_shape"(%2, %dim, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : (tensor<?x?x?xf32>, index, index, index) -> tensor<?x?x?xf32>
    %4 = arith.index_cast %dim : index to i32
    %5 = arith.index_cast %dim_0 : index to i32
    %6 = arith.index_cast %dim_1 : index to i32
    %7 = arith.muli %5, %6 : i32
    %from_elements = tensor.from_elements %4, %7 {disc.shape_op = true} : tensor<2xi32>
    %8 = "disc_shape.tie_shape"(%from_elements, %c2) : (tensor<2xi32>, index) -> tensor<2xi32>
    %9 = arith.index_cast %7 : i32 to index
    %10 = mhlo.dynamic_reshape %3, %8 {disc.device = "gpu"} : (tensor<?x?x?xf32>, tensor<2xi32>) -> tensor<?x?xf32>
    %11 = "disc_shape.tie_shape"(%10, %dim, %9) {kDiscSymbolicDimAttr = [@S0, @S3]} : (tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %12 = mhlo.reduce(%11 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
    %13 = "disc_shape.tie_shape"(%12, %9) {kDiscSymbolicDimAttr = [@S3]} : (tensor<?xf32>, index) -> tensor<?xf32>
    %from_elements_2 = tensor.from_elements %5, %6 {disc.shape_op = true} : tensor<2xi32>
    %14 = "disc_shape.tie_shape"(%from_elements_2, %c2) : (tensor<2xi32>, index) -> tensor<2xi32>
    %15 = mhlo.dynamic_reshape %13, %14 {disc.device = "gpu"} : (tensor<?xf32>, tensor<2xi32>) -> tensor<?x?xf32>
    %16 = "disc_shape.tie_shape"(%15, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S1, @S2]} : (tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    return %16 : tensor<?x?xf32>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<?x?x?xf32>) -> tensor<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
  %dim = tensor.dim %arg0, %c0 : tensor<?x?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?x?xf32>
  %dim_1 = tensor.dim %arg0, %c2 : tensor<?x?x?xf32>
  %1 = "disc_shape.tie_shape"(%arg0, %dim, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : (tensor<?x?x?xf32>, index, index, index) -> tensor<?x?x?xf32>
  %2 = mhlo.abs %1 {disc.device = "gpu"} : tensor<?x?x?xf32>
  %3 = "disc_shape.tie_shape"(%2, %dim, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : (tensor<?x?x?xf32>, index, index, index) -> tensor<?x?x?xf32>
  %4 = arith.index_cast %dim : index to i32
  %5 = arith.index_cast %dim_0 : index to i32
  %6 = arith.index_cast %dim_1 : index to i32
  %7 = arith.muli %5, %6 : i32
  %from_elements = tensor.from_elements %4, %7 {disc.shape_op = true} : tensor<2xi32>
  %8 = arith.index_cast %7 : i32 to index
  %9 = mhlo.dynamic_reshape %3, %from_elements {disc.device = "gpu"} : (tensor<?x?x?xf32>, tensor<2xi32>) -> tensor<?x?xf32>
  %10 = "disc_shape.tie_shape"(%9, %dim, %8) {kDiscSymbolicDimAttr = [@S0, @S3]} : (tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %11 = mhlo.reduce(%10 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
  %12 = "disc_shape.tie_shape"(%11, %8) {kDiscSymbolicDimAttr = [@S3]} : (tensor<?xf32>, index) -> tensor<?xf32>
  %from_elements_2 = tensor.from_elements %5, %6 {disc.shape_op = true} : tensor<2xi32>
  %13 = mhlo.dynamic_reshape %12, %from_elements_2 {disc.device = "gpu"} : (tensor<?xf32>, tensor<2xi32>) -> tensor<?x?xf32>
  %14 = "disc_shape.tie_shape"(%13, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S1, @S2]} : (tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  return %14 : tensor<?x?xf32>
}

// -----// IR Dump After FuncBufferize (func-bufferize) //----- //
module {
  func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = bufferization.to_tensor %arg0 : memref<?x?x?xf32>
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %1 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %dim = tensor.dim %0, %c0 : tensor<?x?x?xf32>
    %dim_0 = tensor.dim %0, %c1 : tensor<?x?x?xf32>
    %dim_1 = tensor.dim %0, %c2 : tensor<?x?x?xf32>
    %2 = "disc_shape.tie_shape"(%0, %dim, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : (tensor<?x?x?xf32>, index, index, index) -> tensor<?x?x?xf32>
    %3 = mhlo.abs %2 {disc.device = "gpu"} : tensor<?x?x?xf32>
    %4 = "disc_shape.tie_shape"(%3, %dim, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : (tensor<?x?x?xf32>, index, index, index) -> tensor<?x?x?xf32>
    %5 = arith.index_cast %dim : index to i32
    %6 = arith.index_cast %dim_0 : index to i32
    %7 = arith.index_cast %dim_1 : index to i32
    %8 = arith.muli %6, %7 : i32
    %from_elements = tensor.from_elements %5, %8 {disc.shape_op = true} : tensor<2xi32>
    %9 = arith.index_cast %8 : i32 to index
    %10 = mhlo.dynamic_reshape %4, %from_elements {disc.device = "gpu"} : (tensor<?x?x?xf32>, tensor<2xi32>) -> tensor<?x?xf32>
    %11 = "disc_shape.tie_shape"(%10, %dim, %9) {kDiscSymbolicDimAttr = [@S0, @S3]} : (tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %12 = mhlo.reduce(%11 init: %1) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
    %13 = "disc_shape.tie_shape"(%12, %9) {kDiscSymbolicDimAttr = [@S3]} : (tensor<?xf32>, index) -> tensor<?xf32>
    %from_elements_2 = tensor.from_elements %6, %7 {disc.shape_op = true} : tensor<2xi32>
    %14 = mhlo.dynamic_reshape %13, %from_elements_2 {disc.device = "gpu"} : (tensor<?xf32>, tensor<2xi32>) -> tensor<?x?xf32>
    %15 = "disc_shape.tie_shape"(%14, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S1, @S2]} : (tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %16 = bufferization.to_memref %15 : memref<?x?xf32>
    return %16 : memref<?x?xf32>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After DiscHloLegalizeToLhloPass (disc-hlo-legalize-to-lhlo) //----- //
module {
  func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = bufferization.to_tensor %arg0 : memref<?x?x?xf32>
    %1 = bufferization.to_memref %0 : memref<?x?x?xf32>
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %2 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %dim = tensor.dim %0, %c0 : tensor<?x?x?xf32>
    %dim_0 = tensor.dim %0, %c1 : tensor<?x?x?xf32>
    %dim_1 = tensor.dim %0, %c2 : tensor<?x?x?xf32>
    %c1_2 = arith.constant 1 : index
    %3 = arith.muli %c1_2, %dim_1 : index
    %4 = arith.muli %3, %dim_0 : index
    %5 = arith.muli %4, %dim : index
    %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%4, %3, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
    %6 = bufferization.to_tensor %reinterpret_cast : memref<?x?x?xf32>
    %7 = mhlo.abs %6 {disc.device = "gpu"} : tensor<?x?x?xf32>
    %8 = bufferization.to_memref %7 : memref<?x?x?xf32>
    %c1_3 = arith.constant 1 : index
    %9 = arith.muli %c1_3, %dim_1 : index
    %10 = arith.muli %9, %dim_0 : index
    %11 = arith.muli %10, %dim : index
    %reinterpret_cast_4 = memref.reinterpret_cast %8 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%10, %9, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
    %12 = bufferization.to_tensor %reinterpret_cast_4 : memref<?x?x?xf32>
    %13 = arith.index_cast %dim : index to i32
    %14 = arith.index_cast %dim_0 : index to i32
    %15 = arith.index_cast %dim_1 : index to i32
    %16 = arith.muli %14, %15 : i32
    %from_elements = tensor.from_elements %13, %16 {disc.shape_op = true} : tensor<2xi32>
    %17 = arith.index_cast %16 : i32 to index
    %18 = mhlo.dynamic_reshape %12, %from_elements {disc.device = "gpu"} : (tensor<?x?x?xf32>, tensor<2xi32>) -> tensor<?x?xf32>
    %19 = bufferization.to_memref %18 : memref<?x?xf32>
    %c1_5 = arith.constant 1 : index
    %20 = arith.muli %c1_5, %17 : index
    %21 = arith.muli %20, %dim : index
    %reinterpret_cast_6 = memref.reinterpret_cast %19 to offset: [0], sizes: [%dim, %17], strides: [%20, 1] {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32> to memref<?x?xf32>
    %22 = bufferization.to_tensor %reinterpret_cast_6 : memref<?x?xf32>
    %23 = mhlo.reduce(%22 init: %2) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
    %24 = bufferization.to_memref %23 : memref<?xf32>
    %c1_7 = arith.constant 1 : index
    %25 = arith.muli %c1_7, %17 : index
    %reinterpret_cast_8 = memref.reinterpret_cast %24 to offset: [0], sizes: [%17], strides: [1] {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32> to memref<?xf32>
    %26 = bufferization.to_tensor %reinterpret_cast_8 : memref<?xf32>
    %from_elements_9 = tensor.from_elements %14, %15 {disc.shape_op = true} : tensor<2xi32>
    %27 = mhlo.dynamic_reshape %26, %from_elements_9 {disc.device = "gpu"} : (tensor<?xf32>, tensor<2xi32>) -> tensor<?x?xf32>
    %28 = bufferization.to_memref %27 : memref<?x?xf32>
    %c1_10 = arith.constant 1 : index
    %29 = arith.muli %c1_10, %dim_1 : index
    %30 = arith.muli %29, %dim_0 : index
    %reinterpret_cast_11 = memref.reinterpret_cast %28 to offset: [0], sizes: [%dim_0, %dim_1], strides: [%29, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32> to memref<?x?xf32>
    %31 = bufferization.to_tensor %reinterpret_cast_11 : memref<?x?xf32>
    %32 = bufferization.to_memref %31 : memref<?x?xf32>
    return %32 : memref<?x?xf32>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After HloLegalizeToLhloPass (hlo-legalize-to-lhlo) //----- //
module {
  func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = bufferization.to_tensor %arg0 : memref<?x?x?xf32>
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %alloc = memref.alloc() : memref<f32>
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
    %dim = tensor.dim %0, %c0 : tensor<?x?x?xf32>
    %dim_0 = tensor.dim %0, %c1 : tensor<?x?x?xf32>
    %dim_1 = tensor.dim %0, %c2 : tensor<?x?x?xf32>
    %c1_2 = arith.constant 1 : index
    %1 = arith.muli %c1_2, %dim_1 : index
    %2 = arith.muli %1, %dim_0 : index
    %3 = arith.muli %2, %dim : index
    %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%2, %1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
    %4 = bufferization.to_tensor %reinterpret_cast : memref<?x?x?xf32>
    %5 = bufferization.to_memref %4 : memref<?x?x?xf32>
    %6 = bufferization.to_tensor %5 : memref<?x?x?xf32>
    %7 = shape.shape_of %6 : tensor<?x?x?xf32> -> tensor<3xindex>
    %c0_3 = arith.constant 0 : index
    %extracted = tensor.extract %7[%c0_3] : tensor<3xindex>
    %c1_4 = arith.constant 1 : index
    %extracted_5 = tensor.extract %7[%c1_4] : tensor<3xindex>
    %c2_6 = arith.constant 2 : index
    %extracted_7 = tensor.extract %7[%c2_6] : tensor<3xindex>
    %alloc_8 = memref.alloc(%extracted, %extracted_5, %extracted_7) : memref<?x?x?xf32>
    "lmhlo.abs"(%5, %alloc_8) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<?x?x?xf32>) -> ()
    %8 = bufferization.to_tensor %alloc_8 : memref<?x?x?xf32>
    %9 = bufferization.to_memref %8 : memref<?x?x?xf32>
    %c1_9 = arith.constant 1 : index
    %10 = arith.muli %c1_9, %dim_1 : index
    %11 = arith.muli %10, %dim_0 : index
    %12 = arith.muli %11, %dim : index
    %reinterpret_cast_10 = memref.reinterpret_cast %9 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%11, %10, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
    %13 = bufferization.to_tensor %reinterpret_cast_10 : memref<?x?x?xf32>
    %14 = bufferization.to_memref %13 : memref<?x?x?xf32>
    %15 = arith.index_cast %dim : index to i32
    %16 = arith.index_cast %dim_0 : index to i32
    %17 = arith.index_cast %dim_1 : index to i32
    %18 = arith.muli %16, %17 : i32
    %from_elements = tensor.from_elements %15, %18 {disc.shape_op = true} : tensor<2xi32>
    %19 = bufferization.to_memref %from_elements : memref<2xi32>
    %20 = arith.index_cast %18 : i32 to index
    %21 = bufferization.to_tensor %14 : memref<?x?x?xf32>
    %22 = bufferization.to_tensor %19 : memref<2xi32>
    %23 = arith.index_cast %22 : tensor<2xi32> to tensor<2xindex>
    %c0_11 = arith.constant 0 : index
    %extracted_12 = tensor.extract %23[%c0_11] : tensor<2xindex>
    %c1_13 = arith.constant 1 : index
    %extracted_14 = tensor.extract %23[%c1_13] : tensor<2xindex>
    %alloc_15 = memref.alloc(%extracted_12, %extracted_14) : memref<?x?xf32>
    "lmhlo.dynamic_reshape"(%14, %19, %alloc_15) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
    %24 = bufferization.to_tensor %alloc_15 : memref<?x?xf32>
    %25 = bufferization.to_memref %24 : memref<?x?xf32>
    %c1_16 = arith.constant 1 : index
    %26 = arith.muli %c1_16, %20 : index
    %27 = arith.muli %26, %dim : index
    %reinterpret_cast_17 = memref.reinterpret_cast %25 to offset: [0], sizes: [%dim, %20], strides: [%26, 1] {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32> to memref<?x?xf32>
    %28 = bufferization.to_tensor %reinterpret_cast_17 : memref<?x?xf32>
    %29 = bufferization.to_memref %28 : memref<?x?xf32>
    %30 = bufferization.to_tensor %29 : memref<?x?xf32>
    %31 = bufferization.to_tensor %alloc : memref<f32>
    %c1_18 = arith.constant 1 : index
    %dim_19 = tensor.dim %30, %c1_18 : tensor<?x?xf32>
    %from_elements_20 = tensor.from_elements %dim_19 : tensor<1xindex>
    %c0_21 = arith.constant 0 : index
    %extracted_22 = tensor.extract %from_elements_20[%c0_21] : tensor<1xindex>
    %alloc_23 = memref.alloc(%extracted_22) : memref<?xf32>
    "lmhlo.reduce"(%29, %alloc, %alloc_23) ({
    ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
      %alloc_34 = memref.alloc() : memref<f32>
      "lmhlo.maximum"(%arg1, %arg2, %alloc_34) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.copy"(%alloc_34, %arg3) : (memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32>, memref<f32>, memref<?xf32>) -> ()
    %32 = bufferization.to_tensor %alloc_23 : memref<?xf32>
    %33 = bufferization.to_memref %32 : memref<?xf32>
    %c1_24 = arith.constant 1 : index
    %34 = arith.muli %c1_24, %20 : index
    %reinterpret_cast_25 = memref.reinterpret_cast %33 to offset: [0], sizes: [%20], strides: [1] {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32> to memref<?xf32>
    %35 = bufferization.to_tensor %reinterpret_cast_25 : memref<?xf32>
    %36 = bufferization.to_memref %35 : memref<?xf32>
    %from_elements_26 = tensor.from_elements %16, %17 {disc.shape_op = true} : tensor<2xi32>
    %37 = bufferization.to_memref %from_elements_26 : memref<2xi32>
    %38 = bufferization.to_tensor %36 : memref<?xf32>
    %39 = bufferization.to_tensor %37 : memref<2xi32>
    %40 = arith.index_cast %39 : tensor<2xi32> to tensor<2xindex>
    %c0_27 = arith.constant 0 : index
    %extracted_28 = tensor.extract %40[%c0_27] : tensor<2xindex>
    %c1_29 = arith.constant 1 : index
    %extracted_30 = tensor.extract %40[%c1_29] : tensor<2xindex>
    %alloc_31 = memref.alloc(%extracted_28, %extracted_30) : memref<?x?xf32>
    "lmhlo.dynamic_reshape"(%36, %37, %alloc_31) {disc.device = "gpu"} : (memref<?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
    %41 = bufferization.to_tensor %alloc_31 : memref<?x?xf32>
    %42 = bufferization.to_memref %41 : memref<?x?xf32>
    %c1_32 = arith.constant 1 : index
    %43 = arith.muli %c1_32, %dim_1 : index
    %44 = arith.muli %43, %dim_0 : index
    %reinterpret_cast_33 = memref.reinterpret_cast %42 to offset: [0], sizes: [%dim_0, %dim_1], strides: [%43, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32> to memref<?x?xf32>
    return %reinterpret_cast_33 : memref<?x?xf32>
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32>
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32>
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32>
  %0 = arith.muli %dim_1, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %alloc_2 = memref.alloc(%dim, %dim_0, %dim_1) : memref<?x?x?xf32>
  "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<?x?x?xf32>) -> ()
  %1 = arith.muli %dim_1, %dim_0 : index
  %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%1, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %2 = arith.index_cast %dim : index to i32
  %3 = arith.index_cast %dim_0 : index to i32
  %4 = arith.index_cast %dim_1 : index to i32
  %5 = arith.muli %3, %4 : i32
  %from_elements = tensor.from_elements %2, %5 {disc.shape_op = true} : tensor<2xi32>
  %6 = bufferization.to_memref %from_elements : memref<2xi32>
  %7 = arith.index_cast %5 : i32 to index
  %8 = bufferization.to_tensor %6 : memref<2xi32>
  %extracted = tensor.extract %8[%c0] : tensor<2xi32>
  %9 = arith.index_cast %extracted : i32 to index
  %extracted_4 = tensor.extract %8[%c1] : tensor<2xi32>
  %10 = arith.index_cast %extracted_4 : i32 to index
  %alloc_5 = memref.alloc(%9, %10) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_3, %6, %alloc_5) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_6 = memref.reinterpret_cast %alloc_5 to offset: [0], sizes: [%dim, %7], strides: [%7, 1] {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32> to memref<?x?xf32>
  %alloc_7 = memref.alloc(%7) : memref<?xf32>
  "lmhlo.reduce"(%reinterpret_cast_6, %alloc, %alloc_7) ({
  ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
    "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32>, memref<f32>, memref<?xf32>) -> ()
  %reinterpret_cast_8 = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [%7], strides: [1] {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32> to memref<?xf32>
  %from_elements_9 = tensor.from_elements %3, %4 {disc.shape_op = true} : tensor<2xi32>
  %11 = bufferization.to_memref %from_elements_9 : memref<2xi32>
  %alloc_10 = memref.alloc(%dim_0, %dim_1) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_8, %11, %alloc_10) {disc.device = "gpu"} : (memref<?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [0], sizes: [%dim_0, %dim_1], strides: [%dim_1, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32> to memref<?x?xf32>
  return %reinterpret_cast_11 : memref<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32>
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32>
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32>
  %0 = arith.muli %dim_1, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %alloc_2 = memref.alloc(%dim, %dim_0, %dim_1) : memref<?x?x?xf32>
  "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<?x?x?xf32>) -> ()
  %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %1 = arith.index_cast %dim : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.muli %2, %3 : i32
  %from_elements = tensor.from_elements %1, %4 {disc.shape_op = true} : tensor<2xi32>
  %5 = bufferization.to_memref %from_elements : memref<2xi32>
  %6 = arith.index_cast %4 : i32 to index
  %7 = bufferization.to_tensor %5 : memref<2xi32>
  %extracted = tensor.extract %7[%c0] : tensor<2xi32>
  %8 = arith.index_cast %extracted : i32 to index
  %extracted_4 = tensor.extract %7[%c1] : tensor<2xi32>
  %9 = arith.index_cast %extracted_4 : i32 to index
  %alloc_5 = memref.alloc(%8, %9) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_3, %5, %alloc_5) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_6 = memref.reinterpret_cast %alloc_5 to offset: [0], sizes: [%dim, %6], strides: [%6, 1] {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32> to memref<?x?xf32>
  %alloc_7 = memref.alloc(%6) : memref<?xf32>
  "lmhlo.reduce"(%reinterpret_cast_6, %alloc, %alloc_7) ({
  ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
    "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32>, memref<f32>, memref<?xf32>) -> ()
  %reinterpret_cast_8 = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [%6], strides: [1] {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32> to memref<?xf32>
  %from_elements_9 = tensor.from_elements %2, %3 {disc.shape_op = true} : tensor<2xi32>
  %10 = bufferization.to_memref %from_elements_9 : memref<2xi32>
  %alloc_10 = memref.alloc(%dim_0, %dim_1) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_8, %10, %alloc_10) {disc.device = "gpu"} : (memref<?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [0], sizes: [%dim_0, %dim_1], strides: [%dim_1, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32> to memref<?x?xf32>
  return %reinterpret_cast_11 : memref<?x?xf32>
}

// -----// IR Dump After LegalizeToTensorOpPass (lhlo-legalize-to-tensor-op) //----- //
func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32>
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32>
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32>
  %0 = arith.muli %dim_1, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %alloc_2 = memref.alloc(%dim, %dim_0, %dim_1) : memref<?x?x?xf32>
  "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<?x?x?xf32>) -> ()
  %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %1 = arith.index_cast %dim : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.muli %2, %3 : i32
  %from_elements = tensor.from_elements %1, %4 {disc.shape_op = true} : tensor<2xi32>
  %5 = bufferization.to_memref %from_elements : memref<2xi32>
  %6 = arith.index_cast %4 : i32 to index
  %7 = memref.load %5[%c0] : memref<2xi32>
  %8 = arith.index_cast %7 : i32 to index
  %9 = memref.load %5[%c1] : memref<2xi32>
  %10 = arith.index_cast %9 : i32 to index
  %alloc_4 = memref.alloc(%8, %10) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_3, %5, %alloc_4) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_5 = memref.reinterpret_cast %alloc_4 to offset: [0], sizes: [%dim, %6], strides: [%6, 1] {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32> to memref<?x?xf32>
  %alloc_6 = memref.alloc(%6) : memref<?xf32>
  "lmhlo.reduce"(%reinterpret_cast_5, %alloc, %alloc_6) ({
  ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
    "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32>, memref<f32>, memref<?xf32>) -> ()
  %reinterpret_cast_7 = memref.reinterpret_cast %alloc_6 to offset: [0], sizes: [%6], strides: [1] {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32> to memref<?xf32>
  %from_elements_8 = tensor.from_elements %2, %3 {disc.shape_op = true} : tensor<2xi32>
  %11 = bufferization.to_memref %from_elements_8 : memref<2xi32>
  %alloc_9 = memref.alloc(%dim_0, %dim_1) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_7, %11, %alloc_9) {disc.device = "gpu"} : (memref<?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_10 = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [%dim_0, %dim_1], strides: [%dim_1, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32> to memref<?x?xf32>
  return %reinterpret_cast_10 : memref<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32>
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32>
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32>
  %0 = arith.muli %dim_1, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %alloc_2 = memref.alloc(%dim, %dim_0, %dim_1) : memref<?x?x?xf32>
  "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<?x?x?xf32>) -> ()
  %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %1 = arith.index_cast %dim : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.muli %2, %3 : i32
  %from_elements = tensor.from_elements %1, %4 {disc.shape_op = true} : tensor<2xi32>
  %5 = bufferization.to_memref %from_elements : memref<2xi32>
  %6 = arith.index_cast %4 : i32 to index
  %7 = arith.index_cast %4 : i32 to index
  %alloc_4 = memref.alloc(%dim, %7) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_3, %5, %alloc_4) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_5 = memref.reinterpret_cast %alloc_4 to offset: [0], sizes: [%dim, %6], strides: [%6, 1] {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32> to memref<?x?xf32>
  %alloc_6 = memref.alloc(%6) : memref<?xf32>
  "lmhlo.reduce"(%reinterpret_cast_5, %alloc, %alloc_6) ({
  ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
    "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32>, memref<f32>, memref<?xf32>) -> ()
  %reinterpret_cast_7 = memref.reinterpret_cast %alloc_6 to offset: [0], sizes: [%6], strides: [1] {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32> to memref<?xf32>
  %from_elements_8 = tensor.from_elements %2, %3 {disc.shape_op = true} : tensor<2xi32>
  %8 = bufferization.to_memref %from_elements_8 : memref<2xi32>
  %alloc_9 = memref.alloc(%dim_0, %dim_1) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_7, %8, %alloc_9) {disc.device = "gpu"} : (memref<?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_10 = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [%dim_0, %dim_1], strides: [%dim_1, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32> to memref<?x?xf32>
  return %reinterpret_cast_10 : memref<?x?xf32>
}

// -----// IR Dump After TensorBufferize (tensor-bufferize) //----- //
func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32>
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32>
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32>
  %0 = arith.muli %dim_1, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %alloc_2 = memref.alloc(%dim, %dim_0, %dim_1) : memref<?x?x?xf32>
  "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<?x?x?xf32>) -> ()
  %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %1 = arith.index_cast %dim : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.muli %2, %3 : i32
  %alloc_4 = memref.alloc() {alignment = 64 : i64} : memref<2xi32>
  %c0_5 = arith.constant 0 : index
  %c1_6 = arith.constant 1 : index
  memref.store %1, %alloc_4[%c0_5] : memref<2xi32>
  memref.store %4, %alloc_4[%c1_6] : memref<2xi32>
  %5 = arith.index_cast %4 : i32 to index
  %6 = arith.index_cast %4 : i32 to index
  %alloc_7 = memref.alloc(%dim, %6) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_3, %alloc_4, %alloc_7) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_8 = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [%dim, %5], strides: [%5, 1] {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32> to memref<?x?xf32>
  %alloc_9 = memref.alloc(%5) : memref<?xf32>
  "lmhlo.reduce"(%reinterpret_cast_8, %alloc, %alloc_9) ({
  ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
    "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32>, memref<f32>, memref<?xf32>) -> ()
  %reinterpret_cast_10 = memref.reinterpret_cast %alloc_9 to offset: [0], sizes: [%5], strides: [1] {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32> to memref<?xf32>
  %alloc_11 = memref.alloc() {alignment = 64 : i64} : memref<2xi32>
  %c0_12 = arith.constant 0 : index
  %c1_13 = arith.constant 1 : index
  memref.store %2, %alloc_11[%c0_12] : memref<2xi32>
  memref.store %3, %alloc_11[%c1_13] : memref<2xi32>
  %alloc_14 = memref.alloc(%dim_0, %dim_1) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_10, %alloc_11, %alloc_14) {disc.device = "gpu"} : (memref<?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_15 = memref.reinterpret_cast %alloc_14 to offset: [0], sizes: [%dim_0, %dim_1], strides: [%dim_1, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32> to memref<?x?xf32>
  return %reinterpret_cast_15 : memref<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32>
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32>
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32>
  %0 = arith.muli %dim_1, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %alloc_2 = memref.alloc(%dim, %dim_0, %dim_1) : memref<?x?x?xf32>
  "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<?x?x?xf32>) -> ()
  %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %1 = arith.index_cast %dim : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.muli %2, %3 : i32
  %alloc_4 = memref.alloc() {alignment = 64 : i64} : memref<2xi32>
  memref.store %1, %alloc_4[%c0] : memref<2xi32>
  memref.store %4, %alloc_4[%c1] : memref<2xi32>
  %5 = arith.index_cast %4 : i32 to index
  %6 = arith.index_cast %4 : i32 to index
  %alloc_5 = memref.alloc(%dim, %6) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_3, %alloc_4, %alloc_5) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_6 = memref.reinterpret_cast %alloc_5 to offset: [0], sizes: [%dim, %5], strides: [%5, 1] {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32> to memref<?x?xf32>
  %alloc_7 = memref.alloc(%5) : memref<?xf32>
  "lmhlo.reduce"(%reinterpret_cast_6, %alloc, %alloc_7) ({
  ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
    "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32>, memref<f32>, memref<?xf32>) -> ()
  %reinterpret_cast_8 = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [%5], strides: [1] {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32> to memref<?xf32>
  %alloc_9 = memref.alloc() {alignment = 64 : i64} : memref<2xi32>
  memref.store %2, %alloc_9[%c0] : memref<2xi32>
  memref.store %3, %alloc_9[%c1] : memref<2xi32>
  %alloc_10 = memref.alloc(%dim_0, %dim_1) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_8, %alloc_9, %alloc_10) {disc.device = "gpu"} : (memref<?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [0], sizes: [%dim_0, %dim_1], strides: [%dim_1, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32> to memref<?x?xf32>
  return %reinterpret_cast_11 : memref<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32>
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32>
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32>
  %0 = arith.muli %dim_1, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %alloc_2 = memref.alloc(%dim, %dim_0, %dim_1) : memref<?x?x?xf32>
  "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<?x?x?xf32>) -> ()
  %reinterpret_cast_3 = memref.reinterpret_cast %alloc_2 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %1 = arith.index_cast %dim : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.muli %2, %3 : i32
  %alloc_4 = memref.alloc() {alignment = 64 : i64} : memref<2xi32>
  memref.store %1, %alloc_4[%c0] : memref<2xi32>
  memref.store %4, %alloc_4[%c1] : memref<2xi32>
  %5 = arith.index_cast %4 : i32 to index
  %alloc_5 = memref.alloc(%dim, %5) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_3, %alloc_4, %alloc_5) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_6 = memref.reinterpret_cast %alloc_5 to offset: [0], sizes: [%dim, %5], strides: [%5, 1] {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32> to memref<?x?xf32>
  %alloc_7 = memref.alloc(%5) : memref<?xf32>
  "lmhlo.reduce"(%reinterpret_cast_6, %alloc, %alloc_7) ({
  ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
    "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32>, memref<f32>, memref<?xf32>) -> ()
  %reinterpret_cast_8 = memref.reinterpret_cast %alloc_7 to offset: [0], sizes: [%5], strides: [1] {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32> to memref<?xf32>
  %alloc_9 = memref.alloc() {alignment = 64 : i64} : memref<2xi32>
  memref.store %2, %alloc_9[%c0] : memref<2xi32>
  memref.store %3, %alloc_9[%c1] : memref<2xi32>
  %alloc_10 = memref.alloc(%dim_0, %dim_1) : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%reinterpret_cast_8, %alloc_9, %alloc_10) {disc.device = "gpu"} : (memref<?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %reinterpret_cast_11 = memref.reinterpret_cast %alloc_10 to offset: [0], sizes: [%dim_0, %dim_1], strides: [%dim_1, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32> to memref<?x?xf32>
  return %reinterpret_cast_11 : memref<?x?xf32>
}

// -----// IR Dump After DiscMemrefCanonicalizer (disc-memref-canonicalize) //----- //
func.func @main(%arg0: memref<?x?x?xf32>) -> memref<?x?xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32>
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32>
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32>
  %0 = arith.muli %dim_1, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32> to memref<?x?x?xf32>
  %alloc_2 = memref.alloc(%dim, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32>
  "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<?x?x?xf32>) -> ()
  %1 = arith.index_cast %dim : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.muli %2, %3 : i32
  %alloc_3 = memref.alloc() {alignment = 64 : i64} : memref<2xi32>
  memref.store %1, %alloc_3[%c0] : memref<2xi32>
  memref.store %4, %alloc_3[%c1] : memref<2xi32>
  %5 = arith.index_cast %4 : i32 to index
  %alloc_4 = memref.alloc(%dim, %5) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%alloc_2, %alloc_3, %alloc_4) {disc.device = "gpu"} : (memref<?x?x?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  %alloc_5 = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32>
  "lmhlo.reduce"(%alloc_4, %alloc, %alloc_5) ({
  ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
    "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32>, memref<f32>, memref<?xf32>) -> ()
  %alloc_6 = memref.alloc() {alignment = 64 : i64} : memref<2xi32>
  memref.store %2, %alloc_6[%c0] : memref<2xi32>
  memref.store %3, %alloc_6[%c1] : memref<2xi32>
  %alloc_7 = memref.alloc(%dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32>
  "lmhlo.dynamic_reshape"(%alloc_5, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?xf32>, memref<2xi32>, memref<?x?xf32>) -> ()
  return %alloc_7 : memref<?x?xf32>
}

// -----// IR Dump After DiscAssignMemorySpacePass (disc-assign-memory-space) //----- //
module {
  func.func @main(%arg0: memref<?x?x?xf32, "gpu">) -> memref<?x?xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %alloc = memref.alloc() : memref<f32, "gpu">
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %0 = arith.muli %dim_1, %dim_0 : index
    %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
    %alloc_2 = memref.alloc(%dim, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
    "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
    %1 = arith.index_cast %dim : index to i32
    %2 = arith.index_cast %dim_0 : index to i32
    %3 = arith.index_cast %dim_1 : index to i32
    %4 = arith.muli %2, %3 : i32
    %alloc_3 = memref.alloc() {alignment = 64 : i64} : memref<2xi32, "cpu">
    memref.store %1, %alloc_3[%c0] : memref<2xi32, "cpu">
    memref.store %4, %alloc_3[%c1] : memref<2xi32, "cpu">
    %5 = arith.index_cast %4 : i32 to index
    %alloc_4 = memref.alloc(%dim, %5) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
    "lmhlo.dynamic_reshape"(%alloc_2, %alloc_3, %alloc_4) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
    %alloc_5 = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
    "lmhlo.reduce"(%alloc_4, %alloc, %alloc_5) ({
    ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
      "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
    %alloc_6 = memref.alloc() {alignment = 64 : i64} : memref<2xi32, "cpu">
    memref.store %2, %alloc_6[%c0] : memref<2xi32, "cpu">
    memref.store %3, %alloc_6[%c1] : memref<2xi32, "cpu">
    %alloc_7 = memref.alloc(%dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu">
    "lmhlo.dynamic_reshape"(%alloc_5, %alloc_6, %alloc_7) {disc.device = "gpu"} : (memref<?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
    return %alloc_7 : memref<?x?xf32, "gpu">
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After PromoteBuffersToStack (promote-buffers-to-stack) //----- //
func.func @main(%arg0: memref<?x?x?xf32, "gpu">) -> memref<?x?xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %alloc = memref.alloc() : memref<f32, "gpu">
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
  %0 = arith.muli %dim_1, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim, %dim_0, %dim_1], strides: [%0, %dim_1, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim, %dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
  %1 = arith.index_cast %dim : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.muli %2, %3 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %1, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %4, %alloca[%c1] : memref<2xi32, "cpu">
  %5 = arith.index_cast %4 : i32 to index
  %alloc_3 = memref.alloc(%dim, %5) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
  %alloc_4 = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  "lmhlo.reduce"(%alloc_3, %alloc, %alloc_4) ({
  ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
    "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
  %alloca_5 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %2, %alloca_5[%c0] : memref<2xi32, "cpu">
  memref.store %3, %alloca_5[%c1] : memref<2xi32, "cpu">
  %alloc_6 = memref.alloc(%dim_0, %dim_1) {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu">
  "lmhlo.dynamic_reshape"(%alloc_4, %alloca_5, %alloc_6) {disc.device = "gpu"} : (memref<?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
  return %alloc_6 : memref<?x?xf32, "gpu">
}

SymbolicDimMgr::save walkRankedTensorValue takes: 1 us
SymbolicDimMgr::save update attributes takes: 6 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 7 us
productSet.size() = 2
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 4 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 13 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 39 us
SymbolicDimMgr::save updateFunctionType takes: 2 us
SymbolicDimMgr::save collect symbolicDim ops takes: 4 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 4 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscFusionPass (disc-fusion) //----- //
func.func @main(%arg0: memref<?x?x?xf32, "gpu">) -> memref<?x?xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %dim = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
  %c1 = arith.constant 1 : index
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
  %c0 = arith.constant 0 : index
  %dim_1 = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %0 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%0, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %1 = arith.index_cast %dim_1 : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %1, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %4, %alloca[%c1] : memref<2xi32, "cpu">
  %5 = arith.index_cast %4 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %5) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
    "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
    "lmhlo.reduce"(%alloc_3, %alloc, %alloc_4) ({
    ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
      "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  %alloca_5 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %2, %alloca_5[%c0] : memref<2xi32, "cpu">
  memref.store %3, %alloca_5[%c1] : memref<2xi32, "cpu">
  %alloc_6 = memref.alloc(%dim_0, %dim) {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu">
  "lmhlo.dynamic_reshape"(%alloc_4, %alloca_5, %alloc_6) {disc.device = "gpu"} : (memref<?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
  return %alloc_6 : memref<?x?xf32, "gpu">
}

SymbolicDimMgr::save walkRankedTensorValue takes: 1 us
SymbolicDimMgr::save update attributes takes: 5 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 6 us
productSet.size() = 2
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 4 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 12 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 37 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 5 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 5 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscSpecializeFusionWithSpeculationPass (disc-specialize-fusion-with-speculation) //----- //
func.func @main(%arg0: memref<?x?x?xf32, "gpu">) -> memref<?x?xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c2 = arith.constant 2 : index
  %dim = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
  %c1 = arith.constant 1 : index
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
  %c0 = arith.constant 0 : index
  %dim_1 = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %0 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%0, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %1 = arith.index_cast %dim_1 : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %1, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %4, %alloca[%c1] : memref<2xi32, "cpu">
  %5 = arith.index_cast %4 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %5) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %c0_5 = arith.constant 0 : index
  %dim_6 = memref.dim %alloc_3, %c0_5 : memref<?x?xf32, "gpu">
  %c1_7 = arith.constant 1 : index
  %dim_8 = memref.dim %alloc_3, %c1_7 : memref<?x?xf32, "gpu">
  %6 = arith.muli %dim_6, %dim_8 : index
  %c256 = arith.constant 256 : index
  %7 = arith.ceildivsi %6, %c256 : index
  %c108 = arith.constant 108 : index
  %8 = arith.cmpi sgt, %7, %c108 : index
  scf.if %8 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_3, %alloc, %alloc_4) ({
      ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
        "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_3, %alloc, %alloc_4) ({
      ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
        "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %alloca_9 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %2, %alloca_9[%c0] : memref<2xi32, "cpu">
  memref.store %3, %alloca_9[%c1] : memref<2xi32, "cpu">
  %alloc_10 = memref.alloc(%dim_0, %dim) {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu">
  "lmhlo.dynamic_reshape"(%alloc_4, %alloca_9, %alloc_10) {disc.device = "gpu"} : (memref<?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
  return %alloc_10 : memref<?x?xf32, "gpu">
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<?x?x?xf32, "gpu">) -> memref<?x?xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c108 = arith.constant 108 : index
  %c256 = arith.constant 256 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %0 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%0, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %1 = arith.index_cast %dim_1 : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %1, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %4, %alloca[%c1] : memref<2xi32, "cpu">
  %5 = arith.index_cast %4 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %5) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.ceildivsi %6, %c256 : index
  %8 = arith.cmpi sgt, %7, %c108 : index
  scf.if %8 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_3, %alloc, %alloc_4) ({
      ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
        "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_3, %alloc, %alloc_4) ({
      ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
        "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %alloca_5 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %2, %alloca_5[%c0] : memref<2xi32, "cpu">
  memref.store %3, %alloca_5[%c1] : memref<2xi32, "cpu">
  %alloc_6 = memref.alloc(%dim_0, %dim) {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu">
  "lmhlo.dynamic_reshape"(%alloc_4, %alloca_5, %alloc_6) {disc.device = "gpu"} : (memref<?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
  return %alloc_6 : memref<?x?xf32, "gpu">
}

// -----// IR Dump After BufferDeallocation (buffer-deallocation) //----- //
func.func @main(%arg0: memref<?x?x?xf32, "gpu">) -> memref<?x?xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c108 = arith.constant 108 : index
  %c256 = arith.constant 256 : index
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %0 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%0, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %1 = arith.index_cast %dim_1 : index to i32
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %1, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %4, %alloca[%c1] : memref<2xi32, "cpu">
  %5 = arith.index_cast %4 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %5) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.ceildivsi %6, %c256 : index
  %8 = arith.cmpi sgt, %7, %c108 : index
  scf.if %8 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_3, %alloc, %alloc_4) ({
      ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
        "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_3, %alloc, %alloc_4) ({
      ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
        "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  memref.dealloc %alloc_3 : memref<?x?xf32, "gpu">
  memref.dealloc %alloc_2 : memref<?x?x?xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %alloca_5 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %2, %alloca_5[%c0] : memref<2xi32, "cpu">
  memref.store %3, %alloca_5[%c1] : memref<2xi32, "cpu">
  %alloc_6 = memref.alloc(%dim_0, %dim) {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu">
  "lmhlo.dynamic_reshape"(%alloc_4, %alloca_5, %alloc_6) {disc.device = "gpu"} : (memref<?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
  memref.dealloc %alloc_4 : memref<?xf32, "gpu">
  return %alloc_6 : memref<?x?xf32, "gpu">
}

// -----// IR Dump After RalInjectExecutionContextPass (disc-ral-inject-execution-context) //----- //
module {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.recv_input"(%arg0, %c0) : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
    %c108 = arith.constant 108 : index
    %c256 = arith.constant 256 : index
    %c0_0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = memref.dim %0, %c2 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %0, %c1 : memref<?x?x?xf32, "gpu">
    %dim_2 = memref.dim %0, %c0_0 : memref<?x?x?xf32, "gpu">
    %alloc = memref.alloc() : memref<f32, "gpu">
    %1 = arith.muli %dim, %dim_1 : index
    %reinterpret_cast = memref.reinterpret_cast %0 to offset: [0], sizes: [%dim_2, %dim_1, %dim], strides: [%1, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
    %alloc_3 = memref.alloc(%dim_2, %dim_1, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
    %2 = arith.index_cast %dim_2 : index to i32
    %3 = arith.index_cast %dim_1 : index to i32
    %4 = arith.index_cast %dim : index to i32
    %5 = arith.muli %3, %4 : i32
    %alloca = memref.alloca() : memref<2xi32, "cpu">
    memref.store %2, %alloca[%c0_0] : memref<2xi32, "cpu">
    memref.store %5, %alloca[%c1] : memref<2xi32, "cpu">
    %6 = arith.index_cast %5 : i32 to index
    %alloc_4 = memref.alloc(%dim_2, %6) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
    %alloc_5 = memref.alloc(%6) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
    %7 = arith.muli %dim_2, %6 : index
    %8 = arith.ceildivsi %7, %c256 : index
    %9 = arith.cmpi sgt, %8, %c108 : index
    scf.if %9 {
      "lmhlo.fusion"() ({
        "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
        "lmhlo.abs"(%reinterpret_cast, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
        "lmhlo.dynamic_reshape"(%alloc_3, %alloca, %alloc_4) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
        "lmhlo.reduce"(%alloc_4, %alloc, %alloc_5) ({
        ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
          "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
          "lmhlo.terminator"() : () -> ()
        }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
        "lmhlo.abs"(%reinterpret_cast, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
        "lmhlo.dynamic_reshape"(%alloc_3, %alloca, %alloc_4) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
        "lmhlo.reduce"(%alloc_4, %alloc, %alloc_5) ({
        ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
          "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
          "lmhlo.terminator"() : () -> ()
        }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
    }
    memref.dealloc %alloc_4 : memref<?x?xf32, "gpu">
    memref.dealloc %alloc_3 : memref<?x?x?xf32, "gpu">
    memref.dealloc %alloc : memref<f32, "gpu">
    %alloca_6 = memref.alloca() : memref<2xi32, "cpu">
    memref.store %3, %alloca_6[%c0_0] : memref<2xi32, "cpu">
    memref.store %4, %alloca_6[%c1] : memref<2xi32, "cpu">
    %alloc_7 = memref.alloc(%dim_1, %dim) {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu">
    "lmhlo.dynamic_reshape"(%alloc_5, %alloca_6, %alloc_7) {disc.device = "gpu"} : (memref<?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
    memref.dealloc %alloc_5 : memref<?xf32, "gpu">
    %c0_8 = arith.constant 0 : index
    "disc_ral.send_output"(%arg0, %c0_8, %alloc_7) : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
    return
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After DiscLowerToLibraryCallPass (disc-lower-to-library-call) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %2 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%2, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.index_cast %dim_0 : index to i32
  %5 = arith.index_cast %dim : index to i32
  %6 = arith.muli %4, %5 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %3, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %6, %alloca[%c1] : memref<2xi32, "cpu">
  %7 = arith.index_cast %6 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %7) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%7) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %8 = arith.muli %dim_1, %7 : index
  %9 = arith.ceildivsi %8, %c256 : index
  %10 = arith.cmpi sgt, %9, %c108 : index
  scf.if %10 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_3, %alloc, %alloc_4) ({
      ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
        "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_3, %alloc, %alloc_4) ({
      ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
        "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<?x?xf32, "gpu">, memref<f32, "gpu">, memref<?xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  memref.dealloc %alloc_3 : memref<?x?xf32, "gpu">
  memref.dealloc %alloc_2 : memref<?x?x?xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %alloca_5 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %4, %alloca_5[%c0] : memref<2xi32, "cpu">
  memref.store %5, %alloca_5[%c1] : memref<2xi32, "cpu">
  %11 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca_6 = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca_6[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca_6[%c1] : memref<2xindex, "cpu">
  %12 = "disc_ral.dispatch"(%arg0, %11, %alloc_4, %alloca_6) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast_7 = memref.reinterpret_cast %12 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc_4 : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast_7) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

kColReduction <main_kColReduction_reduce__4_1_0___8w32h>, use_new: 0 schedule_hint: 1
kColReduction <main_kColReduction_reduce__4_1_0___8w16h>, use_new: 0 schedule_hint: 2
SymbolicDimMgr::save walkRankedTensorValue takes: 4 us
SymbolicDimMgr::save update attributes takes: 9 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 7 us
productSet.size() = 2
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 4 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 13 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 40 us
SymbolicDimMgr::save updateFunctionType takes: 14 us
SymbolicDimMgr::save collect symbolicDim ops takes: 9 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 3 us
SymbolicDimMgr::save replace the name takes: 9 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
// -----// IR Dump After DiscLhloLegalizeRootsToParallelLoopsPass (disc-lhlo-legalize-roots-to-parallel-loops) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %2 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%2, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.index_cast %dim_0 : index to i32
  %5 = arith.index_cast %dim : index to i32
  %6 = arith.muli %4, %5 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %3, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %6, %alloca[%c1] : memref<2xi32, "cpu">
  %7 = arith.index_cast %6 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %7) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%7) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %8 = arith.muli %dim_1, %7 : index
  %9 = arith.ceildivsi %8, %c256 : index
  %10 = arith.cmpi sgt, %9, %c108 : index
  scf.if %10 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %13 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        %14 = memref.load %alloc[] : memref<f32, "gpu">
        memref.store %14, %alloc_4[%13] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %13 = memref.load %alloc[] : memref<f32, "gpu">
        %14 = arith.addi %arg1, %c128 : index
        %15 = arith.cmpi slt, %14, %dim_1 : index
        %16 = arith.remui %dim_1, %c128 : index
        %17 = arith.cmpi eq, %16, %c0 : index
        %18 = arith.ori %17, %15 : i1
        %19 = arith.addi %arg2, %c2 : index
        %20 = arith.cmpi slt, %19, %7 : index
        %21 = arith.remui %7, %c2 : index
        %22 = arith.cmpi eq, %21, %c0 : index
        %23 = arith.ori %22, %20 : i1
        %24 = arith.andi %18, %23 : i1
        %25:2 = scf.if %24 -> (f32, f32) {
          %29:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %13, %arg5 = %13) -> (f32, f32) {
            %30 = arith.addi %arg1, %arg3 : index
            %31 = memref.load %alloc_3[%30, %arg2] : memref<?x?xf32, "gpu">
            %32 = arith.cmpf oge, %arg4, %31 : f32
            %33 = arith.select %32, %arg4, %31 : f32
            %34 = arith.addi %arg2, %c1 : index
            %35 = memref.load %alloc_3[%30, %34] : memref<?x?xf32, "gpu">
            %36 = arith.cmpf oge, %arg5, %35 : f32
            %37 = arith.select %36, %arg5, %35 : f32
            scf.yield %33, %37 : f32, f32
          }
          scf.yield %29#0, %29#1 : f32, f32
        } else {
          %29:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %13, %arg5 = %13) -> (f32, f32) {
            %30 = arith.addi %arg1, %arg3 : index
            %31 = arith.cmpi slt, %30, %dim_1 : index
            %32 = arith.cmpi slt, %arg2, %7 : index
            %33 = arith.andi %31, %32 : i1
            %34 = scf.if %33 -> (f32) {
              %39 = memref.load %alloc_3[%30, %arg2] : memref<?x?xf32, "gpu">
              %40 = arith.cmpf oge, %arg4, %39 : f32
              %41 = arith.select %40, %arg4, %39 : f32
              scf.yield %41 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %35 = arith.addi %arg2, %c1 : index
            %36 = arith.cmpi slt, %35, %7 : index
            %37 = arith.andi %31, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %39 = memref.load %alloc_3[%30, %35] : memref<?x?xf32, "gpu">
              %40 = arith.cmpf oge, %arg5, %39 : f32
              %41 = arith.select %40, %arg5, %39 : f32
              scf.yield %41 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %34, %38 : f32, f32
          }
          scf.yield %29#0, %29#1 : f32, f32
        }
        %26 = arith.cmpi slt, %arg2, %7 : index
        scf.if %26 {
          %29 = memref.atomic_rmw maxf %25#0, %alloc_4[%arg2] : (f32, memref<?xf32, "gpu">) -> f32
        }
        %27 = arith.addi %arg2, %c1 : index
        %28 = arith.cmpi slt, %27, %7 : index
        scf.if %28 {
          %29 = memref.atomic_rmw maxf %25#1, %alloc_4[%27] : (f32, memref<?xf32, "gpu">) -> f32
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %13 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        %14 = memref.load %alloc[] : memref<f32, "gpu">
        memref.store %14, %alloc_4[%13] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %13 = memref.load %alloc[] : memref<f32, "gpu">
        %14 = arith.addi %arg1, %c128 : index
        %15 = arith.cmpi slt, %14, %dim_1 : index
        %16 = arith.remui %dim_1, %c128 : index
        %17 = arith.cmpi eq, %16, %c0 : index
        %18 = arith.ori %17, %15 : i1
        %19 = arith.addi %arg2, %c2 : index
        %20 = arith.cmpi slt, %19, %7 : index
        %21 = arith.remui %7, %c2 : index
        %22 = arith.cmpi eq, %21, %c0 : index
        %23 = arith.ori %22, %20 : i1
        %24 = arith.andi %18, %23 : i1
        %25:2 = scf.if %24 -> (f32, f32) {
          %29:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %13, %arg5 = %13) -> (f32, f32) {
            %30 = arith.addi %arg1, %arg3 : index
            %31 = memref.load %alloc_3[%30, %arg2] : memref<?x?xf32, "gpu">
            %32 = arith.cmpf oge, %arg4, %31 : f32
            %33 = arith.select %32, %arg4, %31 : f32
            %34 = arith.addi %arg2, %c1 : index
            %35 = memref.load %alloc_3[%30, %34] : memref<?x?xf32, "gpu">
            %36 = arith.cmpf oge, %arg5, %35 : f32
            %37 = arith.select %36, %arg5, %35 : f32
            scf.yield %33, %37 : f32, f32
          }
          scf.yield %29#0, %29#1 : f32, f32
        } else {
          %29:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %13, %arg5 = %13) -> (f32, f32) {
            %30 = arith.addi %arg1, %arg3 : index
            %31 = arith.cmpi slt, %30, %dim_1 : index
            %32 = arith.cmpi slt, %arg2, %7 : index
            %33 = arith.andi %31, %32 : i1
            %34 = scf.if %33 -> (f32) {
              %39 = memref.load %alloc_3[%30, %arg2] : memref<?x?xf32, "gpu">
              %40 = arith.cmpf oge, %arg4, %39 : f32
              %41 = arith.select %40, %arg4, %39 : f32
              scf.yield %41 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %35 = arith.addi %arg2, %c1 : index
            %36 = arith.cmpi slt, %35, %7 : index
            %37 = arith.andi %31, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %39 = memref.load %alloc_3[%30, %35] : memref<?x?xf32, "gpu">
              %40 = arith.cmpf oge, %arg5, %39 : f32
              %41 = arith.select %40, %arg5, %39 : f32
              scf.yield %41 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %34, %38 : f32, f32
          }
          scf.yield %29#0, %29#1 : f32, f32
        }
        %26 = arith.cmpi slt, %arg2, %7 : index
        scf.if %26 {
          %29 = memref.atomic_rmw maxf %25#0, %alloc_4[%arg2] : (f32, memref<?xf32, "gpu">) -> f32
        }
        %27 = arith.addi %arg2, %c1 : index
        %28 = arith.cmpi slt, %27, %7 : index
        scf.if %28 {
          %29 = memref.atomic_rmw maxf %25#1, %alloc_4[%27] : (f32, memref<?xf32, "gpu">) -> f32
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  memref.dealloc %alloc_3 : memref<?x?xf32, "gpu">
  memref.dealloc %alloc_2 : memref<?x?x?xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %alloca_5 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %4, %alloca_5[%c0] : memref<2xi32, "cpu">
  memref.store %5, %alloca_5[%c1] : memref<2xi32, "cpu">
  %11 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca_6 = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca_6[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca_6[%c1] : memref<2xindex, "cpu">
  %12 = "disc_ral.dispatch"(%arg0, %11, %alloc_4, %alloca_6) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast_7 = memref.reinterpret_cast %12 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc_4 : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast_7) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %2 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%2, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.index_cast %dim_0 : index to i32
  %5 = arith.index_cast %dim : index to i32
  %6 = arith.muli %4, %5 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %3, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %6, %alloca[%c1] : memref<2xi32, "cpu">
  %7 = arith.index_cast %6 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %7) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%7) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %8 = arith.muli %dim_1, %7 : index
  %9 = arith.ceildivsi %8, %c256 : index
  %10 = arith.cmpi sgt, %9, %c108 : index
  scf.if %10 {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %13 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        %14 = memref.load %alloc[] : memref<f32, "gpu">
        memref.store %14, %alloc_4[%13] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %13 = memref.load %alloc[] : memref<f32, "gpu">
        %14 = arith.addi %arg1, %c128 : index
        %15 = arith.cmpi slt, %14, %dim_1 : index
        %16 = arith.remui %dim_1, %c128 : index
        %17 = arith.cmpi eq, %16, %c0 : index
        %18 = arith.ori %17, %15 : i1
        %19 = arith.addi %arg2, %c2 : index
        %20 = arith.cmpi slt, %19, %7 : index
        %21 = arith.remui %7, %c2 : index
        %22 = arith.cmpi eq, %21, %c0 : index
        %23 = arith.ori %22, %20 : i1
        %24 = arith.andi %18, %23 : i1
        %25:2 = scf.if %24 -> (f32, f32) {
          %29:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %13, %arg5 = %13) -> (f32, f32) {
            %30 = arith.addi %arg1, %arg3 : index
            %31 = memref.load %alloc_3[%30, %arg2] : memref<?x?xf32, "gpu">
            %32 = arith.cmpf oge, %arg4, %31 : f32
            %33 = arith.select %32, %arg4, %31 : f32
            %34 = arith.addi %arg2, %c1 : index
            %35 = memref.load %alloc_3[%30, %34] : memref<?x?xf32, "gpu">
            %36 = arith.cmpf oge, %arg5, %35 : f32
            %37 = arith.select %36, %arg5, %35 : f32
            scf.yield %33, %37 : f32, f32
          }
          scf.yield %29#0, %29#1 : f32, f32
        } else {
          %29:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %13, %arg5 = %13) -> (f32, f32) {
            %30 = arith.addi %arg1, %arg3 : index
            %31 = arith.cmpi slt, %30, %dim_1 : index
            %32 = arith.cmpi slt, %arg2, %7 : index
            %33 = arith.andi %31, %32 : i1
            %34 = scf.if %33 -> (f32) {
              %39 = memref.load %alloc_3[%30, %arg2] : memref<?x?xf32, "gpu">
              %40 = arith.cmpf oge, %arg4, %39 : f32
              %41 = arith.select %40, %arg4, %39 : f32
              scf.yield %41 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %35 = arith.addi %arg2, %c1 : index
            %36 = arith.cmpi slt, %35, %7 : index
            %37 = arith.andi %31, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %39 = memref.load %alloc_3[%30, %35] : memref<?x?xf32, "gpu">
              %40 = arith.cmpf oge, %arg5, %39 : f32
              %41 = arith.select %40, %arg5, %39 : f32
              scf.yield %41 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %34, %38 : f32, f32
          }
          scf.yield %29#0, %29#1 : f32, f32
        }
        %26 = arith.cmpi slt, %arg2, %7 : index
        scf.if %26 {
          %29 = memref.generic_atomic_rmw %alloc_4[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %30 = arith.cmpf ogt, %arg3, %25#0 : f32
            %31 = arith.select %30, %arg3, %25#0 : f32
            memref.atomic_yield %31 : f32
          }
        }
        %27 = arith.addi %arg2, %c1 : index
        %28 = arith.cmpi slt, %27, %7 : index
        scf.if %28 {
          %29 = memref.generic_atomic_rmw %alloc_4[%27] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %30 = arith.cmpf ogt, %arg3, %25#1 : f32
            %31 = arith.select %30, %arg3, %25#1 : f32
            memref.atomic_yield %31 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.abs"(%reinterpret_cast, %alloc_2) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<?x?x?xf32, "gpu">) -> ()
      "lmhlo.dynamic_reshape"(%alloc_2, %alloca, %alloc_3) {disc.device = "gpu"} : (memref<?x?x?xf32, "gpu">, memref<2xi32, "cpu">, memref<?x?xf32, "gpu">) -> ()
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %13 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        %14 = memref.load %alloc[] : memref<f32, "gpu">
        memref.store %14, %alloc_4[%13] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %13 = memref.load %alloc[] : memref<f32, "gpu">
        %14 = arith.addi %arg1, %c128 : index
        %15 = arith.cmpi slt, %14, %dim_1 : index
        %16 = arith.remui %dim_1, %c128 : index
        %17 = arith.cmpi eq, %16, %c0 : index
        %18 = arith.ori %17, %15 : i1
        %19 = arith.addi %arg2, %c2 : index
        %20 = arith.cmpi slt, %19, %7 : index
        %21 = arith.remui %7, %c2 : index
        %22 = arith.cmpi eq, %21, %c0 : index
        %23 = arith.ori %22, %20 : i1
        %24 = arith.andi %18, %23 : i1
        %25:2 = scf.if %24 -> (f32, f32) {
          %29:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %13, %arg5 = %13) -> (f32, f32) {
            %30 = arith.addi %arg1, %arg3 : index
            %31 = memref.load %alloc_3[%30, %arg2] : memref<?x?xf32, "gpu">
            %32 = arith.cmpf oge, %arg4, %31 : f32
            %33 = arith.select %32, %arg4, %31 : f32
            %34 = arith.addi %arg2, %c1 : index
            %35 = memref.load %alloc_3[%30, %34] : memref<?x?xf32, "gpu">
            %36 = arith.cmpf oge, %arg5, %35 : f32
            %37 = arith.select %36, %arg5, %35 : f32
            scf.yield %33, %37 : f32, f32
          }
          scf.yield %29#0, %29#1 : f32, f32
        } else {
          %29:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %13, %arg5 = %13) -> (f32, f32) {
            %30 = arith.addi %arg1, %arg3 : index
            %31 = arith.cmpi slt, %30, %dim_1 : index
            %32 = arith.cmpi slt, %arg2, %7 : index
            %33 = arith.andi %31, %32 : i1
            %34 = scf.if %33 -> (f32) {
              %39 = memref.load %alloc_3[%30, %arg2] : memref<?x?xf32, "gpu">
              %40 = arith.cmpf oge, %arg4, %39 : f32
              %41 = arith.select %40, %arg4, %39 : f32
              scf.yield %41 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %35 = arith.addi %arg2, %c1 : index
            %36 = arith.cmpi slt, %35, %7 : index
            %37 = arith.andi %31, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %39 = memref.load %alloc_3[%30, %35] : memref<?x?xf32, "gpu">
              %40 = arith.cmpf oge, %arg5, %39 : f32
              %41 = arith.select %40, %arg5, %39 : f32
              scf.yield %41 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %34, %38 : f32, f32
          }
          scf.yield %29#0, %29#1 : f32, f32
        }
        %26 = arith.cmpi slt, %arg2, %7 : index
        scf.if %26 {
          %29 = memref.generic_atomic_rmw %alloc_4[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %30 = arith.cmpf ogt, %arg3, %25#0 : f32
            %31 = arith.select %30, %arg3, %25#0 : f32
            memref.atomic_yield %31 : f32
          }
        }
        %27 = arith.addi %arg2, %c1 : index
        %28 = arith.cmpi slt, %27, %7 : index
        scf.if %28 {
          %29 = memref.generic_atomic_rmw %alloc_4[%27] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %30 = arith.cmpf ogt, %arg3, %25#1 : f32
            %31 = arith.select %30, %arg3, %25#1 : f32
            memref.atomic_yield %31 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  memref.dealloc %alloc_3 : memref<?x?xf32, "gpu">
  memref.dealloc %alloc_2 : memref<?x?x?xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %alloca_5 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %4, %alloca_5[%c0] : memref<2xi32, "cpu">
  memref.store %5, %alloca_5[%c1] : memref<2xi32, "cpu">
  %11 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca_6 = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca_6[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca_6[%c1] : memref<2xindex, "cpu">
  %12 = "disc_ral.dispatch"(%arg0, %11, %alloc_4, %alloca_6) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast_7 = memref.reinterpret_cast %12 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc_4 : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast_7) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After InputInlineFusionPass (disc-input-inline-fusion) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %2 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%2, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.index_cast %dim_0 : index to i32
  %5 = arith.index_cast %dim : index to i32
  %6 = arith.muli %4, %5 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %3, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %6, %alloca[%c1] : memref<2xi32, "cpu">
  %7 = arith.index_cast %6 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %7) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%7) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %8 = arith.muli %dim_1, %7 : index
  %9 = arith.ceildivsi %8, %c256 : index
  %10 = arith.cmpi sgt, %9, %c108 : index
  scf.if %10 {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %13 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        memref.store %cst, %alloc_4[%13] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %13 = arith.addi %arg1, %c128 : index
        %14 = arith.cmpi slt, %13, %dim_1 : index
        %15 = arith.remui %dim_1, %c128 : index
        %16 = arith.cmpi eq, %15, %c0 : index
        %17 = arith.ori %16, %14 : i1
        %18 = arith.addi %arg2, %c2 : index
        %19 = arith.cmpi slt, %18, %7 : index
        %20 = arith.remui %7, %c2 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.andi %17, %22 : i1
        %24:2 = scf.if %23 -> (f32, f32) {
          %28:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %29 = arith.addi %arg1, %arg3 : index
            %30 = "disc_shape.linearize"(%29, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %31:3 = "disc_shape.delinearize"(%30, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %32 = memref.load %reinterpret_cast[%31#0, %31#1, %31#2] : memref<?x?x?xf32, "gpu">
            %33 = math.absf %32 : f32
            %34 = arith.cmpf oge, %arg4, %33 : f32
            %35 = arith.select %34, %arg4, %33 : f32
            %36 = arith.addi %arg2, %c1 : index
            %37 = "disc_shape.linearize"(%29, %36, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %38:3 = "disc_shape.delinearize"(%37, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %39 = memref.load %reinterpret_cast[%38#0, %38#1, %38#2] : memref<?x?x?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg5, %40 : f32
            %42 = arith.select %41, %arg5, %40 : f32
            scf.yield %35, %42 : f32, f32
          }
          scf.yield %28#0, %28#1 : f32, f32
        } else {
          %28:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %29 = arith.addi %arg1, %arg3 : index
            %30 = arith.cmpi slt, %29, %dim_1 : index
            %31 = arith.cmpi slt, %arg2, %7 : index
            %32 = arith.andi %30, %31 : i1
            %33 = scf.if %32 -> (f32) {
              %38 = "disc_shape.linearize"(%29, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %39:3 = "disc_shape.delinearize"(%38, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %40 = memref.load %reinterpret_cast[%39#0, %39#1, %39#2] : memref<?x?x?xf32, "gpu">
              %41 = math.absf %40 : f32
              %42 = arith.cmpf oge, %arg4, %41 : f32
              %43 = arith.select %42, %arg4, %41 : f32
              scf.yield %43 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %34 = arith.addi %arg2, %c1 : index
            %35 = arith.cmpi slt, %34, %7 : index
            %36 = arith.andi %30, %35 : i1
            %37 = scf.if %36 -> (f32) {
              %38 = "disc_shape.linearize"(%29, %34, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %39:3 = "disc_shape.delinearize"(%38, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %40 = memref.load %reinterpret_cast[%39#0, %39#1, %39#2] : memref<?x?x?xf32, "gpu">
              %41 = math.absf %40 : f32
              %42 = arith.cmpf oge, %arg5, %41 : f32
              %43 = arith.select %42, %arg5, %41 : f32
              scf.yield %43 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %33, %37 : f32, f32
          }
          scf.yield %28#0, %28#1 : f32, f32
        }
        %25 = arith.cmpi slt, %arg2, %7 : index
        scf.if %25 {
          %28 = memref.generic_atomic_rmw %alloc_4[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %29 = arith.cmpf ogt, %arg3, %24#0 : f32
            %30 = arith.select %29, %arg3, %24#0 : f32
            memref.atomic_yield %30 : f32
          }
        }
        %26 = arith.addi %arg2, %c1 : index
        %27 = arith.cmpi slt, %26, %7 : index
        scf.if %27 {
          %28 = memref.generic_atomic_rmw %alloc_4[%26] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %29 = arith.cmpf ogt, %arg3, %24#1 : f32
            %30 = arith.select %29, %arg3, %24#1 : f32
            memref.atomic_yield %30 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %13 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        memref.store %cst, %alloc_4[%13] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %13 = arith.addi %arg1, %c128 : index
        %14 = arith.cmpi slt, %13, %dim_1 : index
        %15 = arith.remui %dim_1, %c128 : index
        %16 = arith.cmpi eq, %15, %c0 : index
        %17 = arith.ori %16, %14 : i1
        %18 = arith.addi %arg2, %c2 : index
        %19 = arith.cmpi slt, %18, %7 : index
        %20 = arith.remui %7, %c2 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.andi %17, %22 : i1
        %24:2 = scf.if %23 -> (f32, f32) {
          %28:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %29 = arith.addi %arg1, %arg3 : index
            %30 = "disc_shape.linearize"(%29, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %31:3 = "disc_shape.delinearize"(%30, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %32 = memref.load %reinterpret_cast[%31#0, %31#1, %31#2] : memref<?x?x?xf32, "gpu">
            %33 = math.absf %32 : f32
            %34 = arith.cmpf oge, %arg4, %33 : f32
            %35 = arith.select %34, %arg4, %33 : f32
            %36 = arith.addi %arg2, %c1 : index
            %37 = "disc_shape.linearize"(%29, %36, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %38:3 = "disc_shape.delinearize"(%37, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %39 = memref.load %reinterpret_cast[%38#0, %38#1, %38#2] : memref<?x?x?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg5, %40 : f32
            %42 = arith.select %41, %arg5, %40 : f32
            scf.yield %35, %42 : f32, f32
          }
          scf.yield %28#0, %28#1 : f32, f32
        } else {
          %28:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %29 = arith.addi %arg1, %arg3 : index
            %30 = arith.cmpi slt, %29, %dim_1 : index
            %31 = arith.cmpi slt, %arg2, %7 : index
            %32 = arith.andi %30, %31 : i1
            %33 = scf.if %32 -> (f32) {
              %38 = "disc_shape.linearize"(%29, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %39:3 = "disc_shape.delinearize"(%38, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %40 = memref.load %reinterpret_cast[%39#0, %39#1, %39#2] : memref<?x?x?xf32, "gpu">
              %41 = math.absf %40 : f32
              %42 = arith.cmpf oge, %arg4, %41 : f32
              %43 = arith.select %42, %arg4, %41 : f32
              scf.yield %43 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %34 = arith.addi %arg2, %c1 : index
            %35 = arith.cmpi slt, %34, %7 : index
            %36 = arith.andi %30, %35 : i1
            %37 = scf.if %36 -> (f32) {
              %38 = "disc_shape.linearize"(%29, %34, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %39:3 = "disc_shape.delinearize"(%38, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %40 = memref.load %reinterpret_cast[%39#0, %39#1, %39#2] : memref<?x?x?xf32, "gpu">
              %41 = math.absf %40 : f32
              %42 = arith.cmpf oge, %arg5, %41 : f32
              %43 = arith.select %42, %arg5, %41 : f32
              scf.yield %43 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %33, %37 : f32, f32
          }
          scf.yield %28#0, %28#1 : f32, f32
        }
        %25 = arith.cmpi slt, %arg2, %7 : index
        scf.if %25 {
          %28 = memref.generic_atomic_rmw %alloc_4[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %29 = arith.cmpf ogt, %arg3, %24#0 : f32
            %30 = arith.select %29, %arg3, %24#0 : f32
            memref.atomic_yield %30 : f32
          }
        }
        %26 = arith.addi %arg2, %c1 : index
        %27 = arith.cmpi slt, %26, %7 : index
        scf.if %27 {
          %28 = memref.generic_atomic_rmw %alloc_4[%26] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %29 = arith.cmpf ogt, %arg3, %24#1 : f32
            %30 = arith.select %29, %arg3, %24#1 : f32
            memref.atomic_yield %30 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  memref.dealloc %alloc_3 : memref<?x?xf32, "gpu">
  memref.dealloc %alloc_2 : memref<?x?x?xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %alloca_5 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %4, %alloca_5[%c0] : memref<2xi32, "cpu">
  memref.store %5, %alloca_5[%c1] : memref<2xi32, "cpu">
  %11 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca_6 = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca_6[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca_6[%c1] : memref<2xindex, "cpu">
  %12 = "disc_ral.dispatch"(%arg0, %11, %alloc_4, %alloca_6) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast_7 = memref.reinterpret_cast %12 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc_4 : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast_7) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ArithExpandOps (arith-expand) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %2 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%2, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.index_cast %dim_0 : index to i32
  %5 = arith.index_cast %dim : index to i32
  %6 = arith.muli %4, %5 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %3, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %6, %alloca[%c1] : memref<2xi32, "cpu">
  %7 = arith.index_cast %6 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %7) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%7) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %8 = arith.muli %dim_1, %7 : index
  %c1_5 = arith.constant 1 : index
  %c0_6 = arith.constant 0 : index
  %c-1 = arith.constant -1 : index
  %9 = arith.cmpi sgt, %c256, %c0_6 : index
  %10 = arith.select %9, %c-1, %c1_5 : index
  %11 = arith.addi %10, %8 : index
  %12 = arith.divsi %11, %c256 : index
  %13 = arith.addi %c1_5, %12 : index
  %14 = arith.subi %c0_6, %8 : index
  %15 = arith.divsi %14, %c256 : index
  %16 = arith.subi %c0_6, %15 : index
  %17 = arith.cmpi slt, %8, %c0_6 : index
  %18 = arith.cmpi sgt, %8, %c0_6 : index
  %19 = arith.cmpi slt, %c256, %c0_6 : index
  %20 = arith.cmpi sgt, %c256, %c0_6 : index
  %21 = arith.andi %17, %19 : i1
  %22 = arith.andi %18, %20 : i1
  %23 = arith.ori %21, %22 : i1
  %24 = arith.select %23, %13, %16 : index
  %25 = arith.cmpi sgt, %24, %c108 : index
  scf.if %25 {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %28 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        memref.store %cst, %alloc_4[%28] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %28 = arith.addi %arg1, %c128 : index
        %29 = arith.cmpi slt, %28, %dim_1 : index
        %30 = arith.remui %dim_1, %c128 : index
        %31 = arith.cmpi eq, %30, %c0 : index
        %32 = arith.ori %31, %29 : i1
        %33 = arith.addi %arg2, %c2 : index
        %34 = arith.cmpi slt, %33, %7 : index
        %35 = arith.remui %7, %c2 : index
        %36 = arith.cmpi eq, %35, %c0 : index
        %37 = arith.ori %36, %34 : i1
        %38 = arith.andi %32, %37 : i1
        %39:2 = scf.if %38 -> (f32, f32) {
          %43:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %44 = arith.addi %arg1, %arg3 : index
            %45 = "disc_shape.linearize"(%44, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %46:3 = "disc_shape.delinearize"(%45, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %47 = memref.load %reinterpret_cast[%46#0, %46#1, %46#2] : memref<?x?x?xf32, "gpu">
            %48 = math.absf %47 : f32
            %49 = arith.cmpf oge, %arg4, %48 : f32
            %50 = arith.select %49, %arg4, %48 : f32
            %51 = arith.addi %arg2, %c1 : index
            %52 = "disc_shape.linearize"(%44, %51, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %53:3 = "disc_shape.delinearize"(%52, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %54 = memref.load %reinterpret_cast[%53#0, %53#1, %53#2] : memref<?x?x?xf32, "gpu">
            %55 = math.absf %54 : f32
            %56 = arith.cmpf oge, %arg5, %55 : f32
            %57 = arith.select %56, %arg5, %55 : f32
            scf.yield %50, %57 : f32, f32
          }
          scf.yield %43#0, %43#1 : f32, f32
        } else {
          %43:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %44 = arith.addi %arg1, %arg3 : index
            %45 = arith.cmpi slt, %44, %dim_1 : index
            %46 = arith.cmpi slt, %arg2, %7 : index
            %47 = arith.andi %45, %46 : i1
            %48 = scf.if %47 -> (f32) {
              %53 = "disc_shape.linearize"(%44, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %54:3 = "disc_shape.delinearize"(%53, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %55 = memref.load %reinterpret_cast[%54#0, %54#1, %54#2] : memref<?x?x?xf32, "gpu">
              %56 = math.absf %55 : f32
              %57 = arith.cmpf oge, %arg4, %56 : f32
              %58 = arith.select %57, %arg4, %56 : f32
              scf.yield %58 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %49 = arith.addi %arg2, %c1 : index
            %50 = arith.cmpi slt, %49, %7 : index
            %51 = arith.andi %45, %50 : i1
            %52 = scf.if %51 -> (f32) {
              %53 = "disc_shape.linearize"(%44, %49, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %54:3 = "disc_shape.delinearize"(%53, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %55 = memref.load %reinterpret_cast[%54#0, %54#1, %54#2] : memref<?x?x?xf32, "gpu">
              %56 = math.absf %55 : f32
              %57 = arith.cmpf oge, %arg5, %56 : f32
              %58 = arith.select %57, %arg5, %56 : f32
              scf.yield %58 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %48, %52 : f32, f32
          }
          scf.yield %43#0, %43#1 : f32, f32
        }
        %40 = arith.cmpi slt, %arg2, %7 : index
        scf.if %40 {
          %43 = memref.generic_atomic_rmw %alloc_4[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %44 = arith.cmpf ogt, %arg3, %39#0 : f32
            %45 = arith.select %44, %arg3, %39#0 : f32
            memref.atomic_yield %45 : f32
          }
        }
        %41 = arith.addi %arg2, %c1 : index
        %42 = arith.cmpi slt, %41, %7 : index
        scf.if %42 {
          %43 = memref.generic_atomic_rmw %alloc_4[%41] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %44 = arith.cmpf ogt, %arg3, %39#1 : f32
            %45 = arith.select %44, %arg3, %39#1 : f32
            memref.atomic_yield %45 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %28 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        memref.store %cst, %alloc_4[%28] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %28 = arith.addi %arg1, %c128 : index
        %29 = arith.cmpi slt, %28, %dim_1 : index
        %30 = arith.remui %dim_1, %c128 : index
        %31 = arith.cmpi eq, %30, %c0 : index
        %32 = arith.ori %31, %29 : i1
        %33 = arith.addi %arg2, %c2 : index
        %34 = arith.cmpi slt, %33, %7 : index
        %35 = arith.remui %7, %c2 : index
        %36 = arith.cmpi eq, %35, %c0 : index
        %37 = arith.ori %36, %34 : i1
        %38 = arith.andi %32, %37 : i1
        %39:2 = scf.if %38 -> (f32, f32) {
          %43:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %44 = arith.addi %arg1, %arg3 : index
            %45 = "disc_shape.linearize"(%44, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %46:3 = "disc_shape.delinearize"(%45, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %47 = memref.load %reinterpret_cast[%46#0, %46#1, %46#2] : memref<?x?x?xf32, "gpu">
            %48 = math.absf %47 : f32
            %49 = arith.cmpf oge, %arg4, %48 : f32
            %50 = arith.select %49, %arg4, %48 : f32
            %51 = arith.addi %arg2, %c1 : index
            %52 = "disc_shape.linearize"(%44, %51, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %53:3 = "disc_shape.delinearize"(%52, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %54 = memref.load %reinterpret_cast[%53#0, %53#1, %53#2] : memref<?x?x?xf32, "gpu">
            %55 = math.absf %54 : f32
            %56 = arith.cmpf oge, %arg5, %55 : f32
            %57 = arith.select %56, %arg5, %55 : f32
            scf.yield %50, %57 : f32, f32
          }
          scf.yield %43#0, %43#1 : f32, f32
        } else {
          %43:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %44 = arith.addi %arg1, %arg3 : index
            %45 = arith.cmpi slt, %44, %dim_1 : index
            %46 = arith.cmpi slt, %arg2, %7 : index
            %47 = arith.andi %45, %46 : i1
            %48 = scf.if %47 -> (f32) {
              %53 = "disc_shape.linearize"(%44, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %54:3 = "disc_shape.delinearize"(%53, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %55 = memref.load %reinterpret_cast[%54#0, %54#1, %54#2] : memref<?x?x?xf32, "gpu">
              %56 = math.absf %55 : f32
              %57 = arith.cmpf oge, %arg4, %56 : f32
              %58 = arith.select %57, %arg4, %56 : f32
              scf.yield %58 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %49 = arith.addi %arg2, %c1 : index
            %50 = arith.cmpi slt, %49, %7 : index
            %51 = arith.andi %45, %50 : i1
            %52 = scf.if %51 -> (f32) {
              %53 = "disc_shape.linearize"(%44, %49, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %54:3 = "disc_shape.delinearize"(%53, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %55 = memref.load %reinterpret_cast[%54#0, %54#1, %54#2] : memref<?x?x?xf32, "gpu">
              %56 = math.absf %55 : f32
              %57 = arith.cmpf oge, %arg5, %56 : f32
              %58 = arith.select %57, %arg5, %56 : f32
              scf.yield %58 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %48, %52 : f32, f32
          }
          scf.yield %43#0, %43#1 : f32, f32
        }
        %40 = arith.cmpi slt, %arg2, %7 : index
        scf.if %40 {
          %43 = memref.generic_atomic_rmw %alloc_4[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %44 = arith.cmpf ogt, %arg3, %39#0 : f32
            %45 = arith.select %44, %arg3, %39#0 : f32
            memref.atomic_yield %45 : f32
          }
        }
        %41 = arith.addi %arg2, %c1 : index
        %42 = arith.cmpi slt, %41, %7 : index
        scf.if %42 {
          %43 = memref.generic_atomic_rmw %alloc_4[%41] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %44 = arith.cmpf ogt, %arg3, %39#1 : f32
            %45 = arith.select %44, %arg3, %39#1 : f32
            memref.atomic_yield %45 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  memref.dealloc %alloc_3 : memref<?x?xf32, "gpu">
  memref.dealloc %alloc_2 : memref<?x?x?xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %alloca_7 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %4, %alloca_7[%c0] : memref<2xi32, "cpu">
  memref.store %5, %alloca_7[%c1] : memref<2xi32, "cpu">
  %26 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca_8 = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca_8[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca_8[%c1] : memref<2xindex, "cpu">
  %27 = "disc_ral.dispatch"(%arg0, %26, %alloc_4, %alloca_8) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast_9 = memref.reinterpret_cast %27 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc_4 : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast_9) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After DiscBF16ExpansionPass (disc-bf16-expansion) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %2 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%2, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.index_cast %dim_0 : index to i32
  %5 = arith.index_cast %dim : index to i32
  %6 = arith.muli %4, %5 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %3, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %6, %alloca[%c1] : memref<2xi32, "cpu">
  %7 = arith.index_cast %6 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %7) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%7) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %8 = arith.muli %dim_1, %7 : index
  %9 = arith.addi %8, %c-1 : index
  %10 = arith.divsi %9, %c256 : index
  %11 = arith.addi %10, %c1 : index
  %12 = arith.subi %c0, %8 : index
  %13 = arith.divsi %12, %c256 : index
  %14 = arith.subi %c0, %13 : index
  %15 = arith.cmpi sgt, %8, %c0 : index
  %16 = arith.select %15, %11, %14 : index
  %17 = arith.cmpi sgt, %16, %c108 : index
  scf.if %17 {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %20 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        memref.store %cst, %alloc_4[%20] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %20 = arith.addi %arg1, %c128 : index
        %21 = arith.cmpi slt, %20, %dim_1 : index
        %22 = arith.remui %dim_1, %c128 : index
        %23 = arith.cmpi eq, %22, %c0 : index
        %24 = arith.ori %23, %21 : i1
        %25 = arith.addi %arg2, %c2 : index
        %26 = arith.cmpi slt, %25, %7 : index
        %27 = arith.remui %7, %c2 : index
        %28 = arith.cmpi eq, %27, %c0 : index
        %29 = arith.ori %28, %26 : i1
        %30 = arith.andi %24, %29 : i1
        %31:2 = scf.if %30 -> (f32, f32) {
          %35:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %36 = arith.addi %arg1, %arg3 : index
            %37 = "disc_shape.linearize"(%36, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %38:3 = "disc_shape.delinearize"(%37, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %39 = memref.load %reinterpret_cast[%38#0, %38#1, %38#2] : memref<?x?x?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg4, %40 : f32
            %42 = arith.select %41, %arg4, %40 : f32
            %43 = arith.addi %arg2, %c1 : index
            %44 = "disc_shape.linearize"(%36, %43, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %45:3 = "disc_shape.delinearize"(%44, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %46 = memref.load %reinterpret_cast[%45#0, %45#1, %45#2] : memref<?x?x?xf32, "gpu">
            %47 = math.absf %46 : f32
            %48 = arith.cmpf oge, %arg5, %47 : f32
            %49 = arith.select %48, %arg5, %47 : f32
            scf.yield %42, %49 : f32, f32
          }
          scf.yield %35#0, %35#1 : f32, f32
        } else {
          %35:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %36 = arith.addi %arg1, %arg3 : index
            %37 = arith.cmpi slt, %36, %dim_1 : index
            %38 = arith.cmpi slt, %arg2, %7 : index
            %39 = arith.andi %37, %38 : i1
            %40 = scf.if %39 -> (f32) {
              %45 = "disc_shape.linearize"(%36, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %46:3 = "disc_shape.delinearize"(%45, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %47 = memref.load %reinterpret_cast[%46#0, %46#1, %46#2] : memref<?x?x?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg4, %48 : f32
              %50 = arith.select %49, %arg4, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %41 = arith.addi %arg2, %c1 : index
            %42 = arith.cmpi slt, %41, %7 : index
            %43 = arith.andi %37, %42 : i1
            %44 = scf.if %43 -> (f32) {
              %45 = "disc_shape.linearize"(%36, %41, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %46:3 = "disc_shape.delinearize"(%45, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %47 = memref.load %reinterpret_cast[%46#0, %46#1, %46#2] : memref<?x?x?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg5, %48 : f32
              %50 = arith.select %49, %arg5, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %40, %44 : f32, f32
          }
          scf.yield %35#0, %35#1 : f32, f32
        }
        %32 = arith.cmpi slt, %arg2, %7 : index
        scf.if %32 {
          %35 = memref.generic_atomic_rmw %alloc_4[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %36 = arith.cmpf ogt, %arg3, %31#0 : f32
            %37 = arith.select %36, %arg3, %31#0 : f32
            memref.atomic_yield %37 : f32
          }
        }
        %33 = arith.addi %arg2, %c1 : index
        %34 = arith.cmpi slt, %33, %7 : index
        scf.if %34 {
          %35 = memref.generic_atomic_rmw %alloc_4[%33] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %36 = arith.cmpf ogt, %arg3, %31#1 : f32
            %37 = arith.select %36, %arg3, %31#1 : f32
            memref.atomic_yield %37 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %20 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        memref.store %cst, %alloc_4[%20] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %20 = arith.addi %arg1, %c128 : index
        %21 = arith.cmpi slt, %20, %dim_1 : index
        %22 = arith.remui %dim_1, %c128 : index
        %23 = arith.cmpi eq, %22, %c0 : index
        %24 = arith.ori %23, %21 : i1
        %25 = arith.addi %arg2, %c2 : index
        %26 = arith.cmpi slt, %25, %7 : index
        %27 = arith.remui %7, %c2 : index
        %28 = arith.cmpi eq, %27, %c0 : index
        %29 = arith.ori %28, %26 : i1
        %30 = arith.andi %24, %29 : i1
        %31:2 = scf.if %30 -> (f32, f32) {
          %35:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %36 = arith.addi %arg1, %arg3 : index
            %37 = "disc_shape.linearize"(%36, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %38:3 = "disc_shape.delinearize"(%37, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %39 = memref.load %reinterpret_cast[%38#0, %38#1, %38#2] : memref<?x?x?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg4, %40 : f32
            %42 = arith.select %41, %arg4, %40 : f32
            %43 = arith.addi %arg2, %c1 : index
            %44 = "disc_shape.linearize"(%36, %43, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %45:3 = "disc_shape.delinearize"(%44, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %46 = memref.load %reinterpret_cast[%45#0, %45#1, %45#2] : memref<?x?x?xf32, "gpu">
            %47 = math.absf %46 : f32
            %48 = arith.cmpf oge, %arg5, %47 : f32
            %49 = arith.select %48, %arg5, %47 : f32
            scf.yield %42, %49 : f32, f32
          }
          scf.yield %35#0, %35#1 : f32, f32
        } else {
          %35:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %36 = arith.addi %arg1, %arg3 : index
            %37 = arith.cmpi slt, %36, %dim_1 : index
            %38 = arith.cmpi slt, %arg2, %7 : index
            %39 = arith.andi %37, %38 : i1
            %40 = scf.if %39 -> (f32) {
              %45 = "disc_shape.linearize"(%36, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %46:3 = "disc_shape.delinearize"(%45, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %47 = memref.load %reinterpret_cast[%46#0, %46#1, %46#2] : memref<?x?x?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg4, %48 : f32
              %50 = arith.select %49, %arg4, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %41 = arith.addi %arg2, %c1 : index
            %42 = arith.cmpi slt, %41, %7 : index
            %43 = arith.andi %37, %42 : i1
            %44 = scf.if %43 -> (f32) {
              %45 = "disc_shape.linearize"(%36, %41, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %46:3 = "disc_shape.delinearize"(%45, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %47 = memref.load %reinterpret_cast[%46#0, %46#1, %46#2] : memref<?x?x?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg5, %48 : f32
              %50 = arith.select %49, %arg5, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %40, %44 : f32, f32
          }
          scf.yield %35#0, %35#1 : f32, f32
        }
        %32 = arith.cmpi slt, %arg2, %7 : index
        scf.if %32 {
          %35 = memref.generic_atomic_rmw %alloc_4[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %36 = arith.cmpf ogt, %arg3, %31#0 : f32
            %37 = arith.select %36, %arg3, %31#0 : f32
            memref.atomic_yield %37 : f32
          }
        }
        %33 = arith.addi %arg2, %c1 : index
        %34 = arith.cmpi slt, %33, %7 : index
        scf.if %34 {
          %35 = memref.generic_atomic_rmw %alloc_4[%33] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %36 = arith.cmpf ogt, %arg3, %31#1 : f32
            %37 = arith.select %36, %arg3, %31#1 : f32
            memref.atomic_yield %37 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  memref.dealloc %alloc_3 : memref<?x?xf32, "gpu">
  memref.dealloc %alloc_2 : memref<?x?x?xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %alloca_5 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %4, %alloca_5[%c0] : memref<2xi32, "cpu">
  memref.store %5, %alloca_5[%c1] : memref<2xi32, "cpu">
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca_6 = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca_6[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca_6[%c1] : memref<2xindex, "cpu">
  %19 = "disc_ral.dispatch"(%arg0, %18, %alloc_4, %alloca_6) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast_7 = memref.reinterpret_cast %19 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc_4 : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast_7) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After DiscFlattenMemrefAccessPass (disc-flatten-memref-access) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %2 = arith.muli %dim, %dim_0 : index
  %reinterpret_cast = memref.reinterpret_cast %1 to offset: [0], sizes: [%dim_1, %dim_0, %dim], strides: [%2, %dim, 1] {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu"> to memref<?x?x?xf32, "gpu">
  %alloc_2 = memref.alloc(%dim_1, %dim_0, %dim) {kDiscSymbolicDimAttr = [@S0, @S1, @S2]} : memref<?x?x?xf32, "gpu">
  %3 = arith.index_cast %dim_1 : index to i32
  %4 = arith.index_cast %dim_0 : index to i32
  %5 = arith.index_cast %dim : index to i32
  %6 = arith.muli %4, %5 : i32
  %alloca = memref.alloca() : memref<2xi32, "cpu">
  memref.store %3, %alloca[%c0] : memref<2xi32, "cpu">
  memref.store %6, %alloca[%c1] : memref<2xi32, "cpu">
  %7 = arith.index_cast %6 : i32 to index
  %alloc_3 = memref.alloc(%dim_1, %7) {kDiscSymbolicDimAttr = [@S0, @S3]} : memref<?x?xf32, "gpu">
  %alloc_4 = memref.alloc(%7) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %8 = arith.muli %dim_1, %7 : index
  %9 = arith.addi %8, %c-1 : index
  %10 = arith.divsi %9, %c256 : index
  %11 = arith.addi %10, %c1 : index
  %12 = arith.subi %c0, %8 : index
  %13 = arith.divsi %12, %c256 : index
  %14 = arith.subi %c0, %13 : index
  %15 = arith.cmpi sgt, %8, %c0 : index
  %16 = arith.select %15, %11, %14 : index
  %17 = arith.cmpi sgt, %16, %c108 : index
  scf.if %17 {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %20 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        %c0_8 = arith.constant 0 : index
        %dim_9 = memref.dim %alloc_4, %c0_8 : memref<?xf32, "gpu">
        %21 = "disc_shape.linearize"(%20, %dim_9) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_10 = arith.constant 1 : index
        %c0_11 = arith.constant 0 : index
        %dim_12 = memref.dim %alloc_4, %c0_11 : memref<?xf32, "gpu">
        %22 = arith.muli %c1_10, %dim_12 : index
        %c1_13 = arith.constant 1 : index
        %c0_14 = arith.constant 0 : index
        %reinterpret_cast_15 = memref.reinterpret_cast %alloc_4 to offset: [%c0_14], sizes: [%22], strides: [%c1_13] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_15[%21] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %20 = arith.addi %arg1, %c128 : index
        %21 = arith.cmpi slt, %20, %dim_1 : index
        %22 = arith.remui %dim_1, %c128 : index
        %23 = arith.cmpi eq, %22, %c0 : index
        %24 = arith.ori %23, %21 : i1
        %25 = arith.addi %arg2, %c2 : index
        %26 = arith.cmpi slt, %25, %7 : index
        %27 = arith.remui %7, %c2 : index
        %28 = arith.cmpi eq, %27, %c0 : index
        %29 = arith.ori %28, %26 : i1
        %30 = arith.andi %24, %29 : i1
        %31:2 = scf.if %30 -> (f32, f32) {
          %35:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %36 = arith.addi %arg1, %arg3 : index
            %37 = "disc_shape.linearize"(%36, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %38:3 = "disc_shape.delinearize"(%37, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %c0_8 = arith.constant 0 : index
            %dim_9 = memref.dim %reinterpret_cast, %c0_8 : memref<?x?x?xf32, "gpu">
            %c1_10 = arith.constant 1 : index
            %dim_11 = memref.dim %reinterpret_cast, %c1_10 : memref<?x?x?xf32, "gpu">
            %c2_12 = arith.constant 2 : index
            %dim_13 = memref.dim %reinterpret_cast, %c2_12 : memref<?x?x?xf32, "gpu">
            %39 = "disc_shape.linearize"(%38#0, %38#1, %38#2, %dim_9, %dim_11, %dim_13) {operand_segment_sizes = array<i32: 3, 3>} : (index, index, index, index, index, index) -> index
            %c1_14 = arith.constant 1 : index
            %c0_15 = arith.constant 0 : index
            %dim_16 = memref.dim %reinterpret_cast, %c0_15 : memref<?x?x?xf32, "gpu">
            %40 = arith.muli %c1_14, %dim_16 : index
            %c1_17 = arith.constant 1 : index
            %dim_18 = memref.dim %reinterpret_cast, %c1_17 : memref<?x?x?xf32, "gpu">
            %41 = arith.muli %40, %dim_18 : index
            %c2_19 = arith.constant 2 : index
            %dim_20 = memref.dim %reinterpret_cast, %c2_19 : memref<?x?x?xf32, "gpu">
            %42 = arith.muli %41, %dim_20 : index
            %c1_21 = arith.constant 1 : index
            %c0_22 = arith.constant 0 : index
            %reinterpret_cast_23 = memref.reinterpret_cast %reinterpret_cast to offset: [%c0_22], sizes: [%42], strides: [%c1_21] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %43 = memref.load %reinterpret_cast_23[%39] : memref<?xf32, "gpu">
            %44 = math.absf %43 : f32
            %45 = arith.cmpf oge, %arg4, %44 : f32
            %46 = arith.select %45, %arg4, %44 : f32
            %47 = arith.addi %arg2, %c1 : index
            %48 = "disc_shape.linearize"(%36, %47, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %49:3 = "disc_shape.delinearize"(%48, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %c0_24 = arith.constant 0 : index
            %dim_25 = memref.dim %reinterpret_cast, %c0_24 : memref<?x?x?xf32, "gpu">
            %c1_26 = arith.constant 1 : index
            %dim_27 = memref.dim %reinterpret_cast, %c1_26 : memref<?x?x?xf32, "gpu">
            %c2_28 = arith.constant 2 : index
            %dim_29 = memref.dim %reinterpret_cast, %c2_28 : memref<?x?x?xf32, "gpu">
            %50 = "disc_shape.linearize"(%49#0, %49#1, %49#2, %dim_25, %dim_27, %dim_29) {operand_segment_sizes = array<i32: 3, 3>} : (index, index, index, index, index, index) -> index
            %c1_30 = arith.constant 1 : index
            %c0_31 = arith.constant 0 : index
            %dim_32 = memref.dim %reinterpret_cast, %c0_31 : memref<?x?x?xf32, "gpu">
            %51 = arith.muli %c1_30, %dim_32 : index
            %c1_33 = arith.constant 1 : index
            %dim_34 = memref.dim %reinterpret_cast, %c1_33 : memref<?x?x?xf32, "gpu">
            %52 = arith.muli %51, %dim_34 : index
            %c2_35 = arith.constant 2 : index
            %dim_36 = memref.dim %reinterpret_cast, %c2_35 : memref<?x?x?xf32, "gpu">
            %53 = arith.muli %52, %dim_36 : index
            %c1_37 = arith.constant 1 : index
            %c0_38 = arith.constant 0 : index
            %reinterpret_cast_39 = memref.reinterpret_cast %reinterpret_cast to offset: [%c0_38], sizes: [%53], strides: [%c1_37] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %54 = memref.load %reinterpret_cast_39[%50] : memref<?xf32, "gpu">
            %55 = math.absf %54 : f32
            %56 = arith.cmpf oge, %arg5, %55 : f32
            %57 = arith.select %56, %arg5, %55 : f32
            scf.yield %46, %57 : f32, f32
          }
          scf.yield %35#0, %35#1 : f32, f32
        } else {
          %35:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %36 = arith.addi %arg1, %arg3 : index
            %37 = arith.cmpi slt, %36, %dim_1 : index
            %38 = arith.cmpi slt, %arg2, %7 : index
            %39 = arith.andi %37, %38 : i1
            %40 = scf.if %39 -> (f32) {
              %45 = "disc_shape.linearize"(%36, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %46:3 = "disc_shape.delinearize"(%45, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %c0_8 = arith.constant 0 : index
              %dim_9 = memref.dim %reinterpret_cast, %c0_8 : memref<?x?x?xf32, "gpu">
              %c1_10 = arith.constant 1 : index
              %dim_11 = memref.dim %reinterpret_cast, %c1_10 : memref<?x?x?xf32, "gpu">
              %c2_12 = arith.constant 2 : index
              %dim_13 = memref.dim %reinterpret_cast, %c2_12 : memref<?x?x?xf32, "gpu">
              %47 = "disc_shape.linearize"(%46#0, %46#1, %46#2, %dim_9, %dim_11, %dim_13) {operand_segment_sizes = array<i32: 3, 3>} : (index, index, index, index, index, index) -> index
              %c1_14 = arith.constant 1 : index
              %c0_15 = arith.constant 0 : index
              %dim_16 = memref.dim %reinterpret_cast, %c0_15 : memref<?x?x?xf32, "gpu">
              %48 = arith.muli %c1_14, %dim_16 : index
              %c1_17 = arith.constant 1 : index
              %dim_18 = memref.dim %reinterpret_cast, %c1_17 : memref<?x?x?xf32, "gpu">
              %49 = arith.muli %48, %dim_18 : index
              %c2_19 = arith.constant 2 : index
              %dim_20 = memref.dim %reinterpret_cast, %c2_19 : memref<?x?x?xf32, "gpu">
              %50 = arith.muli %49, %dim_20 : index
              %c1_21 = arith.constant 1 : index
              %c0_22 = arith.constant 0 : index
              %reinterpret_cast_23 = memref.reinterpret_cast %reinterpret_cast to offset: [%c0_22], sizes: [%50], strides: [%c1_21] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %51 = memref.load %reinterpret_cast_23[%47] : memref<?xf32, "gpu">
              %52 = math.absf %51 : f32
              %53 = arith.cmpf oge, %arg4, %52 : f32
              %54 = arith.select %53, %arg4, %52 : f32
              scf.yield %54 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %41 = arith.addi %arg2, %c1 : index
            %42 = arith.cmpi slt, %41, %7 : index
            %43 = arith.andi %37, %42 : i1
            %44 = scf.if %43 -> (f32) {
              %45 = "disc_shape.linearize"(%36, %41, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %46:3 = "disc_shape.delinearize"(%45, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %c0_8 = arith.constant 0 : index
              %dim_9 = memref.dim %reinterpret_cast, %c0_8 : memref<?x?x?xf32, "gpu">
              %c1_10 = arith.constant 1 : index
              %dim_11 = memref.dim %reinterpret_cast, %c1_10 : memref<?x?x?xf32, "gpu">
              %c2_12 = arith.constant 2 : index
              %dim_13 = memref.dim %reinterpret_cast, %c2_12 : memref<?x?x?xf32, "gpu">
              %47 = "disc_shape.linearize"(%46#0, %46#1, %46#2, %dim_9, %dim_11, %dim_13) {operand_segment_sizes = array<i32: 3, 3>} : (index, index, index, index, index, index) -> index
              %c1_14 = arith.constant 1 : index
              %c0_15 = arith.constant 0 : index
              %dim_16 = memref.dim %reinterpret_cast, %c0_15 : memref<?x?x?xf32, "gpu">
              %48 = arith.muli %c1_14, %dim_16 : index
              %c1_17 = arith.constant 1 : index
              %dim_18 = memref.dim %reinterpret_cast, %c1_17 : memref<?x?x?xf32, "gpu">
              %49 = arith.muli %48, %dim_18 : index
              %c2_19 = arith.constant 2 : index
              %dim_20 = memref.dim %reinterpret_cast, %c2_19 : memref<?x?x?xf32, "gpu">
              %50 = arith.muli %49, %dim_20 : index
              %c1_21 = arith.constant 1 : index
              %c0_22 = arith.constant 0 : index
              %reinterpret_cast_23 = memref.reinterpret_cast %reinterpret_cast to offset: [%c0_22], sizes: [%50], strides: [%c1_21] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %51 = memref.load %reinterpret_cast_23[%47] : memref<?xf32, "gpu">
              %52 = math.absf %51 : f32
              %53 = arith.cmpf oge, %arg5, %52 : f32
              %54 = arith.select %53, %arg5, %52 : f32
              scf.yield %54 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %40, %44 : f32, f32
          }
          scf.yield %35#0, %35#1 : f32, f32
        }
        %32 = arith.cmpi slt, %arg2, %7 : index
        scf.if %32 {
          %35 = memref.generic_atomic_rmw %alloc_4[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %36 = arith.cmpf ogt, %arg3, %31#0 : f32
            %37 = arith.select %36, %arg3, %31#0 : f32
            memref.atomic_yield %37 : f32
          }
        }
        %33 = arith.addi %arg2, %c1 : index
        %34 = arith.cmpi slt, %33, %7 : index
        scf.if %34 {
          %35 = memref.generic_atomic_rmw %alloc_4[%33] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %36 = arith.cmpf ogt, %arg3, %31#1 : f32
            %37 = arith.select %36, %arg3, %31#1 : f32
            memref.atomic_yield %37 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%7) step (%c1) {
        %20 = "disc_shape.delinearize"(%arg1, %7) : (index, index) -> index
        %c0_8 = arith.constant 0 : index
        %dim_9 = memref.dim %alloc_4, %c0_8 : memref<?xf32, "gpu">
        %21 = "disc_shape.linearize"(%20, %dim_9) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
        %c1_10 = arith.constant 1 : index
        %c0_11 = arith.constant 0 : index
        %dim_12 = memref.dim %alloc_4, %c0_11 : memref<?xf32, "gpu">
        %22 = arith.muli %c1_10, %dim_12 : index
        %c1_13 = arith.constant 1 : index
        %c0_14 = arith.constant 0 : index
        %reinterpret_cast_15 = memref.reinterpret_cast %alloc_4 to offset: [%c0_14], sizes: [%22], strides: [%c1_13] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_15[%21] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %7) step (%c128, %c2) {
        %20 = arith.addi %arg1, %c128 : index
        %21 = arith.cmpi slt, %20, %dim_1 : index
        %22 = arith.remui %dim_1, %c128 : index
        %23 = arith.cmpi eq, %22, %c0 : index
        %24 = arith.ori %23, %21 : i1
        %25 = arith.addi %arg2, %c2 : index
        %26 = arith.cmpi slt, %25, %7 : index
        %27 = arith.remui %7, %c2 : index
        %28 = arith.cmpi eq, %27, %c0 : index
        %29 = arith.ori %28, %26 : i1
        %30 = arith.andi %24, %29 : i1
        %31:2 = scf.if %30 -> (f32, f32) {
          %35:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %36 = arith.addi %arg1, %arg3 : index
            %37 = "disc_shape.linearize"(%36, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %38:3 = "disc_shape.delinearize"(%37, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %c0_8 = arith.constant 0 : index
            %dim_9 = memref.dim %reinterpret_cast, %c0_8 : memref<?x?x?xf32, "gpu">
            %c1_10 = arith.constant 1 : index
            %dim_11 = memref.dim %reinterpret_cast, %c1_10 : memref<?x?x?xf32, "gpu">
            %c2_12 = arith.constant 2 : index
            %dim_13 = memref.dim %reinterpret_cast, %c2_12 : memref<?x?x?xf32, "gpu">
            %39 = "disc_shape.linearize"(%38#0, %38#1, %38#2, %dim_9, %dim_11, %dim_13) {operand_segment_sizes = array<i32: 3, 3>} : (index, index, index, index, index, index) -> index
            %c1_14 = arith.constant 1 : index
            %c0_15 = arith.constant 0 : index
            %dim_16 = memref.dim %reinterpret_cast, %c0_15 : memref<?x?x?xf32, "gpu">
            %40 = arith.muli %c1_14, %dim_16 : index
            %c1_17 = arith.constant 1 : index
            %dim_18 = memref.dim %reinterpret_cast, %c1_17 : memref<?x?x?xf32, "gpu">
            %41 = arith.muli %40, %dim_18 : index
            %c2_19 = arith.constant 2 : index
            %dim_20 = memref.dim %reinterpret_cast, %c2_19 : memref<?x?x?xf32, "gpu">
            %42 = arith.muli %41, %dim_20 : index
            %c1_21 = arith.constant 1 : index
            %c0_22 = arith.constant 0 : index
            %reinterpret_cast_23 = memref.reinterpret_cast %reinterpret_cast to offset: [%c0_22], sizes: [%42], strides: [%c1_21] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %43 = memref.load %reinterpret_cast_23[%39] : memref<?xf32, "gpu">
            %44 = math.absf %43 : f32
            %45 = arith.cmpf oge, %arg4, %44 : f32
            %46 = arith.select %45, %arg4, %44 : f32
            %47 = arith.addi %arg2, %c1 : index
            %48 = "disc_shape.linearize"(%36, %47, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %49:3 = "disc_shape.delinearize"(%48, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
            %c0_24 = arith.constant 0 : index
            %dim_25 = memref.dim %reinterpret_cast, %c0_24 : memref<?x?x?xf32, "gpu">
            %c1_26 = arith.constant 1 : index
            %dim_27 = memref.dim %reinterpret_cast, %c1_26 : memref<?x?x?xf32, "gpu">
            %c2_28 = arith.constant 2 : index
            %dim_29 = memref.dim %reinterpret_cast, %c2_28 : memref<?x?x?xf32, "gpu">
            %50 = "disc_shape.linearize"(%49#0, %49#1, %49#2, %dim_25, %dim_27, %dim_29) {operand_segment_sizes = array<i32: 3, 3>} : (index, index, index, index, index, index) -> index
            %c1_30 = arith.constant 1 : index
            %c0_31 = arith.constant 0 : index
            %dim_32 = memref.dim %reinterpret_cast, %c0_31 : memref<?x?x?xf32, "gpu">
            %51 = arith.muli %c1_30, %dim_32 : index
            %c1_33 = arith.constant 1 : index
            %dim_34 = memref.dim %reinterpret_cast, %c1_33 : memref<?x?x?xf32, "gpu">
            %52 = arith.muli %51, %dim_34 : index
            %c2_35 = arith.constant 2 : index
            %dim_36 = memref.dim %reinterpret_cast, %c2_35 : memref<?x?x?xf32, "gpu">
            %53 = arith.muli %52, %dim_36 : index
            %c1_37 = arith.constant 1 : index
            %c0_38 = arith.constant 0 : index
            %reinterpret_cast_39 = memref.reinterpret_cast %reinterpret_cast to offset: [%c0_38], sizes: [%53], strides: [%c1_37] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %54 = memref.load %reinterpret_cast_39[%50] : memref<?xf32, "gpu">
            %55 = math.absf %54 : f32
            %56 = arith.cmpf oge, %arg5, %55 : f32
            %57 = arith.select %56, %arg5, %55 : f32
            scf.yield %46, %57 : f32, f32
          }
          scf.yield %35#0, %35#1 : f32, f32
        } else {
          %35:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %36 = arith.addi %arg1, %arg3 : index
            %37 = arith.cmpi slt, %36, %dim_1 : index
            %38 = arith.cmpi slt, %arg2, %7 : index
            %39 = arith.andi %37, %38 : i1
            %40 = scf.if %39 -> (f32) {
              %45 = "disc_shape.linearize"(%36, %arg2, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %46:3 = "disc_shape.delinearize"(%45, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %c0_8 = arith.constant 0 : index
              %dim_9 = memref.dim %reinterpret_cast, %c0_8 : memref<?x?x?xf32, "gpu">
              %c1_10 = arith.constant 1 : index
              %dim_11 = memref.dim %reinterpret_cast, %c1_10 : memref<?x?x?xf32, "gpu">
              %c2_12 = arith.constant 2 : index
              %dim_13 = memref.dim %reinterpret_cast, %c2_12 : memref<?x?x?xf32, "gpu">
              %47 = "disc_shape.linearize"(%46#0, %46#1, %46#2, %dim_9, %dim_11, %dim_13) {operand_segment_sizes = array<i32: 3, 3>} : (index, index, index, index, index, index) -> index
              %c1_14 = arith.constant 1 : index
              %c0_15 = arith.constant 0 : index
              %dim_16 = memref.dim %reinterpret_cast, %c0_15 : memref<?x?x?xf32, "gpu">
              %48 = arith.muli %c1_14, %dim_16 : index
              %c1_17 = arith.constant 1 : index
              %dim_18 = memref.dim %reinterpret_cast, %c1_17 : memref<?x?x?xf32, "gpu">
              %49 = arith.muli %48, %dim_18 : index
              %c2_19 = arith.constant 2 : index
              %dim_20 = memref.dim %reinterpret_cast, %c2_19 : memref<?x?x?xf32, "gpu">
              %50 = arith.muli %49, %dim_20 : index
              %c1_21 = arith.constant 1 : index
              %c0_22 = arith.constant 0 : index
              %reinterpret_cast_23 = memref.reinterpret_cast %reinterpret_cast to offset: [%c0_22], sizes: [%50], strides: [%c1_21] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %51 = memref.load %reinterpret_cast_23[%47] : memref<?xf32, "gpu">
              %52 = math.absf %51 : f32
              %53 = arith.cmpf oge, %arg4, %52 : f32
              %54 = arith.select %53, %arg4, %52 : f32
              scf.yield %54 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %41 = arith.addi %arg2, %c1 : index
            %42 = arith.cmpi slt, %41, %7 : index
            %43 = arith.andi %37, %42 : i1
            %44 = scf.if %43 -> (f32) {
              %45 = "disc_shape.linearize"(%36, %41, %dim_1, %7) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %46:3 = "disc_shape.delinearize"(%45, %dim_1, %dim_0, %dim) : (index, index, index, index) -> (index, index, index)
              %c0_8 = arith.constant 0 : index
              %dim_9 = memref.dim %reinterpret_cast, %c0_8 : memref<?x?x?xf32, "gpu">
              %c1_10 = arith.constant 1 : index
              %dim_11 = memref.dim %reinterpret_cast, %c1_10 : memref<?x?x?xf32, "gpu">
              %c2_12 = arith.constant 2 : index
              %dim_13 = memref.dim %reinterpret_cast, %c2_12 : memref<?x?x?xf32, "gpu">
              %47 = "disc_shape.linearize"(%46#0, %46#1, %46#2, %dim_9, %dim_11, %dim_13) {operand_segment_sizes = array<i32: 3, 3>} : (index, index, index, index, index, index) -> index
              %c1_14 = arith.constant 1 : index
              %c0_15 = arith.constant 0 : index
              %dim_16 = memref.dim %reinterpret_cast, %c0_15 : memref<?x?x?xf32, "gpu">
              %48 = arith.muli %c1_14, %dim_16 : index
              %c1_17 = arith.constant 1 : index
              %dim_18 = memref.dim %reinterpret_cast, %c1_17 : memref<?x?x?xf32, "gpu">
              %49 = arith.muli %48, %dim_18 : index
              %c2_19 = arith.constant 2 : index
              %dim_20 = memref.dim %reinterpret_cast, %c2_19 : memref<?x?x?xf32, "gpu">
              %50 = arith.muli %49, %dim_20 : index
              %c1_21 = arith.constant 1 : index
              %c0_22 = arith.constant 0 : index
              %reinterpret_cast_23 = memref.reinterpret_cast %reinterpret_cast to offset: [%c0_22], sizes: [%50], strides: [%c1_21] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %51 = memref.load %reinterpret_cast_23[%47] : memref<?xf32, "gpu">
              %52 = math.absf %51 : f32
              %53 = arith.cmpf oge, %arg5, %52 : f32
              %54 = arith.select %53, %arg5, %52 : f32
              scf.yield %54 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %40, %44 : f32, f32
          }
          scf.yield %35#0, %35#1 : f32, f32
        }
        %32 = arith.cmpi slt, %arg2, %7 : index
        scf.if %32 {
          %35 = memref.generic_atomic_rmw %alloc_4[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %36 = arith.cmpf ogt, %arg3, %31#0 : f32
            %37 = arith.select %36, %arg3, %31#0 : f32
            memref.atomic_yield %37 : f32
          }
        }
        %33 = arith.addi %arg2, %c1 : index
        %34 = arith.cmpi slt, %33, %7 : index
        scf.if %34 {
          %35 = memref.generic_atomic_rmw %alloc_4[%33] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %36 = arith.cmpf ogt, %arg3, %31#1 : f32
            %37 = arith.select %36, %arg3, %31#1 : f32
            memref.atomic_yield %37 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  memref.dealloc %alloc_3 : memref<?x?xf32, "gpu">
  memref.dealloc %alloc_2 : memref<?x?x?xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %alloca_5 = memref.alloca() : memref<2xi32, "cpu">
  memref.store %4, %alloca_5[%c0] : memref<2xi32, "cpu">
  memref.store %5, %alloca_5[%c1] : memref<2xi32, "cpu">
  %18 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca_6 = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca_6[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca_6[%c1] : memref<2xindex, "cpu">
  %19 = "disc_ral.dispatch"(%arg0, %18, %alloc_4, %alloca_6) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast_7 = memref.reinterpret_cast %19 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc_4 : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast_7) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After Canonicalizer (disc-canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_2[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %5) step (%c128, %c2) {
        %18 = arith.addi %arg1, %c128 : index
        %19 = arith.cmpi slt, %18, %dim_1 : index
        %20 = arith.remui %dim_1, %c128 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.addi %arg2, %c2 : index
        %24 = arith.cmpi slt, %23, %5 : index
        %25 = arith.remui %5, %c2 : index
        %26 = arith.cmpi eq, %25, %c0 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.andi %22, %27 : i1
        %29:2 = scf.if %28 -> (f32, f32) {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = "disc_shape.linearize"(%34, %arg2, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %36 = arith.muli %dim_1, %dim_0 : index
            %37 = arith.muli %36, %dim : index
            %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%37], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %38 = memref.load %reinterpret_cast_2[%35] : memref<?xf32, "gpu">
            %39 = math.absf %38 : f32
            %40 = arith.cmpf oge, %arg4, %39 : f32
            %41 = arith.select %40, %arg4, %39 : f32
            %42 = arith.addi %arg2, %c1 : index
            %43 = "disc_shape.linearize"(%34, %42, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %44 = arith.muli %dim_1, %dim_0 : index
            %45 = arith.muli %44, %dim : index
            %reinterpret_cast_3 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%45], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %46 = memref.load %reinterpret_cast_3[%43] : memref<?xf32, "gpu">
            %47 = math.absf %46 : f32
            %48 = arith.cmpf oge, %arg5, %47 : f32
            %49 = arith.select %48, %arg5, %47 : f32
            scf.yield %41, %49 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        } else {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.cmpi slt, %34, %dim_1 : index
            %36 = arith.cmpi slt, %arg2, %5 : index
            %37 = arith.andi %35, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %43 = "disc_shape.linearize"(%34, %arg2, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %44 = arith.muli %dim_1, %dim_0 : index
              %45 = arith.muli %44, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%45], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %46 = memref.load %reinterpret_cast_2[%43] : memref<?xf32, "gpu">
              %47 = math.absf %46 : f32
              %48 = arith.cmpf oge, %arg4, %47 : f32
              %49 = arith.select %48, %arg4, %47 : f32
              scf.yield %49 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %39 = arith.addi %arg2, %c1 : index
            %40 = arith.cmpi slt, %39, %5 : index
            %41 = arith.andi %35, %40 : i1
            %42 = scf.if %41 -> (f32) {
              %43 = "disc_shape.linearize"(%34, %39, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %44 = arith.muli %dim_1, %dim_0 : index
              %45 = arith.muli %44, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%45], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %46 = memref.load %reinterpret_cast_2[%43] : memref<?xf32, "gpu">
              %47 = math.absf %46 : f32
              %48 = arith.cmpf oge, %arg5, %47 : f32
              %49 = arith.select %48, %arg5, %47 : f32
              scf.yield %49 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %38, %42 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        }
        %30 = arith.cmpi slt, %arg2, %5 : index
        scf.if %30 {
          %33 = memref.generic_atomic_rmw %alloc[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#0 : f32
            %35 = arith.select %34, %arg3, %29#0 : f32
            memref.atomic_yield %35 : f32
          }
        }
        %31 = arith.addi %arg2, %c1 : index
        %32 = arith.cmpi slt, %31, %5 : index
        scf.if %32 {
          %33 = memref.generic_atomic_rmw %alloc[%31] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#1 : f32
            %35 = arith.select %34, %arg3, %29#1 : f32
            memref.atomic_yield %35 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_2[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %5) step (%c128, %c2) {
        %18 = arith.addi %arg1, %c128 : index
        %19 = arith.cmpi slt, %18, %dim_1 : index
        %20 = arith.remui %dim_1, %c128 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.addi %arg2, %c2 : index
        %24 = arith.cmpi slt, %23, %5 : index
        %25 = arith.remui %5, %c2 : index
        %26 = arith.cmpi eq, %25, %c0 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.andi %22, %27 : i1
        %29:2 = scf.if %28 -> (f32, f32) {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = "disc_shape.linearize"(%34, %arg2, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %36 = arith.muli %dim_1, %dim_0 : index
            %37 = arith.muli %36, %dim : index
            %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%37], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %38 = memref.load %reinterpret_cast_2[%35] : memref<?xf32, "gpu">
            %39 = math.absf %38 : f32
            %40 = arith.cmpf oge, %arg4, %39 : f32
            %41 = arith.select %40, %arg4, %39 : f32
            %42 = arith.addi %arg2, %c1 : index
            %43 = "disc_shape.linearize"(%34, %42, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %44 = arith.muli %dim_1, %dim_0 : index
            %45 = arith.muli %44, %dim : index
            %reinterpret_cast_3 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%45], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %46 = memref.load %reinterpret_cast_3[%43] : memref<?xf32, "gpu">
            %47 = math.absf %46 : f32
            %48 = arith.cmpf oge, %arg5, %47 : f32
            %49 = arith.select %48, %arg5, %47 : f32
            scf.yield %41, %49 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        } else {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.cmpi slt, %34, %dim_1 : index
            %36 = arith.cmpi slt, %arg2, %5 : index
            %37 = arith.andi %35, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %43 = "disc_shape.linearize"(%34, %arg2, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %44 = arith.muli %dim_1, %dim_0 : index
              %45 = arith.muli %44, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%45], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %46 = memref.load %reinterpret_cast_2[%43] : memref<?xf32, "gpu">
              %47 = math.absf %46 : f32
              %48 = arith.cmpf oge, %arg4, %47 : f32
              %49 = arith.select %48, %arg4, %47 : f32
              scf.yield %49 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %39 = arith.addi %arg2, %c1 : index
            %40 = arith.cmpi slt, %39, %5 : index
            %41 = arith.andi %35, %40 : i1
            %42 = scf.if %41 -> (f32) {
              %43 = "disc_shape.linearize"(%34, %39, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %44 = arith.muli %dim_1, %dim_0 : index
              %45 = arith.muli %44, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%45], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %46 = memref.load %reinterpret_cast_2[%43] : memref<?xf32, "gpu">
              %47 = math.absf %46 : f32
              %48 = arith.cmpf oge, %arg5, %47 : f32
              %49 = arith.select %48, %arg5, %47 : f32
              scf.yield %49 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %38, %42 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        }
        %30 = arith.cmpi slt, %arg2, %5 : index
        scf.if %30 {
          %33 = memref.generic_atomic_rmw %alloc[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#0 : f32
            %35 = arith.select %34, %arg3, %29#0 : f32
            memref.atomic_yield %35 : f32
          }
        }
        %31 = arith.addi %arg2, %c1 : index
        %32 = arith.cmpi slt, %31, %5 : index
        scf.if %32 {
          %33 = memref.generic_atomic_rmw %alloc[%31] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#1 : f32
            %35 = arith.select %34, %arg3, %29#1 : f32
            memref.atomic_yield %35 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_2[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %5) step (%c128, %c2) {
        %18 = arith.addi %arg1, %c128 : index
        %19 = arith.cmpi slt, %18, %dim_1 : index
        %20 = arith.remui %dim_1, %c128 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.addi %arg2, %c2 : index
        %24 = arith.cmpi slt, %23, %5 : index
        %25 = arith.remui %5, %c2 : index
        %26 = arith.cmpi eq, %25, %c0 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.andi %22, %27 : i1
        %29:2 = scf.if %28 -> (f32, f32) {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = "disc_shape.linearize"(%34, %arg2, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %36 = arith.muli %dim_1, %dim_0 : index
            %37 = arith.muli %36, %dim : index
            %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%37], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %38 = memref.load %reinterpret_cast_2[%35] : memref<?xf32, "gpu">
            %39 = math.absf %38 : f32
            %40 = arith.cmpf oge, %arg4, %39 : f32
            %41 = arith.select %40, %arg4, %39 : f32
            %42 = arith.addi %arg2, %c1 : index
            %43 = "disc_shape.linearize"(%34, %42, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %44 = memref.load %reinterpret_cast_2[%43] : memref<?xf32, "gpu">
            %45 = math.absf %44 : f32
            %46 = arith.cmpf oge, %arg5, %45 : f32
            %47 = arith.select %46, %arg5, %45 : f32
            scf.yield %41, %47 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        } else {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.cmpi slt, %34, %dim_1 : index
            %36 = arith.cmpi slt, %arg2, %5 : index
            %37 = arith.andi %35, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %43 = "disc_shape.linearize"(%34, %arg2, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %44 = arith.muli %dim_1, %dim_0 : index
              %45 = arith.muli %44, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%45], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %46 = memref.load %reinterpret_cast_2[%43] : memref<?xf32, "gpu">
              %47 = math.absf %46 : f32
              %48 = arith.cmpf oge, %arg4, %47 : f32
              %49 = arith.select %48, %arg4, %47 : f32
              scf.yield %49 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %39 = arith.addi %arg2, %c1 : index
            %40 = arith.cmpi slt, %39, %5 : index
            %41 = arith.andi %35, %40 : i1
            %42 = scf.if %41 -> (f32) {
              %43 = "disc_shape.linearize"(%34, %39, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %44 = arith.muli %dim_1, %dim_0 : index
              %45 = arith.muli %44, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%45], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %46 = memref.load %reinterpret_cast_2[%43] : memref<?xf32, "gpu">
              %47 = math.absf %46 : f32
              %48 = arith.cmpf oge, %arg5, %47 : f32
              %49 = arith.select %48, %arg5, %47 : f32
              scf.yield %49 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %38, %42 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        }
        %30 = arith.cmpi slt, %arg2, %5 : index
        scf.if %30 {
          %33 = memref.generic_atomic_rmw %alloc[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#0 : f32
            %35 = arith.select %34, %arg3, %29#0 : f32
            memref.atomic_yield %35 : f32
          }
        }
        %31 = arith.addi %arg2, %c1 : index
        %32 = arith.cmpi slt, %31, %5 : index
        scf.if %32 {
          %33 = memref.generic_atomic_rmw %alloc[%31] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#1 : f32
            %35 = arith.select %34, %arg3, %29#1 : f32
            memref.atomic_yield %35 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_2[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %5) step (%c128, %c2) {
        %18 = arith.addi %arg1, %c128 : index
        %19 = arith.cmpi slt, %18, %dim_1 : index
        %20 = arith.remui %dim_1, %c128 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.addi %arg2, %c2 : index
        %24 = arith.cmpi slt, %23, %5 : index
        %25 = arith.remui %5, %c2 : index
        %26 = arith.cmpi eq, %25, %c0 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.andi %22, %27 : i1
        %29:2 = scf.if %28 -> (f32, f32) {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = "disc_shape.linearize"(%34, %arg2, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %36 = arith.muli %dim_1, %dim_0 : index
            %37 = arith.muli %36, %dim : index
            %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%37], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %38 = memref.load %reinterpret_cast_2[%35] : memref<?xf32, "gpu">
            %39 = math.absf %38 : f32
            %40 = arith.cmpf oge, %arg4, %39 : f32
            %41 = arith.select %40, %arg4, %39 : f32
            %42 = arith.addi %arg2, %c1 : index
            %43 = "disc_shape.linearize"(%34, %42, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %44 = memref.load %reinterpret_cast_2[%43] : memref<?xf32, "gpu">
            %45 = math.absf %44 : f32
            %46 = arith.cmpf oge, %arg5, %45 : f32
            %47 = arith.select %46, %arg5, %45 : f32
            scf.yield %41, %47 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        } else {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.cmpi slt, %34, %dim_1 : index
            %36 = arith.cmpi slt, %arg2, %5 : index
            %37 = arith.andi %35, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %43 = "disc_shape.linearize"(%34, %arg2, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %44 = arith.muli %dim_1, %dim_0 : index
              %45 = arith.muli %44, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%45], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %46 = memref.load %reinterpret_cast_2[%43] : memref<?xf32, "gpu">
              %47 = math.absf %46 : f32
              %48 = arith.cmpf oge, %arg4, %47 : f32
              %49 = arith.select %48, %arg4, %47 : f32
              scf.yield %49 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %39 = arith.addi %arg2, %c1 : index
            %40 = arith.cmpi slt, %39, %5 : index
            %41 = arith.andi %35, %40 : i1
            %42 = scf.if %41 -> (f32) {
              %43 = "disc_shape.linearize"(%34, %39, %dim_1, %5) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
              %44 = arith.muli %dim_1, %dim_0 : index
              %45 = arith.muli %44, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%45], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %46 = memref.load %reinterpret_cast_2[%43] : memref<?xf32, "gpu">
              %47 = math.absf %46 : f32
              %48 = arith.cmpf oge, %arg5, %47 : f32
              %49 = arith.select %48, %arg5, %47 : f32
              scf.yield %49 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %38, %42 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        }
        %30 = arith.cmpi slt, %arg2, %5 : index
        scf.if %30 {
          %33 = memref.generic_atomic_rmw %alloc[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#0 : f32
            %35 = arith.select %34, %arg3, %29#0 : f32
            memref.atomic_yield %35 : f32
          }
        }
        %31 = arith.addi %arg2, %c1 : index
        %32 = arith.cmpi slt, %31, %5 : index
        scf.if %32 {
          %33 = memref.generic_atomic_rmw %alloc[%31] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#1 : f32
            %35 = arith.select %34, %arg3, %29#1 : f32
            memref.atomic_yield %35 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ConvertShapeToStandardPass (disc-convert-shape-to-std) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_2[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %5) step (%c128, %c2) {
        %18 = arith.addi %arg1, %c128 : index
        %19 = arith.cmpi slt, %18, %dim_1 : index
        %20 = arith.remui %dim_1, %c128 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.addi %arg2, %c2 : index
        %24 = arith.cmpi slt, %23, %5 : index
        %25 = arith.remui %5, %c2 : index
        %26 = arith.cmpi eq, %25, %c0 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.andi %22, %27 : i1
        %29:2 = scf.if %28 -> (f32, f32) {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %c0_2 = arith.constant 0 : index
            %35 = arith.muli %34, %5 : index
            %36 = arith.addi %35, %arg2 : index
            %37 = arith.muli %dim_1, %dim_0 : index
            %38 = arith.muli %37, %dim : index
            %reinterpret_cast_3 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%38], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %39 = memref.load %reinterpret_cast_3[%36] : memref<?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg4, %40 : f32
            %42 = arith.select %41, %arg4, %40 : f32
            %43 = arith.addi %arg2, %c1 : index
            %c0_4 = arith.constant 0 : index
            %44 = arith.muli %34, %5 : index
            %45 = arith.addi %44, %43 : index
            %46 = memref.load %reinterpret_cast_3[%45] : memref<?xf32, "gpu">
            %47 = math.absf %46 : f32
            %48 = arith.cmpf oge, %arg5, %47 : f32
            %49 = arith.select %48, %arg5, %47 : f32
            scf.yield %42, %49 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        } else {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.cmpi slt, %34, %dim_1 : index
            %36 = arith.cmpi slt, %arg2, %5 : index
            %37 = arith.andi %35, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %c0_2 = arith.constant 0 : index
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %arg2 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_3 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_3[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg4, %48 : f32
              %50 = arith.select %49, %arg4, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %39 = arith.addi %arg2, %c1 : index
            %40 = arith.cmpi slt, %39, %5 : index
            %41 = arith.andi %35, %40 : i1
            %42 = scf.if %41 -> (f32) {
              %c0_2 = arith.constant 0 : index
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %39 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_3 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_3[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg5, %48 : f32
              %50 = arith.select %49, %arg5, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %38, %42 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        }
        %30 = arith.cmpi slt, %arg2, %5 : index
        scf.if %30 {
          %33 = memref.generic_atomic_rmw %alloc[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#0 : f32
            %35 = arith.select %34, %arg3, %29#0 : f32
            memref.atomic_yield %35 : f32
          }
        }
        %31 = arith.addi %arg2, %c1 : index
        %32 = arith.cmpi slt, %31, %5 : index
        scf.if %32 {
          %33 = memref.generic_atomic_rmw %alloc[%31] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#1 : f32
            %35 = arith.select %34, %arg3, %29#1 : f32
            memref.atomic_yield %35 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_2[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %5) step (%c128, %c2) {
        %18 = arith.addi %arg1, %c128 : index
        %19 = arith.cmpi slt, %18, %dim_1 : index
        %20 = arith.remui %dim_1, %c128 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.addi %arg2, %c2 : index
        %24 = arith.cmpi slt, %23, %5 : index
        %25 = arith.remui %5, %c2 : index
        %26 = arith.cmpi eq, %25, %c0 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.andi %22, %27 : i1
        %29:2 = scf.if %28 -> (f32, f32) {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %c0_2 = arith.constant 0 : index
            %35 = arith.muli %34, %5 : index
            %36 = arith.addi %35, %arg2 : index
            %37 = arith.muli %dim_1, %dim_0 : index
            %38 = arith.muli %37, %dim : index
            %reinterpret_cast_3 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%38], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %39 = memref.load %reinterpret_cast_3[%36] : memref<?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg4, %40 : f32
            %42 = arith.select %41, %arg4, %40 : f32
            %43 = arith.addi %arg2, %c1 : index
            %c0_4 = arith.constant 0 : index
            %44 = arith.muli %34, %5 : index
            %45 = arith.addi %44, %43 : index
            %46 = memref.load %reinterpret_cast_3[%45] : memref<?xf32, "gpu">
            %47 = math.absf %46 : f32
            %48 = arith.cmpf oge, %arg5, %47 : f32
            %49 = arith.select %48, %arg5, %47 : f32
            scf.yield %42, %49 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        } else {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.cmpi slt, %34, %dim_1 : index
            %36 = arith.cmpi slt, %arg2, %5 : index
            %37 = arith.andi %35, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %c0_2 = arith.constant 0 : index
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %arg2 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_3 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_3[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg4, %48 : f32
              %50 = arith.select %49, %arg4, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %39 = arith.addi %arg2, %c1 : index
            %40 = arith.cmpi slt, %39, %5 : index
            %41 = arith.andi %35, %40 : i1
            %42 = scf.if %41 -> (f32) {
              %c0_2 = arith.constant 0 : index
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %39 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_3 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_3[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg5, %48 : f32
              %50 = arith.select %49, %arg5, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %38, %42 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        }
        %30 = arith.cmpi slt, %arg2, %5 : index
        scf.if %30 {
          %33 = memref.generic_atomic_rmw %alloc[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#0 : f32
            %35 = arith.select %34, %arg3, %29#0 : f32
            memref.atomic_yield %35 : f32
          }
        }
        %31 = arith.addi %arg2, %c1 : index
        %32 = arith.cmpi slt, %31, %5 : index
        scf.if %32 {
          %33 = memref.generic_atomic_rmw %alloc[%31] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#1 : f32
            %35 = arith.select %34, %arg3, %29#1 : f32
            memref.atomic_yield %35 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After Canonicalizer (disc-canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_2[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %5) step (%c128, %c2) {
        %18 = arith.addi %arg1, %c128 : index
        %19 = arith.cmpi slt, %18, %dim_1 : index
        %20 = arith.remui %dim_1, %c128 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.addi %arg2, %c2 : index
        %24 = arith.cmpi slt, %23, %5 : index
        %25 = arith.remui %5, %c2 : index
        %26 = arith.cmpi eq, %25, %c0 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.andi %22, %27 : i1
        %29:2 = scf.if %28 -> (f32, f32) {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.muli %34, %5 : index
            %36 = arith.addi %35, %arg2 : index
            %37 = arith.muli %dim_1, %dim_0 : index
            %38 = arith.muli %37, %dim : index
            %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%38], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %39 = memref.load %reinterpret_cast_2[%36] : memref<?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg4, %40 : f32
            %42 = arith.select %41, %arg4, %40 : f32
            %43 = arith.addi %arg2, %c1 : index
            %44 = arith.muli %34, %5 : index
            %45 = arith.addi %44, %43 : index
            %46 = memref.load %reinterpret_cast_2[%45] : memref<?xf32, "gpu">
            %47 = math.absf %46 : f32
            %48 = arith.cmpf oge, %arg5, %47 : f32
            %49 = arith.select %48, %arg5, %47 : f32
            scf.yield %42, %49 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        } else {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.cmpi slt, %34, %dim_1 : index
            %36 = arith.cmpi slt, %arg2, %5 : index
            %37 = arith.andi %35, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %arg2 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_2[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg4, %48 : f32
              %50 = arith.select %49, %arg4, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %39 = arith.addi %arg2, %c1 : index
            %40 = arith.cmpi slt, %39, %5 : index
            %41 = arith.andi %35, %40 : i1
            %42 = scf.if %41 -> (f32) {
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %39 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_2[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg5, %48 : f32
              %50 = arith.select %49, %arg5, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %38, %42 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        }
        %30 = arith.cmpi slt, %arg2, %5 : index
        scf.if %30 {
          %33 = memref.generic_atomic_rmw %alloc[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#0 : f32
            %35 = arith.select %34, %arg3, %29#0 : f32
            memref.atomic_yield %35 : f32
          }
        }
        %31 = arith.addi %arg2, %c1 : index
        %32 = arith.cmpi slt, %31, %5 : index
        scf.if %32 {
          %33 = memref.generic_atomic_rmw %alloc[%31] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#1 : f32
            %35 = arith.select %34, %arg3, %29#1 : f32
            memref.atomic_yield %35 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_2[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %5) step (%c128, %c2) {
        %18 = arith.addi %arg1, %c128 : index
        %19 = arith.cmpi slt, %18, %dim_1 : index
        %20 = arith.remui %dim_1, %c128 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.addi %arg2, %c2 : index
        %24 = arith.cmpi slt, %23, %5 : index
        %25 = arith.remui %5, %c2 : index
        %26 = arith.cmpi eq, %25, %c0 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.andi %22, %27 : i1
        %29:2 = scf.if %28 -> (f32, f32) {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.muli %34, %5 : index
            %36 = arith.addi %35, %arg2 : index
            %37 = arith.muli %dim_1, %dim_0 : index
            %38 = arith.muli %37, %dim : index
            %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%38], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %39 = memref.load %reinterpret_cast_2[%36] : memref<?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg4, %40 : f32
            %42 = arith.select %41, %arg4, %40 : f32
            %43 = arith.addi %arg2, %c1 : index
            %44 = arith.muli %34, %5 : index
            %45 = arith.addi %44, %43 : index
            %46 = memref.load %reinterpret_cast_2[%45] : memref<?xf32, "gpu">
            %47 = math.absf %46 : f32
            %48 = arith.cmpf oge, %arg5, %47 : f32
            %49 = arith.select %48, %arg5, %47 : f32
            scf.yield %42, %49 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        } else {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.cmpi slt, %34, %dim_1 : index
            %36 = arith.cmpi slt, %arg2, %5 : index
            %37 = arith.andi %35, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %arg2 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_2[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg4, %48 : f32
              %50 = arith.select %49, %arg4, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %39 = arith.addi %arg2, %c1 : index
            %40 = arith.cmpi slt, %39, %5 : index
            %41 = arith.andi %35, %40 : i1
            %42 = scf.if %41 -> (f32) {
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %39 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_2[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg5, %48 : f32
              %50 = arith.select %49, %arg5, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %38, %42 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        }
        %30 = arith.cmpi slt, %arg2, %5 : index
        scf.if %30 {
          %33 = memref.generic_atomic_rmw %alloc[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#0 : f32
            %35 = arith.select %34, %arg3, %29#0 : f32
            memref.atomic_yield %35 : f32
          }
        }
        %31 = arith.addi %arg2, %c1 : index
        %32 = arith.cmpi slt, %31, %5 : index
        scf.if %32 {
          %33 = memref.generic_atomic_rmw %alloc[%31] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#1 : f32
            %35 = arith.select %34, %arg3, %29#1 : f32
            memref.atomic_yield %35 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_2[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %5) step (%c128, %c2) {
        %18 = arith.addi %arg1, %c128 : index
        %19 = arith.cmpi slt, %18, %dim_1 : index
        %20 = arith.remui %dim_1, %c128 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.addi %arg2, %c2 : index
        %24 = arith.cmpi slt, %23, %5 : index
        %25 = arith.remui %5, %c2 : index
        %26 = arith.cmpi eq, %25, %c0 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.andi %22, %27 : i1
        %29:2 = scf.if %28 -> (f32, f32) {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.muli %34, %5 : index
            %36 = arith.addi %35, %arg2 : index
            %37 = arith.muli %dim_1, %dim_0 : index
            %38 = arith.muli %37, %dim : index
            %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%38], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %39 = memref.load %reinterpret_cast_2[%36] : memref<?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg4, %40 : f32
            %42 = arith.select %41, %arg4, %40 : f32
            %43 = arith.addi %arg2, %c1 : index
            %44 = arith.addi %35, %43 : index
            %45 = memref.load %reinterpret_cast_2[%44] : memref<?xf32, "gpu">
            %46 = math.absf %45 : f32
            %47 = arith.cmpf oge, %arg5, %46 : f32
            %48 = arith.select %47, %arg5, %46 : f32
            scf.yield %42, %48 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        } else {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.cmpi slt, %34, %dim_1 : index
            %36 = arith.cmpi slt, %arg2, %5 : index
            %37 = arith.andi %35, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %arg2 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_2[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg4, %48 : f32
              %50 = arith.select %49, %arg4, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %39 = arith.addi %arg2, %c1 : index
            %40 = arith.cmpi slt, %39, %5 : index
            %41 = arith.andi %35, %40 : i1
            %42 = scf.if %41 -> (f32) {
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %39 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_2[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg5, %48 : f32
              %50 = arith.select %49, %arg5, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %38, %42 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        }
        %30 = arith.cmpi slt, %arg2, %5 : index
        scf.if %30 {
          %33 = memref.generic_atomic_rmw %alloc[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#0 : f32
            %35 = arith.select %34, %arg3, %29#0 : f32
            memref.atomic_yield %35 : f32
          }
        }
        %31 = arith.addi %arg2, %c1 : index
        %32 = arith.cmpi slt, %31, %5 : index
        scf.if %32 {
          %33 = memref.generic_atomic_rmw %alloc[%31] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#1 : f32
            %35 = arith.select %34, %arg3, %29#1 : f32
            memref.atomic_yield %35 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_2 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_2[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%dim_1, %5) step (%c128, %c2) {
        %18 = arith.addi %arg1, %c128 : index
        %19 = arith.cmpi slt, %18, %dim_1 : index
        %20 = arith.remui %dim_1, %c128 : index
        %21 = arith.cmpi eq, %20, %c0 : index
        %22 = arith.ori %21, %19 : i1
        %23 = arith.addi %arg2, %c2 : index
        %24 = arith.cmpi slt, %23, %5 : index
        %25 = arith.remui %5, %c2 : index
        %26 = arith.cmpi eq, %25, %c0 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.andi %22, %27 : i1
        %29:2 = scf.if %28 -> (f32, f32) {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.muli %34, %5 : index
            %36 = arith.addi %35, %arg2 : index
            %37 = arith.muli %dim_1, %dim_0 : index
            %38 = arith.muli %37, %dim : index
            %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%38], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %39 = memref.load %reinterpret_cast_2[%36] : memref<?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg4, %40 : f32
            %42 = arith.select %41, %arg4, %40 : f32
            %43 = arith.addi %arg2, %c1 : index
            %44 = arith.addi %35, %43 : index
            %45 = memref.load %reinterpret_cast_2[%44] : memref<?xf32, "gpu">
            %46 = math.absf %45 : f32
            %47 = arith.cmpf oge, %arg5, %46 : f32
            %48 = arith.select %47, %arg5, %46 : f32
            scf.yield %42, %48 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        } else {
          %33:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
            %34 = arith.addi %arg1, %arg3 : index
            %35 = arith.cmpi slt, %34, %dim_1 : index
            %36 = arith.cmpi slt, %arg2, %5 : index
            %37 = arith.andi %35, %36 : i1
            %38 = scf.if %37 -> (f32) {
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %arg2 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_2[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg4, %48 : f32
              %50 = arith.select %49, %arg4, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg4 : f32
            }
            %39 = arith.addi %arg2, %c1 : index
            %40 = arith.cmpi slt, %39, %5 : index
            %41 = arith.andi %35, %40 : i1
            %42 = scf.if %41 -> (f32) {
              %43 = arith.muli %34, %5 : index
              %44 = arith.addi %43, %39 : index
              %45 = arith.muli %dim_1, %dim_0 : index
              %46 = arith.muli %45, %dim : index
              %reinterpret_cast_2 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%46], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %47 = memref.load %reinterpret_cast_2[%44] : memref<?xf32, "gpu">
              %48 = math.absf %47 : f32
              %49 = arith.cmpf oge, %arg5, %48 : f32
              %50 = arith.select %49, %arg5, %48 : f32
              scf.yield %50 : f32
            } else {
              scf.yield %arg5 : f32
            }
            scf.yield %38, %42 : f32, f32
          }
          scf.yield %33#0, %33#1 : f32, f32
        }
        %30 = arith.cmpi slt, %arg2, %5 : index
        scf.if %30 {
          %33 = memref.generic_atomic_rmw %alloc[%arg2] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#0 : f32
            %35 = arith.select %34, %arg3, %29#0 : f32
            memref.atomic_yield %35 : f32
          }
        }
        %31 = arith.addi %arg2, %c1 : index
        %32 = arith.cmpi slt, %31, %5 : index
        scf.if %32 {
          %33 = memref.generic_atomic_rmw %alloc[%31] : memref<?xf32, "gpu"> {
          ^bb0(%arg3: f32):
            %34 = arith.cmpf ogt, %arg3, %29#1 : f32
            %35 = arith.select %34, %arg3, %29#1 : f32
            memref.atomic_yield %35 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ParallelLoopCollapsing (disc-parallel-loop-collapsing) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_7 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_7[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      %18 = arith.subi %dim_1, %c0 : index
      %19 = arith.ceildivsi %18, %c128 : index
      %c1_2 = arith.constant 1 : index
      %20 = arith.subi %5, %c0 : index
      %21 = arith.ceildivsi %20, %c2 : index
      %c1_3 = arith.constant 1 : index
      %c0_4 = arith.constant 0 : index
      %c1_5 = arith.constant 1 : index
      %c1_6 = arith.constant 1 : index
      %22 = arith.muli %c1_6, %19 : index
      %23 = arith.muli %22, %21 : index
      scf.parallel (%arg1) = (%c0_4) to (%23) step (%c1_5) {
        %24 = arith.remsi %arg1, %21 : index
        %25 = arith.divsi %arg1, %21 : index
        %26 = arith.muli %24, %c2 : index
        %27 = arith.muli %25, %c128 : index
        %28 = arith.addi %27, %c128 : index
        %29 = arith.cmpi slt, %28, %dim_1 : index
        %30 = arith.remui %dim_1, %c128 : index
        %31 = arith.cmpi eq, %30, %c0 : index
        %32 = arith.ori %31, %29 : i1
        %33 = arith.addi %26, %c2 : index
        %34 = arith.cmpi slt, %33, %5 : index
        %35 = arith.remui %5, %c2 : index
        %36 = arith.cmpi eq, %35, %c0 : index
        %37 = arith.ori %36, %34 : i1
        %38 = arith.andi %32, %37 : i1
        %39:2 = scf.if %38 -> (f32, f32) {
          %43:2 = scf.for %arg2 = %c0 to %c128 step %c1 iter_args(%arg3 = %cst, %arg4 = %cst) -> (f32, f32) {
            %44 = arith.addi %27, %arg2 : index
            %45 = arith.muli %44, %5 : index
            %46 = arith.addi %45, %26 : index
            %47 = arith.muli %dim_1, %dim_0 : index
            %48 = arith.muli %47, %dim : index
            %reinterpret_cast_7 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%48], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %49 = memref.load %reinterpret_cast_7[%46] : memref<?xf32, "gpu">
            %50 = math.absf %49 : f32
            %51 = arith.cmpf oge, %arg3, %50 : f32
            %52 = arith.select %51, %arg3, %50 : f32
            %53 = arith.addi %26, %c1 : index
            %54 = arith.addi %45, %53 : index
            %55 = memref.load %reinterpret_cast_7[%54] : memref<?xf32, "gpu">
            %56 = math.absf %55 : f32
            %57 = arith.cmpf oge, %arg4, %56 : f32
            %58 = arith.select %57, %arg4, %56 : f32
            scf.yield %52, %58 : f32, f32
          }
          scf.yield %43#0, %43#1 : f32, f32
        } else {
          %43:2 = scf.for %arg2 = %c0 to %c128 step %c1 iter_args(%arg3 = %cst, %arg4 = %cst) -> (f32, f32) {
            %44 = arith.addi %27, %arg2 : index
            %45 = arith.cmpi slt, %44, %dim_1 : index
            %46 = arith.cmpi slt, %26, %5 : index
            %47 = arith.andi %45, %46 : i1
            %48 = scf.if %47 -> (f32) {
              %53 = arith.muli %44, %5 : index
              %54 = arith.addi %53, %26 : index
              %55 = arith.muli %dim_1, %dim_0 : index
              %56 = arith.muli %55, %dim : index
              %reinterpret_cast_7 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%56], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %57 = memref.load %reinterpret_cast_7[%54] : memref<?xf32, "gpu">
              %58 = math.absf %57 : f32
              %59 = arith.cmpf oge, %arg3, %58 : f32
              %60 = arith.select %59, %arg3, %58 : f32
              scf.yield %60 : f32
            } else {
              scf.yield %arg3 : f32
            }
            %49 = arith.addi %26, %c1 : index
            %50 = arith.cmpi slt, %49, %5 : index
            %51 = arith.andi %45, %50 : i1
            %52 = scf.if %51 -> (f32) {
              %53 = arith.muli %44, %5 : index
              %54 = arith.addi %53, %49 : index
              %55 = arith.muli %dim_1, %dim_0 : index
              %56 = arith.muli %55, %dim : index
              %reinterpret_cast_7 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%56], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %57 = memref.load %reinterpret_cast_7[%54] : memref<?xf32, "gpu">
              %58 = math.absf %57 : f32
              %59 = arith.cmpf oge, %arg4, %58 : f32
              %60 = arith.select %59, %arg4, %58 : f32
              scf.yield %60 : f32
            } else {
              scf.yield %arg4 : f32
            }
            scf.yield %48, %52 : f32, f32
          }
          scf.yield %43#0, %43#1 : f32, f32
        }
        %40 = arith.cmpi slt, %26, %5 : index
        scf.if %40 {
          %43 = memref.generic_atomic_rmw %alloc[%26] : memref<?xf32, "gpu"> {
          ^bb0(%arg2: f32):
            %44 = arith.cmpf ogt, %arg2, %39#0 : f32
            %45 = arith.select %44, %arg2, %39#0 : f32
            memref.atomic_yield %45 : f32
          }
        }
        %41 = arith.addi %26, %c1 : index
        %42 = arith.cmpi slt, %41, %5 : index
        scf.if %42 {
          %43 = memref.generic_atomic_rmw %alloc[%41] : memref<?xf32, "gpu"> {
          ^bb0(%arg2: f32):
            %44 = arith.cmpf ogt, %arg2, %39#1 : f32
            %45 = arith.select %44, %arg2, %39#1 : f32
            memref.atomic_yield %45 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      scf.parallel (%arg1) = (%c0) to (%5) step (%c1) {
        %reinterpret_cast_7 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast_7[%arg1] : memref<?xf32, "gpu">
        scf.yield
      }
      %18 = arith.subi %dim_1, %c0 : index
      %19 = arith.ceildivsi %18, %c128 : index
      %c1_2 = arith.constant 1 : index
      %20 = arith.subi %5, %c0 : index
      %21 = arith.ceildivsi %20, %c2 : index
      %c1_3 = arith.constant 1 : index
      %c0_4 = arith.constant 0 : index
      %c1_5 = arith.constant 1 : index
      %c1_6 = arith.constant 1 : index
      %22 = arith.muli %c1_6, %19 : index
      %23 = arith.muli %22, %21 : index
      scf.parallel (%arg1) = (%c0_4) to (%23) step (%c1_5) {
        %24 = arith.remsi %arg1, %21 : index
        %25 = arith.divsi %arg1, %21 : index
        %26 = arith.muli %24, %c2 : index
        %27 = arith.muli %25, %c128 : index
        %28 = arith.addi %27, %c128 : index
        %29 = arith.cmpi slt, %28, %dim_1 : index
        %30 = arith.remui %dim_1, %c128 : index
        %31 = arith.cmpi eq, %30, %c0 : index
        %32 = arith.ori %31, %29 : i1
        %33 = arith.addi %26, %c2 : index
        %34 = arith.cmpi slt, %33, %5 : index
        %35 = arith.remui %5, %c2 : index
        %36 = arith.cmpi eq, %35, %c0 : index
        %37 = arith.ori %36, %34 : i1
        %38 = arith.andi %32, %37 : i1
        %39:2 = scf.if %38 -> (f32, f32) {
          %43:2 = scf.for %arg2 = %c0 to %c128 step %c1 iter_args(%arg3 = %cst, %arg4 = %cst) -> (f32, f32) {
            %44 = arith.addi %27, %arg2 : index
            %45 = arith.muli %44, %5 : index
            %46 = arith.addi %45, %26 : index
            %47 = arith.muli %dim_1, %dim_0 : index
            %48 = arith.muli %47, %dim : index
            %reinterpret_cast_7 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%48], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %49 = memref.load %reinterpret_cast_7[%46] : memref<?xf32, "gpu">
            %50 = math.absf %49 : f32
            %51 = arith.cmpf oge, %arg3, %50 : f32
            %52 = arith.select %51, %arg3, %50 : f32
            %53 = arith.addi %26, %c1 : index
            %54 = arith.addi %45, %53 : index
            %55 = memref.load %reinterpret_cast_7[%54] : memref<?xf32, "gpu">
            %56 = math.absf %55 : f32
            %57 = arith.cmpf oge, %arg4, %56 : f32
            %58 = arith.select %57, %arg4, %56 : f32
            scf.yield %52, %58 : f32, f32
          }
          scf.yield %43#0, %43#1 : f32, f32
        } else {
          %43:2 = scf.for %arg2 = %c0 to %c128 step %c1 iter_args(%arg3 = %cst, %arg4 = %cst) -> (f32, f32) {
            %44 = arith.addi %27, %arg2 : index
            %45 = arith.cmpi slt, %44, %dim_1 : index
            %46 = arith.cmpi slt, %26, %5 : index
            %47 = arith.andi %45, %46 : i1
            %48 = scf.if %47 -> (f32) {
              %53 = arith.muli %44, %5 : index
              %54 = arith.addi %53, %26 : index
              %55 = arith.muli %dim_1, %dim_0 : index
              %56 = arith.muli %55, %dim : index
              %reinterpret_cast_7 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%56], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %57 = memref.load %reinterpret_cast_7[%54] : memref<?xf32, "gpu">
              %58 = math.absf %57 : f32
              %59 = arith.cmpf oge, %arg3, %58 : f32
              %60 = arith.select %59, %arg3, %58 : f32
              scf.yield %60 : f32
            } else {
              scf.yield %arg3 : f32
            }
            %49 = arith.addi %26, %c1 : index
            %50 = arith.cmpi slt, %49, %5 : index
            %51 = arith.andi %45, %50 : i1
            %52 = scf.if %51 -> (f32) {
              %53 = arith.muli %44, %5 : index
              %54 = arith.addi %53, %49 : index
              %55 = arith.muli %dim_1, %dim_0 : index
              %56 = arith.muli %55, %dim : index
              %reinterpret_cast_7 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%56], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %57 = memref.load %reinterpret_cast_7[%54] : memref<?xf32, "gpu">
              %58 = math.absf %57 : f32
              %59 = arith.cmpf oge, %arg4, %58 : f32
              %60 = arith.select %59, %arg4, %58 : f32
              scf.yield %60 : f32
            } else {
              scf.yield %arg4 : f32
            }
            scf.yield %48, %52 : f32, f32
          }
          scf.yield %43#0, %43#1 : f32, f32
        }
        %40 = arith.cmpi slt, %26, %5 : index
        scf.if %40 {
          %43 = memref.generic_atomic_rmw %alloc[%26] : memref<?xf32, "gpu"> {
          ^bb0(%arg2: f32):
            %44 = arith.cmpf ogt, %arg2, %39#0 : f32
            %45 = arith.select %44, %arg2, %39#0 : f32
            memref.atomic_yield %45 : f32
          }
        }
        %41 = arith.addi %26, %c1 : index
        %42 = arith.cmpi slt, %41, %5 : index
        scf.if %42 {
          %43 = memref.generic_atomic_rmw %alloc[%41] : memref<?xf32, "gpu"> {
          ^bb0(%arg2: f32):
            %44 = arith.cmpf ogt, %arg2, %39#1 : f32
            %45 = arith.select %44, %arg2, %39#1 : f32
            memref.atomic_yield %45 : f32
          }
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After SCFParallelLoopTiling (disc-parallel-loop-tiling) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    "lmhlo.fusion"() ({
      %c0_2 = arith.constant 0 : index
      %c256_3 = arith.constant 256 : index
      %18 = arith.muli %c1, %c256_3 : index
      scf.parallel (%arg1) = (%c0) to (%5) step (%18) {
        scf.parallel (%arg2) = (%c0_2) to (%18) step (%c1) {
          %26 = arith.addi %arg2, %arg1 : index
          %true = arith.constant true
          %27 = arith.muli %arg2, %c1 : index
          %28 = arith.addi %27, %arg1 : index
          %29 = arith.cmpi ult, %28, %5 : index
          %30 = arith.andi %true, %29 : i1
          scf.if %30 {
            %reinterpret_cast_11 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
            memref.store %cst, %reinterpret_cast_11[%26] : memref<?xf32, "gpu">
          }
          scf.yield
        }
        scf.yield
      }
      %19 = arith.subi %dim_1, %c0 : index
      %20 = arith.ceildivsi %19, %c128 : index
      %c1_4 = arith.constant 1 : index
      %21 = arith.subi %5, %c0 : index
      %22 = arith.ceildivsi %21, %c2 : index
      %c1_5 = arith.constant 1 : index
      %c0_6 = arith.constant 0 : index
      %c1_7 = arith.constant 1 : index
      %c1_8 = arith.constant 1 : index
      %23 = arith.muli %c1_8, %20 : index
      %24 = arith.muli %23, %22 : index
      %c0_9 = arith.constant 0 : index
      %c256_10 = arith.constant 256 : index
      %25 = arith.muli %c1_7, %c256_10 : index
      scf.parallel (%arg1) = (%c0_6) to (%24) step (%25) {
        scf.parallel (%arg2) = (%c0_9) to (%25) step (%c1_7) {
          %26 = arith.addi %arg2, %arg1 : index
          %true = arith.constant true
          %27 = arith.muli %arg2, %c1_7 : index
          %28 = arith.addi %27, %arg1 : index
          %29 = arith.cmpi ult, %28, %24 : index
          %30 = arith.andi %true, %29 : i1
          scf.if %30 {
            %31 = arith.remsi %26, %22 : index
            %32 = arith.divsi %26, %22 : index
            %33 = arith.muli %31, %c2 : index
            %34 = arith.muli %32, %c128 : index
            %35 = arith.addi %34, %c128 : index
            %36 = arith.cmpi slt, %35, %dim_1 : index
            %37 = arith.remui %dim_1, %c128 : index
            %38 = arith.cmpi eq, %37, %c0 : index
            %39 = arith.ori %38, %36 : i1
            %40 = arith.addi %33, %c2 : index
            %41 = arith.cmpi slt, %40, %5 : index
            %42 = arith.remui %5, %c2 : index
            %43 = arith.cmpi eq, %42, %c0 : index
            %44 = arith.ori %43, %41 : i1
            %45 = arith.andi %39, %44 : i1
            %46:2 = scf.if %45 -> (f32, f32) {
              %50:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
                %51 = arith.addi %34, %arg3 : index
                %52 = arith.muli %51, %5 : index
                %53 = arith.addi %52, %33 : index
                %54 = arith.muli %dim_1, %dim_0 : index
                %55 = arith.muli %54, %dim : index
                %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%55], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                %56 = memref.load %reinterpret_cast_11[%53] : memref<?xf32, "gpu">
                %57 = math.absf %56 : f32
                %58 = arith.cmpf oge, %arg4, %57 : f32
                %59 = arith.select %58, %arg4, %57 : f32
                %60 = arith.addi %33, %c1 : index
                %61 = arith.addi %52, %60 : index
                %62 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                %63 = math.absf %62 : f32
                %64 = arith.cmpf oge, %arg5, %63 : f32
                %65 = arith.select %64, %arg5, %63 : f32
                scf.yield %59, %65 : f32, f32
              }
              scf.yield %50#0, %50#1 : f32, f32
            } else {
              %50:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
                %51 = arith.addi %34, %arg3 : index
                %52 = arith.cmpi slt, %51, %dim_1 : index
                %53 = arith.cmpi slt, %33, %5 : index
                %54 = arith.andi %52, %53 : i1
                %55 = scf.if %54 -> (f32) {
                  %60 = arith.muli %51, %5 : index
                  %61 = arith.addi %60, %33 : index
                  %62 = arith.muli %dim_1, %dim_0 : index
                  %63 = arith.muli %62, %dim : index
                  %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%63], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %64 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                  %65 = math.absf %64 : f32
                  %66 = arith.cmpf oge, %arg4, %65 : f32
                  %67 = arith.select %66, %arg4, %65 : f32
                  scf.yield %67 : f32
                } else {
                  scf.yield %arg4 : f32
                }
                %56 = arith.addi %33, %c1 : index
                %57 = arith.cmpi slt, %56, %5 : index
                %58 = arith.andi %52, %57 : i1
                %59 = scf.if %58 -> (f32) {
                  %60 = arith.muli %51, %5 : index
                  %61 = arith.addi %60, %56 : index
                  %62 = arith.muli %dim_1, %dim_0 : index
                  %63 = arith.muli %62, %dim : index
                  %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%63], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %64 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                  %65 = math.absf %64 : f32
                  %66 = arith.cmpf oge, %arg5, %65 : f32
                  %67 = arith.select %66, %arg5, %65 : f32
                  scf.yield %67 : f32
                } else {
                  scf.yield %arg5 : f32
                }
                scf.yield %55, %59 : f32, f32
              }
              scf.yield %50#0, %50#1 : f32, f32
            }
            %47 = arith.cmpi slt, %33, %5 : index
            scf.if %47 {
              %50 = memref.generic_atomic_rmw %alloc[%33] : memref<?xf32, "gpu"> {
              ^bb0(%arg3: f32):
                %51 = arith.cmpf ogt, %arg3, %46#0 : f32
                %52 = arith.select %51, %arg3, %46#0 : f32
                memref.atomic_yield %52 : f32
              }
            }
            %48 = arith.addi %33, %c1 : index
            %49 = arith.cmpi slt, %48, %5 : index
            scf.if %49 {
              %50 = memref.generic_atomic_rmw %alloc[%48] : memref<?xf32, "gpu"> {
              ^bb0(%arg3: f32):
                %51 = arith.cmpf ogt, %arg3, %46#1 : f32
                %52 = arith.select %51, %arg3, %46#1 : f32
                memref.atomic_yield %52 : f32
              }
            }
          }
          scf.yield
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %c0_2 = arith.constant 0 : index
      %c128_3 = arith.constant 128 : index
      %18 = arith.muli %c1, %c128_3 : index
      scf.parallel (%arg1) = (%c0) to (%5) step (%18) {
        scf.parallel (%arg2) = (%c0_2) to (%18) step (%c1) {
          %26 = arith.addi %arg2, %arg1 : index
          %true = arith.constant true
          %27 = arith.muli %arg2, %c1 : index
          %28 = arith.addi %27, %arg1 : index
          %29 = arith.cmpi ult, %28, %5 : index
          %30 = arith.andi %true, %29 : i1
          scf.if %30 {
            %reinterpret_cast_11 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
            memref.store %cst, %reinterpret_cast_11[%26] : memref<?xf32, "gpu">
          }
          scf.yield
        }
        scf.yield
      }
      %19 = arith.subi %dim_1, %c0 : index
      %20 = arith.ceildivsi %19, %c128 : index
      %c1_4 = arith.constant 1 : index
      %21 = arith.subi %5, %c0 : index
      %22 = arith.ceildivsi %21, %c2 : index
      %c1_5 = arith.constant 1 : index
      %c0_6 = arith.constant 0 : index
      %c1_7 = arith.constant 1 : index
      %c1_8 = arith.constant 1 : index
      %23 = arith.muli %c1_8, %20 : index
      %24 = arith.muli %23, %22 : index
      %c0_9 = arith.constant 0 : index
      %c128_10 = arith.constant 128 : index
      %25 = arith.muli %c1_7, %c128_10 : index
      scf.parallel (%arg1) = (%c0_6) to (%24) step (%25) {
        scf.parallel (%arg2) = (%c0_9) to (%25) step (%c1_7) {
          %26 = arith.addi %arg2, %arg1 : index
          %true = arith.constant true
          %27 = arith.muli %arg2, %c1_7 : index
          %28 = arith.addi %27, %arg1 : index
          %29 = arith.cmpi ult, %28, %24 : index
          %30 = arith.andi %true, %29 : i1
          scf.if %30 {
            %31 = arith.remsi %26, %22 : index
            %32 = arith.divsi %26, %22 : index
            %33 = arith.muli %31, %c2 : index
            %34 = arith.muli %32, %c128 : index
            %35 = arith.addi %34, %c128 : index
            %36 = arith.cmpi slt, %35, %dim_1 : index
            %37 = arith.remui %dim_1, %c128 : index
            %38 = arith.cmpi eq, %37, %c0 : index
            %39 = arith.ori %38, %36 : i1
            %40 = arith.addi %33, %c2 : index
            %41 = arith.cmpi slt, %40, %5 : index
            %42 = arith.remui %5, %c2 : index
            %43 = arith.cmpi eq, %42, %c0 : index
            %44 = arith.ori %43, %41 : i1
            %45 = arith.andi %39, %44 : i1
            %46:2 = scf.if %45 -> (f32, f32) {
              %50:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
                %51 = arith.addi %34, %arg3 : index
                %52 = arith.muli %51, %5 : index
                %53 = arith.addi %52, %33 : index
                %54 = arith.muli %dim_1, %dim_0 : index
                %55 = arith.muli %54, %dim : index
                %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%55], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                %56 = memref.load %reinterpret_cast_11[%53] : memref<?xf32, "gpu">
                %57 = math.absf %56 : f32
                %58 = arith.cmpf oge, %arg4, %57 : f32
                %59 = arith.select %58, %arg4, %57 : f32
                %60 = arith.addi %33, %c1 : index
                %61 = arith.addi %52, %60 : index
                %62 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                %63 = math.absf %62 : f32
                %64 = arith.cmpf oge, %arg5, %63 : f32
                %65 = arith.select %64, %arg5, %63 : f32
                scf.yield %59, %65 : f32, f32
              }
              scf.yield %50#0, %50#1 : f32, f32
            } else {
              %50:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
                %51 = arith.addi %34, %arg3 : index
                %52 = arith.cmpi slt, %51, %dim_1 : index
                %53 = arith.cmpi slt, %33, %5 : index
                %54 = arith.andi %52, %53 : i1
                %55 = scf.if %54 -> (f32) {
                  %60 = arith.muli %51, %5 : index
                  %61 = arith.addi %60, %33 : index
                  %62 = arith.muli %dim_1, %dim_0 : index
                  %63 = arith.muli %62, %dim : index
                  %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%63], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %64 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                  %65 = math.absf %64 : f32
                  %66 = arith.cmpf oge, %arg4, %65 : f32
                  %67 = arith.select %66, %arg4, %65 : f32
                  scf.yield %67 : f32
                } else {
                  scf.yield %arg4 : f32
                }
                %56 = arith.addi %33, %c1 : index
                %57 = arith.cmpi slt, %56, %5 : index
                %58 = arith.andi %52, %57 : i1
                %59 = scf.if %58 -> (f32) {
                  %60 = arith.muli %51, %5 : index
                  %61 = arith.addi %60, %56 : index
                  %62 = arith.muli %dim_1, %dim_0 : index
                  %63 = arith.muli %62, %dim : index
                  %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%63], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %64 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                  %65 = math.absf %64 : f32
                  %66 = arith.cmpf oge, %arg5, %65 : f32
                  %67 = arith.select %66, %arg5, %65 : f32
                  scf.yield %67 : f32
                } else {
                  scf.yield %arg5 : f32
                }
                scf.yield %55, %59 : f32, f32
              }
              scf.yield %50#0, %50#1 : f32, f32
            }
            %47 = arith.cmpi slt, %33, %5 : index
            scf.if %47 {
              %50 = memref.generic_atomic_rmw %alloc[%33] : memref<?xf32, "gpu"> {
              ^bb0(%arg3: f32):
                %51 = arith.cmpf ogt, %arg3, %46#0 : f32
                %52 = arith.select %51, %arg3, %46#0 : f32
                memref.atomic_yield %52 : f32
              }
            }
            %48 = arith.addi %33, %c1 : index
            %49 = arith.cmpi slt, %48, %5 : index
            scf.if %49 {
              %50 = memref.generic_atomic_rmw %alloc[%48] : memref<?xf32, "gpu"> {
              ^bb0(%arg3: f32):
                %51 = arith.cmpf ogt, %arg3, %46#1 : f32
                %52 = arith.select %51, %arg3, %46#1 : f32
                memref.atomic_yield %52 : f32
              }
            }
          }
          scf.yield
        }
        scf.yield
      }
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After GpuMapParallelLoopsPass (gpu-map-parallel-loops) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    "lmhlo.fusion"() ({
      %c0_2 = arith.constant 0 : index
      %c256_3 = arith.constant 256 : index
      %18 = arith.muli %c1, %c256_3 : index
      scf.parallel (%arg1) = (%c0) to (%5) step (%18) {
        scf.parallel (%arg2) = (%c0_2) to (%18) step (%c1) {
          %26 = arith.addi %arg2, %arg1 : index
          %true = arith.constant true
          %27 = arith.muli %arg2, %c1 : index
          %28 = arith.addi %27, %arg1 : index
          %29 = arith.cmpi ult, %28, %5 : index
          %30 = arith.andi %true, %29 : i1
          scf.if %30 {
            %reinterpret_cast_11 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
            memref.store %cst, %reinterpret_cast_11[%26] : memref<?xf32, "gpu">
          }
          scf.yield
        } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      %19 = arith.subi %dim_1, %c0 : index
      %20 = arith.ceildivsi %19, %c128 : index
      %c1_4 = arith.constant 1 : index
      %21 = arith.subi %5, %c0 : index
      %22 = arith.ceildivsi %21, %c2 : index
      %c1_5 = arith.constant 1 : index
      %c0_6 = arith.constant 0 : index
      %c1_7 = arith.constant 1 : index
      %c1_8 = arith.constant 1 : index
      %23 = arith.muli %c1_8, %20 : index
      %24 = arith.muli %23, %22 : index
      %c0_9 = arith.constant 0 : index
      %c256_10 = arith.constant 256 : index
      %25 = arith.muli %c1_7, %c256_10 : index
      scf.parallel (%arg1) = (%c0_6) to (%24) step (%25) {
        scf.parallel (%arg2) = (%c0_9) to (%25) step (%c1_7) {
          %26 = arith.addi %arg2, %arg1 : index
          %true = arith.constant true
          %27 = arith.muli %arg2, %c1_7 : index
          %28 = arith.addi %27, %arg1 : index
          %29 = arith.cmpi ult, %28, %24 : index
          %30 = arith.andi %true, %29 : i1
          scf.if %30 {
            %31 = arith.remsi %26, %22 : index
            %32 = arith.divsi %26, %22 : index
            %33 = arith.muli %31, %c2 : index
            %34 = arith.muli %32, %c128 : index
            %35 = arith.addi %34, %c128 : index
            %36 = arith.cmpi slt, %35, %dim_1 : index
            %37 = arith.remui %dim_1, %c128 : index
            %38 = arith.cmpi eq, %37, %c0 : index
            %39 = arith.ori %38, %36 : i1
            %40 = arith.addi %33, %c2 : index
            %41 = arith.cmpi slt, %40, %5 : index
            %42 = arith.remui %5, %c2 : index
            %43 = arith.cmpi eq, %42, %c0 : index
            %44 = arith.ori %43, %41 : i1
            %45 = arith.andi %39, %44 : i1
            %46:2 = scf.if %45 -> (f32, f32) {
              %50:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
                %51 = arith.addi %34, %arg3 : index
                %52 = arith.muli %51, %5 : index
                %53 = arith.addi %52, %33 : index
                %54 = arith.muli %dim_1, %dim_0 : index
                %55 = arith.muli %54, %dim : index
                %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%55], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                %56 = memref.load %reinterpret_cast_11[%53] : memref<?xf32, "gpu">
                %57 = math.absf %56 : f32
                %58 = arith.cmpf oge, %arg4, %57 : f32
                %59 = arith.select %58, %arg4, %57 : f32
                %60 = arith.addi %33, %c1 : index
                %61 = arith.addi %52, %60 : index
                %62 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                %63 = math.absf %62 : f32
                %64 = arith.cmpf oge, %arg5, %63 : f32
                %65 = arith.select %64, %arg5, %63 : f32
                scf.yield %59, %65 : f32, f32
              }
              scf.yield %50#0, %50#1 : f32, f32
            } else {
              %50:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
                %51 = arith.addi %34, %arg3 : index
                %52 = arith.cmpi slt, %51, %dim_1 : index
                %53 = arith.cmpi slt, %33, %5 : index
                %54 = arith.andi %52, %53 : i1
                %55 = scf.if %54 -> (f32) {
                  %60 = arith.muli %51, %5 : index
                  %61 = arith.addi %60, %33 : index
                  %62 = arith.muli %dim_1, %dim_0 : index
                  %63 = arith.muli %62, %dim : index
                  %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%63], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %64 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                  %65 = math.absf %64 : f32
                  %66 = arith.cmpf oge, %arg4, %65 : f32
                  %67 = arith.select %66, %arg4, %65 : f32
                  scf.yield %67 : f32
                } else {
                  scf.yield %arg4 : f32
                }
                %56 = arith.addi %33, %c1 : index
                %57 = arith.cmpi slt, %56, %5 : index
                %58 = arith.andi %52, %57 : i1
                %59 = scf.if %58 -> (f32) {
                  %60 = arith.muli %51, %5 : index
                  %61 = arith.addi %60, %56 : index
                  %62 = arith.muli %dim_1, %dim_0 : index
                  %63 = arith.muli %62, %dim : index
                  %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%63], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %64 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                  %65 = math.absf %64 : f32
                  %66 = arith.cmpf oge, %arg5, %65 : f32
                  %67 = arith.select %66, %arg5, %65 : f32
                  scf.yield %67 : f32
                } else {
                  scf.yield %arg5 : f32
                }
                scf.yield %55, %59 : f32, f32
              }
              scf.yield %50#0, %50#1 : f32, f32
            }
            %47 = arith.cmpi slt, %33, %5 : index
            scf.if %47 {
              %50 = memref.generic_atomic_rmw %alloc[%33] : memref<?xf32, "gpu"> {
              ^bb0(%arg3: f32):
                %51 = arith.cmpf ogt, %arg3, %46#0 : f32
                %52 = arith.select %51, %arg3, %46#0 : f32
                memref.atomic_yield %52 : f32
              }
            }
            %48 = arith.addi %33, %c1 : index
            %49 = arith.cmpi slt, %48, %5 : index
            scf.if %49 {
              %50 = memref.generic_atomic_rmw %alloc[%48] : memref<?xf32, "gpu"> {
              ^bb0(%arg3: f32):
                %51 = arith.cmpf ogt, %arg3, %46#1 : f32
                %52 = arith.select %51, %arg3, %46#1 : f32
                memref.atomic_yield %52 : f32
              }
            }
          }
          scf.yield
        } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %c0_2 = arith.constant 0 : index
      %c128_3 = arith.constant 128 : index
      %18 = arith.muli %c1, %c128_3 : index
      scf.parallel (%arg1) = (%c0) to (%5) step (%18) {
        scf.parallel (%arg2) = (%c0_2) to (%18) step (%c1) {
          %26 = arith.addi %arg2, %arg1 : index
          %true = arith.constant true
          %27 = arith.muli %arg2, %c1 : index
          %28 = arith.addi %27, %arg1 : index
          %29 = arith.cmpi ult, %28, %5 : index
          %30 = arith.andi %true, %29 : i1
          scf.if %30 {
            %reinterpret_cast_11 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
            memref.store %cst, %reinterpret_cast_11[%26] : memref<?xf32, "gpu">
          }
          scf.yield
        } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      %19 = arith.subi %dim_1, %c0 : index
      %20 = arith.ceildivsi %19, %c128 : index
      %c1_4 = arith.constant 1 : index
      %21 = arith.subi %5, %c0 : index
      %22 = arith.ceildivsi %21, %c2 : index
      %c1_5 = arith.constant 1 : index
      %c0_6 = arith.constant 0 : index
      %c1_7 = arith.constant 1 : index
      %c1_8 = arith.constant 1 : index
      %23 = arith.muli %c1_8, %20 : index
      %24 = arith.muli %23, %22 : index
      %c0_9 = arith.constant 0 : index
      %c128_10 = arith.constant 128 : index
      %25 = arith.muli %c1_7, %c128_10 : index
      scf.parallel (%arg1) = (%c0_6) to (%24) step (%25) {
        scf.parallel (%arg2) = (%c0_9) to (%25) step (%c1_7) {
          %26 = arith.addi %arg2, %arg1 : index
          %true = arith.constant true
          %27 = arith.muli %arg2, %c1_7 : index
          %28 = arith.addi %27, %arg1 : index
          %29 = arith.cmpi ult, %28, %24 : index
          %30 = arith.andi %true, %29 : i1
          scf.if %30 {
            %31 = arith.remsi %26, %22 : index
            %32 = arith.divsi %26, %22 : index
            %33 = arith.muli %31, %c2 : index
            %34 = arith.muli %32, %c128 : index
            %35 = arith.addi %34, %c128 : index
            %36 = arith.cmpi slt, %35, %dim_1 : index
            %37 = arith.remui %dim_1, %c128 : index
            %38 = arith.cmpi eq, %37, %c0 : index
            %39 = arith.ori %38, %36 : i1
            %40 = arith.addi %33, %c2 : index
            %41 = arith.cmpi slt, %40, %5 : index
            %42 = arith.remui %5, %c2 : index
            %43 = arith.cmpi eq, %42, %c0 : index
            %44 = arith.ori %43, %41 : i1
            %45 = arith.andi %39, %44 : i1
            %46:2 = scf.if %45 -> (f32, f32) {
              %50:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
                %51 = arith.addi %34, %arg3 : index
                %52 = arith.muli %51, %5 : index
                %53 = arith.addi %52, %33 : index
                %54 = arith.muli %dim_1, %dim_0 : index
                %55 = arith.muli %54, %dim : index
                %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%55], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                %56 = memref.load %reinterpret_cast_11[%53] : memref<?xf32, "gpu">
                %57 = math.absf %56 : f32
                %58 = arith.cmpf oge, %arg4, %57 : f32
                %59 = arith.select %58, %arg4, %57 : f32
                %60 = arith.addi %33, %c1 : index
                %61 = arith.addi %52, %60 : index
                %62 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                %63 = math.absf %62 : f32
                %64 = arith.cmpf oge, %arg5, %63 : f32
                %65 = arith.select %64, %arg5, %63 : f32
                scf.yield %59, %65 : f32, f32
              }
              scf.yield %50#0, %50#1 : f32, f32
            } else {
              %50:2 = scf.for %arg3 = %c0 to %c128 step %c1 iter_args(%arg4 = %cst, %arg5 = %cst) -> (f32, f32) {
                %51 = arith.addi %34, %arg3 : index
                %52 = arith.cmpi slt, %51, %dim_1 : index
                %53 = arith.cmpi slt, %33, %5 : index
                %54 = arith.andi %52, %53 : i1
                %55 = scf.if %54 -> (f32) {
                  %60 = arith.muli %51, %5 : index
                  %61 = arith.addi %60, %33 : index
                  %62 = arith.muli %dim_1, %dim_0 : index
                  %63 = arith.muli %62, %dim : index
                  %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%63], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %64 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                  %65 = math.absf %64 : f32
                  %66 = arith.cmpf oge, %arg4, %65 : f32
                  %67 = arith.select %66, %arg4, %65 : f32
                  scf.yield %67 : f32
                } else {
                  scf.yield %arg4 : f32
                }
                %56 = arith.addi %33, %c1 : index
                %57 = arith.cmpi slt, %56, %5 : index
                %58 = arith.andi %52, %57 : i1
                %59 = scf.if %58 -> (f32) {
                  %60 = arith.muli %51, %5 : index
                  %61 = arith.addi %60, %56 : index
                  %62 = arith.muli %dim_1, %dim_0 : index
                  %63 = arith.muli %62, %dim : index
                  %reinterpret_cast_11 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%63], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %64 = memref.load %reinterpret_cast_11[%61] : memref<?xf32, "gpu">
                  %65 = math.absf %64 : f32
                  %66 = arith.cmpf oge, %arg5, %65 : f32
                  %67 = arith.select %66, %arg5, %65 : f32
                  scf.yield %67 : f32
                } else {
                  scf.yield %arg5 : f32
                }
                scf.yield %55, %59 : f32, f32
              }
              scf.yield %50#0, %50#1 : f32, f32
            }
            %47 = arith.cmpi slt, %33, %5 : index
            scf.if %47 {
              %50 = memref.generic_atomic_rmw %alloc[%33] : memref<?xf32, "gpu"> {
              ^bb0(%arg3: f32):
                %51 = arith.cmpf ogt, %arg3, %46#0 : f32
                %52 = arith.select %51, %arg3, %46#0 : f32
                memref.atomic_yield %52 : f32
              }
            }
            %48 = arith.addi %33, %c1 : index
            %49 = arith.cmpi slt, %48, %5 : index
            scf.if %49 {
              %50 = memref.generic_atomic_rmw %alloc[%48] : memref<?xf32, "gpu"> {
              ^bb0(%arg3: f32):
                %51 = arith.cmpf ogt, %arg3, %46#1 : f32
                %52 = arith.select %51, %arg3, %46#1 : f32
                memref.atomic_yield %52 : f32
              }
            }
          }
          scf.yield
        } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ConvertParallelLoopToGpu (convert-parallel-loops-to-gpu) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    "lmhlo.fusion"() ({
      %c0_2 = arith.constant 0 : index
      %c256_3 = arith.constant 256 : index
      %18 = arith.muli %c1, %c256_3 : index
      %c1_4 = arith.constant 1 : index
      %19 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%5)[%c0, %18]
      %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0_2, %c1]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %19, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %20, %arg11 = %c1_4, %arg12 = %c1_4) {
        %30 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%18, %c0]
        %31 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1, %c0_2]
        %32 = arith.addi %31, %30 : index
        %true = arith.constant true
        %33 = arith.muli %31, %c1 : index
        %34 = arith.addi %33, %30 : index
        %35 = arith.cmpi ult, %34, %5 : index
        %36 = arith.andi %true, %35 : i1
        scf.if %36 {
          %reinterpret_cast_13 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
          memref.store %cst, %reinterpret_cast_13[%32] : memref<?xf32, "gpu">
        }
        gpu.terminator
      } {SCFToGPU_visited}
      %21 = arith.subi %dim_1, %c0 : index
      %22 = arith.ceildivsi %21, %c128 : index
      %c1_5 = arith.constant 1 : index
      %23 = arith.subi %5, %c0 : index
      %24 = arith.ceildivsi %23, %c2 : index
      %c1_6 = arith.constant 1 : index
      %c0_7 = arith.constant 0 : index
      %c1_8 = arith.constant 1 : index
      %c1_9 = arith.constant 1 : index
      %25 = arith.muli %c1_9, %22 : index
      %26 = arith.muli %25, %24 : index
      %c0_10 = arith.constant 0 : index
      %c256_11 = arith.constant 256 : index
      %27 = arith.muli %c1_8, %c256_11 : index
      %c1_12 = arith.constant 1 : index
      %28 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%26)[%c0_7, %27]
      %29 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%27)[%c0_10, %c1_8]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %28, %arg8 = %c1_12, %arg9 = %c1_12) threads(%arg4, %arg5, %arg6) in (%arg10 = %29, %arg11 = %c1_12, %arg12 = %c1_12) {
        %30 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%27, %c0_7]
        %31 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1_8, %c0_10]
        %32 = arith.addi %31, %30 : index
        %true = arith.constant true
        %33 = arith.muli %31, %c1_8 : index
        %34 = arith.addi %33, %30 : index
        %35 = arith.cmpi ult, %34, %26 : index
        %36 = arith.andi %true, %35 : i1
        scf.if %36 {
          %37 = arith.remsi %32, %24 : index
          %38 = arith.divsi %32, %24 : index
          %39 = arith.muli %37, %c2 : index
          %40 = arith.muli %38, %c128 : index
          %41 = arith.addi %40, %c128 : index
          %42 = arith.cmpi slt, %41, %dim_1 : index
          %43 = arith.remui %dim_1, %c128 : index
          %44 = arith.cmpi eq, %43, %c0 : index
          %45 = arith.ori %44, %42 : i1
          %46 = arith.addi %39, %c2 : index
          %47 = arith.cmpi slt, %46, %5 : index
          %48 = arith.remui %5, %c2 : index
          %49 = arith.cmpi eq, %48, %c0 : index
          %50 = arith.ori %49, %47 : i1
          %51 = arith.andi %45, %50 : i1
          %52:2 = scf.if %51 -> (f32, f32) {
            %56:2 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %cst, %arg15 = %cst) -> (f32, f32) {
              %57 = arith.addi %40, %arg13 : index
              %58 = arith.muli %57, %5 : index
              %59 = arith.addi %58, %39 : index
              %60 = arith.muli %dim_1, %dim_0 : index
              %61 = arith.muli %60, %dim : index
              %reinterpret_cast_13 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%61], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %62 = memref.load %reinterpret_cast_13[%59] : memref<?xf32, "gpu">
              %63 = math.absf %62 : f32
              %64 = arith.cmpf oge, %arg14, %63 : f32
              %65 = arith.select %64, %arg14, %63 : f32
              %66 = arith.addi %39, %c1 : index
              %67 = arith.addi %58, %66 : index
              %68 = memref.load %reinterpret_cast_13[%67] : memref<?xf32, "gpu">
              %69 = math.absf %68 : f32
              %70 = arith.cmpf oge, %arg15, %69 : f32
              %71 = arith.select %70, %arg15, %69 : f32
              scf.yield %65, %71 : f32, f32
            }
            scf.yield %56#0, %56#1 : f32, f32
          } else {
            %56:2 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %cst, %arg15 = %cst) -> (f32, f32) {
              %57 = arith.addi %40, %arg13 : index
              %58 = arith.cmpi slt, %57, %dim_1 : index
              %59 = arith.cmpi slt, %39, %5 : index
              %60 = arith.andi %58, %59 : i1
              %61 = scf.if %60 -> (f32) {
                %66 = arith.muli %57, %5 : index
                %67 = arith.addi %66, %39 : index
                %68 = arith.muli %dim_1, %dim_0 : index
                %69 = arith.muli %68, %dim : index
                %reinterpret_cast_13 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%69], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                %70 = memref.load %reinterpret_cast_13[%67] : memref<?xf32, "gpu">
                %71 = math.absf %70 : f32
                %72 = arith.cmpf oge, %arg14, %71 : f32
                %73 = arith.select %72, %arg14, %71 : f32
                scf.yield %73 : f32
              } else {
                scf.yield %arg14 : f32
              }
              %62 = arith.addi %39, %c1 : index
              %63 = arith.cmpi slt, %62, %5 : index
              %64 = arith.andi %58, %63 : i1
              %65 = scf.if %64 -> (f32) {
                %66 = arith.muli %57, %5 : index
                %67 = arith.addi %66, %62 : index
                %68 = arith.muli %dim_1, %dim_0 : index
                %69 = arith.muli %68, %dim : index
                %reinterpret_cast_13 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%69], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                %70 = memref.load %reinterpret_cast_13[%67] : memref<?xf32, "gpu">
                %71 = math.absf %70 : f32
                %72 = arith.cmpf oge, %arg15, %71 : f32
                %73 = arith.select %72, %arg15, %71 : f32
                scf.yield %73 : f32
              } else {
                scf.yield %arg15 : f32
              }
              scf.yield %61, %65 : f32, f32
            }
            scf.yield %56#0, %56#1 : f32, f32
          }
          %53 = arith.cmpi slt, %39, %5 : index
          scf.if %53 {
            %56 = memref.generic_atomic_rmw %alloc[%39] : memref<?xf32, "gpu"> {
            ^bb0(%arg13: f32):
              %57 = arith.cmpf ogt, %arg13, %52#0 : f32
              %58 = arith.select %57, %arg13, %52#0 : f32
              memref.atomic_yield %58 : f32
            }
          }
          %54 = arith.addi %39, %c1 : index
          %55 = arith.cmpi slt, %54, %5 : index
          scf.if %55 {
            %56 = memref.generic_atomic_rmw %alloc[%54] : memref<?xf32, "gpu"> {
            ^bb0(%arg13: f32):
              %57 = arith.cmpf ogt, %arg13, %52#1 : f32
              %58 = arith.select %57, %arg13, %52#1 : f32
              memref.atomic_yield %58 : f32
            }
          }
        }
        gpu.terminator
      } {SCFToGPU_visited}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
  } else {
    "lmhlo.fusion"() ({
      %c0_2 = arith.constant 0 : index
      %c128_3 = arith.constant 128 : index
      %18 = arith.muli %c1, %c128_3 : index
      %c1_4 = arith.constant 1 : index
      %19 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%5)[%c0, %18]
      %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0_2, %c1]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %19, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %20, %arg11 = %c1_4, %arg12 = %c1_4) {
        %30 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%18, %c0]
        %31 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1, %c0_2]
        %32 = arith.addi %31, %30 : index
        %true = arith.constant true
        %33 = arith.muli %31, %c1 : index
        %34 = arith.addi %33, %30 : index
        %35 = arith.cmpi ult, %34, %5 : index
        %36 = arith.andi %true, %35 : i1
        scf.if %36 {
          %reinterpret_cast_13 = memref.reinterpret_cast %alloc to offset: [%c0], sizes: [%5], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
          memref.store %cst, %reinterpret_cast_13[%32] : memref<?xf32, "gpu">
        }
        gpu.terminator
      } {SCFToGPU_visited}
      %21 = arith.subi %dim_1, %c0 : index
      %22 = arith.ceildivsi %21, %c128 : index
      %c1_5 = arith.constant 1 : index
      %23 = arith.subi %5, %c0 : index
      %24 = arith.ceildivsi %23, %c2 : index
      %c1_6 = arith.constant 1 : index
      %c0_7 = arith.constant 0 : index
      %c1_8 = arith.constant 1 : index
      %c1_9 = arith.constant 1 : index
      %25 = arith.muli %c1_9, %22 : index
      %26 = arith.muli %25, %24 : index
      %c0_10 = arith.constant 0 : index
      %c128_11 = arith.constant 128 : index
      %27 = arith.muli %c1_8, %c128_11 : index
      %c1_12 = arith.constant 1 : index
      %28 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%26)[%c0_7, %27]
      %29 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%27)[%c0_10, %c1_8]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %28, %arg8 = %c1_12, %arg9 = %c1_12) threads(%arg4, %arg5, %arg6) in (%arg10 = %29, %arg11 = %c1_12, %arg12 = %c1_12) {
        %30 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%27, %c0_7]
        %31 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1_8, %c0_10]
        %32 = arith.addi %31, %30 : index
        %true = arith.constant true
        %33 = arith.muli %31, %c1_8 : index
        %34 = arith.addi %33, %30 : index
        %35 = arith.cmpi ult, %34, %26 : index
        %36 = arith.andi %true, %35 : i1
        scf.if %36 {
          %37 = arith.remsi %32, %24 : index
          %38 = arith.divsi %32, %24 : index
          %39 = arith.muli %37, %c2 : index
          %40 = arith.muli %38, %c128 : index
          %41 = arith.addi %40, %c128 : index
          %42 = arith.cmpi slt, %41, %dim_1 : index
          %43 = arith.remui %dim_1, %c128 : index
          %44 = arith.cmpi eq, %43, %c0 : index
          %45 = arith.ori %44, %42 : i1
          %46 = arith.addi %39, %c2 : index
          %47 = arith.cmpi slt, %46, %5 : index
          %48 = arith.remui %5, %c2 : index
          %49 = arith.cmpi eq, %48, %c0 : index
          %50 = arith.ori %49, %47 : i1
          %51 = arith.andi %45, %50 : i1
          %52:2 = scf.if %51 -> (f32, f32) {
            %56:2 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %cst, %arg15 = %cst) -> (f32, f32) {
              %57 = arith.addi %40, %arg13 : index
              %58 = arith.muli %57, %5 : index
              %59 = arith.addi %58, %39 : index
              %60 = arith.muli %dim_1, %dim_0 : index
              %61 = arith.muli %60, %dim : index
              %reinterpret_cast_13 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%61], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %62 = memref.load %reinterpret_cast_13[%59] : memref<?xf32, "gpu">
              %63 = math.absf %62 : f32
              %64 = arith.cmpf oge, %arg14, %63 : f32
              %65 = arith.select %64, %arg14, %63 : f32
              %66 = arith.addi %39, %c1 : index
              %67 = arith.addi %58, %66 : index
              %68 = memref.load %reinterpret_cast_13[%67] : memref<?xf32, "gpu">
              %69 = math.absf %68 : f32
              %70 = arith.cmpf oge, %arg15, %69 : f32
              %71 = arith.select %70, %arg15, %69 : f32
              scf.yield %65, %71 : f32, f32
            }
            scf.yield %56#0, %56#1 : f32, f32
          } else {
            %56:2 = scf.for %arg13 = %c0 to %c128 step %c1 iter_args(%arg14 = %cst, %arg15 = %cst) -> (f32, f32) {
              %57 = arith.addi %40, %arg13 : index
              %58 = arith.cmpi slt, %57, %dim_1 : index
              %59 = arith.cmpi slt, %39, %5 : index
              %60 = arith.andi %58, %59 : i1
              %61 = scf.if %60 -> (f32) {
                %66 = arith.muli %57, %5 : index
                %67 = arith.addi %66, %39 : index
                %68 = arith.muli %dim_1, %dim_0 : index
                %69 = arith.muli %68, %dim : index
                %reinterpret_cast_13 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%69], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                %70 = memref.load %reinterpret_cast_13[%67] : memref<?xf32, "gpu">
                %71 = math.absf %70 : f32
                %72 = arith.cmpf oge, %arg14, %71 : f32
                %73 = arith.select %72, %arg14, %71 : f32
                scf.yield %73 : f32
              } else {
                scf.yield %arg14 : f32
              }
              %62 = arith.addi %39, %c1 : index
              %63 = arith.cmpi slt, %62, %5 : index
              %64 = arith.andi %58, %63 : i1
              %65 = scf.if %64 -> (f32) {
                %66 = arith.muli %57, %5 : index
                %67 = arith.addi %66, %62 : index
                %68 = arith.muli %dim_1, %dim_0 : index
                %69 = arith.muli %68, %dim : index
                %reinterpret_cast_13 = memref.reinterpret_cast %1 to offset: [%c0], sizes: [%69], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                %70 = memref.load %reinterpret_cast_13[%67] : memref<?xf32, "gpu">
                %71 = math.absf %70 : f32
                %72 = arith.cmpf oge, %arg15, %71 : f32
                %73 = arith.select %72, %arg15, %71 : f32
                scf.yield %73 : f32
              } else {
                scf.yield %arg15 : f32
              }
              scf.yield %61, %65 : f32, f32
            }
            scf.yield %56#0, %56#1 : f32, f32
          }
          %53 = arith.cmpi slt, %39, %5 : index
          scf.if %53 {
            %56 = memref.generic_atomic_rmw %alloc[%39] : memref<?xf32, "gpu"> {
            ^bb0(%arg13: f32):
              %57 = arith.cmpf ogt, %arg13, %52#0 : f32
              %58 = arith.select %57, %arg13, %52#0 : f32
              memref.atomic_yield %58 : f32
            }
          }
          %54 = arith.addi %39, %c1 : index
          %55 = arith.cmpi slt, %54, %5 : index
          scf.if %55 {
            %56 = memref.generic_atomic_rmw %alloc[%54] : memref<?xf32, "gpu"> {
            ^bb0(%arg13: f32):
              %57 = arith.cmpf ogt, %arg13, %52#1 : f32
              %58 = arith.select %57, %arg13, %52#1 : f32
              memref.atomic_yield %58 : f32
            }
          }
        }
        gpu.terminator
      } {SCFToGPU_visited}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After GpuLaunchSinkIndexComputations (gpu-launch-sink-index-computations) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c-1 = arith.constant -1 : index
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c256 = arith.constant 256 : index
    %c108 = arith.constant 108 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
    %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
    %2 = arith.index_cast %dim_0 : index to i32
    %3 = arith.index_cast %dim : index to i32
    %4 = arith.muli %2, %3 : i32
    %5 = arith.index_cast %4 : i32 to index
    %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
    %6 = arith.muli %dim_1, %5 : index
    %7 = arith.addi %6, %c-1 : index
    %8 = arith.divsi %7, %c256 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.subi %c0, %6 : index
    %11 = arith.divsi %10, %c256 : index
    %12 = arith.subi %c0, %11 : index
    %13 = arith.cmpi sgt, %6, %c0 : index
    %14 = arith.select %13, %9, %12 : index
    %15 = arith.cmpi sgt, %14, %c108 : index
    scf.if %15 {
      "lmhlo.fusion"() ({
        %c0_2 = arith.constant 0 : index
        %c256_3 = arith.constant 256 : index
        %18 = arith.muli %c1, %c256_3 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%5)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_2, %c1]
        gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %19, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %20, %arg11 = %c1_4, %arg12 = %c1_4) {
          %c0_13 = arith.constant 0 : index
          %c1_14 = arith.constant 1 : index
          %c0_15 = arith.constant 0 : index
          %cst_16 = arith.constant 0xFF800000 : f32
          %30 = affine.apply #map1(%arg1)[%18, %c0_13]
          %31 = affine.apply #map1(%arg4)[%c1_14, %c0_15]
          %32 = arith.addi %31, %30 : index
          %true = arith.constant true
          %33 = arith.muli %31, %c1_14 : index
          %34 = arith.addi %33, %30 : index
          %35 = arith.cmpi ult, %34, %5 : index
          %36 = arith.andi %true, %35 : i1
          scf.if %36 {
            %reinterpret_cast_17 = memref.reinterpret_cast %alloc to offset: [%c0_13], sizes: [%5], strides: [%c1_14] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
            memref.store %cst_16, %reinterpret_cast_17[%32] : memref<?xf32, "gpu">
          }
          gpu.terminator
        } {SCFToGPU_visited}
        %21 = arith.subi %dim_1, %c0 : index
        %22 = arith.ceildivsi %21, %c128 : index
        %c1_5 = arith.constant 1 : index
        %23 = arith.subi %5, %c0 : index
        %24 = arith.ceildivsi %23, %c2 : index
        %c1_6 = arith.constant 1 : index
        %c0_7 = arith.constant 0 : index
        %c1_8 = arith.constant 1 : index
        %c1_9 = arith.constant 1 : index
        %25 = arith.muli %c1_9, %22 : index
        %26 = arith.muli %25, %24 : index
        %c0_10 = arith.constant 0 : index
        %c256_11 = arith.constant 256 : index
        %27 = arith.muli %c1_8, %c256_11 : index
        %c1_12 = arith.constant 1 : index
        %28 = affine.apply #map(%26)[%c0_7, %27]
        %29 = affine.apply #map(%27)[%c0_10, %c1_8]
        gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %28, %arg8 = %c1_12, %arg9 = %c1_12) threads(%arg4, %arg5, %arg6) in (%arg10 = %29, %arg11 = %c1_12, %arg12 = %c1_12) {
          %c0_13 = arith.constant 0 : index
          %c1_14 = arith.constant 1 : index
          %c0_15 = arith.constant 0 : index
          %c2_16 = arith.constant 2 : index
          %c128_17 = arith.constant 128 : index
          %c0_18 = arith.constant 0 : index
          %dim_19 = memref.dim %1, %c0_18 : memref<?x?x?xf32, "gpu">
          %c1_20 = arith.constant 1 : index
          %dim_21 = memref.dim %1, %c1_20 : memref<?x?x?xf32, "gpu">
          %dim_22 = memref.dim %1, %c2_16 : memref<?x?x?xf32, "gpu">
          %cst_23 = arith.constant 0xFF800000 : f32
          %30 = affine.apply #map1(%arg1)[%27, %c0_13]
          %31 = affine.apply #map1(%arg4)[%c1_14, %c0_15]
          %32 = arith.addi %31, %30 : index
          %true = arith.constant true
          %33 = arith.muli %31, %c1_14 : index
          %34 = arith.addi %33, %30 : index
          %35 = arith.cmpi ult, %34, %26 : index
          %36 = arith.andi %true, %35 : i1
          scf.if %36 {
            %37 = arith.remsi %32, %24 : index
            %38 = arith.divsi %32, %24 : index
            %39 = arith.muli %37, %c2_16 : index
            %40 = arith.muli %38, %c128_17 : index
            %41 = arith.addi %40, %c128_17 : index
            %42 = arith.cmpi slt, %41, %dim_19 : index
            %43 = arith.remui %dim_19, %c128_17 : index
            %44 = arith.cmpi eq, %43, %c0_18 : index
            %45 = arith.ori %44, %42 : i1
            %46 = arith.addi %39, %c2_16 : index
            %47 = arith.cmpi slt, %46, %5 : index
            %48 = arith.remui %5, %c2_16 : index
            %49 = arith.cmpi eq, %48, %c0_18 : index
            %50 = arith.ori %49, %47 : i1
            %51 = arith.andi %45, %50 : i1
            %52:2 = scf.if %51 -> (f32, f32) {
              %56:2 = scf.for %arg13 = %c0_18 to %c128_17 step %c1_20 iter_args(%arg14 = %cst_23, %arg15 = %cst_23) -> (f32, f32) {
                %57 = arith.addi %40, %arg13 : index
                %58 = arith.muli %57, %5 : index
                %59 = arith.addi %58, %39 : index
                %60 = arith.muli %dim_19, %dim_21 : index
                %61 = arith.muli %60, %dim_22 : index
                %reinterpret_cast_24 = memref.reinterpret_cast %1 to offset: [%c0_18], sizes: [%61], strides: [%c1_20] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                %62 = memref.load %reinterpret_cast_24[%59] : memref<?xf32, "gpu">
                %63 = math.absf %62 : f32
                %64 = arith.cmpf oge, %arg14, %63 : f32
                %65 = arith.select %64, %arg14, %63 : f32
                %66 = arith.addi %39, %c1_20 : index
                %67 = arith.addi %58, %66 : index
                %68 = memref.load %reinterpret_cast_24[%67] : memref<?xf32, "gpu">
                %69 = math.absf %68 : f32
                %70 = arith.cmpf oge, %arg15, %69 : f32
                %71 = arith.select %70, %arg15, %69 : f32
                scf.yield %65, %71 : f32, f32
              }
              scf.yield %56#0, %56#1 : f32, f32
            } else {
              %56:2 = scf.for %arg13 = %c0_18 to %c128_17 step %c1_20 iter_args(%arg14 = %cst_23, %arg15 = %cst_23) -> (f32, f32) {
                %57 = arith.addi %40, %arg13 : index
                %58 = arith.cmpi slt, %57, %dim_19 : index
                %59 = arith.cmpi slt, %39, %5 : index
                %60 = arith.andi %58, %59 : i1
                %61 = scf.if %60 -> (f32) {
                  %66 = arith.muli %57, %5 : index
                  %67 = arith.addi %66, %39 : index
                  %68 = arith.muli %dim_19, %dim_21 : index
                  %69 = arith.muli %68, %dim_22 : index
                  %reinterpret_cast_24 = memref.reinterpret_cast %1 to offset: [%c0_18], sizes: [%69], strides: [%c1_20] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %70 = memref.load %reinterpret_cast_24[%67] : memref<?xf32, "gpu">
                  %71 = math.absf %70 : f32
                  %72 = arith.cmpf oge, %arg14, %71 : f32
                  %73 = arith.select %72, %arg14, %71 : f32
                  scf.yield %73 : f32
                } else {
                  scf.yield %arg14 : f32
                }
                %62 = arith.addi %39, %c1_20 : index
                %63 = arith.cmpi slt, %62, %5 : index
                %64 = arith.andi %58, %63 : i1
                %65 = scf.if %64 -> (f32) {
                  %66 = arith.muli %57, %5 : index
                  %67 = arith.addi %66, %62 : index
                  %68 = arith.muli %dim_19, %dim_21 : index
                  %69 = arith.muli %68, %dim_22 : index
                  %reinterpret_cast_24 = memref.reinterpret_cast %1 to offset: [%c0_18], sizes: [%69], strides: [%c1_20] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %70 = memref.load %reinterpret_cast_24[%67] : memref<?xf32, "gpu">
                  %71 = math.absf %70 : f32
                  %72 = arith.cmpf oge, %arg15, %71 : f32
                  %73 = arith.select %72, %arg15, %71 : f32
                  scf.yield %73 : f32
                } else {
                  scf.yield %arg15 : f32
                }
                scf.yield %61, %65 : f32, f32
              }
              scf.yield %56#0, %56#1 : f32, f32
            }
            %53 = arith.cmpi slt, %39, %5 : index
            scf.if %53 {
              %56 = memref.generic_atomic_rmw %alloc[%39] : memref<?xf32, "gpu"> {
              ^bb0(%arg13: f32):
                %57 = arith.cmpf ogt, %arg13, %52#0 : f32
                %58 = arith.select %57, %arg13, %52#0 : f32
                memref.atomic_yield %58 : f32
              }
            }
            %54 = arith.addi %39, %c1_20 : index
            %55 = arith.cmpi slt, %54, %5 : index
            scf.if %55 {
              %56 = memref.generic_atomic_rmw %alloc[%54] : memref<?xf32, "gpu"> {
              ^bb0(%arg13: f32):
                %57 = arith.cmpf ogt, %arg13, %52#1 : f32
                %58 = arith.select %57, %arg13, %52#1 : f32
                memref.atomic_yield %58 : f32
              }
            }
          }
          gpu.terminator
        } {SCFToGPU_visited}
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        %c0_2 = arith.constant 0 : index
        %c128_3 = arith.constant 128 : index
        %18 = arith.muli %c1, %c128_3 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%5)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_2, %c1]
        gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %19, %arg8 = %c1_4, %arg9 = %c1_4) threads(%arg4, %arg5, %arg6) in (%arg10 = %20, %arg11 = %c1_4, %arg12 = %c1_4) {
          %c0_13 = arith.constant 0 : index
          %c1_14 = arith.constant 1 : index
          %c0_15 = arith.constant 0 : index
          %cst_16 = arith.constant 0xFF800000 : f32
          %30 = affine.apply #map1(%arg1)[%18, %c0_13]
          %31 = affine.apply #map1(%arg4)[%c1_14, %c0_15]
          %32 = arith.addi %31, %30 : index
          %true = arith.constant true
          %33 = arith.muli %31, %c1_14 : index
          %34 = arith.addi %33, %30 : index
          %35 = arith.cmpi ult, %34, %5 : index
          %36 = arith.andi %true, %35 : i1
          scf.if %36 {
            %reinterpret_cast_17 = memref.reinterpret_cast %alloc to offset: [%c0_13], sizes: [%5], strides: [%c1_14] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
            memref.store %cst_16, %reinterpret_cast_17[%32] : memref<?xf32, "gpu">
          }
          gpu.terminator
        } {SCFToGPU_visited}
        %21 = arith.subi %dim_1, %c0 : index
        %22 = arith.ceildivsi %21, %c128 : index
        %c1_5 = arith.constant 1 : index
        %23 = arith.subi %5, %c0 : index
        %24 = arith.ceildivsi %23, %c2 : index
        %c1_6 = arith.constant 1 : index
        %c0_7 = arith.constant 0 : index
        %c1_8 = arith.constant 1 : index
        %c1_9 = arith.constant 1 : index
        %25 = arith.muli %c1_9, %22 : index
        %26 = arith.muli %25, %24 : index
        %c0_10 = arith.constant 0 : index
        %c128_11 = arith.constant 128 : index
        %27 = arith.muli %c1_8, %c128_11 : index
        %c1_12 = arith.constant 1 : index
        %28 = affine.apply #map(%26)[%c0_7, %27]
        %29 = affine.apply #map(%27)[%c0_10, %c1_8]
        gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %28, %arg8 = %c1_12, %arg9 = %c1_12) threads(%arg4, %arg5, %arg6) in (%arg10 = %29, %arg11 = %c1_12, %arg12 = %c1_12) {
          %c0_13 = arith.constant 0 : index
          %c1_14 = arith.constant 1 : index
          %c0_15 = arith.constant 0 : index
          %c2_16 = arith.constant 2 : index
          %c128_17 = arith.constant 128 : index
          %c0_18 = arith.constant 0 : index
          %dim_19 = memref.dim %1, %c0_18 : memref<?x?x?xf32, "gpu">
          %c1_20 = arith.constant 1 : index
          %dim_21 = memref.dim %1, %c1_20 : memref<?x?x?xf32, "gpu">
          %dim_22 = memref.dim %1, %c2_16 : memref<?x?x?xf32, "gpu">
          %cst_23 = arith.constant 0xFF800000 : f32
          %30 = affine.apply #map1(%arg1)[%27, %c0_13]
          %31 = affine.apply #map1(%arg4)[%c1_14, %c0_15]
          %32 = arith.addi %31, %30 : index
          %true = arith.constant true
          %33 = arith.muli %31, %c1_14 : index
          %34 = arith.addi %33, %30 : index
          %35 = arith.cmpi ult, %34, %26 : index
          %36 = arith.andi %true, %35 : i1
          scf.if %36 {
            %37 = arith.remsi %32, %24 : index
            %38 = arith.divsi %32, %24 : index
            %39 = arith.muli %37, %c2_16 : index
            %40 = arith.muli %38, %c128_17 : index
            %41 = arith.addi %40, %c128_17 : index
            %42 = arith.cmpi slt, %41, %dim_19 : index
            %43 = arith.remui %dim_19, %c128_17 : index
            %44 = arith.cmpi eq, %43, %c0_18 : index
            %45 = arith.ori %44, %42 : i1
            %46 = arith.addi %39, %c2_16 : index
            %47 = arith.cmpi slt, %46, %5 : index
            %48 = arith.remui %5, %c2_16 : index
            %49 = arith.cmpi eq, %48, %c0_18 : index
            %50 = arith.ori %49, %47 : i1
            %51 = arith.andi %45, %50 : i1
            %52:2 = scf.if %51 -> (f32, f32) {
              %56:2 = scf.for %arg13 = %c0_18 to %c128_17 step %c1_20 iter_args(%arg14 = %cst_23, %arg15 = %cst_23) -> (f32, f32) {
                %57 = arith.addi %40, %arg13 : index
                %58 = arith.muli %57, %5 : index
                %59 = arith.addi %58, %39 : index
                %60 = arith.muli %dim_19, %dim_21 : index
                %61 = arith.muli %60, %dim_22 : index
                %reinterpret_cast_24 = memref.reinterpret_cast %1 to offset: [%c0_18], sizes: [%61], strides: [%c1_20] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                %62 = memref.load %reinterpret_cast_24[%59] : memref<?xf32, "gpu">
                %63 = math.absf %62 : f32
                %64 = arith.cmpf oge, %arg14, %63 : f32
                %65 = arith.select %64, %arg14, %63 : f32
                %66 = arith.addi %39, %c1_20 : index
                %67 = arith.addi %58, %66 : index
                %68 = memref.load %reinterpret_cast_24[%67] : memref<?xf32, "gpu">
                %69 = math.absf %68 : f32
                %70 = arith.cmpf oge, %arg15, %69 : f32
                %71 = arith.select %70, %arg15, %69 : f32
                scf.yield %65, %71 : f32, f32
              }
              scf.yield %56#0, %56#1 : f32, f32
            } else {
              %56:2 = scf.for %arg13 = %c0_18 to %c128_17 step %c1_20 iter_args(%arg14 = %cst_23, %arg15 = %cst_23) -> (f32, f32) {
                %57 = arith.addi %40, %arg13 : index
                %58 = arith.cmpi slt, %57, %dim_19 : index
                %59 = arith.cmpi slt, %39, %5 : index
                %60 = arith.andi %58, %59 : i1
                %61 = scf.if %60 -> (f32) {
                  %66 = arith.muli %57, %5 : index
                  %67 = arith.addi %66, %39 : index
                  %68 = arith.muli %dim_19, %dim_21 : index
                  %69 = arith.muli %68, %dim_22 : index
                  %reinterpret_cast_24 = memref.reinterpret_cast %1 to offset: [%c0_18], sizes: [%69], strides: [%c1_20] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %70 = memref.load %reinterpret_cast_24[%67] : memref<?xf32, "gpu">
                  %71 = math.absf %70 : f32
                  %72 = arith.cmpf oge, %arg14, %71 : f32
                  %73 = arith.select %72, %arg14, %71 : f32
                  scf.yield %73 : f32
                } else {
                  scf.yield %arg14 : f32
                }
                %62 = arith.addi %39, %c1_20 : index
                %63 = arith.cmpi slt, %62, %5 : index
                %64 = arith.andi %58, %63 : i1
                %65 = scf.if %64 -> (f32) {
                  %66 = arith.muli %57, %5 : index
                  %67 = arith.addi %66, %62 : index
                  %68 = arith.muli %dim_19, %dim_21 : index
                  %69 = arith.muli %68, %dim_22 : index
                  %reinterpret_cast_24 = memref.reinterpret_cast %1 to offset: [%c0_18], sizes: [%69], strides: [%c1_20] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
                  %70 = memref.load %reinterpret_cast_24[%67] : memref<?xf32, "gpu">
                  %71 = math.absf %70 : f32
                  %72 = arith.cmpf oge, %arg15, %71 : f32
                  %73 = arith.select %72, %arg15, %71 : f32
                  scf.yield %73 : f32
                } else {
                  scf.yield %arg15 : f32
                }
                scf.yield %61, %65 : f32, f32
              }
              scf.yield %56#0, %56#1 : f32, f32
            }
            %53 = arith.cmpi slt, %39, %5 : index
            scf.if %53 {
              %56 = memref.generic_atomic_rmw %alloc[%39] : memref<?xf32, "gpu"> {
              ^bb0(%arg13: f32):
                %57 = arith.cmpf ogt, %arg13, %52#0 : f32
                %58 = arith.select %57, %arg13, %52#0 : f32
                memref.atomic_yield %58 : f32
              }
            }
            %54 = arith.addi %39, %c1_20 : index
            %55 = arith.cmpi slt, %54, %5 : index
            scf.if %55 {
              %56 = memref.generic_atomic_rmw %alloc[%54] : memref<?xf32, "gpu"> {
              ^bb0(%arg13: f32):
                %57 = arith.cmpf ogt, %arg13, %52#1 : f32
                %58 = arith.select %57, %arg13, %52#1 : f32
                memref.atomic_yield %58 : f32
              }
            }
          }
          gpu.terminator
        } {SCFToGPU_visited}
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
    }
    %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
    %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
    memref.dealloc %alloc : memref<?xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
    return
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After GpuKernelOutlining (gpu-kernel-outlining) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c-1 = arith.constant -1 : index
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c256 = arith.constant 256 : index
    %c108 = arith.constant 108 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
    %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
    %2 = arith.index_cast %dim_0 : index to i32
    %3 = arith.index_cast %dim : index to i32
    %4 = arith.muli %2, %3 : i32
    %5 = arith.index_cast %4 : i32 to index
    %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
    %6 = arith.muli %dim_1, %5 : index
    %7 = arith.addi %6, %c-1 : index
    %8 = arith.divsi %7, %c256 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.subi %c0, %6 : index
    %11 = arith.divsi %10, %c256 : index
    %12 = arith.subi %c0, %11 : index
    %13 = arith.cmpi sgt, %6, %c0 : index
    %14 = arith.select %13, %9, %12 : index
    %15 = arith.cmpi sgt, %14, %c108 : index
    scf.if %15 {
      "lmhlo.fusion"() ({
        %c0_2 = arith.constant 0 : index
        %c256_3 = arith.constant 256 : index
        %18 = arith.muli %c1, %c256_3 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%5)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_2, %c1]
        gpu.launch_func  @main_kernel::@main_kernel blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
        %21 = arith.subi %dim_1, %c0 : index
        %22 = arith.ceildivsi %21, %c128 : index
        %c1_5 = arith.constant 1 : index
        %23 = arith.subi %5, %c0 : index
        %24 = arith.ceildivsi %23, %c2 : index
        %c1_6 = arith.constant 1 : index
        %c0_7 = arith.constant 0 : index
        %c1_8 = arith.constant 1 : index
        %c1_9 = arith.constant 1 : index
        %25 = arith.muli %c1_9, %22 : index
        %26 = arith.muli %25, %24 : index
        %c0_10 = arith.constant 0 : index
        %c256_11 = arith.constant 256 : index
        %27 = arith.muli %c1_8, %c256_11 : index
        %c1_12 = arith.constant 1 : index
        %28 = affine.apply #map(%26)[%c0_7, %27]
        %29 = affine.apply #map(%27)[%c0_10, %c1_8]
        gpu.launch_func  @main_kernel_0::@main_kernel blocks in (%28, %c1_12, %c1_12) threads in (%29, %c1_12, %c1_12) args(%1 : memref<?x?x?xf32, "gpu">, %27 : index, %26 : index, %24 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        %c0_2 = arith.constant 0 : index
        %c128_3 = arith.constant 128 : index
        %18 = arith.muli %c1, %c128_3 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%5)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_2, %c1]
        gpu.launch_func  @main_kernel_1::@main_kernel blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
        %21 = arith.subi %dim_1, %c0 : index
        %22 = arith.ceildivsi %21, %c128 : index
        %c1_5 = arith.constant 1 : index
        %23 = arith.subi %5, %c0 : index
        %24 = arith.ceildivsi %23, %c2 : index
        %c1_6 = arith.constant 1 : index
        %c0_7 = arith.constant 0 : index
        %c1_8 = arith.constant 1 : index
        %c1_9 = arith.constant 1 : index
        %25 = arith.muli %c1_9, %22 : index
        %26 = arith.muli %25, %24 : index
        %c0_10 = arith.constant 0 : index
        %c128_11 = arith.constant 128 : index
        %27 = arith.muli %c1_8, %c128_11 : index
        %c1_12 = arith.constant 1 : index
        %28 = affine.apply #map(%26)[%c0_7, %27]
        %29 = affine.apply #map(%27)[%c0_10, %c1_8]
        gpu.launch_func  @main_kernel_2::@main_kernel blocks in (%28, %c1_12, %c1_12) threads in (%29, %c1_12, %c1_12) args(%1 : memref<?x?x?xf32, "gpu">, %27 : index, %26 : index, %24 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
    }
    %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
    %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
    memref.dealloc %alloc : memref<?xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel {
    gpu.func @main_kernel(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %cst = arith.constant 0xFF800000 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast[%14] : memref<?xf32, "gpu">
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_0 {
    gpu.func @main_kernel(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c2 = arith.constant 2 : index
      %c128 = arith.constant 128 : index
      %c0_1 = arith.constant 0 : index
      %dim = memref.dim %arg0, %c0_1 : memref<?x?x?xf32, "gpu">
      %c1_2 = arith.constant 1 : index
      %dim_3 = memref.dim %arg0, %c1_2 : memref<?x?x?xf32, "gpu">
      %dim_4 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
      %cst = arith.constant 0xFF800000 : f32
      %12 = affine.apply #map1(%0)[%arg1, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg2 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remsi %14, %arg3 : index
        %20 = arith.divsi %14, %arg3 : index
        %21 = arith.muli %19, %c2 : index
        %22 = arith.muli %20, %c128 : index
        %23 = arith.addi %22, %c128 : index
        %24 = arith.cmpi slt, %23, %dim : index
        %25 = arith.remui %dim, %c128 : index
        %26 = arith.cmpi eq, %25, %c0_1 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.addi %21, %c2 : index
        %29 = arith.cmpi slt, %28, %arg4 : index
        %30 = arith.remui %arg4, %c2 : index
        %31 = arith.cmpi eq, %30, %c0_1 : index
        %32 = arith.ori %31, %29 : i1
        %33 = arith.andi %27, %32 : i1
        %34:2 = scf.if %33 -> (f32, f32) {
          %38:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
            %39 = arith.addi %22, %arg6 : index
            %40 = arith.muli %39, %arg4 : index
            %41 = arith.addi %40, %21 : index
            %42 = arith.muli %dim, %dim_3 : index
            %43 = arith.muli %42, %dim_4 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%43], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %44 = memref.load %reinterpret_cast[%41] : memref<?xf32, "gpu">
            %45 = math.absf %44 : f32
            %46 = arith.cmpf oge, %arg7, %45 : f32
            %47 = arith.select %46, %arg7, %45 : f32
            %48 = arith.addi %21, %c1_2 : index
            %49 = arith.addi %40, %48 : index
            %50 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
            %51 = math.absf %50 : f32
            %52 = arith.cmpf oge, %arg8, %51 : f32
            %53 = arith.select %52, %arg8, %51 : f32
            scf.yield %47, %53 : f32, f32
          }
          scf.yield %38#0, %38#1 : f32, f32
        } else {
          %38:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
            %39 = arith.addi %22, %arg6 : index
            %40 = arith.cmpi slt, %39, %dim : index
            %41 = arith.cmpi slt, %21, %arg4 : index
            %42 = arith.andi %40, %41 : i1
            %43 = scf.if %42 -> (f32) {
              %48 = arith.muli %39, %arg4 : index
              %49 = arith.addi %48, %21 : index
              %50 = arith.muli %dim, %dim_3 : index
              %51 = arith.muli %50, %dim_4 : index
              %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
              %53 = math.absf %52 : f32
              %54 = arith.cmpf oge, %arg7, %53 : f32
              %55 = arith.select %54, %arg7, %53 : f32
              scf.yield %55 : f32
            } else {
              scf.yield %arg7 : f32
            }
            %44 = arith.addi %21, %c1_2 : index
            %45 = arith.cmpi slt, %44, %arg4 : index
            %46 = arith.andi %40, %45 : i1
            %47 = scf.if %46 -> (f32) {
              %48 = arith.muli %39, %arg4 : index
              %49 = arith.addi %48, %44 : index
              %50 = arith.muli %dim, %dim_3 : index
              %51 = arith.muli %50, %dim_4 : index
              %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
              %53 = math.absf %52 : f32
              %54 = arith.cmpf oge, %arg8, %53 : f32
              %55 = arith.select %54, %arg8, %53 : f32
              scf.yield %55 : f32
            } else {
              scf.yield %arg8 : f32
            }
            scf.yield %43, %47 : f32, f32
          }
          scf.yield %38#0, %38#1 : f32, f32
        }
        %35 = arith.cmpi slt, %21, %arg4 : index
        scf.if %35 {
          %38 = memref.generic_atomic_rmw %arg5[%21] : memref<?xf32, "gpu"> {
          ^bb0(%arg6: f32):
            %39 = arith.cmpf ogt, %arg6, %34#0 : f32
            %40 = arith.select %39, %arg6, %34#0 : f32
            memref.atomic_yield %40 : f32
          }
        }
        %36 = arith.addi %21, %c1_2 : index
        %37 = arith.cmpi slt, %36, %arg4 : index
        scf.if %37 {
          %38 = memref.generic_atomic_rmw %arg5[%36] : memref<?xf32, "gpu"> {
          ^bb0(%arg6: f32):
            %39 = arith.cmpf ogt, %arg6, %34#1 : f32
            %40 = arith.select %39, %arg6, %34#1 : f32
            memref.atomic_yield %40 : f32
          }
        }
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_1 {
    gpu.func @main_kernel(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %cst = arith.constant 0xFF800000 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast[%14] : memref<?xf32, "gpu">
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_2 {
    gpu.func @main_kernel(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c2 = arith.constant 2 : index
      %c128 = arith.constant 128 : index
      %c0_1 = arith.constant 0 : index
      %dim = memref.dim %arg0, %c0_1 : memref<?x?x?xf32, "gpu">
      %c1_2 = arith.constant 1 : index
      %dim_3 = memref.dim %arg0, %c1_2 : memref<?x?x?xf32, "gpu">
      %dim_4 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
      %cst = arith.constant 0xFF800000 : f32
      %12 = affine.apply #map1(%0)[%arg1, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg2 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remsi %14, %arg3 : index
        %20 = arith.divsi %14, %arg3 : index
        %21 = arith.muli %19, %c2 : index
        %22 = arith.muli %20, %c128 : index
        %23 = arith.addi %22, %c128 : index
        %24 = arith.cmpi slt, %23, %dim : index
        %25 = arith.remui %dim, %c128 : index
        %26 = arith.cmpi eq, %25, %c0_1 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.addi %21, %c2 : index
        %29 = arith.cmpi slt, %28, %arg4 : index
        %30 = arith.remui %arg4, %c2 : index
        %31 = arith.cmpi eq, %30, %c0_1 : index
        %32 = arith.ori %31, %29 : i1
        %33 = arith.andi %27, %32 : i1
        %34:2 = scf.if %33 -> (f32, f32) {
          %38:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
            %39 = arith.addi %22, %arg6 : index
            %40 = arith.muli %39, %arg4 : index
            %41 = arith.addi %40, %21 : index
            %42 = arith.muli %dim, %dim_3 : index
            %43 = arith.muli %42, %dim_4 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%43], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %44 = memref.load %reinterpret_cast[%41] : memref<?xf32, "gpu">
            %45 = math.absf %44 : f32
            %46 = arith.cmpf oge, %arg7, %45 : f32
            %47 = arith.select %46, %arg7, %45 : f32
            %48 = arith.addi %21, %c1_2 : index
            %49 = arith.addi %40, %48 : index
            %50 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
            %51 = math.absf %50 : f32
            %52 = arith.cmpf oge, %arg8, %51 : f32
            %53 = arith.select %52, %arg8, %51 : f32
            scf.yield %47, %53 : f32, f32
          }
          scf.yield %38#0, %38#1 : f32, f32
        } else {
          %38:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
            %39 = arith.addi %22, %arg6 : index
            %40 = arith.cmpi slt, %39, %dim : index
            %41 = arith.cmpi slt, %21, %arg4 : index
            %42 = arith.andi %40, %41 : i1
            %43 = scf.if %42 -> (f32) {
              %48 = arith.muli %39, %arg4 : index
              %49 = arith.addi %48, %21 : index
              %50 = arith.muli %dim, %dim_3 : index
              %51 = arith.muli %50, %dim_4 : index
              %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
              %53 = math.absf %52 : f32
              %54 = arith.cmpf oge, %arg7, %53 : f32
              %55 = arith.select %54, %arg7, %53 : f32
              scf.yield %55 : f32
            } else {
              scf.yield %arg7 : f32
            }
            %44 = arith.addi %21, %c1_2 : index
            %45 = arith.cmpi slt, %44, %arg4 : index
            %46 = arith.andi %40, %45 : i1
            %47 = scf.if %46 -> (f32) {
              %48 = arith.muli %39, %arg4 : index
              %49 = arith.addi %48, %44 : index
              %50 = arith.muli %dim, %dim_3 : index
              %51 = arith.muli %50, %dim_4 : index
              %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
              %53 = math.absf %52 : f32
              %54 = arith.cmpf oge, %arg8, %53 : f32
              %55 = arith.select %54, %arg8, %53 : f32
              scf.yield %55 : f32
            } else {
              scf.yield %arg8 : f32
            }
            scf.yield %43, %47 : f32, f32
          }
          scf.yield %38#0, %38#1 : f32, f32
        }
        %35 = arith.cmpi slt, %21, %arg4 : index
        scf.if %35 {
          %38 = memref.generic_atomic_rmw %arg5[%21] : memref<?xf32, "gpu"> {
          ^bb0(%arg6: f32):
            %39 = arith.cmpf ogt, %arg6, %34#0 : f32
            %40 = arith.select %39, %arg6, %34#0 : f32
            memref.atomic_yield %40 : f32
          }
        }
        %36 = arith.addi %21, %c1_2 : index
        %37 = arith.cmpi slt, %36, %arg4 : index
        scf.if %37 {
          %38 = memref.generic_atomic_rmw %arg5[%36] : memref<?xf32, "gpu"> {
          ^bb0(%arg6: f32):
            %39 = arith.cmpf ogt, %arg6, %34#1 : f32
            %40 = arith.select %39, %arg6, %34#1 : f32
            memref.atomic_yield %40 : f32
          }
        }
      }
      gpu.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After AssignKernelNamePass (disc-assign-kernel-name) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c-1 = arith.constant -1 : index
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c256 = arith.constant 256 : index
    %c108 = arith.constant 108 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
    %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
    %2 = arith.index_cast %dim_0 : index to i32
    %3 = arith.index_cast %dim : index to i32
    %4 = arith.muli %2, %3 : i32
    %5 = arith.index_cast %4 : i32 to index
    %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
    %6 = arith.muli %dim_1, %5 : index
    %7 = arith.addi %6, %c-1 : index
    %8 = arith.divsi %7, %c256 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.subi %c0, %6 : index
    %11 = arith.divsi %10, %c256 : index
    %12 = arith.subi %c0, %11 : index
    %13 = arith.cmpi sgt, %6, %c0 : index
    %14 = arith.select %13, %9, %12 : index
    %15 = arith.cmpi sgt, %14, %c108 : index
    scf.if %15 {
      "lmhlo.fusion"() ({
        %c0_2 = arith.constant 0 : index
        %c256_3 = arith.constant 256 : index
        %18 = arith.muli %c1, %c256_3 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%5)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_2, %c1]
        gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
        %21 = arith.subi %dim_1, %c0 : index
        %22 = arith.ceildivsi %21, %c128 : index
        %c1_5 = arith.constant 1 : index
        %23 = arith.subi %5, %c0 : index
        %24 = arith.ceildivsi %23, %c2 : index
        %c1_6 = arith.constant 1 : index
        %c0_7 = arith.constant 0 : index
        %c1_8 = arith.constant 1 : index
        %c1_9 = arith.constant 1 : index
        %25 = arith.muli %c1_9, %22 : index
        %26 = arith.muli %25, %24 : index
        %c0_10 = arith.constant 0 : index
        %c256_11 = arith.constant 256 : index
        %27 = arith.muli %c1_8, %c256_11 : index
        %c1_12 = arith.constant 1 : index
        %28 = affine.apply #map(%26)[%c0_7, %27]
        %29 = affine.apply #map(%27)[%c0_10, %c1_8]
        gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%28, %c1_12, %c1_12) threads in (%29, %c1_12, %c1_12) args(%1 : memref<?x?x?xf32, "gpu">, %27 : index, %26 : index, %24 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w32h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 1 : i32, disc_thread_per_block_hint = 256 : i32} : () -> ()
    } else {
      "lmhlo.fusion"() ({
        %c0_2 = arith.constant 0 : index
        %c128_3 = arith.constant 128 : index
        %18 = arith.muli %c1, %c128_3 : index
        %c1_4 = arith.constant 1 : index
        %19 = affine.apply #map(%5)[%c0, %18]
        %20 = affine.apply #map(%18)[%c0_2, %c1]
        gpu.launch_func  @main_kernel_1::@main_kColReduction_reduce__4_1_0___8w16h blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
        %21 = arith.subi %dim_1, %c0 : index
        %22 = arith.ceildivsi %21, %c128 : index
        %c1_5 = arith.constant 1 : index
        %23 = arith.subi %5, %c0 : index
        %24 = arith.ceildivsi %23, %c2 : index
        %c1_6 = arith.constant 1 : index
        %c0_7 = arith.constant 0 : index
        %c1_8 = arith.constant 1 : index
        %c1_9 = arith.constant 1 : index
        %25 = arith.muli %c1_9, %22 : index
        %26 = arith.muli %25, %24 : index
        %c0_10 = arith.constant 0 : index
        %c128_11 = arith.constant 128 : index
        %27 = arith.muli %c1_8, %c128_11 : index
        %c1_12 = arith.constant 1 : index
        %28 = affine.apply #map(%26)[%c0_7, %27]
        %29 = affine.apply #map(%27)[%c0_10, %c1_8]
        gpu.launch_func  @main_kernel_2::@main_kColReduction_reduce__4_1_0___8w16h_1 blocks in (%28, %c1_12, %c1_12) threads in (%29, %c1_12, %c1_12) args(%1 : memref<?x?x?xf32, "gpu">, %27 : index, %26 : index, %24 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
        "lmhlo.terminator"() : () -> ()
      }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__4_1_0", disc.fusion.tag = "8w16h", disc.fusion_type = "kColReduction", disc_col_reduction_schedule_hint = 2 : i32, disc_thread_per_block_hint = 128 : i32} : () -> ()
    }
    %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
    %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
    memref.dealloc %alloc : memref<?xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel {
    gpu.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %cst = arith.constant 0xFF800000 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast[%14] : memref<?xf32, "gpu">
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_0 {
    gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c2 = arith.constant 2 : index
      %c128 = arith.constant 128 : index
      %c0_1 = arith.constant 0 : index
      %dim = memref.dim %arg0, %c0_1 : memref<?x?x?xf32, "gpu">
      %c1_2 = arith.constant 1 : index
      %dim_3 = memref.dim %arg0, %c1_2 : memref<?x?x?xf32, "gpu">
      %dim_4 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
      %cst = arith.constant 0xFF800000 : f32
      %12 = affine.apply #map1(%0)[%arg1, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg2 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remsi %14, %arg3 : index
        %20 = arith.divsi %14, %arg3 : index
        %21 = arith.muli %19, %c2 : index
        %22 = arith.muli %20, %c128 : index
        %23 = arith.addi %22, %c128 : index
        %24 = arith.cmpi slt, %23, %dim : index
        %25 = arith.remui %dim, %c128 : index
        %26 = arith.cmpi eq, %25, %c0_1 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.addi %21, %c2 : index
        %29 = arith.cmpi slt, %28, %arg4 : index
        %30 = arith.remui %arg4, %c2 : index
        %31 = arith.cmpi eq, %30, %c0_1 : index
        %32 = arith.ori %31, %29 : i1
        %33 = arith.andi %27, %32 : i1
        %34:2 = scf.if %33 -> (f32, f32) {
          %38:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
            %39 = arith.addi %22, %arg6 : index
            %40 = arith.muli %39, %arg4 : index
            %41 = arith.addi %40, %21 : index
            %42 = arith.muli %dim, %dim_3 : index
            %43 = arith.muli %42, %dim_4 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%43], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %44 = memref.load %reinterpret_cast[%41] : memref<?xf32, "gpu">
            %45 = math.absf %44 : f32
            %46 = arith.cmpf oge, %arg7, %45 : f32
            %47 = arith.select %46, %arg7, %45 : f32
            %48 = arith.addi %21, %c1_2 : index
            %49 = arith.addi %40, %48 : index
            %50 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
            %51 = math.absf %50 : f32
            %52 = arith.cmpf oge, %arg8, %51 : f32
            %53 = arith.select %52, %arg8, %51 : f32
            scf.yield %47, %53 : f32, f32
          }
          scf.yield %38#0, %38#1 : f32, f32
        } else {
          %38:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
            %39 = arith.addi %22, %arg6 : index
            %40 = arith.cmpi slt, %39, %dim : index
            %41 = arith.cmpi slt, %21, %arg4 : index
            %42 = arith.andi %40, %41 : i1
            %43 = scf.if %42 -> (f32) {
              %48 = arith.muli %39, %arg4 : index
              %49 = arith.addi %48, %21 : index
              %50 = arith.muli %dim, %dim_3 : index
              %51 = arith.muli %50, %dim_4 : index
              %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
              %53 = math.absf %52 : f32
              %54 = arith.cmpf oge, %arg7, %53 : f32
              %55 = arith.select %54, %arg7, %53 : f32
              scf.yield %55 : f32
            } else {
              scf.yield %arg7 : f32
            }
            %44 = arith.addi %21, %c1_2 : index
            %45 = arith.cmpi slt, %44, %arg4 : index
            %46 = arith.andi %40, %45 : i1
            %47 = scf.if %46 -> (f32) {
              %48 = arith.muli %39, %arg4 : index
              %49 = arith.addi %48, %44 : index
              %50 = arith.muli %dim, %dim_3 : index
              %51 = arith.muli %50, %dim_4 : index
              %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
              %53 = math.absf %52 : f32
              %54 = arith.cmpf oge, %arg8, %53 : f32
              %55 = arith.select %54, %arg8, %53 : f32
              scf.yield %55 : f32
            } else {
              scf.yield %arg8 : f32
            }
            scf.yield %43, %47 : f32, f32
          }
          scf.yield %38#0, %38#1 : f32, f32
        }
        %35 = arith.cmpi slt, %21, %arg4 : index
        scf.if %35 {
          %38 = memref.generic_atomic_rmw %arg5[%21] : memref<?xf32, "gpu"> {
          ^bb0(%arg6: f32):
            %39 = arith.cmpf ogt, %arg6, %34#0 : f32
            %40 = arith.select %39, %arg6, %34#0 : f32
            memref.atomic_yield %40 : f32
          }
        }
        %36 = arith.addi %21, %c1_2 : index
        %37 = arith.cmpi slt, %36, %arg4 : index
        scf.if %37 {
          %38 = memref.generic_atomic_rmw %arg5[%36] : memref<?xf32, "gpu"> {
          ^bb0(%arg6: f32):
            %39 = arith.cmpf ogt, %arg6, %34#1 : f32
            %40 = arith.select %39, %arg6, %34#1 : f32
            memref.atomic_yield %40 : f32
          }
        }
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_1 {
    gpu.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %cst = arith.constant 0xFF800000 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
        memref.store %cst, %reinterpret_cast[%14] : memref<?xf32, "gpu">
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_2 {
    gpu.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c2 = arith.constant 2 : index
      %c128 = arith.constant 128 : index
      %c0_1 = arith.constant 0 : index
      %dim = memref.dim %arg0, %c0_1 : memref<?x?x?xf32, "gpu">
      %c1_2 = arith.constant 1 : index
      %dim_3 = memref.dim %arg0, %c1_2 : memref<?x?x?xf32, "gpu">
      %dim_4 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
      %cst = arith.constant 0xFF800000 : f32
      %12 = affine.apply #map1(%0)[%arg1, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg2 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remsi %14, %arg3 : index
        %20 = arith.divsi %14, %arg3 : index
        %21 = arith.muli %19, %c2 : index
        %22 = arith.muli %20, %c128 : index
        %23 = arith.addi %22, %c128 : index
        %24 = arith.cmpi slt, %23, %dim : index
        %25 = arith.remui %dim, %c128 : index
        %26 = arith.cmpi eq, %25, %c0_1 : index
        %27 = arith.ori %26, %24 : i1
        %28 = arith.addi %21, %c2 : index
        %29 = arith.cmpi slt, %28, %arg4 : index
        %30 = arith.remui %arg4, %c2 : index
        %31 = arith.cmpi eq, %30, %c0_1 : index
        %32 = arith.ori %31, %29 : i1
        %33 = arith.andi %27, %32 : i1
        %34:2 = scf.if %33 -> (f32, f32) {
          %38:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
            %39 = arith.addi %22, %arg6 : index
            %40 = arith.muli %39, %arg4 : index
            %41 = arith.addi %40, %21 : index
            %42 = arith.muli %dim, %dim_3 : index
            %43 = arith.muli %42, %dim_4 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%43], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %44 = memref.load %reinterpret_cast[%41] : memref<?xf32, "gpu">
            %45 = math.absf %44 : f32
            %46 = arith.cmpf oge, %arg7, %45 : f32
            %47 = arith.select %46, %arg7, %45 : f32
            %48 = arith.addi %21, %c1_2 : index
            %49 = arith.addi %40, %48 : index
            %50 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
            %51 = math.absf %50 : f32
            %52 = arith.cmpf oge, %arg8, %51 : f32
            %53 = arith.select %52, %arg8, %51 : f32
            scf.yield %47, %53 : f32, f32
          }
          scf.yield %38#0, %38#1 : f32, f32
        } else {
          %38:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
            %39 = arith.addi %22, %arg6 : index
            %40 = arith.cmpi slt, %39, %dim : index
            %41 = arith.cmpi slt, %21, %arg4 : index
            %42 = arith.andi %40, %41 : i1
            %43 = scf.if %42 -> (f32) {
              %48 = arith.muli %39, %arg4 : index
              %49 = arith.addi %48, %21 : index
              %50 = arith.muli %dim, %dim_3 : index
              %51 = arith.muli %50, %dim_4 : index
              %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
              %53 = math.absf %52 : f32
              %54 = arith.cmpf oge, %arg7, %53 : f32
              %55 = arith.select %54, %arg7, %53 : f32
              scf.yield %55 : f32
            } else {
              scf.yield %arg7 : f32
            }
            %44 = arith.addi %21, %c1_2 : index
            %45 = arith.cmpi slt, %44, %arg4 : index
            %46 = arith.andi %40, %45 : i1
            %47 = scf.if %46 -> (f32) {
              %48 = arith.muli %39, %arg4 : index
              %49 = arith.addi %48, %44 : index
              %50 = arith.muli %dim, %dim_3 : index
              %51 = arith.muli %50, %dim_4 : index
              %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
              %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
              %53 = math.absf %52 : f32
              %54 = arith.cmpf oge, %arg8, %53 : f32
              %55 = arith.select %54, %arg8, %53 : f32
              scf.yield %55 : f32
            } else {
              scf.yield %arg8 : f32
            }
            scf.yield %43, %47 : f32, f32
          }
          scf.yield %38#0, %38#1 : f32, f32
        }
        %35 = arith.cmpi slt, %21, %arg4 : index
        scf.if %35 {
          %38 = memref.generic_atomic_rmw %arg5[%21] : memref<?xf32, "gpu"> {
          ^bb0(%arg6: f32):
            %39 = arith.cmpf ogt, %arg6, %34#0 : f32
            %40 = arith.select %39, %arg6, %34#0 : f32
            memref.atomic_yield %40 : f32
          }
        }
        %36 = arith.addi %21, %c1_2 : index
        %37 = arith.cmpi slt, %36, %arg4 : index
        scf.if %37 {
          %38 = memref.generic_atomic_rmw %arg5[%36] : memref<?xf32, "gpu"> {
          ^bb0(%arg6: f32):
            %39 = arith.cmpf ogt, %arg6, %34#1 : f32
            %40 = arith.select %39, %arg6, %34#1 : f32
            memref.atomic_yield %40 : f32
          }
        }
      }
      gpu.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After LhloFusionInlinerPass (lhlo-fusion-inliner) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    %c0_2 = arith.constant 0 : index
    %c256_3 = arith.constant 256 : index
    %18 = arith.muli %c1, %c256_3 : index
    %c1_4 = arith.constant 1 : index
    %19 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%5)[%c0, %18]
    %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0_2, %c1]
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %21 = arith.subi %dim_1, %c0 : index
    %22 = arith.ceildivsi %21, %c128 : index
    %c1_5 = arith.constant 1 : index
    %23 = arith.subi %5, %c0 : index
    %24 = arith.ceildivsi %23, %c2 : index
    %c1_6 = arith.constant 1 : index
    %c0_7 = arith.constant 0 : index
    %c1_8 = arith.constant 1 : index
    %c1_9 = arith.constant 1 : index
    %25 = arith.muli %c1_9, %22 : index
    %26 = arith.muli %25, %24 : index
    %c0_10 = arith.constant 0 : index
    %c256_11 = arith.constant 256 : index
    %27 = arith.muli %c1_8, %c256_11 : index
    %c1_12 = arith.constant 1 : index
    %28 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%26)[%c0_7, %27]
    %29 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%27)[%c0_10, %c1_8]
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%28, %c1_12, %c1_12) threads in (%29, %c1_12, %c1_12) args(%1 : memref<?x?x?xf32, "gpu">, %27 : index, %26 : index, %24 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
  } else {
    %c0_2 = arith.constant 0 : index
    %c128_3 = arith.constant 128 : index
    %18 = arith.muli %c1, %c128_3 : index
    %c1_4 = arith.constant 1 : index
    %19 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%5)[%c0, %18]
    %20 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%18)[%c0_2, %c1]
    gpu.launch_func  @main_kernel_1::@main_kColReduction_reduce__4_1_0___8w16h blocks in (%19, %c1_4, %c1_4) threads in (%20, %c1_4, %c1_4) args(%18 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %21 = arith.subi %dim_1, %c0 : index
    %22 = arith.ceildivsi %21, %c128 : index
    %c1_5 = arith.constant 1 : index
    %23 = arith.subi %5, %c0 : index
    %24 = arith.ceildivsi %23, %c2 : index
    %c1_6 = arith.constant 1 : index
    %c0_7 = arith.constant 0 : index
    %c1_8 = arith.constant 1 : index
    %c1_9 = arith.constant 1 : index
    %25 = arith.muli %c1_9, %22 : index
    %26 = arith.muli %25, %24 : index
    %c0_10 = arith.constant 0 : index
    %c128_11 = arith.constant 128 : index
    %27 = arith.muli %c1_8, %c128_11 : index
    %c1_12 = arith.constant 1 : index
    %28 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%26)[%c0_7, %27]
    %29 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%27)[%c0_10, %c1_8]
    gpu.launch_func  @main_kernel_2::@main_kColReduction_reduce__4_1_0___8w16h_1 blocks in (%28, %c1_12, %c1_12) threads in (%29, %c1_12, %c1_12) args(%1 : memref<?x?x?xf32, "gpu">, %27 : index, %26 : index, %24 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After SideEffectLoopInvariantCodeMotionPass (disc-side-effect-loop-invariant-code-motion) //----- //
gpu.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
  %cst = arith.constant 0xFF800000 : f32
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = gpu.block_id  x
  %1 = gpu.thread_id  x
  cf.br ^bb1
^bb1:  // pred: ^bb0
  %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
  %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
  %4 = arith.addi %3, %2 : index
  %5 = arith.addi %3, %2 : index
  %6 = arith.cmpi ult, %5, %arg1 : index
  scf.if %6 {
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%4] : memref<?xf32, "gpu">
  }
  gpu.return
}

// -----// IR Dump After CSE (cse) //----- //
gpu.module @main_kernel {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    scf.if %5 {
      %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%4] : memref<?xf32, "gpu">
    }
    gpu.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    cf.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%4] : memref<?xf32, "gpu">
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%6] : memref<?xf32, "gpu">
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%6] : memref<?xf32, "gpu">
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel {
  llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %5 = llvm.insertvalue %arg6, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %6 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %7 = llvm.mlir.constant(1 : index) : i32
    %8 = llvm.mlir.constant(0 : index) : i32
    %9 = nvvm.read.ptx.sreg.ctaid.x : i32
    %10 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %11 = llvm.mul %9, %arg0  : i32
    %12 = llvm.add %10, %11  : i32
    %13 = llvm.icmp "ult" %12, %arg1 : i32
    llvm.cond_br %13, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %14 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %15 = llvm.extractvalue %5[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %16 = llvm.extractvalue %5[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %17 = llvm.insertvalue %15, %14[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %18 = llvm.insertvalue %16, %17[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %19 = llvm.insertvalue %8, %18[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %20 = llvm.insertvalue %arg1, %19[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %21 = llvm.insertvalue %7, %20[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %22 = llvm.extractvalue %21[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %23 = llvm.getelementptr %22[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %6, %23 : !llvm.ptr<f32>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After LLVMInsertValueSimplifierPass (disc-llvm-insert-value-simplifier) //----- //
llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32) attributes {gpu.kernel, nvvm.kernel} {
  %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
  %1 = nvvm.read.ptx.sreg.ctaid.x : i32
  %2 = nvvm.read.ptx.sreg.tid.x : i32
  llvm.br ^bb1
^bb1:  // pred: ^bb0
  %3 = llvm.mul %1, %arg0  : i32
  %4 = llvm.add %2, %3  : i32
  %5 = llvm.icmp "ult" %4, %arg1 : i32
  llvm.cond_br %5, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %6 = llvm.getelementptr %arg3[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  llvm.store %0, %6 : !llvm.ptr<f32>
  llvm.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  llvm.return
}

// -----// IR Dump After FunctionDeadArgumentEliminationPass (disc-function-dead-argument-elimination) //----- //
gpu.module @main_kernel {
  llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %1 = nvvm.read.ptx.sreg.ctaid.x : i32
    %2 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.mul %1, %arg0  : i32
    %4 = llvm.add %2, %3  : i32
    %5 = llvm.icmp "ult" %4, %arg1 : i32
    llvm.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %0, %6 : !llvm.ptr<f32>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel attributes {gpu.binary = "P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
  llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %1 = nvvm.read.ptx.sreg.ctaid.x : i32
    %2 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.mul %1, %arg0  : i32
    %4 = llvm.add %2, %3  : i32
    %5 = llvm.icmp "ult" %4, %arg1 : i32
    llvm.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %0, %6 : !llvm.ptr<f32>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
    %0 = gpu.block_id  x
    %1 = gpu.block_id  y
    %2 = gpu.block_id  z
    %3 = gpu.thread_id  x
    %4 = gpu.thread_id  y
    %5 = gpu.thread_id  z
    %6 = gpu.grid_dim  x
    %7 = gpu.grid_dim  y
    %8 = gpu.grid_dim  z
    %9 = gpu.block_dim  x
    %10 = gpu.block_dim  y
    %11 = gpu.block_dim  z
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c0_0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c128 = arith.constant 128 : index
    %c0_1 = arith.constant 0 : index
    %dim = memref.dim %arg0, %c0_1 : memref<?x?x?xf32, "gpu">
    %c1_2 = arith.constant 1 : index
    %dim_3 = memref.dim %arg0, %c1_2 : memref<?x?x?xf32, "gpu">
    %dim_4 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %cst = arith.constant 0xFF800000 : f32
    %12 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg1, %c0]
    %13 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%3)[%c1, %c0_0]
    %14 = arith.addi %13, %12 : index
    %true = arith.constant true
    %15 = arith.muli %13, %c1 : index
    %16 = arith.addi %15, %12 : index
    %17 = arith.cmpi ult, %16, %arg2 : index
    %18 = arith.andi %true, %17 : i1
    scf.if %18 {
      %19 = arith.remsi %14, %arg3 : index
      %20 = arith.divsi %14, %arg3 : index
      %21 = arith.muli %19, %c2 : index
      %22 = arith.muli %20, %c128 : index
      %23 = arith.addi %22, %c128 : index
      %24 = arith.cmpi slt, %23, %dim : index
      %25 = arith.remui %dim, %c128 : index
      %26 = arith.cmpi eq, %25, %c0_1 : index
      %27 = arith.ori %26, %24 : i1
      %28 = arith.addi %21, %c2 : index
      %29 = arith.cmpi slt, %28, %arg4 : index
      %30 = arith.remui %arg4, %c2 : index
      %31 = arith.cmpi eq, %30, %c0_1 : index
      %32 = arith.ori %31, %29 : i1
      %33 = arith.andi %27, %32 : i1
      %34:2 = scf.if %33 -> (f32, f32) {
        %38 = arith.muli %dim, %dim_3 : index
        %39 = arith.muli %38, %dim_4 : index
        %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%39], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
        %40 = arith.addi %21, %c1_2 : index
        %41:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
          %42 = arith.addi %22, %arg6 : index
          %43 = arith.muli %42, %arg4 : index
          %44 = arith.addi %43, %21 : index
          %45 = memref.load %reinterpret_cast[%44] : memref<?xf32, "gpu">
          %46 = math.absf %45 : f32
          %47 = arith.cmpf oge, %arg7, %46 : f32
          %48 = arith.select %47, %arg7, %46 : f32
          %49 = arith.addi %43, %40 : index
          %50 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
          %51 = math.absf %50 : f32
          %52 = arith.cmpf oge, %arg8, %51 : f32
          %53 = arith.select %52, %arg8, %51 : f32
          scf.yield %48, %53 : f32, f32
        }
        scf.yield %41#0, %41#1 : f32, f32
      } else {
        %38 = arith.cmpi slt, %21, %arg4 : index
        %39 = arith.addi %21, %c1_2 : index
        %40 = arith.cmpi slt, %39, %arg4 : index
        %41:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
          %42 = arith.addi %22, %arg6 : index
          %43 = arith.cmpi slt, %42, %dim : index
          %44 = arith.andi %43, %38 : i1
          %45 = scf.if %44 -> (f32) {
            %48 = arith.muli %42, %arg4 : index
            %49 = arith.addi %48, %21 : index
            %50 = arith.muli %dim, %dim_3 : index
            %51 = arith.muli %50, %dim_4 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
            %53 = math.absf %52 : f32
            %54 = arith.cmpf oge, %arg7, %53 : f32
            %55 = arith.select %54, %arg7, %53 : f32
            scf.yield %55 : f32
          } else {
            scf.yield %arg7 : f32
          }
          %46 = arith.andi %43, %40 : i1
          %47 = scf.if %46 -> (f32) {
            %48 = arith.muli %42, %arg4 : index
            %49 = arith.addi %48, %39 : index
            %50 = arith.muli %dim, %dim_3 : index
            %51 = arith.muli %50, %dim_4 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
            %53 = math.absf %52 : f32
            %54 = arith.cmpf oge, %arg8, %53 : f32
            %55 = arith.select %54, %arg8, %53 : f32
            scf.yield %55 : f32
          } else {
            scf.yield %arg8 : f32
          }
          scf.yield %45, %47 : f32, f32
        }
        scf.yield %41#0, %41#1 : f32, f32
      }
      %35 = arith.cmpi slt, %21, %arg4 : index
      scf.if %35 {
        %38 = memref.generic_atomic_rmw %arg5[%21] : memref<?xf32, "gpu"> {
        ^bb0(%arg6: f32):
          %39 = arith.cmpf ogt, %arg6, %34#0 : f32
          %40 = arith.select %39, %arg6, %34#0 : f32
          memref.atomic_yield %40 : f32
        }
      }
      %36 = arith.addi %21, %c1_2 : index
      %37 = arith.cmpi slt, %36, %arg4 : index
      scf.if %37 {
        %38 = memref.generic_atomic_rmw %arg5[%36] : memref<?xf32, "gpu"> {
        ^bb0(%arg6: f32):
          %39 = arith.cmpf ogt, %arg6, %34#1 : f32
          %40 = arith.select %39, %arg6, %34#1 : f32
          memref.atomic_yield %40 : f32
        }
      }
    }
    gpu.return
  }
}

// -----// IR Dump After SideEffectLoopInvariantCodeMotionPass (disc-side-effect-loop-invariant-code-motion) //----- //
gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = gpu.block_id  x
  %1 = gpu.thread_id  x
  cf.br ^bb1
^bb1:  // pred: ^bb0
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
  %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg1, %c0]
  %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
  %4 = arith.addi %3, %2 : index
  %5 = arith.addi %3, %2 : index
  %6 = arith.cmpi ult, %5, %arg2 : index
  scf.if %6 {
    %7 = arith.remsi %4, %arg3 : index
    %8 = arith.divsi %4, %arg3 : index
    %9 = arith.muli %7, %c2 : index
    %10 = arith.muli %8, %c128 : index
    %11 = arith.addi %10, %c128 : index
    %12 = arith.cmpi slt, %11, %dim : index
    %13 = arith.remui %dim, %c128 : index
    %14 = arith.cmpi eq, %13, %c0 : index
    %15 = arith.ori %14, %12 : i1
    %16 = arith.addi %9, %c2 : index
    %17 = arith.cmpi slt, %16, %arg4 : index
    %18 = arith.remui %arg4, %c2 : index
    %19 = arith.cmpi eq, %18, %c0 : index
    %20 = arith.ori %19, %17 : i1
    %21 = arith.andi %15, %20 : i1
    %22:2 = scf.if %21 -> (f32, f32) {
      %26 = arith.muli %dim, %dim_0 : index
      %27 = arith.muli %26, %dim_1 : index
      %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%27], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
      %28 = arith.addi %9, %c1 : index
      %29:2 = scf.for %arg6 = %c0 to %c128 step %c1 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
        %30 = arith.addi %10, %arg6 : index
        %31 = arith.muli %30, %arg4 : index
        %32 = arith.addi %31, %9 : index
        %33 = memref.load %reinterpret_cast[%32] : memref<?xf32, "gpu">
        %34 = math.absf %33 : f32
        %35 = arith.cmpf oge, %arg7, %34 : f32
        %36 = arith.select %35, %arg7, %34 : f32
        %37 = arith.addi %31, %28 : index
        %38 = memref.load %reinterpret_cast[%37] : memref<?xf32, "gpu">
        %39 = math.absf %38 : f32
        %40 = arith.cmpf oge, %arg8, %39 : f32
        %41 = arith.select %40, %arg8, %39 : f32
        scf.yield %36, %41 : f32, f32
      }
      scf.yield %29#0, %29#1 : f32, f32
    } else {
      %26 = arith.cmpi slt, %9, %arg4 : index
      %27 = arith.addi %9, %c1 : index
      %28 = arith.cmpi slt, %27, %arg4 : index
      %29:2 = scf.for %arg6 = %c0 to %c128 step %c1 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
        %30 = arith.addi %10, %arg6 : index
        %31 = arith.cmpi slt, %30, %dim : index
        %32 = arith.andi %31, %26 : i1
        %33 = scf.if %32 -> (f32) {
          %36 = arith.muli %30, %arg4 : index
          %37 = arith.addi %36, %9 : index
          %38 = arith.muli %dim, %dim_0 : index
          %39 = arith.muli %38, %dim_1 : index
          %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%39], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
          %40 = memref.load %reinterpret_cast[%37] : memref<?xf32, "gpu">
          %41 = math.absf %40 : f32
          %42 = arith.cmpf oge, %arg7, %41 : f32
          %43 = arith.select %42, %arg7, %41 : f32
          scf.yield %43 : f32
        } else {
          scf.yield %arg7 : f32
        }
        %34 = arith.andi %31, %28 : i1
        %35 = scf.if %34 -> (f32) {
          %36 = arith.muli %30, %arg4 : index
          %37 = arith.addi %36, %27 : index
          %38 = arith.muli %dim, %dim_0 : index
          %39 = arith.muli %38, %dim_1 : index
          %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%39], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
          %40 = memref.load %reinterpret_cast[%37] : memref<?xf32, "gpu">
          %41 = math.absf %40 : f32
          %42 = arith.cmpf oge, %arg8, %41 : f32
          %43 = arith.select %42, %arg8, %41 : f32
          scf.yield %43 : f32
        } else {
          scf.yield %arg8 : f32
        }
        scf.yield %33, %35 : f32, f32
      }
      scf.yield %29#0, %29#1 : f32, f32
    }
    %23 = arith.cmpi slt, %9, %arg4 : index
    scf.if %23 {
      %26 = memref.generic_atomic_rmw %arg5[%9] : memref<?xf32, "gpu"> {
      ^bb0(%arg6: f32):
        %27 = arith.cmpf ogt, %arg6, %22#0 : f32
        %28 = arith.select %27, %arg6, %22#0 : f32
        memref.atomic_yield %28 : f32
      }
    }
    %24 = arith.addi %9, %c1 : index
    %25 = arith.cmpi slt, %24, %arg4 : index
    scf.if %25 {
      %26 = memref.generic_atomic_rmw %arg5[%24] : memref<?xf32, "gpu"> {
      ^bb0(%arg6: f32):
        %27 = arith.cmpf ogt, %arg6, %22#1 : f32
        %28 = arith.select %27, %arg6, %22#1 : f32
        memref.atomic_yield %28 : f32
      }
    }
  }
  gpu.return
}

// -----// IR Dump After CSE (cse) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg1, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg2 : index
    scf.if %5 {
      %6 = arith.remsi %4, %arg3 : index
      %7 = arith.divsi %4, %arg3 : index
      %8 = arith.muli %6, %c2 : index
      %9 = arith.muli %7, %c128 : index
      %10 = arith.addi %9, %c128 : index
      %11 = arith.cmpi slt, %10, %dim : index
      %12 = arith.remui %dim, %c128 : index
      %13 = arith.cmpi eq, %12, %c0 : index
      %14 = arith.ori %13, %11 : i1
      %15 = arith.addi %8, %c2 : index
      %16 = arith.cmpi slt, %15, %arg4 : index
      %17 = arith.remui %arg4, %c2 : index
      %18 = arith.cmpi eq, %17, %c0 : index
      %19 = arith.ori %18, %16 : i1
      %20 = arith.andi %14, %19 : i1
      %21:2 = scf.if %20 -> (f32, f32) {
        %25 = arith.muli %dim, %dim_0 : index
        %26 = arith.muli %25, %dim_1 : index
        %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%26], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
        %27 = arith.addi %8, %c1 : index
        %28:2 = scf.for %arg6 = %c0 to %c128 step %c1 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
          %29 = arith.addi %9, %arg6 : index
          %30 = arith.muli %29, %arg4 : index
          %31 = arith.addi %30, %8 : index
          %32 = memref.load %reinterpret_cast[%31] : memref<?xf32, "gpu">
          %33 = math.absf %32 : f32
          %34 = arith.cmpf oge, %arg7, %33 : f32
          %35 = arith.select %34, %arg7, %33 : f32
          %36 = arith.addi %30, %27 : index
          %37 = memref.load %reinterpret_cast[%36] : memref<?xf32, "gpu">
          %38 = math.absf %37 : f32
          %39 = arith.cmpf oge, %arg8, %38 : f32
          %40 = arith.select %39, %arg8, %38 : f32
          scf.yield %35, %40 : f32, f32
        }
        scf.yield %28#0, %28#1 : f32, f32
      } else {
        %25 = arith.cmpi slt, %8, %arg4 : index
        %26 = arith.addi %8, %c1 : index
        %27 = arith.cmpi slt, %26, %arg4 : index
        %28:2 = scf.for %arg6 = %c0 to %c128 step %c1 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
          %29 = arith.addi %9, %arg6 : index
          %30 = arith.cmpi slt, %29, %dim : index
          %31 = arith.andi %30, %25 : i1
          %32 = scf.if %31 -> (f32) {
            %35 = arith.muli %29, %arg4 : index
            %36 = arith.addi %35, %8 : index
            %37 = arith.muli %dim, %dim_0 : index
            %38 = arith.muli %37, %dim_1 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%38], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %39 = memref.load %reinterpret_cast[%36] : memref<?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg7, %40 : f32
            %42 = arith.select %41, %arg7, %40 : f32
            scf.yield %42 : f32
          } else {
            scf.yield %arg7 : f32
          }
          %33 = arith.andi %30, %27 : i1
          %34 = scf.if %33 -> (f32) {
            %35 = arith.muli %29, %arg4 : index
            %36 = arith.addi %35, %26 : index
            %37 = arith.muli %dim, %dim_0 : index
            %38 = arith.muli %37, %dim_1 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%38], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %39 = memref.load %reinterpret_cast[%36] : memref<?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg8, %40 : f32
            %42 = arith.select %41, %arg8, %40 : f32
            scf.yield %42 : f32
          } else {
            scf.yield %arg8 : f32
          }
          scf.yield %32, %34 : f32, f32
        }
        scf.yield %28#0, %28#1 : f32, f32
      }
      %22 = arith.cmpi slt, %8, %arg4 : index
      scf.if %22 {
        %25 = memref.generic_atomic_rmw %arg5[%8] : memref<?xf32, "gpu"> {
        ^bb0(%arg6: f32):
          %26 = arith.cmpf ogt, %arg6, %21#0 : f32
          %27 = arith.select %26, %arg6, %21#0 : f32
          memref.atomic_yield %27 : f32
        }
      }
      %23 = arith.addi %8, %c1 : index
      %24 = arith.cmpi slt, %23, %arg4 : index
      scf.if %24 {
        %25 = memref.generic_atomic_rmw %arg5[%23] : memref<?xf32, "gpu"> {
        ^bb0(%arg6: f32):
          %26 = arith.cmpf ogt, %arg6, %21#1 : f32
          %27 = arith.select %26, %arg6, %21#1 : f32
          memref.atomic_yield %27 : f32
        }
      }
    }
    gpu.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg1, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg2 : index
    cf.cond_br %5, ^bb2, ^bb25
  ^bb2:  // pred: ^bb1
    %6 = arith.remsi %4, %arg3 : index
    %7 = arith.divsi %4, %arg3 : index
    %8 = arith.muli %6, %c2 : index
    %9 = arith.muli %7, %c128 : index
    %10 = arith.addi %9, %c128 : index
    %11 = arith.cmpi slt, %10, %dim : index
    %12 = arith.remui %dim, %c128 : index
    %13 = arith.cmpi eq, %12, %c0 : index
    %14 = arith.ori %13, %11 : i1
    %15 = arith.addi %8, %c2 : index
    %16 = arith.cmpi slt, %15, %arg4 : index
    %17 = arith.remui %arg4, %c2 : index
    %18 = arith.cmpi eq, %17, %c0 : index
    %19 = arith.ori %18, %16 : i1
    %20 = arith.andi %14, %19 : i1
    cf.cond_br %20, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %21 = arith.muli %dim, %dim_0 : index
    %22 = arith.muli %21, %dim_1 : index
    %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%22], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %23 = arith.addi %8, %c1 : index
    cf.br ^bb4(%c0, %cst, %cst : index, f32, f32)
  ^bb4(%24: index, %25: f32, %26: f32):  // 2 preds: ^bb3, ^bb5
    %27 = arith.cmpi slt, %24, %c128 : index
    cf.cond_br %27, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    %28 = arith.addi %9, %24 : index
    %29 = arith.muli %28, %arg4 : index
    %30 = arith.addi %29, %8 : index
    %31 = memref.load %reinterpret_cast[%30] : memref<?xf32, "gpu">
    %32 = math.absf %31 : f32
    %33 = arith.cmpf oge, %25, %32 : f32
    %34 = arith.select %33, %25, %32 : f32
    %35 = arith.addi %29, %23 : index
    %36 = memref.load %reinterpret_cast[%35] : memref<?xf32, "gpu">
    %37 = math.absf %36 : f32
    %38 = arith.cmpf oge, %26, %37 : f32
    %39 = arith.select %38, %26, %37 : f32
    %40 = arith.addi %24, %c1 : index
    cf.br ^bb4(%40, %34, %39 : index, f32, f32)
  ^bb6:  // pred: ^bb4
    cf.br ^bb19(%25, %26 : f32, f32)
  ^bb7:  // pred: ^bb2
    %41 = arith.cmpi slt, %8, %arg4 : index
    %42 = arith.addi %8, %c1 : index
    %43 = arith.cmpi slt, %42, %arg4 : index
    cf.br ^bb8(%c0, %cst, %cst : index, f32, f32)
  ^bb8(%44: index, %45: f32, %46: f32):  // 2 preds: ^bb7, ^bb17
    %47 = arith.cmpi slt, %44, %c128 : index
    cf.cond_br %47, ^bb9, ^bb18
  ^bb9:  // pred: ^bb8
    %48 = arith.addi %9, %44 : index
    %49 = arith.cmpi slt, %48, %dim : index
    %50 = arith.andi %49, %41 : i1
    cf.cond_br %50, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %51 = arith.muli %48, %arg4 : index
    %52 = arith.addi %51, %8 : index
    %53 = arith.muli %dim, %dim_0 : index
    %54 = arith.muli %53, %dim_1 : index
    %reinterpret_cast_2 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%54], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %55 = memref.load %reinterpret_cast_2[%52] : memref<?xf32, "gpu">
    %56 = math.absf %55 : f32
    %57 = arith.cmpf oge, %45, %56 : f32
    %58 = arith.select %57, %45, %56 : f32
    cf.br ^bb12(%58 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%45 : f32)
  ^bb12(%59: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %60 = arith.andi %49, %43 : i1
    cf.cond_br %60, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %61 = arith.muli %48, %arg4 : index
    %62 = arith.addi %61, %42 : index
    %63 = arith.muli %dim, %dim_0 : index
    %64 = arith.muli %63, %dim_1 : index
    %reinterpret_cast_3 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%64], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %65 = memref.load %reinterpret_cast_3[%62] : memref<?xf32, "gpu">
    %66 = math.absf %65 : f32
    %67 = arith.cmpf oge, %46, %66 : f32
    %68 = arith.select %67, %46, %66 : f32
    cf.br ^bb16(%68 : f32)
  ^bb15:  // pred: ^bb13
    cf.br ^bb16(%46 : f32)
  ^bb16(%69: f32):  // 2 preds: ^bb14, ^bb15
    cf.br ^bb17
  ^bb17:  // pred: ^bb16
    %70 = arith.addi %44, %c1 : index
    cf.br ^bb8(%70, %59, %69 : index, f32, f32)
  ^bb18:  // pred: ^bb8
    cf.br ^bb19(%45, %46 : f32, f32)
  ^bb19(%71: f32, %72: f32):  // 2 preds: ^bb6, ^bb18
    cf.br ^bb20
  ^bb20:  // pred: ^bb19
    %73 = arith.cmpi slt, %8, %arg4 : index
    cf.cond_br %73, ^bb21, ^bb22
  ^bb21:  // pred: ^bb20
    %74 = memref.generic_atomic_rmw %arg5[%8] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %78 = arith.cmpf ogt, %arg6, %71 : f32
      %79 = arith.select %78, %arg6, %71 : f32
      memref.atomic_yield %79 : f32
    }
    cf.br ^bb22
  ^bb22:  // 2 preds: ^bb20, ^bb21
    %75 = arith.addi %8, %c1 : index
    %76 = arith.cmpi slt, %75, %arg4 : index
    cf.cond_br %76, ^bb23, ^bb24
  ^bb23:  // pred: ^bb22
    %77 = memref.generic_atomic_rmw %arg5[%75] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %78 = arith.cmpf ogt, %arg6, %72 : f32
      %79 = arith.select %78, %arg6, %72 : f32
      memref.atomic_yield %79 : f32
    }
    cf.br ^bb24
  ^bb24:  // 2 preds: ^bb22, ^bb23
    cf.br ^bb25
  ^bb25:  // 2 preds: ^bb1, ^bb24
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %2 = arith.muli %0, %arg1 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg2 : index
    cf.cond_br %7, ^bb2, ^bb25
  ^bb2:  // pred: ^bb1
    %8 = arith.remsi %6, %arg3 : index
    %9 = arith.divsi %6, %arg3 : index
    %10 = arith.muli %8, %c2 : index
    %11 = arith.muli %9, %c128 : index
    %12 = arith.addi %11, %c128 : index
    %13 = arith.cmpi slt, %12, %dim : index
    %14 = arith.remui %dim, %c128 : index
    %15 = arith.cmpi eq, %14, %c0 : index
    %16 = arith.ori %15, %13 : i1
    %17 = arith.addi %10, %c2 : index
    %18 = arith.cmpi slt, %17, %arg4 : index
    %19 = arith.remui %arg4, %c2 : index
    %20 = arith.cmpi eq, %19, %c0 : index
    %21 = arith.ori %20, %18 : i1
    %22 = arith.andi %16, %21 : i1
    cf.cond_br %22, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %23 = arith.muli %dim, %dim_0 : index
    %24 = arith.muli %23, %dim_1 : index
    %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %25 = arith.addi %10, %c1 : index
    cf.br ^bb4(%c0, %cst, %cst : index, f32, f32)
  ^bb4(%26: index, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
    %29 = arith.cmpi slt, %26, %c128 : index
    cf.cond_br %29, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    %30 = arith.addi %11, %26 : index
    %31 = arith.muli %30, %arg4 : index
    %32 = arith.addi %31, %10 : index
    %33 = memref.load %reinterpret_cast[%32] : memref<?xf32, "gpu">
    %34 = math.absf %33 : f32
    %35 = arith.cmpf oge, %27, %34 : f32
    %36 = arith.select %35, %27, %34 : f32
    %37 = arith.addi %31, %25 : index
    %38 = memref.load %reinterpret_cast[%37] : memref<?xf32, "gpu">
    %39 = math.absf %38 : f32
    %40 = arith.cmpf oge, %28, %39 : f32
    %41 = arith.select %40, %28, %39 : f32
    %42 = arith.addi %26, %c1 : index
    cf.br ^bb4(%42, %36, %41 : index, f32, f32)
  ^bb6:  // pred: ^bb4
    cf.br ^bb19(%27, %28 : f32, f32)
  ^bb7:  // pred: ^bb2
    %43 = arith.cmpi slt, %10, %arg4 : index
    %44 = arith.addi %10, %c1 : index
    %45 = arith.cmpi slt, %44, %arg4 : index
    cf.br ^bb8(%c0, %cst, %cst : index, f32, f32)
  ^bb8(%46: index, %47: f32, %48: f32):  // 2 preds: ^bb7, ^bb17
    %49 = arith.cmpi slt, %46, %c128 : index
    cf.cond_br %49, ^bb9, ^bb18
  ^bb9:  // pred: ^bb8
    %50 = arith.addi %11, %46 : index
    %51 = arith.cmpi slt, %50, %dim : index
    %52 = arith.andi %51, %43 : i1
    cf.cond_br %52, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %53 = arith.muli %50, %arg4 : index
    %54 = arith.addi %53, %10 : index
    %55 = arith.muli %dim, %dim_0 : index
    %56 = arith.muli %55, %dim_1 : index
    %reinterpret_cast_2 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%56], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %57 = memref.load %reinterpret_cast_2[%54] : memref<?xf32, "gpu">
    %58 = math.absf %57 : f32
    %59 = arith.cmpf oge, %47, %58 : f32
    %60 = arith.select %59, %47, %58 : f32
    cf.br ^bb12(%60 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%47 : f32)
  ^bb12(%61: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %62 = arith.andi %51, %45 : i1
    cf.cond_br %62, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %63 = arith.muli %50, %arg4 : index
    %64 = arith.addi %63, %44 : index
    %65 = arith.muli %dim, %dim_0 : index
    %66 = arith.muli %65, %dim_1 : index
    %reinterpret_cast_3 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%66], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %67 = memref.load %reinterpret_cast_3[%64] : memref<?xf32, "gpu">
    %68 = math.absf %67 : f32
    %69 = arith.cmpf oge, %48, %68 : f32
    %70 = arith.select %69, %48, %68 : f32
    cf.br ^bb16(%70 : f32)
  ^bb15:  // pred: ^bb13
    cf.br ^bb16(%48 : f32)
  ^bb16(%71: f32):  // 2 preds: ^bb14, ^bb15
    cf.br ^bb17
  ^bb17:  // pred: ^bb16
    %72 = arith.addi %46, %c1 : index
    cf.br ^bb8(%72, %61, %71 : index, f32, f32)
  ^bb18:  // pred: ^bb8
    cf.br ^bb19(%47, %48 : f32, f32)
  ^bb19(%73: f32, %74: f32):  // 2 preds: ^bb6, ^bb18
    cf.br ^bb20
  ^bb20:  // pred: ^bb19
    %75 = arith.cmpi slt, %10, %arg4 : index
    cf.cond_br %75, ^bb21, ^bb22
  ^bb21:  // pred: ^bb20
    %76 = memref.generic_atomic_rmw %arg5[%10] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %80 = arith.cmpf ogt, %arg6, %73 : f32
      %81 = arith.select %80, %arg6, %73 : f32
      memref.atomic_yield %81 : f32
    }
    cf.br ^bb22
  ^bb22:  // 2 preds: ^bb20, ^bb21
    %77 = arith.addi %10, %c1 : index
    %78 = arith.cmpi slt, %77, %arg4 : index
    cf.cond_br %78, ^bb23, ^bb24
  ^bb23:  // pred: ^bb22
    %79 = memref.generic_atomic_rmw %arg5[%77] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %80 = arith.cmpf ogt, %arg6, %74 : f32
      %81 = arith.select %80, %arg6, %74 : f32
      memref.atomic_yield %81 : f32
    }
    cf.br ^bb24
  ^bb24:  // 2 preds: ^bb22, ^bb23
    cf.br ^bb25
  ^bb25:  // 2 preds: ^bb1, ^bb24
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %2 = arith.muli %0, %arg1 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg2 : index
    cf.cond_br %7, ^bb2, ^bb25
  ^bb2:  // pred: ^bb1
    %8 = arith.remsi %6, %arg3 : index
    %9 = arith.divsi %6, %arg3 : index
    %10 = arith.muli %8, %c2 : index
    %11 = arith.muli %9, %c128 : index
    %12 = arith.addi %11, %c128 : index
    %13 = arith.cmpi slt, %12, %dim : index
    %14 = arith.remui %dim, %c128 : index
    %15 = arith.cmpi eq, %14, %c0 : index
    %16 = arith.ori %15, %13 : i1
    %17 = arith.addi %10, %c2 : index
    %18 = arith.cmpi slt, %17, %arg4 : index
    %19 = arith.remui %arg4, %c2 : index
    %20 = arith.cmpi eq, %19, %c0 : index
    %21 = arith.ori %20, %18 : i1
    %22 = arith.andi %16, %21 : i1
    cf.cond_br %22, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %23 = arith.muli %dim, %dim_0 : index
    %24 = arith.muli %23, %dim_1 : index
    %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %25 = arith.addi %10, %c1 : index
    cf.br ^bb4(%c0, %cst, %cst : index, f32, f32)
  ^bb4(%26: index, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
    %29 = arith.cmpi slt, %26, %c128 : index
    cf.cond_br %29, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    %30 = arith.addi %11, %26 : index
    %31 = arith.muli %30, %arg4 : index
    %32 = arith.addi %31, %10 : index
    %33 = memref.load %reinterpret_cast[%32] : memref<?xf32, "gpu">
    %34 = math.absf %33 : f32
    %35 = arith.cmpf oge, %27, %34 : f32
    %36 = arith.select %35, %27, %34 : f32
    %37 = arith.addi %31, %25 : index
    %38 = memref.load %reinterpret_cast[%37] : memref<?xf32, "gpu">
    %39 = math.absf %38 : f32
    %40 = arith.cmpf oge, %28, %39 : f32
    %41 = arith.select %40, %28, %39 : f32
    %42 = arith.addi %26, %c1 : index
    cf.br ^bb4(%42, %36, %41 : index, f32, f32)
  ^bb6:  // pred: ^bb4
    cf.br ^bb19(%27, %28 : f32, f32)
  ^bb7:  // pred: ^bb2
    %43 = arith.cmpi slt, %10, %arg4 : index
    %44 = arith.addi %10, %c1 : index
    %45 = arith.cmpi slt, %44, %arg4 : index
    cf.br ^bb8(%c0, %cst, %cst : index, f32, f32)
  ^bb8(%46: index, %47: f32, %48: f32):  // 2 preds: ^bb7, ^bb17
    %49 = arith.cmpi slt, %46, %c128 : index
    cf.cond_br %49, ^bb9, ^bb18
  ^bb9:  // pred: ^bb8
    %50 = arith.addi %11, %46 : index
    %51 = arith.cmpi slt, %50, %dim : index
    %52 = arith.andi %51, %43 : i1
    cf.cond_br %52, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %53 = arith.muli %50, %arg4 : index
    %54 = arith.addi %53, %10 : index
    %55 = arith.muli %dim, %dim_0 : index
    %56 = arith.muli %55, %dim_1 : index
    %reinterpret_cast_2 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%56], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %57 = memref.load %reinterpret_cast_2[%54] : memref<?xf32, "gpu">
    %58 = math.absf %57 : f32
    %59 = arith.cmpf oge, %47, %58 : f32
    %60 = arith.select %59, %47, %58 : f32
    cf.br ^bb12(%60 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%47 : f32)
  ^bb12(%61: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %62 = arith.andi %51, %45 : i1
    cf.cond_br %62, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %63 = arith.muli %50, %arg4 : index
    %64 = arith.addi %63, %44 : index
    %65 = arith.muli %dim, %dim_0 : index
    %66 = arith.muli %65, %dim_1 : index
    %reinterpret_cast_3 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%66], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %67 = memref.load %reinterpret_cast_3[%64] : memref<?xf32, "gpu">
    %68 = math.absf %67 : f32
    %69 = arith.cmpf oge, %48, %68 : f32
    %70 = arith.select %69, %48, %68 : f32
    cf.br ^bb16(%70 : f32)
  ^bb15:  // pred: ^bb13
    cf.br ^bb16(%48 : f32)
  ^bb16(%71: f32):  // 2 preds: ^bb14, ^bb15
    cf.br ^bb17
  ^bb17:  // pred: ^bb16
    %72 = arith.addi %46, %c1 : index
    cf.br ^bb8(%72, %61, %71 : index, f32, f32)
  ^bb18:  // pred: ^bb8
    cf.br ^bb19(%47, %48 : f32, f32)
  ^bb19(%73: f32, %74: f32):  // 2 preds: ^bb6, ^bb18
    cf.br ^bb20
  ^bb20:  // pred: ^bb19
    %75 = arith.cmpi slt, %10, %arg4 : index
    cf.cond_br %75, ^bb21, ^bb22
  ^bb21:  // pred: ^bb20
    %76 = memref.generic_atomic_rmw %arg5[%10] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %80 = arith.cmpf ogt, %arg6, %73 : f32
      %81 = arith.select %80, %arg6, %73 : f32
      memref.atomic_yield %81 : f32
    }
    cf.br ^bb22
  ^bb22:  // 2 preds: ^bb20, ^bb21
    %77 = arith.addi %10, %c1 : index
    %78 = arith.cmpi slt, %77, %arg4 : index
    cf.cond_br %78, ^bb23, ^bb24
  ^bb23:  // pred: ^bb22
    %79 = memref.generic_atomic_rmw %arg5[%77] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %80 = arith.cmpf ogt, %arg6, %74 : f32
      %81 = arith.select %80, %arg6, %74 : f32
      memref.atomic_yield %81 : f32
    }
    cf.br ^bb24
  ^bb24:  // 2 preds: ^bb22, ^bb23
    cf.br ^bb25
  ^bb25:  // 2 preds: ^bb1, ^bb24
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel_0 {
  llvm.func @__nv_fabsf(f32) -> f32
  llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: !llvm.ptr<f32>, %arg1: !llvm.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: !llvm.ptr<f32>, %arg14: !llvm.ptr<f32>, %arg15: i32, %arg16: i32, %arg17: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)>
    %1 = llvm.insertvalue %arg0, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %2 = llvm.insertvalue %arg1, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %3 = llvm.insertvalue %arg2, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %4 = llvm.insertvalue %arg3, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %5 = llvm.insertvalue %arg6, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %6 = llvm.insertvalue %arg4, %5[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %7 = llvm.insertvalue %arg7, %6[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %8 = llvm.insertvalue %arg5, %7[3, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %9 = llvm.insertvalue %arg8, %8[4, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %10 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %11 = llvm.insertvalue %arg13, %10[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %12 = llvm.insertvalue %arg14, %11[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %13 = llvm.insertvalue %arg15, %12[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %14 = llvm.insertvalue %arg16, %13[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %15 = llvm.insertvalue %arg17, %14[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %16 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %17 = llvm.mlir.constant(128 : index) : i32
    %18 = llvm.mlir.constant(2 : index) : i32
    %19 = llvm.mlir.constant(1 : index) : i32
    %20 = llvm.mlir.constant(0 : index) : i32
    %21 = nvvm.read.ptx.sreg.ctaid.x : i32
    %22 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %23 = llvm.extractvalue %9[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %24 = llvm.extractvalue %9[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %25 = llvm.extractvalue %9[3, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %26 = llvm.mul %21, %arg9  : i32
    %27 = llvm.add %22, %26  : i32
    %28 = llvm.icmp "ult" %27, %arg10 : i32
    llvm.cond_br %28, ^bb2, ^bb28
  ^bb2:  // pred: ^bb1
    %29 = llvm.srem %27, %arg11  : i32
    %30 = llvm.sdiv %27, %arg11  : i32
    %31 = llvm.mul %29, %18  : i32
    %32 = llvm.mul %30, %17  : i32
    %33 = llvm.add %32, %17  : i32
    %34 = llvm.icmp "slt" %33, %23 : i32
    %35 = llvm.urem %23, %17  : i32
    %36 = llvm.icmp "eq" %35, %20 : i32
    %37 = llvm.or %36, %34  : i1
    %38 = llvm.add %31, %18  : i32
    %39 = llvm.icmp "slt" %38, %arg12 : i32
    %40 = llvm.urem %arg12, %18  : i32
    %41 = llvm.icmp "eq" %40, %20 : i32
    %42 = llvm.or %41, %39  : i1
    %43 = llvm.and %37, %42  : i1
    llvm.cond_br %43, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %44 = llvm.mul %23, %24  : i32
    %45 = llvm.mul %44, %25  : i32
    %46 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %47 = llvm.extractvalue %9[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %48 = llvm.extractvalue %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %49 = llvm.insertvalue %47, %46[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %50 = llvm.insertvalue %48, %49[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %51 = llvm.insertvalue %20, %50[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %52 = llvm.insertvalue %45, %51[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %53 = llvm.insertvalue %19, %52[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %54 = llvm.add %31, %19  : i32
    llvm.br ^bb4(%20, %16, %16 : i32, f32, f32)
  ^bb4(%55: i32, %56: f32, %57: f32):  // 2 preds: ^bb3, ^bb5
    %58 = llvm.icmp "slt" %55, %17 : i32
    llvm.cond_br %58, ^bb5, ^bb6(%56, %57 : f32, f32)
  ^bb5:  // pred: ^bb4
    %59 = llvm.add %32, %55  : i32
    %60 = llvm.mul %59, %arg12  : i32
    %61 = llvm.add %60, %31  : i32
    %62 = llvm.extractvalue %53[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %63 = llvm.getelementptr %62[%61] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %64 = llvm.load %63 : !llvm.ptr<f32>
    %65 = llvm.call @__nv_fabsf(%64) : (f32) -> f32
    %66 = llvm.fcmp "oge" %56, %65 : f32
    %67 = llvm.select %66, %56, %65 : i1, f32
    %68 = llvm.add %60, %54  : i32
    %69 = llvm.extractvalue %53[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %70 = llvm.getelementptr %69[%68] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %71 = llvm.load %70 : !llvm.ptr<f32>
    %72 = llvm.call @__nv_fabsf(%71) : (f32) -> f32
    %73 = llvm.fcmp "oge" %57, %72 : f32
    %74 = llvm.select %73, %57, %72 : i1, f32
    %75 = llvm.add %55, %19  : i32
    llvm.br ^bb4(%75, %67, %74 : i32, f32, f32)
  ^bb6(%76: f32, %77: f32):  // 2 preds: ^bb4, ^bb8
    llvm.br ^bb18(%76, %77 : f32, f32)
  ^bb7:  // pred: ^bb2
    %78 = llvm.icmp "slt" %31, %arg12 : i32
    %79 = llvm.add %31, %19  : i32
    %80 = llvm.icmp "slt" %79, %arg12 : i32
    llvm.br ^bb8(%20, %16, %16 : i32, f32, f32)
  ^bb8(%81: i32, %82: f32, %83: f32):  // 2 preds: ^bb7, ^bb17
    %84 = llvm.icmp "slt" %81, %17 : i32
    llvm.cond_br %84, ^bb9, ^bb6(%82, %83 : f32, f32)
  ^bb9:  // pred: ^bb8
    %85 = llvm.add %32, %81  : i32
    %86 = llvm.icmp "slt" %85, %23 : i32
    %87 = llvm.and %86, %78  : i1
    llvm.cond_br %87, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %88 = llvm.mul %85, %arg12  : i32
    %89 = llvm.add %88, %31  : i32
    %90 = llvm.mul %23, %24  : i32
    %91 = llvm.mul %90, %25  : i32
    %92 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %93 = llvm.extractvalue %9[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %94 = llvm.extractvalue %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %95 = llvm.insertvalue %93, %92[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %96 = llvm.insertvalue %94, %95[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %97 = llvm.insertvalue %20, %96[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %98 = llvm.insertvalue %91, %97[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %99 = llvm.insertvalue %19, %98[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %100 = llvm.extractvalue %99[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %101 = llvm.getelementptr %100[%89] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %102 = llvm.load %101 : !llvm.ptr<f32>
    %103 = llvm.call @__nv_fabsf(%102) : (f32) -> f32
    %104 = llvm.fcmp "oge" %82, %103 : f32
    %105 = llvm.select %104, %82, %103 : i1, f32
    llvm.br ^bb12(%105 : f32)
  ^bb11:  // pred: ^bb9
    llvm.br ^bb12(%82 : f32)
  ^bb12(%106: f32):  // 2 preds: ^bb10, ^bb11
    llvm.br ^bb13
  ^bb13:  // pred: ^bb12
    %107 = llvm.and %86, %80  : i1
    llvm.cond_br %107, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %108 = llvm.mul %85, %arg12  : i32
    %109 = llvm.add %108, %79  : i32
    %110 = llvm.mul %23, %24  : i32
    %111 = llvm.mul %110, %25  : i32
    %112 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %113 = llvm.extractvalue %9[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %114 = llvm.extractvalue %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %115 = llvm.insertvalue %113, %112[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %116 = llvm.insertvalue %114, %115[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %117 = llvm.insertvalue %20, %116[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %118 = llvm.insertvalue %111, %117[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %119 = llvm.insertvalue %19, %118[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %120 = llvm.extractvalue %119[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %121 = llvm.getelementptr %120[%109] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %122 = llvm.load %121 : !llvm.ptr<f32>
    %123 = llvm.call @__nv_fabsf(%122) : (f32) -> f32
    %124 = llvm.fcmp "oge" %83, %123 : f32
    %125 = llvm.select %124, %83, %123 : i1, f32
    llvm.br ^bb16(%125 : f32)
  ^bb15:  // pred: ^bb13
    llvm.br ^bb16(%83 : f32)
  ^bb16(%126: f32):  // 2 preds: ^bb14, ^bb15
    llvm.br ^bb17
  ^bb17:  // pred: ^bb16
    %127 = llvm.add %81, %19  : i32
    llvm.br ^bb8(%127, %106, %126 : i32, f32, f32)
  ^bb18(%128: f32, %129: f32):  // pred: ^bb6
    llvm.br ^bb19
  ^bb19:  // pred: ^bb18
    %130 = llvm.icmp "slt" %31, %arg12 : i32
    llvm.cond_br %130, ^bb20, ^bb23
  ^bb20:  // pred: ^bb19
    %131 = llvm.extractvalue %15[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %132 = llvm.getelementptr %131[%31] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %133 = llvm.load %132 : !llvm.ptr<f32>
    llvm.br ^bb21(%133 : f32)
  ^bb21(%134: f32):  // 2 preds: ^bb20, ^bb21
    %135 = llvm.fcmp "ogt" %134, %128 : f32
    %136 = llvm.select %135, %134, %128 : i1, f32
    %137 = llvm.bitcast %132 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %138 = llvm.bitcast %134 : f32 to i32
    %139 = llvm.bitcast %136 : f32 to i32
    %140 = llvm.cmpxchg %137, %138, %139 acq_rel monotonic : !llvm.ptr<i32>, i32
    %141 = llvm.extractvalue %140[0] : !llvm.struct<(i32, i1)> 
    %142 = llvm.bitcast %141 : i32 to f32
    %143 = llvm.extractvalue %140[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %143, ^bb22, ^bb21(%142 : f32)
  ^bb22:  // pred: ^bb21
    llvm.br ^bb23
  ^bb23:  // 2 preds: ^bb19, ^bb22
    %144 = llvm.add %31, %19  : i32
    %145 = llvm.icmp "slt" %144, %arg12 : i32
    llvm.cond_br %145, ^bb24, ^bb27
  ^bb24:  // pred: ^bb23
    %146 = llvm.extractvalue %15[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %147 = llvm.getelementptr %146[%144] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %148 = llvm.load %147 : !llvm.ptr<f32>
    llvm.br ^bb25(%148 : f32)
  ^bb25(%149: f32):  // 2 preds: ^bb24, ^bb25
    %150 = llvm.fcmp "ogt" %149, %129 : f32
    %151 = llvm.select %150, %149, %129 : i1, f32
    %152 = llvm.bitcast %147 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %153 = llvm.bitcast %149 : f32 to i32
    %154 = llvm.bitcast %151 : f32 to i32
    %155 = llvm.cmpxchg %152, %153, %154 acq_rel monotonic : !llvm.ptr<i32>, i32
    %156 = llvm.extractvalue %155[0] : !llvm.struct<(i32, i1)> 
    %157 = llvm.bitcast %156 : i32 to f32
    %158 = llvm.extractvalue %155[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %158, ^bb26, ^bb25(%157 : f32)
  ^bb26:  // pred: ^bb25
    llvm.br ^bb27
  ^bb27:  // 2 preds: ^bb23, ^bb26
    llvm.br ^bb28
  ^bb28:  // 2 preds: ^bb1, ^bb27
    llvm.return
  }
}

// -----// IR Dump After LLVMInsertValueSimplifierPass (disc-llvm-insert-value-simplifier) //----- //
llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: !llvm.ptr<f32>, %arg1: !llvm.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: !llvm.ptr<f32>, %arg14: !llvm.ptr<f32>, %arg15: i32, %arg16: i32, %arg17: i32) attributes {gpu.kernel, nvvm.kernel} {
  %0 = llvm.mlir.constant(0 : index) : i32
  %1 = llvm.mlir.constant(1 : index) : i32
  %2 = llvm.mlir.constant(2 : index) : i32
  %3 = llvm.mlir.constant(128 : index) : i32
  %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
  %5 = nvvm.read.ptx.sreg.ctaid.x : i32
  %6 = nvvm.read.ptx.sreg.tid.x : i32
  llvm.br ^bb1
^bb1:  // pred: ^bb0
  %7 = llvm.mul %5, %arg9  : i32
  %8 = llvm.add %6, %7  : i32
  %9 = llvm.icmp "ult" %8, %arg10 : i32
  llvm.cond_br %9, ^bb2, ^bb28
^bb2:  // pred: ^bb1
  %10 = llvm.srem %8, %arg11  : i32
  %11 = llvm.sdiv %8, %arg11  : i32
  %12 = llvm.mul %10, %2  : i32
  %13 = llvm.mul %11, %3  : i32
  %14 = llvm.add %13, %3  : i32
  %15 = llvm.icmp "slt" %14, %arg3 : i32
  %16 = llvm.urem %arg3, %3  : i32
  %17 = llvm.icmp "eq" %16, %0 : i32
  %18 = llvm.or %17, %15  : i1
  %19 = llvm.add %12, %2  : i32
  %20 = llvm.icmp "slt" %19, %arg12 : i32
  %21 = llvm.urem %arg12, %2  : i32
  %22 = llvm.icmp "eq" %21, %0 : i32
  %23 = llvm.or %22, %20  : i1
  %24 = llvm.and %18, %23  : i1
  llvm.cond_br %24, ^bb3, ^bb7
^bb3:  // pred: ^bb2
  %25 = llvm.add %12, %1  : i32
  llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
  %29 = llvm.icmp "slt" %26, %3 : i32
  llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
^bb5:  // pred: ^bb4
  %30 = llvm.add %13, %26  : i32
  %31 = llvm.mul %30, %arg12  : i32
  %32 = llvm.add %31, %12  : i32
  %33 = llvm.getelementptr %arg1[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %34 = llvm.load %33 : !llvm.ptr<f32>
  %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
  %36 = llvm.fcmp "oge" %27, %35 : f32
  %37 = llvm.select %36, %27, %35 : i1, f32
  %38 = llvm.add %31, %25  : i32
  %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %40 = llvm.load %39 : !llvm.ptr<f32>
  %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
  %42 = llvm.fcmp "oge" %28, %41 : f32
  %43 = llvm.select %42, %28, %41 : i1, f32
  %44 = llvm.add %26, %1  : i32
  llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
  llvm.br ^bb18(%45, %46 : f32, f32)
^bb7:  // pred: ^bb2
  %47 = llvm.icmp "slt" %12, %arg12 : i32
  %48 = llvm.add %12, %1  : i32
  %49 = llvm.icmp "slt" %48, %arg12 : i32
  llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
  %53 = llvm.icmp "slt" %50, %3 : i32
  llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
^bb9:  // pred: ^bb8
  %54 = llvm.add %13, %50  : i32
  %55 = llvm.icmp "slt" %54, %arg3 : i32
  %56 = llvm.and %55, %47  : i1
  llvm.cond_br %56, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %57 = llvm.mul %54, %arg12  : i32
  %58 = llvm.add %57, %12  : i32
  %59 = llvm.getelementptr %arg1[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %60 = llvm.load %59 : !llvm.ptr<f32>
  %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
  %62 = llvm.fcmp "oge" %51, %61 : f32
  %63 = llvm.select %62, %51, %61 : i1, f32
  llvm.br ^bb12(%63 : f32)
^bb11:  // pred: ^bb9
  llvm.br ^bb12(%51 : f32)
^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
  llvm.br ^bb13
^bb13:  // pred: ^bb12
  %65 = llvm.and %55, %49  : i1
  llvm.cond_br %65, ^bb14, ^bb15
^bb14:  // pred: ^bb13
  %66 = llvm.mul %54, %arg12  : i32
  %67 = llvm.add %66, %48  : i32
  %68 = llvm.getelementptr %arg1[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %69 = llvm.load %68 : !llvm.ptr<f32>
  %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
  %71 = llvm.fcmp "oge" %52, %70 : f32
  %72 = llvm.select %71, %52, %70 : i1, f32
  llvm.br ^bb16(%72 : f32)
^bb15:  // pred: ^bb13
  llvm.br ^bb16(%52 : f32)
^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
  llvm.br ^bb17
^bb17:  // pred: ^bb16
  %74 = llvm.add %50, %1  : i32
  llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
^bb18(%75: f32, %76: f32):  // pred: ^bb6
  llvm.br ^bb19
^bb19:  // pred: ^bb18
  %77 = llvm.icmp "slt" %12, %arg12 : i32
  llvm.cond_br %77, ^bb20, ^bb23
^bb20:  // pred: ^bb19
  %78 = llvm.getelementptr %arg14[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %79 = llvm.load %78 : !llvm.ptr<f32>
  llvm.br ^bb21(%79 : f32)
^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
  %81 = llvm.fcmp "ogt" %80, %75 : f32
  %82 = llvm.select %81, %80, %75 : i1, f32
  %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
  %84 = llvm.bitcast %80 : f32 to i32
  %85 = llvm.bitcast %82 : f32 to i32
  %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
  %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
  %88 = llvm.bitcast %87 : i32 to f32
  %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
  llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
^bb22:  // pred: ^bb21
  llvm.br ^bb23
^bb23:  // 2 preds: ^bb19, ^bb22
  %90 = llvm.add %12, %1  : i32
  %91 = llvm.icmp "slt" %90, %arg12 : i32
  llvm.cond_br %91, ^bb24, ^bb27
^bb24:  // pred: ^bb23
  %92 = llvm.getelementptr %arg14[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %93 = llvm.load %92 : !llvm.ptr<f32>
  llvm.br ^bb25(%93 : f32)
^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
  %95 = llvm.fcmp "ogt" %94, %76 : f32
  %96 = llvm.select %95, %94, %76 : i1, f32
  %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
  %98 = llvm.bitcast %94 : f32 to i32
  %99 = llvm.bitcast %96 : f32 to i32
  %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
  %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
  %102 = llvm.bitcast %101 : i32 to f32
  %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
  llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
^bb26:  // pred: ^bb25
  llvm.br ^bb27
^bb27:  // 2 preds: ^bb23, ^bb26
  llvm.br ^bb28
^bb28:  // 2 preds: ^bb1, ^bb27
  llvm.return
}

// -----// IR Dump After FunctionDeadArgumentEliminationPass (disc-function-dead-argument-elimination) //----- //
gpu.module @main_kernel_0 {
  llvm.func @__nv_fabsf(f32) -> f32
  llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(0 : index) : i32
    %1 = llvm.mlir.constant(1 : index) : i32
    %2 = llvm.mlir.constant(2 : index) : i32
    %3 = llvm.mlir.constant(128 : index) : i32
    %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %5 = nvvm.read.ptx.sreg.ctaid.x : i32
    %6 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %7 = llvm.mul %5, %arg2  : i32
    %8 = llvm.add %6, %7  : i32
    %9 = llvm.icmp "ult" %8, %arg3 : i32
    llvm.cond_br %9, ^bb2, ^bb28
  ^bb2:  // pred: ^bb1
    %10 = llvm.srem %8, %arg4  : i32
    %11 = llvm.sdiv %8, %arg4  : i32
    %12 = llvm.mul %10, %2  : i32
    %13 = llvm.mul %11, %3  : i32
    %14 = llvm.add %13, %3  : i32
    %15 = llvm.icmp "slt" %14, %arg1 : i32
    %16 = llvm.urem %arg1, %3  : i32
    %17 = llvm.icmp "eq" %16, %0 : i32
    %18 = llvm.or %17, %15  : i1
    %19 = llvm.add %12, %2  : i32
    %20 = llvm.icmp "slt" %19, %arg5 : i32
    %21 = llvm.urem %arg5, %2  : i32
    %22 = llvm.icmp "eq" %21, %0 : i32
    %23 = llvm.or %22, %20  : i1
    %24 = llvm.and %18, %23  : i1
    llvm.cond_br %24, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %25 = llvm.add %12, %1  : i32
    llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
  ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
    %29 = llvm.icmp "slt" %26, %3 : i32
    llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
  ^bb5:  // pred: ^bb4
    %30 = llvm.add %13, %26  : i32
    %31 = llvm.mul %30, %arg5  : i32
    %32 = llvm.add %31, %12  : i32
    %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %34 = llvm.load %33 : !llvm.ptr<f32>
    %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
    %36 = llvm.fcmp "oge" %27, %35 : f32
    %37 = llvm.select %36, %27, %35 : i1, f32
    %38 = llvm.add %31, %25  : i32
    %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %40 = llvm.load %39 : !llvm.ptr<f32>
    %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
    %42 = llvm.fcmp "oge" %28, %41 : f32
    %43 = llvm.select %42, %28, %41 : i1, f32
    %44 = llvm.add %26, %1  : i32
    llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
  ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
    llvm.br ^bb18(%45, %46 : f32, f32)
  ^bb7:  // pred: ^bb2
    %47 = llvm.icmp "slt" %12, %arg5 : i32
    %48 = llvm.add %12, %1  : i32
    %49 = llvm.icmp "slt" %48, %arg5 : i32
    llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
  ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
    %53 = llvm.icmp "slt" %50, %3 : i32
    llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
  ^bb9:  // pred: ^bb8
    %54 = llvm.add %13, %50  : i32
    %55 = llvm.icmp "slt" %54, %arg1 : i32
    %56 = llvm.and %55, %47  : i1
    llvm.cond_br %56, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %57 = llvm.mul %54, %arg5  : i32
    %58 = llvm.add %57, %12  : i32
    %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %60 = llvm.load %59 : !llvm.ptr<f32>
    %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
    %62 = llvm.fcmp "oge" %51, %61 : f32
    %63 = llvm.select %62, %51, %61 : i1, f32
    llvm.br ^bb12(%63 : f32)
  ^bb11:  // pred: ^bb9
    llvm.br ^bb12(%51 : f32)
  ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
    llvm.br ^bb13
  ^bb13:  // pred: ^bb12
    %65 = llvm.and %55, %49  : i1
    llvm.cond_br %65, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %66 = llvm.mul %54, %arg5  : i32
    %67 = llvm.add %66, %48  : i32
    %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %69 = llvm.load %68 : !llvm.ptr<f32>
    %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
    %71 = llvm.fcmp "oge" %52, %70 : f32
    %72 = llvm.select %71, %52, %70 : i1, f32
    llvm.br ^bb16(%72 : f32)
  ^bb15:  // pred: ^bb13
    llvm.br ^bb16(%52 : f32)
  ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
    llvm.br ^bb17
  ^bb17:  // pred: ^bb16
    %74 = llvm.add %50, %1  : i32
    llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
  ^bb18(%75: f32, %76: f32):  // pred: ^bb6
    llvm.br ^bb19
  ^bb19:  // pred: ^bb18
    %77 = llvm.icmp "slt" %12, %arg5 : i32
    llvm.cond_br %77, ^bb20, ^bb23
  ^bb20:  // pred: ^bb19
    %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %79 = llvm.load %78 : !llvm.ptr<f32>
    llvm.br ^bb21(%79 : f32)
  ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
    %81 = llvm.fcmp "ogt" %80, %75 : f32
    %82 = llvm.select %81, %80, %75 : i1, f32
    %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %84 = llvm.bitcast %80 : f32 to i32
    %85 = llvm.bitcast %82 : f32 to i32
    %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
    %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
    %88 = llvm.bitcast %87 : i32 to f32
    %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
  ^bb22:  // pred: ^bb21
    llvm.br ^bb23
  ^bb23:  // 2 preds: ^bb19, ^bb22
    %90 = llvm.add %12, %1  : i32
    %91 = llvm.icmp "slt" %90, %arg5 : i32
    llvm.cond_br %91, ^bb24, ^bb27
  ^bb24:  // pred: ^bb23
    %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %93 = llvm.load %92 : !llvm.ptr<f32>
    llvm.br ^bb25(%93 : f32)
  ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
    %95 = llvm.fcmp "ogt" %94, %76 : f32
    %96 = llvm.select %95, %94, %76 : i1, f32
    %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %98 = llvm.bitcast %94 : f32 to i32
    %99 = llvm.bitcast %96 : f32 to i32
    %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
    %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
    %102 = llvm.bitcast %101 : i32 to f32
    %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
  ^bb26:  // pred: ^bb25
    llvm.br ^bb27
  ^bb27:  // 2 preds: ^bb23, ^bb26
    llvm.br ^bb28
  ^bb28:  // 2 preds: ^bb1, ^bb27
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel_0 attributes {gpu.binary = "P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
  llvm.func @__nv_fabsf(f32) -> f32
  llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(0 : index) : i32
    %1 = llvm.mlir.constant(1 : index) : i32
    %2 = llvm.mlir.constant(2 : index) : i32
    %3 = llvm.mlir.constant(128 : index) : i32
    %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %5 = nvvm.read.ptx.sreg.ctaid.x : i32
    %6 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %7 = llvm.mul %5, %arg2  : i32
    %8 = llvm.add %6, %7  : i32
    %9 = llvm.icmp "ult" %8, %arg3 : i32
    llvm.cond_br %9, ^bb2, ^bb28
  ^bb2:  // pred: ^bb1
    %10 = llvm.srem %8, %arg4  : i32
    %11 = llvm.sdiv %8, %arg4  : i32
    %12 = llvm.mul %10, %2  : i32
    %13 = llvm.mul %11, %3  : i32
    %14 = llvm.add %13, %3  : i32
    %15 = llvm.icmp "slt" %14, %arg1 : i32
    %16 = llvm.urem %arg1, %3  : i32
    %17 = llvm.icmp "eq" %16, %0 : i32
    %18 = llvm.or %17, %15  : i1
    %19 = llvm.add %12, %2  : i32
    %20 = llvm.icmp "slt" %19, %arg5 : i32
    %21 = llvm.urem %arg5, %2  : i32
    %22 = llvm.icmp "eq" %21, %0 : i32
    %23 = llvm.or %22, %20  : i1
    %24 = llvm.and %18, %23  : i1
    llvm.cond_br %24, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %25 = llvm.add %12, %1  : i32
    llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
  ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
    %29 = llvm.icmp "slt" %26, %3 : i32
    llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
  ^bb5:  // pred: ^bb4
    %30 = llvm.add %13, %26  : i32
    %31 = llvm.mul %30, %arg5  : i32
    %32 = llvm.add %31, %12  : i32
    %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %34 = llvm.load %33 : !llvm.ptr<f32>
    %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
    %36 = llvm.fcmp "oge" %27, %35 : f32
    %37 = llvm.select %36, %27, %35 : i1, f32
    %38 = llvm.add %31, %25  : i32
    %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %40 = llvm.load %39 : !llvm.ptr<f32>
    %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
    %42 = llvm.fcmp "oge" %28, %41 : f32
    %43 = llvm.select %42, %28, %41 : i1, f32
    %44 = llvm.add %26, %1  : i32
    llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
  ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
    llvm.br ^bb18(%45, %46 : f32, f32)
  ^bb7:  // pred: ^bb2
    %47 = llvm.icmp "slt" %12, %arg5 : i32
    %48 = llvm.add %12, %1  : i32
    %49 = llvm.icmp "slt" %48, %arg5 : i32
    llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
  ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
    %53 = llvm.icmp "slt" %50, %3 : i32
    llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
  ^bb9:  // pred: ^bb8
    %54 = llvm.add %13, %50  : i32
    %55 = llvm.icmp "slt" %54, %arg1 : i32
    %56 = llvm.and %55, %47  : i1
    llvm.cond_br %56, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %57 = llvm.mul %54, %arg5  : i32
    %58 = llvm.add %57, %12  : i32
    %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %60 = llvm.load %59 : !llvm.ptr<f32>
    %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
    %62 = llvm.fcmp "oge" %51, %61 : f32
    %63 = llvm.select %62, %51, %61 : i1, f32
    llvm.br ^bb12(%63 : f32)
  ^bb11:  // pred: ^bb9
    llvm.br ^bb12(%51 : f32)
  ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
    llvm.br ^bb13
  ^bb13:  // pred: ^bb12
    %65 = llvm.and %55, %49  : i1
    llvm.cond_br %65, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %66 = llvm.mul %54, %arg5  : i32
    %67 = llvm.add %66, %48  : i32
    %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %69 = llvm.load %68 : !llvm.ptr<f32>
    %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
    %71 = llvm.fcmp "oge" %52, %70 : f32
    %72 = llvm.select %71, %52, %70 : i1, f32
    llvm.br ^bb16(%72 : f32)
  ^bb15:  // pred: ^bb13
    llvm.br ^bb16(%52 : f32)
  ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
    llvm.br ^bb17
  ^bb17:  // pred: ^bb16
    %74 = llvm.add %50, %1  : i32
    llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
  ^bb18(%75: f32, %76: f32):  // pred: ^bb6
    llvm.br ^bb19
  ^bb19:  // pred: ^bb18
    %77 = llvm.icmp "slt" %12, %arg5 : i32
    llvm.cond_br %77, ^bb20, ^bb23
  ^bb20:  // pred: ^bb19
    %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %79 = llvm.load %78 : !llvm.ptr<f32>
    llvm.br ^bb21(%79 : f32)
  ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
    %81 = llvm.fcmp "ogt" %80, %75 : f32
    %82 = llvm.select %81, %80, %75 : i1, f32
    %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %84 = llvm.bitcast %80 : f32 to i32
    %85 = llvm.bitcast %82 : f32 to i32
    %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
    %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
    %88 = llvm.bitcast %87 : i32 to f32
    %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
  ^bb22:  // pred: ^bb21
    llvm.br ^bb23
  ^bb23:  // 2 preds: ^bb19, ^bb22
    %90 = llvm.add %12, %1  : i32
    %91 = llvm.icmp "slt" %90, %arg5 : i32
    llvm.cond_br %91, ^bb24, ^bb27
  ^bb24:  // pred: ^bb23
    %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %93 = llvm.load %92 : !llvm.ptr<f32>
    llvm.br ^bb25(%93 : f32)
  ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
    %95 = llvm.fcmp "ogt" %94, %76 : f32
    %96 = llvm.select %95, %94, %76 : i1, f32
    %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %98 = llvm.bitcast %94 : f32 to i32
    %99 = llvm.bitcast %96 : f32 to i32
    %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
    %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
    %102 = llvm.bitcast %101 : i32 to f32
    %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
  ^bb26:  // pred: ^bb25
    llvm.br ^bb27
  ^bb27:  // 2 preds: ^bb23, ^bb26
    llvm.br ^bb28
  ^bb28:  // 2 preds: ^bb1, ^bb27
    llvm.return
  }
}

// -----// IR Dump After SideEffectLoopInvariantCodeMotionPass (disc-side-effect-loop-invariant-code-motion) //----- //
gpu.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
  %cst = arith.constant 0xFF800000 : f32
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = gpu.block_id  x
  %1 = gpu.thread_id  x
  cf.br ^bb1
^bb1:  // pred: ^bb0
  %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
  %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
  %4 = arith.addi %3, %2 : index
  %5 = arith.addi %3, %2 : index
  %6 = arith.cmpi ult, %5, %arg1 : index
  scf.if %6 {
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%4] : memref<?xf32, "gpu">
  }
  gpu.return
}

// -----// IR Dump After CSE (cse) //----- //
gpu.module @main_kernel_1 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    scf.if %5 {
      %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%4] : memref<?xf32, "gpu">
    }
    gpu.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel_1 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    cf.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%4] : memref<?xf32, "gpu">
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel_1 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%6] : memref<?xf32, "gpu">
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel_1 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: index, %arg1: index, %arg2: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [%c0], sizes: [%arg1], strides: [%c1] : memref<?xf32, "gpu"> to memref<?xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%6] : memref<?xf32, "gpu">
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel_1 {
  llvm.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %5 = llvm.insertvalue %arg6, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %6 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %7 = llvm.mlir.constant(1 : index) : i32
    %8 = llvm.mlir.constant(0 : index) : i32
    %9 = nvvm.read.ptx.sreg.ctaid.x : i32
    %10 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %11 = llvm.mul %9, %arg0  : i32
    %12 = llvm.add %10, %11  : i32
    %13 = llvm.icmp "ult" %12, %arg1 : i32
    llvm.cond_br %13, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %14 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %15 = llvm.extractvalue %5[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %16 = llvm.extractvalue %5[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %17 = llvm.insertvalue %15, %14[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %18 = llvm.insertvalue %16, %17[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %19 = llvm.insertvalue %8, %18[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %20 = llvm.insertvalue %arg1, %19[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %21 = llvm.insertvalue %7, %20[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %22 = llvm.extractvalue %21[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %23 = llvm.getelementptr %22[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %6, %23 : !llvm.ptr<f32>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After LLVMInsertValueSimplifierPass (disc-llvm-insert-value-simplifier) //----- //
llvm.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32) attributes {gpu.kernel, nvvm.kernel} {
  %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
  %1 = nvvm.read.ptx.sreg.ctaid.x : i32
  %2 = nvvm.read.ptx.sreg.tid.x : i32
  llvm.br ^bb1
^bb1:  // pred: ^bb0
  %3 = llvm.mul %1, %arg0  : i32
  %4 = llvm.add %2, %3  : i32
  %5 = llvm.icmp "ult" %4, %arg1 : i32
  llvm.cond_br %5, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %6 = llvm.getelementptr %arg3[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  llvm.store %0, %6 : !llvm.ptr<f32>
  llvm.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  llvm.return
}

// -----// IR Dump After FunctionDeadArgumentEliminationPass (disc-function-dead-argument-elimination) //----- //
gpu.module @main_kernel_1 {
  llvm.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %1 = nvvm.read.ptx.sreg.ctaid.x : i32
    %2 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.mul %1, %arg0  : i32
    %4 = llvm.add %2, %3  : i32
    %5 = llvm.icmp "ult" %4, %arg1 : i32
    llvm.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %0, %6 : !llvm.ptr<f32>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel_1 attributes {gpu.binary = "P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w16h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
  llvm.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %1 = nvvm.read.ptx.sreg.ctaid.x : i32
    %2 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.mul %1, %arg0  : i32
    %4 = llvm.add %2, %3  : i32
    %5 = llvm.icmp "ult" %4, %arg1 : i32
    llvm.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %0, %6 : !llvm.ptr<f32>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
gpu.module @main_kernel_2 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
    %0 = gpu.block_id  x
    %1 = gpu.block_id  y
    %2 = gpu.block_id  z
    %3 = gpu.thread_id  x
    %4 = gpu.thread_id  y
    %5 = gpu.thread_id  z
    %6 = gpu.grid_dim  x
    %7 = gpu.grid_dim  y
    %8 = gpu.grid_dim  z
    %9 = gpu.block_dim  x
    %10 = gpu.block_dim  y
    %11 = gpu.block_dim  z
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c0_0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c128 = arith.constant 128 : index
    %c0_1 = arith.constant 0 : index
    %dim = memref.dim %arg0, %c0_1 : memref<?x?x?xf32, "gpu">
    %c1_2 = arith.constant 1 : index
    %dim_3 = memref.dim %arg0, %c1_2 : memref<?x?x?xf32, "gpu">
    %dim_4 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %cst = arith.constant 0xFF800000 : f32
    %12 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg1, %c0]
    %13 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%3)[%c1, %c0_0]
    %14 = arith.addi %13, %12 : index
    %true = arith.constant true
    %15 = arith.muli %13, %c1 : index
    %16 = arith.addi %15, %12 : index
    %17 = arith.cmpi ult, %16, %arg2 : index
    %18 = arith.andi %true, %17 : i1
    scf.if %18 {
      %19 = arith.remsi %14, %arg3 : index
      %20 = arith.divsi %14, %arg3 : index
      %21 = arith.muli %19, %c2 : index
      %22 = arith.muli %20, %c128 : index
      %23 = arith.addi %22, %c128 : index
      %24 = arith.cmpi slt, %23, %dim : index
      %25 = arith.remui %dim, %c128 : index
      %26 = arith.cmpi eq, %25, %c0_1 : index
      %27 = arith.ori %26, %24 : i1
      %28 = arith.addi %21, %c2 : index
      %29 = arith.cmpi slt, %28, %arg4 : index
      %30 = arith.remui %arg4, %c2 : index
      %31 = arith.cmpi eq, %30, %c0_1 : index
      %32 = arith.ori %31, %29 : i1
      %33 = arith.andi %27, %32 : i1
      %34:2 = scf.if %33 -> (f32, f32) {
        %38 = arith.muli %dim, %dim_3 : index
        %39 = arith.muli %38, %dim_4 : index
        %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%39], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
        %40 = arith.addi %21, %c1_2 : index
        %41:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
          %42 = arith.addi %22, %arg6 : index
          %43 = arith.muli %42, %arg4 : index
          %44 = arith.addi %43, %21 : index
          %45 = memref.load %reinterpret_cast[%44] : memref<?xf32, "gpu">
          %46 = math.absf %45 : f32
          %47 = arith.cmpf oge, %arg7, %46 : f32
          %48 = arith.select %47, %arg7, %46 : f32
          %49 = arith.addi %43, %40 : index
          %50 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
          %51 = math.absf %50 : f32
          %52 = arith.cmpf oge, %arg8, %51 : f32
          %53 = arith.select %52, %arg8, %51 : f32
          scf.yield %48, %53 : f32, f32
        }
        scf.yield %41#0, %41#1 : f32, f32
      } else {
        %38 = arith.cmpi slt, %21, %arg4 : index
        %39 = arith.addi %21, %c1_2 : index
        %40 = arith.cmpi slt, %39, %arg4 : index
        %41:2 = scf.for %arg6 = %c0_1 to %c128 step %c1_2 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
          %42 = arith.addi %22, %arg6 : index
          %43 = arith.cmpi slt, %42, %dim : index
          %44 = arith.andi %43, %38 : i1
          %45 = scf.if %44 -> (f32) {
            %48 = arith.muli %42, %arg4 : index
            %49 = arith.addi %48, %21 : index
            %50 = arith.muli %dim, %dim_3 : index
            %51 = arith.muli %50, %dim_4 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
            %53 = math.absf %52 : f32
            %54 = arith.cmpf oge, %arg7, %53 : f32
            %55 = arith.select %54, %arg7, %53 : f32
            scf.yield %55 : f32
          } else {
            scf.yield %arg7 : f32
          }
          %46 = arith.andi %43, %40 : i1
          %47 = scf.if %46 -> (f32) {
            %48 = arith.muli %42, %arg4 : index
            %49 = arith.addi %48, %39 : index
            %50 = arith.muli %dim, %dim_3 : index
            %51 = arith.muli %50, %dim_4 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0_1], sizes: [%51], strides: [%c1_2] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %52 = memref.load %reinterpret_cast[%49] : memref<?xf32, "gpu">
            %53 = math.absf %52 : f32
            %54 = arith.cmpf oge, %arg8, %53 : f32
            %55 = arith.select %54, %arg8, %53 : f32
            scf.yield %55 : f32
          } else {
            scf.yield %arg8 : f32
          }
          scf.yield %45, %47 : f32, f32
        }
        scf.yield %41#0, %41#1 : f32, f32
      }
      %35 = arith.cmpi slt, %21, %arg4 : index
      scf.if %35 {
        %38 = memref.generic_atomic_rmw %arg5[%21] : memref<?xf32, "gpu"> {
        ^bb0(%arg6: f32):
          %39 = arith.cmpf ogt, %arg6, %34#0 : f32
          %40 = arith.select %39, %arg6, %34#0 : f32
          memref.atomic_yield %40 : f32
        }
      }
      %36 = arith.addi %21, %c1_2 : index
      %37 = arith.cmpi slt, %36, %arg4 : index
      scf.if %37 {
        %38 = memref.generic_atomic_rmw %arg5[%36] : memref<?xf32, "gpu"> {
        ^bb0(%arg6: f32):
          %39 = arith.cmpf ogt, %arg6, %34#1 : f32
          %40 = arith.select %39, %arg6, %34#1 : f32
          memref.atomic_yield %40 : f32
        }
      }
    }
    gpu.return
  }
}

// -----// IR Dump After SideEffectLoopInvariantCodeMotionPass (disc-side-effect-loop-invariant-code-motion) //----- //
gpu.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
  %cst = arith.constant 0xFF800000 : f32
  %c128 = arith.constant 128 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = gpu.block_id  x
  %1 = gpu.thread_id  x
  cf.br ^bb1
^bb1:  // pred: ^bb0
  %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
  %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg1, %c0]
  %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
  %4 = arith.addi %3, %2 : index
  %5 = arith.addi %3, %2 : index
  %6 = arith.cmpi ult, %5, %arg2 : index
  scf.if %6 {
    %7 = arith.remsi %4, %arg3 : index
    %8 = arith.divsi %4, %arg3 : index
    %9 = arith.muli %7, %c2 : index
    %10 = arith.muli %8, %c128 : index
    %11 = arith.addi %10, %c128 : index
    %12 = arith.cmpi slt, %11, %dim : index
    %13 = arith.remui %dim, %c128 : index
    %14 = arith.cmpi eq, %13, %c0 : index
    %15 = arith.ori %14, %12 : i1
    %16 = arith.addi %9, %c2 : index
    %17 = arith.cmpi slt, %16, %arg4 : index
    %18 = arith.remui %arg4, %c2 : index
    %19 = arith.cmpi eq, %18, %c0 : index
    %20 = arith.ori %19, %17 : i1
    %21 = arith.andi %15, %20 : i1
    %22:2 = scf.if %21 -> (f32, f32) {
      %26 = arith.muli %dim, %dim_0 : index
      %27 = arith.muli %26, %dim_1 : index
      %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%27], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
      %28 = arith.addi %9, %c1 : index
      %29:2 = scf.for %arg6 = %c0 to %c128 step %c1 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
        %30 = arith.addi %10, %arg6 : index
        %31 = arith.muli %30, %arg4 : index
        %32 = arith.addi %31, %9 : index
        %33 = memref.load %reinterpret_cast[%32] : memref<?xf32, "gpu">
        %34 = math.absf %33 : f32
        %35 = arith.cmpf oge, %arg7, %34 : f32
        %36 = arith.select %35, %arg7, %34 : f32
        %37 = arith.addi %31, %28 : index
        %38 = memref.load %reinterpret_cast[%37] : memref<?xf32, "gpu">
        %39 = math.absf %38 : f32
        %40 = arith.cmpf oge, %arg8, %39 : f32
        %41 = arith.select %40, %arg8, %39 : f32
        scf.yield %36, %41 : f32, f32
      }
      scf.yield %29#0, %29#1 : f32, f32
    } else {
      %26 = arith.cmpi slt, %9, %arg4 : index
      %27 = arith.addi %9, %c1 : index
      %28 = arith.cmpi slt, %27, %arg4 : index
      %29:2 = scf.for %arg6 = %c0 to %c128 step %c1 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
        %30 = arith.addi %10, %arg6 : index
        %31 = arith.cmpi slt, %30, %dim : index
        %32 = arith.andi %31, %26 : i1
        %33 = scf.if %32 -> (f32) {
          %36 = arith.muli %30, %arg4 : index
          %37 = arith.addi %36, %9 : index
          %38 = arith.muli %dim, %dim_0 : index
          %39 = arith.muli %38, %dim_1 : index
          %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%39], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
          %40 = memref.load %reinterpret_cast[%37] : memref<?xf32, "gpu">
          %41 = math.absf %40 : f32
          %42 = arith.cmpf oge, %arg7, %41 : f32
          %43 = arith.select %42, %arg7, %41 : f32
          scf.yield %43 : f32
        } else {
          scf.yield %arg7 : f32
        }
        %34 = arith.andi %31, %28 : i1
        %35 = scf.if %34 -> (f32) {
          %36 = arith.muli %30, %arg4 : index
          %37 = arith.addi %36, %27 : index
          %38 = arith.muli %dim, %dim_0 : index
          %39 = arith.muli %38, %dim_1 : index
          %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%39], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
          %40 = memref.load %reinterpret_cast[%37] : memref<?xf32, "gpu">
          %41 = math.absf %40 : f32
          %42 = arith.cmpf oge, %arg8, %41 : f32
          %43 = arith.select %42, %arg8, %41 : f32
          scf.yield %43 : f32
        } else {
          scf.yield %arg8 : f32
        }
        scf.yield %33, %35 : f32, f32
      }
      scf.yield %29#0, %29#1 : f32, f32
    }
    %23 = arith.cmpi slt, %9, %arg4 : index
    scf.if %23 {
      %26 = memref.generic_atomic_rmw %arg5[%9] : memref<?xf32, "gpu"> {
      ^bb0(%arg6: f32):
        %27 = arith.cmpf ogt, %arg6, %22#0 : f32
        %28 = arith.select %27, %arg6, %22#0 : f32
        memref.atomic_yield %28 : f32
      }
    }
    %24 = arith.addi %9, %c1 : index
    %25 = arith.cmpi slt, %24, %arg4 : index
    scf.if %25 {
      %26 = memref.generic_atomic_rmw %arg5[%24] : memref<?xf32, "gpu"> {
      ^bb0(%arg6: f32):
        %27 = arith.cmpf ogt, %arg6, %22#1 : f32
        %28 = arith.select %27, %arg6, %22#1 : f32
        memref.atomic_yield %28 : f32
      }
    }
  }
  gpu.return
}

// -----// IR Dump After CSE (cse) //----- //
gpu.module @main_kernel_2 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg1, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg2 : index
    scf.if %5 {
      %6 = arith.remsi %4, %arg3 : index
      %7 = arith.divsi %4, %arg3 : index
      %8 = arith.muli %6, %c2 : index
      %9 = arith.muli %7, %c128 : index
      %10 = arith.addi %9, %c128 : index
      %11 = arith.cmpi slt, %10, %dim : index
      %12 = arith.remui %dim, %c128 : index
      %13 = arith.cmpi eq, %12, %c0 : index
      %14 = arith.ori %13, %11 : i1
      %15 = arith.addi %8, %c2 : index
      %16 = arith.cmpi slt, %15, %arg4 : index
      %17 = arith.remui %arg4, %c2 : index
      %18 = arith.cmpi eq, %17, %c0 : index
      %19 = arith.ori %18, %16 : i1
      %20 = arith.andi %14, %19 : i1
      %21:2 = scf.if %20 -> (f32, f32) {
        %25 = arith.muli %dim, %dim_0 : index
        %26 = arith.muli %25, %dim_1 : index
        %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%26], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
        %27 = arith.addi %8, %c1 : index
        %28:2 = scf.for %arg6 = %c0 to %c128 step %c1 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
          %29 = arith.addi %9, %arg6 : index
          %30 = arith.muli %29, %arg4 : index
          %31 = arith.addi %30, %8 : index
          %32 = memref.load %reinterpret_cast[%31] : memref<?xf32, "gpu">
          %33 = math.absf %32 : f32
          %34 = arith.cmpf oge, %arg7, %33 : f32
          %35 = arith.select %34, %arg7, %33 : f32
          %36 = arith.addi %30, %27 : index
          %37 = memref.load %reinterpret_cast[%36] : memref<?xf32, "gpu">
          %38 = math.absf %37 : f32
          %39 = arith.cmpf oge, %arg8, %38 : f32
          %40 = arith.select %39, %arg8, %38 : f32
          scf.yield %35, %40 : f32, f32
        }
        scf.yield %28#0, %28#1 : f32, f32
      } else {
        %25 = arith.cmpi slt, %8, %arg4 : index
        %26 = arith.addi %8, %c1 : index
        %27 = arith.cmpi slt, %26, %arg4 : index
        %28:2 = scf.for %arg6 = %c0 to %c128 step %c1 iter_args(%arg7 = %cst, %arg8 = %cst) -> (f32, f32) {
          %29 = arith.addi %9, %arg6 : index
          %30 = arith.cmpi slt, %29, %dim : index
          %31 = arith.andi %30, %25 : i1
          %32 = scf.if %31 -> (f32) {
            %35 = arith.muli %29, %arg4 : index
            %36 = arith.addi %35, %8 : index
            %37 = arith.muli %dim, %dim_0 : index
            %38 = arith.muli %37, %dim_1 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%38], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %39 = memref.load %reinterpret_cast[%36] : memref<?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg7, %40 : f32
            %42 = arith.select %41, %arg7, %40 : f32
            scf.yield %42 : f32
          } else {
            scf.yield %arg7 : f32
          }
          %33 = arith.andi %30, %27 : i1
          %34 = scf.if %33 -> (f32) {
            %35 = arith.muli %29, %arg4 : index
            %36 = arith.addi %35, %26 : index
            %37 = arith.muli %dim, %dim_0 : index
            %38 = arith.muli %37, %dim_1 : index
            %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%38], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
            %39 = memref.load %reinterpret_cast[%36] : memref<?xf32, "gpu">
            %40 = math.absf %39 : f32
            %41 = arith.cmpf oge, %arg8, %40 : f32
            %42 = arith.select %41, %arg8, %40 : f32
            scf.yield %42 : f32
          } else {
            scf.yield %arg8 : f32
          }
          scf.yield %32, %34 : f32, f32
        }
        scf.yield %28#0, %28#1 : f32, f32
      }
      %22 = arith.cmpi slt, %8, %arg4 : index
      scf.if %22 {
        %25 = memref.generic_atomic_rmw %arg5[%8] : memref<?xf32, "gpu"> {
        ^bb0(%arg6: f32):
          %26 = arith.cmpf ogt, %arg6, %21#0 : f32
          %27 = arith.select %26, %arg6, %21#0 : f32
          memref.atomic_yield %27 : f32
        }
      }
      %23 = arith.addi %8, %c1 : index
      %24 = arith.cmpi slt, %23, %arg4 : index
      scf.if %24 {
        %25 = memref.generic_atomic_rmw %arg5[%23] : memref<?xf32, "gpu"> {
        ^bb0(%arg6: f32):
          %26 = arith.cmpf ogt, %arg6, %21#1 : f32
          %27 = arith.select %26, %arg6, %21#1 : f32
          memref.atomic_yield %27 : f32
        }
      }
    }
    gpu.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel_2 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg1, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg2 : index
    cf.cond_br %5, ^bb2, ^bb25
  ^bb2:  // pred: ^bb1
    %6 = arith.remsi %4, %arg3 : index
    %7 = arith.divsi %4, %arg3 : index
    %8 = arith.muli %6, %c2 : index
    %9 = arith.muli %7, %c128 : index
    %10 = arith.addi %9, %c128 : index
    %11 = arith.cmpi slt, %10, %dim : index
    %12 = arith.remui %dim, %c128 : index
    %13 = arith.cmpi eq, %12, %c0 : index
    %14 = arith.ori %13, %11 : i1
    %15 = arith.addi %8, %c2 : index
    %16 = arith.cmpi slt, %15, %arg4 : index
    %17 = arith.remui %arg4, %c2 : index
    %18 = arith.cmpi eq, %17, %c0 : index
    %19 = arith.ori %18, %16 : i1
    %20 = arith.andi %14, %19 : i1
    cf.cond_br %20, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %21 = arith.muli %dim, %dim_0 : index
    %22 = arith.muli %21, %dim_1 : index
    %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%22], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %23 = arith.addi %8, %c1 : index
    cf.br ^bb4(%c0, %cst, %cst : index, f32, f32)
  ^bb4(%24: index, %25: f32, %26: f32):  // 2 preds: ^bb3, ^bb5
    %27 = arith.cmpi slt, %24, %c128 : index
    cf.cond_br %27, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    %28 = arith.addi %9, %24 : index
    %29 = arith.muli %28, %arg4 : index
    %30 = arith.addi %29, %8 : index
    %31 = memref.load %reinterpret_cast[%30] : memref<?xf32, "gpu">
    %32 = math.absf %31 : f32
    %33 = arith.cmpf oge, %25, %32 : f32
    %34 = arith.select %33, %25, %32 : f32
    %35 = arith.addi %29, %23 : index
    %36 = memref.load %reinterpret_cast[%35] : memref<?xf32, "gpu">
    %37 = math.absf %36 : f32
    %38 = arith.cmpf oge, %26, %37 : f32
    %39 = arith.select %38, %26, %37 : f32
    %40 = arith.addi %24, %c1 : index
    cf.br ^bb4(%40, %34, %39 : index, f32, f32)
  ^bb6:  // pred: ^bb4
    cf.br ^bb19(%25, %26 : f32, f32)
  ^bb7:  // pred: ^bb2
    %41 = arith.cmpi slt, %8, %arg4 : index
    %42 = arith.addi %8, %c1 : index
    %43 = arith.cmpi slt, %42, %arg4 : index
    cf.br ^bb8(%c0, %cst, %cst : index, f32, f32)
  ^bb8(%44: index, %45: f32, %46: f32):  // 2 preds: ^bb7, ^bb17
    %47 = arith.cmpi slt, %44, %c128 : index
    cf.cond_br %47, ^bb9, ^bb18
  ^bb9:  // pred: ^bb8
    %48 = arith.addi %9, %44 : index
    %49 = arith.cmpi slt, %48, %dim : index
    %50 = arith.andi %49, %41 : i1
    cf.cond_br %50, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %51 = arith.muli %48, %arg4 : index
    %52 = arith.addi %51, %8 : index
    %53 = arith.muli %dim, %dim_0 : index
    %54 = arith.muli %53, %dim_1 : index
    %reinterpret_cast_2 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%54], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %55 = memref.load %reinterpret_cast_2[%52] : memref<?xf32, "gpu">
    %56 = math.absf %55 : f32
    %57 = arith.cmpf oge, %45, %56 : f32
    %58 = arith.select %57, %45, %56 : f32
    cf.br ^bb12(%58 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%45 : f32)
  ^bb12(%59: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %60 = arith.andi %49, %43 : i1
    cf.cond_br %60, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %61 = arith.muli %48, %arg4 : index
    %62 = arith.addi %61, %42 : index
    %63 = arith.muli %dim, %dim_0 : index
    %64 = arith.muli %63, %dim_1 : index
    %reinterpret_cast_3 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%64], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %65 = memref.load %reinterpret_cast_3[%62] : memref<?xf32, "gpu">
    %66 = math.absf %65 : f32
    %67 = arith.cmpf oge, %46, %66 : f32
    %68 = arith.select %67, %46, %66 : f32
    cf.br ^bb16(%68 : f32)
  ^bb15:  // pred: ^bb13
    cf.br ^bb16(%46 : f32)
  ^bb16(%69: f32):  // 2 preds: ^bb14, ^bb15
    cf.br ^bb17
  ^bb17:  // pred: ^bb16
    %70 = arith.addi %44, %c1 : index
    cf.br ^bb8(%70, %59, %69 : index, f32, f32)
  ^bb18:  // pred: ^bb8
    cf.br ^bb19(%45, %46 : f32, f32)
  ^bb19(%71: f32, %72: f32):  // 2 preds: ^bb6, ^bb18
    cf.br ^bb20
  ^bb20:  // pred: ^bb19
    %73 = arith.cmpi slt, %8, %arg4 : index
    cf.cond_br %73, ^bb21, ^bb22
  ^bb21:  // pred: ^bb20
    %74 = memref.generic_atomic_rmw %arg5[%8] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %78 = arith.cmpf ogt, %arg6, %71 : f32
      %79 = arith.select %78, %arg6, %71 : f32
      memref.atomic_yield %79 : f32
    }
    cf.br ^bb22
  ^bb22:  // 2 preds: ^bb20, ^bb21
    %75 = arith.addi %8, %c1 : index
    %76 = arith.cmpi slt, %75, %arg4 : index
    cf.cond_br %76, ^bb23, ^bb24
  ^bb23:  // pred: ^bb22
    %77 = memref.generic_atomic_rmw %arg5[%75] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %78 = arith.cmpf ogt, %arg6, %72 : f32
      %79 = arith.select %78, %arg6, %72 : f32
      memref.atomic_yield %79 : f32
    }
    cf.br ^bb24
  ^bb24:  // 2 preds: ^bb22, ^bb23
    cf.br ^bb25
  ^bb25:  // 2 preds: ^bb1, ^bb24
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel_2 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %2 = arith.muli %0, %arg1 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg2 : index
    cf.cond_br %7, ^bb2, ^bb25
  ^bb2:  // pred: ^bb1
    %8 = arith.remsi %6, %arg3 : index
    %9 = arith.divsi %6, %arg3 : index
    %10 = arith.muli %8, %c2 : index
    %11 = arith.muli %9, %c128 : index
    %12 = arith.addi %11, %c128 : index
    %13 = arith.cmpi slt, %12, %dim : index
    %14 = arith.remui %dim, %c128 : index
    %15 = arith.cmpi eq, %14, %c0 : index
    %16 = arith.ori %15, %13 : i1
    %17 = arith.addi %10, %c2 : index
    %18 = arith.cmpi slt, %17, %arg4 : index
    %19 = arith.remui %arg4, %c2 : index
    %20 = arith.cmpi eq, %19, %c0 : index
    %21 = arith.ori %20, %18 : i1
    %22 = arith.andi %16, %21 : i1
    cf.cond_br %22, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %23 = arith.muli %dim, %dim_0 : index
    %24 = arith.muli %23, %dim_1 : index
    %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %25 = arith.addi %10, %c1 : index
    cf.br ^bb4(%c0, %cst, %cst : index, f32, f32)
  ^bb4(%26: index, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
    %29 = arith.cmpi slt, %26, %c128 : index
    cf.cond_br %29, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    %30 = arith.addi %11, %26 : index
    %31 = arith.muli %30, %arg4 : index
    %32 = arith.addi %31, %10 : index
    %33 = memref.load %reinterpret_cast[%32] : memref<?xf32, "gpu">
    %34 = math.absf %33 : f32
    %35 = arith.cmpf oge, %27, %34 : f32
    %36 = arith.select %35, %27, %34 : f32
    %37 = arith.addi %31, %25 : index
    %38 = memref.load %reinterpret_cast[%37] : memref<?xf32, "gpu">
    %39 = math.absf %38 : f32
    %40 = arith.cmpf oge, %28, %39 : f32
    %41 = arith.select %40, %28, %39 : f32
    %42 = arith.addi %26, %c1 : index
    cf.br ^bb4(%42, %36, %41 : index, f32, f32)
  ^bb6:  // pred: ^bb4
    cf.br ^bb19(%27, %28 : f32, f32)
  ^bb7:  // pred: ^bb2
    %43 = arith.cmpi slt, %10, %arg4 : index
    %44 = arith.addi %10, %c1 : index
    %45 = arith.cmpi slt, %44, %arg4 : index
    cf.br ^bb8(%c0, %cst, %cst : index, f32, f32)
  ^bb8(%46: index, %47: f32, %48: f32):  // 2 preds: ^bb7, ^bb17
    %49 = arith.cmpi slt, %46, %c128 : index
    cf.cond_br %49, ^bb9, ^bb18
  ^bb9:  // pred: ^bb8
    %50 = arith.addi %11, %46 : index
    %51 = arith.cmpi slt, %50, %dim : index
    %52 = arith.andi %51, %43 : i1
    cf.cond_br %52, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %53 = arith.muli %50, %arg4 : index
    %54 = arith.addi %53, %10 : index
    %55 = arith.muli %dim, %dim_0 : index
    %56 = arith.muli %55, %dim_1 : index
    %reinterpret_cast_2 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%56], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %57 = memref.load %reinterpret_cast_2[%54] : memref<?xf32, "gpu">
    %58 = math.absf %57 : f32
    %59 = arith.cmpf oge, %47, %58 : f32
    %60 = arith.select %59, %47, %58 : f32
    cf.br ^bb12(%60 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%47 : f32)
  ^bb12(%61: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %62 = arith.andi %51, %45 : i1
    cf.cond_br %62, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %63 = arith.muli %50, %arg4 : index
    %64 = arith.addi %63, %44 : index
    %65 = arith.muli %dim, %dim_0 : index
    %66 = arith.muli %65, %dim_1 : index
    %reinterpret_cast_3 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%66], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %67 = memref.load %reinterpret_cast_3[%64] : memref<?xf32, "gpu">
    %68 = math.absf %67 : f32
    %69 = arith.cmpf oge, %48, %68 : f32
    %70 = arith.select %69, %48, %68 : f32
    cf.br ^bb16(%70 : f32)
  ^bb15:  // pred: ^bb13
    cf.br ^bb16(%48 : f32)
  ^bb16(%71: f32):  // 2 preds: ^bb14, ^bb15
    cf.br ^bb17
  ^bb17:  // pred: ^bb16
    %72 = arith.addi %46, %c1 : index
    cf.br ^bb8(%72, %61, %71 : index, f32, f32)
  ^bb18:  // pred: ^bb8
    cf.br ^bb19(%47, %48 : f32, f32)
  ^bb19(%73: f32, %74: f32):  // 2 preds: ^bb6, ^bb18
    cf.br ^bb20
  ^bb20:  // pred: ^bb19
    %75 = arith.cmpi slt, %10, %arg4 : index
    cf.cond_br %75, ^bb21, ^bb22
  ^bb21:  // pred: ^bb20
    %76 = memref.generic_atomic_rmw %arg5[%10] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %80 = arith.cmpf ogt, %arg6, %73 : f32
      %81 = arith.select %80, %arg6, %73 : f32
      memref.atomic_yield %81 : f32
    }
    cf.br ^bb22
  ^bb22:  // 2 preds: ^bb20, ^bb21
    %77 = arith.addi %10, %c1 : index
    %78 = arith.cmpi slt, %77, %arg4 : index
    cf.cond_br %78, ^bb23, ^bb24
  ^bb23:  // pred: ^bb22
    %79 = memref.generic_atomic_rmw %arg5[%77] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %80 = arith.cmpf ogt, %arg6, %74 : f32
      %81 = arith.select %80, %arg6, %74 : f32
      memref.atomic_yield %81 : f32
    }
    cf.br ^bb24
  ^bb24:  // 2 preds: ^bb22, ^bb23
    cf.br ^bb25
  ^bb25:  // 2 preds: ^bb1, ^bb24
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel_2 {
  gpu.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: memref<?x?x?xf32, "gpu">, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: memref<?xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c128 = arith.constant 128 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %dim = memref.dim %arg0, %c0 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %arg0, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %arg0, %c2 : memref<?x?x?xf32, "gpu">
    %2 = arith.muli %0, %arg1 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg2 : index
    cf.cond_br %7, ^bb2, ^bb25
  ^bb2:  // pred: ^bb1
    %8 = arith.remsi %6, %arg3 : index
    %9 = arith.divsi %6, %arg3 : index
    %10 = arith.muli %8, %c2 : index
    %11 = arith.muli %9, %c128 : index
    %12 = arith.addi %11, %c128 : index
    %13 = arith.cmpi slt, %12, %dim : index
    %14 = arith.remui %dim, %c128 : index
    %15 = arith.cmpi eq, %14, %c0 : index
    %16 = arith.ori %15, %13 : i1
    %17 = arith.addi %10, %c2 : index
    %18 = arith.cmpi slt, %17, %arg4 : index
    %19 = arith.remui %arg4, %c2 : index
    %20 = arith.cmpi eq, %19, %c0 : index
    %21 = arith.ori %20, %18 : i1
    %22 = arith.andi %16, %21 : i1
    cf.cond_br %22, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %23 = arith.muli %dim, %dim_0 : index
    %24 = arith.muli %23, %dim_1 : index
    %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%24], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %25 = arith.addi %10, %c1 : index
    cf.br ^bb4(%c0, %cst, %cst : index, f32, f32)
  ^bb4(%26: index, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
    %29 = arith.cmpi slt, %26, %c128 : index
    cf.cond_br %29, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    %30 = arith.addi %11, %26 : index
    %31 = arith.muli %30, %arg4 : index
    %32 = arith.addi %31, %10 : index
    %33 = memref.load %reinterpret_cast[%32] : memref<?xf32, "gpu">
    %34 = math.absf %33 : f32
    %35 = arith.cmpf oge, %27, %34 : f32
    %36 = arith.select %35, %27, %34 : f32
    %37 = arith.addi %31, %25 : index
    %38 = memref.load %reinterpret_cast[%37] : memref<?xf32, "gpu">
    %39 = math.absf %38 : f32
    %40 = arith.cmpf oge, %28, %39 : f32
    %41 = arith.select %40, %28, %39 : f32
    %42 = arith.addi %26, %c1 : index
    cf.br ^bb4(%42, %36, %41 : index, f32, f32)
  ^bb6:  // pred: ^bb4
    cf.br ^bb19(%27, %28 : f32, f32)
  ^bb7:  // pred: ^bb2
    %43 = arith.cmpi slt, %10, %arg4 : index
    %44 = arith.addi %10, %c1 : index
    %45 = arith.cmpi slt, %44, %arg4 : index
    cf.br ^bb8(%c0, %cst, %cst : index, f32, f32)
  ^bb8(%46: index, %47: f32, %48: f32):  // 2 preds: ^bb7, ^bb17
    %49 = arith.cmpi slt, %46, %c128 : index
    cf.cond_br %49, ^bb9, ^bb18
  ^bb9:  // pred: ^bb8
    %50 = arith.addi %11, %46 : index
    %51 = arith.cmpi slt, %50, %dim : index
    %52 = arith.andi %51, %43 : i1
    cf.cond_br %52, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %53 = arith.muli %50, %arg4 : index
    %54 = arith.addi %53, %10 : index
    %55 = arith.muli %dim, %dim_0 : index
    %56 = arith.muli %55, %dim_1 : index
    %reinterpret_cast_2 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%56], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %57 = memref.load %reinterpret_cast_2[%54] : memref<?xf32, "gpu">
    %58 = math.absf %57 : f32
    %59 = arith.cmpf oge, %47, %58 : f32
    %60 = arith.select %59, %47, %58 : f32
    cf.br ^bb12(%60 : f32)
  ^bb11:  // pred: ^bb9
    cf.br ^bb12(%47 : f32)
  ^bb12(%61: f32):  // 2 preds: ^bb10, ^bb11
    cf.br ^bb13
  ^bb13:  // pred: ^bb12
    %62 = arith.andi %51, %45 : i1
    cf.cond_br %62, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %63 = arith.muli %50, %arg4 : index
    %64 = arith.addi %63, %44 : index
    %65 = arith.muli %dim, %dim_0 : index
    %66 = arith.muli %65, %dim_1 : index
    %reinterpret_cast_3 = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [%66], strides: [%c1] : memref<?x?x?xf32, "gpu"> to memref<?xf32, "gpu">
    %67 = memref.load %reinterpret_cast_3[%64] : memref<?xf32, "gpu">
    %68 = math.absf %67 : f32
    %69 = arith.cmpf oge, %48, %68 : f32
    %70 = arith.select %69, %48, %68 : f32
    cf.br ^bb16(%70 : f32)
  ^bb15:  // pred: ^bb13
    cf.br ^bb16(%48 : f32)
  ^bb16(%71: f32):  // 2 preds: ^bb14, ^bb15
    cf.br ^bb17
  ^bb17:  // pred: ^bb16
    %72 = arith.addi %46, %c1 : index
    cf.br ^bb8(%72, %61, %71 : index, f32, f32)
  ^bb18:  // pred: ^bb8
    cf.br ^bb19(%47, %48 : f32, f32)
  ^bb19(%73: f32, %74: f32):  // 2 preds: ^bb6, ^bb18
    cf.br ^bb20
  ^bb20:  // pred: ^bb19
    %75 = arith.cmpi slt, %10, %arg4 : index
    cf.cond_br %75, ^bb21, ^bb22
  ^bb21:  // pred: ^bb20
    %76 = memref.generic_atomic_rmw %arg5[%10] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %80 = arith.cmpf ogt, %arg6, %73 : f32
      %81 = arith.select %80, %arg6, %73 : f32
      memref.atomic_yield %81 : f32
    }
    cf.br ^bb22
  ^bb22:  // 2 preds: ^bb20, ^bb21
    %77 = arith.addi %10, %c1 : index
    %78 = arith.cmpi slt, %77, %arg4 : index
    cf.cond_br %78, ^bb23, ^bb24
  ^bb23:  // pred: ^bb22
    %79 = memref.generic_atomic_rmw %arg5[%77] : memref<?xf32, "gpu"> {
    ^bb0(%arg6: f32):
      %80 = arith.cmpf ogt, %arg6, %74 : f32
      %81 = arith.select %80, %arg6, %74 : f32
      memref.atomic_yield %81 : f32
    }
    cf.br ^bb24
  ^bb24:  // 2 preds: ^bb22, ^bb23
    cf.br ^bb25
  ^bb25:  // 2 preds: ^bb1, ^bb24
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel_2 {
  llvm.func @__nv_fabsf(f32) -> f32
  llvm.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: !llvm.ptr<f32>, %arg1: !llvm.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: !llvm.ptr<f32>, %arg14: !llvm.ptr<f32>, %arg15: i32, %arg16: i32, %arg17: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)>
    %1 = llvm.insertvalue %arg0, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %2 = llvm.insertvalue %arg1, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %3 = llvm.insertvalue %arg2, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %4 = llvm.insertvalue %arg3, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %5 = llvm.insertvalue %arg6, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %6 = llvm.insertvalue %arg4, %5[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %7 = llvm.insertvalue %arg7, %6[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %8 = llvm.insertvalue %arg5, %7[3, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %9 = llvm.insertvalue %arg8, %8[4, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %10 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %11 = llvm.insertvalue %arg13, %10[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %12 = llvm.insertvalue %arg14, %11[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %13 = llvm.insertvalue %arg15, %12[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %14 = llvm.insertvalue %arg16, %13[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %15 = llvm.insertvalue %arg17, %14[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %16 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %17 = llvm.mlir.constant(128 : index) : i32
    %18 = llvm.mlir.constant(2 : index) : i32
    %19 = llvm.mlir.constant(1 : index) : i32
    %20 = llvm.mlir.constant(0 : index) : i32
    %21 = nvvm.read.ptx.sreg.ctaid.x : i32
    %22 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %23 = llvm.extractvalue %9[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %24 = llvm.extractvalue %9[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %25 = llvm.extractvalue %9[3, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %26 = llvm.mul %21, %arg9  : i32
    %27 = llvm.add %22, %26  : i32
    %28 = llvm.icmp "ult" %27, %arg10 : i32
    llvm.cond_br %28, ^bb2, ^bb28
  ^bb2:  // pred: ^bb1
    %29 = llvm.srem %27, %arg11  : i32
    %30 = llvm.sdiv %27, %arg11  : i32
    %31 = llvm.mul %29, %18  : i32
    %32 = llvm.mul %30, %17  : i32
    %33 = llvm.add %32, %17  : i32
    %34 = llvm.icmp "slt" %33, %23 : i32
    %35 = llvm.urem %23, %17  : i32
    %36 = llvm.icmp "eq" %35, %20 : i32
    %37 = llvm.or %36, %34  : i1
    %38 = llvm.add %31, %18  : i32
    %39 = llvm.icmp "slt" %38, %arg12 : i32
    %40 = llvm.urem %arg12, %18  : i32
    %41 = llvm.icmp "eq" %40, %20 : i32
    %42 = llvm.or %41, %39  : i1
    %43 = llvm.and %37, %42  : i1
    llvm.cond_br %43, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %44 = llvm.mul %23, %24  : i32
    %45 = llvm.mul %44, %25  : i32
    %46 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %47 = llvm.extractvalue %9[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %48 = llvm.extractvalue %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %49 = llvm.insertvalue %47, %46[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %50 = llvm.insertvalue %48, %49[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %51 = llvm.insertvalue %20, %50[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %52 = llvm.insertvalue %45, %51[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %53 = llvm.insertvalue %19, %52[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %54 = llvm.add %31, %19  : i32
    llvm.br ^bb4(%20, %16, %16 : i32, f32, f32)
  ^bb4(%55: i32, %56: f32, %57: f32):  // 2 preds: ^bb3, ^bb5
    %58 = llvm.icmp "slt" %55, %17 : i32
    llvm.cond_br %58, ^bb5, ^bb6(%56, %57 : f32, f32)
  ^bb5:  // pred: ^bb4
    %59 = llvm.add %32, %55  : i32
    %60 = llvm.mul %59, %arg12  : i32
    %61 = llvm.add %60, %31  : i32
    %62 = llvm.extractvalue %53[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %63 = llvm.getelementptr %62[%61] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %64 = llvm.load %63 : !llvm.ptr<f32>
    %65 = llvm.call @__nv_fabsf(%64) : (f32) -> f32
    %66 = llvm.fcmp "oge" %56, %65 : f32
    %67 = llvm.select %66, %56, %65 : i1, f32
    %68 = llvm.add %60, %54  : i32
    %69 = llvm.extractvalue %53[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %70 = llvm.getelementptr %69[%68] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %71 = llvm.load %70 : !llvm.ptr<f32>
    %72 = llvm.call @__nv_fabsf(%71) : (f32) -> f32
    %73 = llvm.fcmp "oge" %57, %72 : f32
    %74 = llvm.select %73, %57, %72 : i1, f32
    %75 = llvm.add %55, %19  : i32
    llvm.br ^bb4(%75, %67, %74 : i32, f32, f32)
  ^bb6(%76: f32, %77: f32):  // 2 preds: ^bb4, ^bb8
    llvm.br ^bb18(%76, %77 : f32, f32)
  ^bb7:  // pred: ^bb2
    %78 = llvm.icmp "slt" %31, %arg12 : i32
    %79 = llvm.add %31, %19  : i32
    %80 = llvm.icmp "slt" %79, %arg12 : i32
    llvm.br ^bb8(%20, %16, %16 : i32, f32, f32)
  ^bb8(%81: i32, %82: f32, %83: f32):  // 2 preds: ^bb7, ^bb17
    %84 = llvm.icmp "slt" %81, %17 : i32
    llvm.cond_br %84, ^bb9, ^bb6(%82, %83 : f32, f32)
  ^bb9:  // pred: ^bb8
    %85 = llvm.add %32, %81  : i32
    %86 = llvm.icmp "slt" %85, %23 : i32
    %87 = llvm.and %86, %78  : i1
    llvm.cond_br %87, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %88 = llvm.mul %85, %arg12  : i32
    %89 = llvm.add %88, %31  : i32
    %90 = llvm.mul %23, %24  : i32
    %91 = llvm.mul %90, %25  : i32
    %92 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %93 = llvm.extractvalue %9[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %94 = llvm.extractvalue %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %95 = llvm.insertvalue %93, %92[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %96 = llvm.insertvalue %94, %95[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %97 = llvm.insertvalue %20, %96[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %98 = llvm.insertvalue %91, %97[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %99 = llvm.insertvalue %19, %98[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %100 = llvm.extractvalue %99[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %101 = llvm.getelementptr %100[%89] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %102 = llvm.load %101 : !llvm.ptr<f32>
    %103 = llvm.call @__nv_fabsf(%102) : (f32) -> f32
    %104 = llvm.fcmp "oge" %82, %103 : f32
    %105 = llvm.select %104, %82, %103 : i1, f32
    llvm.br ^bb12(%105 : f32)
  ^bb11:  // pred: ^bb9
    llvm.br ^bb12(%82 : f32)
  ^bb12(%106: f32):  // 2 preds: ^bb10, ^bb11
    llvm.br ^bb13
  ^bb13:  // pred: ^bb12
    %107 = llvm.and %86, %80  : i1
    llvm.cond_br %107, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %108 = llvm.mul %85, %arg12  : i32
    %109 = llvm.add %108, %79  : i32
    %110 = llvm.mul %23, %24  : i32
    %111 = llvm.mul %110, %25  : i32
    %112 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %113 = llvm.extractvalue %9[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %114 = llvm.extractvalue %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %115 = llvm.insertvalue %113, %112[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %116 = llvm.insertvalue %114, %115[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %117 = llvm.insertvalue %20, %116[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %118 = llvm.insertvalue %111, %117[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %119 = llvm.insertvalue %19, %118[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %120 = llvm.extractvalue %119[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %121 = llvm.getelementptr %120[%109] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %122 = llvm.load %121 : !llvm.ptr<f32>
    %123 = llvm.call @__nv_fabsf(%122) : (f32) -> f32
    %124 = llvm.fcmp "oge" %83, %123 : f32
    %125 = llvm.select %124, %83, %123 : i1, f32
    llvm.br ^bb16(%125 : f32)
  ^bb15:  // pred: ^bb13
    llvm.br ^bb16(%83 : f32)
  ^bb16(%126: f32):  // 2 preds: ^bb14, ^bb15
    llvm.br ^bb17
  ^bb17:  // pred: ^bb16
    %127 = llvm.add %81, %19  : i32
    llvm.br ^bb8(%127, %106, %126 : i32, f32, f32)
  ^bb18(%128: f32, %129: f32):  // pred: ^bb6
    llvm.br ^bb19
  ^bb19:  // pred: ^bb18
    %130 = llvm.icmp "slt" %31, %arg12 : i32
    llvm.cond_br %130, ^bb20, ^bb23
  ^bb20:  // pred: ^bb19
    %131 = llvm.extractvalue %15[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %132 = llvm.getelementptr %131[%31] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %133 = llvm.load %132 : !llvm.ptr<f32>
    llvm.br ^bb21(%133 : f32)
  ^bb21(%134: f32):  // 2 preds: ^bb20, ^bb21
    %135 = llvm.fcmp "ogt" %134, %128 : f32
    %136 = llvm.select %135, %134, %128 : i1, f32
    %137 = llvm.bitcast %132 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %138 = llvm.bitcast %134 : f32 to i32
    %139 = llvm.bitcast %136 : f32 to i32
    %140 = llvm.cmpxchg %137, %138, %139 acq_rel monotonic : !llvm.ptr<i32>, i32
    %141 = llvm.extractvalue %140[0] : !llvm.struct<(i32, i1)> 
    %142 = llvm.bitcast %141 : i32 to f32
    %143 = llvm.extractvalue %140[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %143, ^bb22, ^bb21(%142 : f32)
  ^bb22:  // pred: ^bb21
    llvm.br ^bb23
  ^bb23:  // 2 preds: ^bb19, ^bb22
    %144 = llvm.add %31, %19  : i32
    %145 = llvm.icmp "slt" %144, %arg12 : i32
    llvm.cond_br %145, ^bb24, ^bb27
  ^bb24:  // pred: ^bb23
    %146 = llvm.extractvalue %15[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %147 = llvm.getelementptr %146[%144] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %148 = llvm.load %147 : !llvm.ptr<f32>
    llvm.br ^bb25(%148 : f32)
  ^bb25(%149: f32):  // 2 preds: ^bb24, ^bb25
    %150 = llvm.fcmp "ogt" %149, %129 : f32
    %151 = llvm.select %150, %149, %129 : i1, f32
    %152 = llvm.bitcast %147 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %153 = llvm.bitcast %149 : f32 to i32
    %154 = llvm.bitcast %151 : f32 to i32
    %155 = llvm.cmpxchg %152, %153, %154 acq_rel monotonic : !llvm.ptr<i32>, i32
    %156 = llvm.extractvalue %155[0] : !llvm.struct<(i32, i1)> 
    %157 = llvm.bitcast %156 : i32 to f32
    %158 = llvm.extractvalue %155[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %158, ^bb26, ^bb25(%157 : f32)
  ^bb26:  // pred: ^bb25
    llvm.br ^bb27
  ^bb27:  // 2 preds: ^bb23, ^bb26
    llvm.br ^bb28
  ^bb28:  // 2 preds: ^bb1, ^bb27
    llvm.return
  }
}

// -----// IR Dump After LLVMInsertValueSimplifierPass (disc-llvm-insert-value-simplifier) //----- //
llvm.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: !llvm.ptr<f32>, %arg1: !llvm.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: !llvm.ptr<f32>, %arg14: !llvm.ptr<f32>, %arg15: i32, %arg16: i32, %arg17: i32) attributes {gpu.kernel, nvvm.kernel} {
  %0 = llvm.mlir.constant(0 : index) : i32
  %1 = llvm.mlir.constant(1 : index) : i32
  %2 = llvm.mlir.constant(2 : index) : i32
  %3 = llvm.mlir.constant(128 : index) : i32
  %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
  %5 = nvvm.read.ptx.sreg.ctaid.x : i32
  %6 = nvvm.read.ptx.sreg.tid.x : i32
  llvm.br ^bb1
^bb1:  // pred: ^bb0
  %7 = llvm.mul %5, %arg9  : i32
  %8 = llvm.add %6, %7  : i32
  %9 = llvm.icmp "ult" %8, %arg10 : i32
  llvm.cond_br %9, ^bb2, ^bb28
^bb2:  // pred: ^bb1
  %10 = llvm.srem %8, %arg11  : i32
  %11 = llvm.sdiv %8, %arg11  : i32
  %12 = llvm.mul %10, %2  : i32
  %13 = llvm.mul %11, %3  : i32
  %14 = llvm.add %13, %3  : i32
  %15 = llvm.icmp "slt" %14, %arg3 : i32
  %16 = llvm.urem %arg3, %3  : i32
  %17 = llvm.icmp "eq" %16, %0 : i32
  %18 = llvm.or %17, %15  : i1
  %19 = llvm.add %12, %2  : i32
  %20 = llvm.icmp "slt" %19, %arg12 : i32
  %21 = llvm.urem %arg12, %2  : i32
  %22 = llvm.icmp "eq" %21, %0 : i32
  %23 = llvm.or %22, %20  : i1
  %24 = llvm.and %18, %23  : i1
  llvm.cond_br %24, ^bb3, ^bb7
^bb3:  // pred: ^bb2
  %25 = llvm.add %12, %1  : i32
  llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
  %29 = llvm.icmp "slt" %26, %3 : i32
  llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
^bb5:  // pred: ^bb4
  %30 = llvm.add %13, %26  : i32
  %31 = llvm.mul %30, %arg12  : i32
  %32 = llvm.add %31, %12  : i32
  %33 = llvm.getelementptr %arg1[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %34 = llvm.load %33 : !llvm.ptr<f32>
  %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
  %36 = llvm.fcmp "oge" %27, %35 : f32
  %37 = llvm.select %36, %27, %35 : i1, f32
  %38 = llvm.add %31, %25  : i32
  %39 = llvm.getelementptr %arg1[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %40 = llvm.load %39 : !llvm.ptr<f32>
  %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
  %42 = llvm.fcmp "oge" %28, %41 : f32
  %43 = llvm.select %42, %28, %41 : i1, f32
  %44 = llvm.add %26, %1  : i32
  llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
  llvm.br ^bb18(%45, %46 : f32, f32)
^bb7:  // pred: ^bb2
  %47 = llvm.icmp "slt" %12, %arg12 : i32
  %48 = llvm.add %12, %1  : i32
  %49 = llvm.icmp "slt" %48, %arg12 : i32
  llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
  %53 = llvm.icmp "slt" %50, %3 : i32
  llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
^bb9:  // pred: ^bb8
  %54 = llvm.add %13, %50  : i32
  %55 = llvm.icmp "slt" %54, %arg3 : i32
  %56 = llvm.and %55, %47  : i1
  llvm.cond_br %56, ^bb10, ^bb11
^bb10:  // pred: ^bb9
  %57 = llvm.mul %54, %arg12  : i32
  %58 = llvm.add %57, %12  : i32
  %59 = llvm.getelementptr %arg1[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %60 = llvm.load %59 : !llvm.ptr<f32>
  %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
  %62 = llvm.fcmp "oge" %51, %61 : f32
  %63 = llvm.select %62, %51, %61 : i1, f32
  llvm.br ^bb12(%63 : f32)
^bb11:  // pred: ^bb9
  llvm.br ^bb12(%51 : f32)
^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
  llvm.br ^bb13
^bb13:  // pred: ^bb12
  %65 = llvm.and %55, %49  : i1
  llvm.cond_br %65, ^bb14, ^bb15
^bb14:  // pred: ^bb13
  %66 = llvm.mul %54, %arg12  : i32
  %67 = llvm.add %66, %48  : i32
  %68 = llvm.getelementptr %arg1[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %69 = llvm.load %68 : !llvm.ptr<f32>
  %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
  %71 = llvm.fcmp "oge" %52, %70 : f32
  %72 = llvm.select %71, %52, %70 : i1, f32
  llvm.br ^bb16(%72 : f32)
^bb15:  // pred: ^bb13
  llvm.br ^bb16(%52 : f32)
^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
  llvm.br ^bb17
^bb17:  // pred: ^bb16
  %74 = llvm.add %50, %1  : i32
  llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
^bb18(%75: f32, %76: f32):  // pred: ^bb6
  llvm.br ^bb19
^bb19:  // pred: ^bb18
  %77 = llvm.icmp "slt" %12, %arg12 : i32
  llvm.cond_br %77, ^bb20, ^bb23
^bb20:  // pred: ^bb19
  %78 = llvm.getelementptr %arg14[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %79 = llvm.load %78 : !llvm.ptr<f32>
  llvm.br ^bb21(%79 : f32)
^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
  %81 = llvm.fcmp "ogt" %80, %75 : f32
  %82 = llvm.select %81, %80, %75 : i1, f32
  %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
  %84 = llvm.bitcast %80 : f32 to i32
  %85 = llvm.bitcast %82 : f32 to i32
  %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
  %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
  %88 = llvm.bitcast %87 : i32 to f32
  %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
  llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
^bb22:  // pred: ^bb21
  llvm.br ^bb23
^bb23:  // 2 preds: ^bb19, ^bb22
  %90 = llvm.add %12, %1  : i32
  %91 = llvm.icmp "slt" %90, %arg12 : i32
  llvm.cond_br %91, ^bb24, ^bb27
^bb24:  // pred: ^bb23
  %92 = llvm.getelementptr %arg14[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %93 = llvm.load %92 : !llvm.ptr<f32>
  llvm.br ^bb25(%93 : f32)
^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
  %95 = llvm.fcmp "ogt" %94, %76 : f32
  %96 = llvm.select %95, %94, %76 : i1, f32
  %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
  %98 = llvm.bitcast %94 : f32 to i32
  %99 = llvm.bitcast %96 : f32 to i32
  %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
  %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
  %102 = llvm.bitcast %101 : i32 to f32
  %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
  llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
^bb26:  // pred: ^bb25
  llvm.br ^bb27
^bb27:  // 2 preds: ^bb23, ^bb26
  llvm.br ^bb28
^bb28:  // 2 preds: ^bb1, ^bb27
  llvm.return
}

// -----// IR Dump After FunctionDeadArgumentEliminationPass (disc-function-dead-argument-elimination) //----- //
gpu.module @main_kernel_2 {
  llvm.func @__nv_fabsf(f32) -> f32
  llvm.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(0 : index) : i32
    %1 = llvm.mlir.constant(1 : index) : i32
    %2 = llvm.mlir.constant(2 : index) : i32
    %3 = llvm.mlir.constant(128 : index) : i32
    %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %5 = nvvm.read.ptx.sreg.ctaid.x : i32
    %6 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %7 = llvm.mul %5, %arg2  : i32
    %8 = llvm.add %6, %7  : i32
    %9 = llvm.icmp "ult" %8, %arg3 : i32
    llvm.cond_br %9, ^bb2, ^bb28
  ^bb2:  // pred: ^bb1
    %10 = llvm.srem %8, %arg4  : i32
    %11 = llvm.sdiv %8, %arg4  : i32
    %12 = llvm.mul %10, %2  : i32
    %13 = llvm.mul %11, %3  : i32
    %14 = llvm.add %13, %3  : i32
    %15 = llvm.icmp "slt" %14, %arg1 : i32
    %16 = llvm.urem %arg1, %3  : i32
    %17 = llvm.icmp "eq" %16, %0 : i32
    %18 = llvm.or %17, %15  : i1
    %19 = llvm.add %12, %2  : i32
    %20 = llvm.icmp "slt" %19, %arg5 : i32
    %21 = llvm.urem %arg5, %2  : i32
    %22 = llvm.icmp "eq" %21, %0 : i32
    %23 = llvm.or %22, %20  : i1
    %24 = llvm.and %18, %23  : i1
    llvm.cond_br %24, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %25 = llvm.add %12, %1  : i32
    llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
  ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
    %29 = llvm.icmp "slt" %26, %3 : i32
    llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
  ^bb5:  // pred: ^bb4
    %30 = llvm.add %13, %26  : i32
    %31 = llvm.mul %30, %arg5  : i32
    %32 = llvm.add %31, %12  : i32
    %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %34 = llvm.load %33 : !llvm.ptr<f32>
    %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
    %36 = llvm.fcmp "oge" %27, %35 : f32
    %37 = llvm.select %36, %27, %35 : i1, f32
    %38 = llvm.add %31, %25  : i32
    %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %40 = llvm.load %39 : !llvm.ptr<f32>
    %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
    %42 = llvm.fcmp "oge" %28, %41 : f32
    %43 = llvm.select %42, %28, %41 : i1, f32
    %44 = llvm.add %26, %1  : i32
    llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
  ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
    llvm.br ^bb18(%45, %46 : f32, f32)
  ^bb7:  // pred: ^bb2
    %47 = llvm.icmp "slt" %12, %arg5 : i32
    %48 = llvm.add %12, %1  : i32
    %49 = llvm.icmp "slt" %48, %arg5 : i32
    llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
  ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
    %53 = llvm.icmp "slt" %50, %3 : i32
    llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
  ^bb9:  // pred: ^bb8
    %54 = llvm.add %13, %50  : i32
    %55 = llvm.icmp "slt" %54, %arg1 : i32
    %56 = llvm.and %55, %47  : i1
    llvm.cond_br %56, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %57 = llvm.mul %54, %arg5  : i32
    %58 = llvm.add %57, %12  : i32
    %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %60 = llvm.load %59 : !llvm.ptr<f32>
    %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
    %62 = llvm.fcmp "oge" %51, %61 : f32
    %63 = llvm.select %62, %51, %61 : i1, f32
    llvm.br ^bb12(%63 : f32)
  ^bb11:  // pred: ^bb9
    llvm.br ^bb12(%51 : f32)
  ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
    llvm.br ^bb13
  ^bb13:  // pred: ^bb12
    %65 = llvm.and %55, %49  : i1
    llvm.cond_br %65, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %66 = llvm.mul %54, %arg5  : i32
    %67 = llvm.add %66, %48  : i32
    %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %69 = llvm.load %68 : !llvm.ptr<f32>
    %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
    %71 = llvm.fcmp "oge" %52, %70 : f32
    %72 = llvm.select %71, %52, %70 : i1, f32
    llvm.br ^bb16(%72 : f32)
  ^bb15:  // pred: ^bb13
    llvm.br ^bb16(%52 : f32)
  ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
    llvm.br ^bb17
  ^bb17:  // pred: ^bb16
    %74 = llvm.add %50, %1  : i32
    llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
  ^bb18(%75: f32, %76: f32):  // pred: ^bb6
    llvm.br ^bb19
  ^bb19:  // pred: ^bb18
    %77 = llvm.icmp "slt" %12, %arg5 : i32
    llvm.cond_br %77, ^bb20, ^bb23
  ^bb20:  // pred: ^bb19
    %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %79 = llvm.load %78 : !llvm.ptr<f32>
    llvm.br ^bb21(%79 : f32)
  ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
    %81 = llvm.fcmp "ogt" %80, %75 : f32
    %82 = llvm.select %81, %80, %75 : i1, f32
    %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %84 = llvm.bitcast %80 : f32 to i32
    %85 = llvm.bitcast %82 : f32 to i32
    %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
    %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
    %88 = llvm.bitcast %87 : i32 to f32
    %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
  ^bb22:  // pred: ^bb21
    llvm.br ^bb23
  ^bb23:  // 2 preds: ^bb19, ^bb22
    %90 = llvm.add %12, %1  : i32
    %91 = llvm.icmp "slt" %90, %arg5 : i32
    llvm.cond_br %91, ^bb24, ^bb27
  ^bb24:  // pred: ^bb23
    %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %93 = llvm.load %92 : !llvm.ptr<f32>
    llvm.br ^bb25(%93 : f32)
  ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
    %95 = llvm.fcmp "ogt" %94, %76 : f32
    %96 = llvm.select %95, %94, %76 : i1, f32
    %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %98 = llvm.bitcast %94 : f32 to i32
    %99 = llvm.bitcast %96 : f32 to i32
    %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
    %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
    %102 = llvm.bitcast %101 : i32 to f32
    %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
  ^bb26:  // pred: ^bb25
    llvm.br ^bb27
  ^bb27:  // 2 preds: ^bb23, ^bb26
    llvm.br ^bb28
  ^bb28:  // 2 preds: ^bb1, ^bb27
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel_2 attributes {gpu.binary = "P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w16h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
  llvm.func @__nv_fabsf(f32) -> f32
  llvm.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(0 : index) : i32
    %1 = llvm.mlir.constant(1 : index) : i32
    %2 = llvm.mlir.constant(2 : index) : i32
    %3 = llvm.mlir.constant(128 : index) : i32
    %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %5 = nvvm.read.ptx.sreg.ctaid.x : i32
    %6 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %7 = llvm.mul %5, %arg2  : i32
    %8 = llvm.add %6, %7  : i32
    %9 = llvm.icmp "ult" %8, %arg3 : i32
    llvm.cond_br %9, ^bb2, ^bb28
  ^bb2:  // pred: ^bb1
    %10 = llvm.srem %8, %arg4  : i32
    %11 = llvm.sdiv %8, %arg4  : i32
    %12 = llvm.mul %10, %2  : i32
    %13 = llvm.mul %11, %3  : i32
    %14 = llvm.add %13, %3  : i32
    %15 = llvm.icmp "slt" %14, %arg1 : i32
    %16 = llvm.urem %arg1, %3  : i32
    %17 = llvm.icmp "eq" %16, %0 : i32
    %18 = llvm.or %17, %15  : i1
    %19 = llvm.add %12, %2  : i32
    %20 = llvm.icmp "slt" %19, %arg5 : i32
    %21 = llvm.urem %arg5, %2  : i32
    %22 = llvm.icmp "eq" %21, %0 : i32
    %23 = llvm.or %22, %20  : i1
    %24 = llvm.and %18, %23  : i1
    llvm.cond_br %24, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %25 = llvm.add %12, %1  : i32
    llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
  ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
    %29 = llvm.icmp "slt" %26, %3 : i32
    llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
  ^bb5:  // pred: ^bb4
    %30 = llvm.add %13, %26  : i32
    %31 = llvm.mul %30, %arg5  : i32
    %32 = llvm.add %31, %12  : i32
    %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %34 = llvm.load %33 : !llvm.ptr<f32>
    %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
    %36 = llvm.fcmp "oge" %27, %35 : f32
    %37 = llvm.select %36, %27, %35 : i1, f32
    %38 = llvm.add %31, %25  : i32
    %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %40 = llvm.load %39 : !llvm.ptr<f32>
    %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
    %42 = llvm.fcmp "oge" %28, %41 : f32
    %43 = llvm.select %42, %28, %41 : i1, f32
    %44 = llvm.add %26, %1  : i32
    llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
  ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
    llvm.br ^bb18(%45, %46 : f32, f32)
  ^bb7:  // pred: ^bb2
    %47 = llvm.icmp "slt" %12, %arg5 : i32
    %48 = llvm.add %12, %1  : i32
    %49 = llvm.icmp "slt" %48, %arg5 : i32
    llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
  ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
    %53 = llvm.icmp "slt" %50, %3 : i32
    llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
  ^bb9:  // pred: ^bb8
    %54 = llvm.add %13, %50  : i32
    %55 = llvm.icmp "slt" %54, %arg1 : i32
    %56 = llvm.and %55, %47  : i1
    llvm.cond_br %56, ^bb10, ^bb11
  ^bb10:  // pred: ^bb9
    %57 = llvm.mul %54, %arg5  : i32
    %58 = llvm.add %57, %12  : i32
    %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %60 = llvm.load %59 : !llvm.ptr<f32>
    %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
    %62 = llvm.fcmp "oge" %51, %61 : f32
    %63 = llvm.select %62, %51, %61 : i1, f32
    llvm.br ^bb12(%63 : f32)
  ^bb11:  // pred: ^bb9
    llvm.br ^bb12(%51 : f32)
  ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
    llvm.br ^bb13
  ^bb13:  // pred: ^bb12
    %65 = llvm.and %55, %49  : i1
    llvm.cond_br %65, ^bb14, ^bb15
  ^bb14:  // pred: ^bb13
    %66 = llvm.mul %54, %arg5  : i32
    %67 = llvm.add %66, %48  : i32
    %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %69 = llvm.load %68 : !llvm.ptr<f32>
    %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
    %71 = llvm.fcmp "oge" %52, %70 : f32
    %72 = llvm.select %71, %52, %70 : i1, f32
    llvm.br ^bb16(%72 : f32)
  ^bb15:  // pred: ^bb13
    llvm.br ^bb16(%52 : f32)
  ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
    llvm.br ^bb17
  ^bb17:  // pred: ^bb16
    %74 = llvm.add %50, %1  : i32
    llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
  ^bb18(%75: f32, %76: f32):  // pred: ^bb6
    llvm.br ^bb19
  ^bb19:  // pred: ^bb18
    %77 = llvm.icmp "slt" %12, %arg5 : i32
    llvm.cond_br %77, ^bb20, ^bb23
  ^bb20:  // pred: ^bb19
    %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %79 = llvm.load %78 : !llvm.ptr<f32>
    llvm.br ^bb21(%79 : f32)
  ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
    %81 = llvm.fcmp "ogt" %80, %75 : f32
    %82 = llvm.select %81, %80, %75 : i1, f32
    %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %84 = llvm.bitcast %80 : f32 to i32
    %85 = llvm.bitcast %82 : f32 to i32
    %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
    %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
    %88 = llvm.bitcast %87 : i32 to f32
    %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
  ^bb22:  // pred: ^bb21
    llvm.br ^bb23
  ^bb23:  // 2 preds: ^bb19, ^bb22
    %90 = llvm.add %12, %1  : i32
    %91 = llvm.icmp "slt" %90, %arg5 : i32
    llvm.cond_br %91, ^bb24, ^bb27
  ^bb24:  // pred: ^bb23
    %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %93 = llvm.load %92 : !llvm.ptr<f32>
    llvm.br ^bb25(%93 : f32)
  ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
    %95 = llvm.fcmp "ogt" %94, %76 : f32
    %96 = llvm.select %95, %94, %76 : i1, f32
    %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %98 = llvm.bitcast %94 : f32 to i32
    %99 = llvm.bitcast %96 : f32 to i32
    %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
    %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
    %102 = llvm.bitcast %101 : i32 to f32
    %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
  ^bb26:  // pred: ^bb25
    llvm.br ^bb27
  ^bb27:  // 2 preds: ^bb23, ^bb26
    llvm.br ^bb28
  ^bb28:  // 2 preds: ^bb1, ^bb27
    llvm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  scf.if %15 {
    %18 = affine.apply affine_map<()[s0] -> (s0 ceildiv 256)>()[%5]
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%18, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %19 = arith.ceildivsi %dim_1, %c128 : index
    %20 = arith.ceildivsi %5, %c2 : index
    %21 = arith.muli %19, %20 : index
    %22 = affine.apply affine_map<(d0) -> (d0 ceildiv 256)>(%21)
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%22, %c1, %c1) threads in (%c256, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c256 : index, %21 : index, %20 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
  } else {
    %18 = affine.apply affine_map<()[s0] -> (s0 ceildiv 128)>()[%5]
    gpu.launch_func  @main_kernel_1::@main_kColReduction_reduce__4_1_0___8w16h blocks in (%18, %c1, %c1) threads in (%c128, %c1, %c1) args(%c128 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %19 = arith.ceildivsi %dim_1, %c128 : index
    %20 = arith.ceildivsi %5, %c2 : index
    %21 = arith.muli %19, %20 : index
    %22 = affine.apply affine_map<(d0) -> (d0 ceildiv 128)>(%21)
    gpu.launch_func  @main_kernel_2::@main_kColReduction_reduce__4_1_0___8w16h_1 blocks in (%22, %c1, %c1) threads in (%c128, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c128 : index, %21 : index, %20 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
  }
  %16 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %17 = "disc_ral.dispatch"(%arg0, %16, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %17 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
#map = affine_map<()[s0] -> (s0 ceildiv 256)>
#map1 = affine_map<(d0) -> (d0 ceildiv 256)>
#map2 = affine_map<()[s0] -> (s0 ceildiv 128)>
#map3 = affine_map<(d0) -> (d0 ceildiv 128)>
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c256 = arith.constant 256 : index
    %c108 = arith.constant 108 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
    %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
    %2 = arith.index_cast %dim_0 : index to i32
    %3 = arith.index_cast %dim : index to i32
    %4 = arith.muli %2, %3 : i32
    %5 = arith.index_cast %4 : i32 to index
    %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
    %6 = arith.muli %dim_1, %5 : index
    %7 = arith.addi %6, %c-1 : index
    %8 = arith.divsi %7, %c256 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.subi %c0, %6 : index
    %11 = arith.divsi %10, %c256 : index
    %12 = arith.subi %c0, %11 : index
    %13 = arith.cmpi sgt, %6, %c0 : index
    %14 = arith.select %13, %9, %12 : index
    %15 = arith.cmpi sgt, %14, %c108 : index
    cf.cond_br %15, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %16 = affine.apply #map()[%5]
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%16, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %17 = arith.ceildivsi %dim_1, %c128 : index
    %18 = arith.ceildivsi %5, %c2 : index
    %19 = arith.muli %17, %18 : index
    %20 = affine.apply #map1(%19)
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%20, %c1, %c1) threads in (%c256, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c256 : index, %19 : index, %18 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    %21 = affine.apply #map2()[%5]
    gpu.launch_func  @main_kernel_1::@main_kColReduction_reduce__4_1_0___8w16h blocks in (%21, %c1, %c1) threads in (%c128, %c1, %c1) args(%c128 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %22 = arith.ceildivsi %dim_1, %c128 : index
    %23 = arith.ceildivsi %5, %c2 : index
    %24 = arith.muli %22, %23 : index
    %25 = affine.apply #map3(%24)
    gpu.launch_func  @main_kernel_2::@main_kColReduction_reduce__4_1_0___8w16h_1 blocks in (%25, %c1, %c1) threads in (%c128, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c128 : index, %24 : index, %23 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    %26 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
    %27 = "disc_ral.dispatch"(%arg0, %26, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %27 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
    memref.dealloc %alloc : memref<?xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary = "P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %1 = nvvm.read.ptx.sreg.ctaid.x : i32
      %2 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %3 = llvm.mul %1, %arg0  : i32
      %4 = llvm.add %2, %3  : i32
      %5 = llvm.icmp "ult" %4, %arg1 : i32
      llvm.cond_br %5, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %0, %6 : !llvm.ptr<f32>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary = "P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @__nv_fabsf(f32) -> f32
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0 : index) : i32
      %1 = llvm.mlir.constant(1 : index) : i32
      %2 = llvm.mlir.constant(2 : index) : i32
      %3 = llvm.mlir.constant(128 : index) : i32
      %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %5 = nvvm.read.ptx.sreg.ctaid.x : i32
      %6 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %7 = llvm.mul %5, %arg2  : i32
      %8 = llvm.add %6, %7  : i32
      %9 = llvm.icmp "ult" %8, %arg3 : i32
      llvm.cond_br %9, ^bb2, ^bb28
    ^bb2:  // pred: ^bb1
      %10 = llvm.srem %8, %arg4  : i32
      %11 = llvm.sdiv %8, %arg4  : i32
      %12 = llvm.mul %10, %2  : i32
      %13 = llvm.mul %11, %3  : i32
      %14 = llvm.add %13, %3  : i32
      %15 = llvm.icmp "slt" %14, %arg1 : i32
      %16 = llvm.urem %arg1, %3  : i32
      %17 = llvm.icmp "eq" %16, %0 : i32
      %18 = llvm.or %17, %15  : i1
      %19 = llvm.add %12, %2  : i32
      %20 = llvm.icmp "slt" %19, %arg5 : i32
      %21 = llvm.urem %arg5, %2  : i32
      %22 = llvm.icmp "eq" %21, %0 : i32
      %23 = llvm.or %22, %20  : i1
      %24 = llvm.and %18, %23  : i1
      llvm.cond_br %24, ^bb3, ^bb7
    ^bb3:  // pred: ^bb2
      %25 = llvm.add %12, %1  : i32
      llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
    ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
      %29 = llvm.icmp "slt" %26, %3 : i32
      llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
    ^bb5:  // pred: ^bb4
      %30 = llvm.add %13, %26  : i32
      %31 = llvm.mul %30, %arg5  : i32
      %32 = llvm.add %31, %12  : i32
      %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %34 = llvm.load %33 : !llvm.ptr<f32>
      %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
      %36 = llvm.fcmp "oge" %27, %35 : f32
      %37 = llvm.select %36, %27, %35 : i1, f32
      %38 = llvm.add %31, %25  : i32
      %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %40 = llvm.load %39 : !llvm.ptr<f32>
      %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
      %42 = llvm.fcmp "oge" %28, %41 : f32
      %43 = llvm.select %42, %28, %41 : i1, f32
      %44 = llvm.add %26, %1  : i32
      llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
    ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
      llvm.br ^bb18(%45, %46 : f32, f32)
    ^bb7:  // pred: ^bb2
      %47 = llvm.icmp "slt" %12, %arg5 : i32
      %48 = llvm.add %12, %1  : i32
      %49 = llvm.icmp "slt" %48, %arg5 : i32
      llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
    ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
      %53 = llvm.icmp "slt" %50, %3 : i32
      llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
    ^bb9:  // pred: ^bb8
      %54 = llvm.add %13, %50  : i32
      %55 = llvm.icmp "slt" %54, %arg1 : i32
      %56 = llvm.and %55, %47  : i1
      llvm.cond_br %56, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %57 = llvm.mul %54, %arg5  : i32
      %58 = llvm.add %57, %12  : i32
      %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %60 = llvm.load %59 : !llvm.ptr<f32>
      %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
      %62 = llvm.fcmp "oge" %51, %61 : f32
      %63 = llvm.select %62, %51, %61 : i1, f32
      llvm.br ^bb12(%63 : f32)
    ^bb11:  // pred: ^bb9
      llvm.br ^bb12(%51 : f32)
    ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
      llvm.br ^bb13
    ^bb13:  // pred: ^bb12
      %65 = llvm.and %55, %49  : i1
      llvm.cond_br %65, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %66 = llvm.mul %54, %arg5  : i32
      %67 = llvm.add %66, %48  : i32
      %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %69 = llvm.load %68 : !llvm.ptr<f32>
      %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
      %71 = llvm.fcmp "oge" %52, %70 : f32
      %72 = llvm.select %71, %52, %70 : i1, f32
      llvm.br ^bb16(%72 : f32)
    ^bb15:  // pred: ^bb13
      llvm.br ^bb16(%52 : f32)
    ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
      llvm.br ^bb17
    ^bb17:  // pred: ^bb16
      %74 = llvm.add %50, %1  : i32
      llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
    ^bb18(%75: f32, %76: f32):  // pred: ^bb6
      llvm.br ^bb19
    ^bb19:  // pred: ^bb18
      %77 = llvm.icmp "slt" %12, %arg5 : i32
      llvm.cond_br %77, ^bb20, ^bb23
    ^bb20:  // pred: ^bb19
      %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %79 = llvm.load %78 : !llvm.ptr<f32>
      llvm.br ^bb21(%79 : f32)
    ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
      %81 = llvm.fcmp "ogt" %80, %75 : f32
      %82 = llvm.select %81, %80, %75 : i1, f32
      %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %84 = llvm.bitcast %80 : f32 to i32
      %85 = llvm.bitcast %82 : f32 to i32
      %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
      %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
      %88 = llvm.bitcast %87 : i32 to f32
      %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
    ^bb22:  // pred: ^bb21
      llvm.br ^bb23
    ^bb23:  // 2 preds: ^bb19, ^bb22
      %90 = llvm.add %12, %1  : i32
      %91 = llvm.icmp "slt" %90, %arg5 : i32
      llvm.cond_br %91, ^bb24, ^bb27
    ^bb24:  // pred: ^bb23
      %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %93 = llvm.load %92 : !llvm.ptr<f32>
      llvm.br ^bb25(%93 : f32)
    ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
      %95 = llvm.fcmp "ogt" %94, %76 : f32
      %96 = llvm.select %95, %94, %76 : i1, f32
      %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %98 = llvm.bitcast %94 : f32 to i32
      %99 = llvm.bitcast %96 : f32 to i32
      %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
      %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
      %102 = llvm.bitcast %101 : i32 to f32
      %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
    ^bb26:  // pred: ^bb25
      llvm.br ^bb27
    ^bb27:  // 2 preds: ^bb23, ^bb26
      llvm.br ^bb28
    ^bb28:  // 2 preds: ^bb1, ^bb27
      llvm.return
    }
  }
  gpu.module @main_kernel_1 attributes {gpu.binary = "P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w16h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %1 = nvvm.read.ptx.sreg.ctaid.x : i32
      %2 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %3 = llvm.mul %1, %arg0  : i32
      %4 = llvm.add %2, %3  : i32
      %5 = llvm.icmp "ult" %4, %arg1 : i32
      llvm.cond_br %5, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %0, %6 : !llvm.ptr<f32>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_2 attributes {gpu.binary = "P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w16h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @__nv_fabsf(f32) -> f32
    llvm.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0 : index) : i32
      %1 = llvm.mlir.constant(1 : index) : i32
      %2 = llvm.mlir.constant(2 : index) : i32
      %3 = llvm.mlir.constant(128 : index) : i32
      %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %5 = nvvm.read.ptx.sreg.ctaid.x : i32
      %6 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %7 = llvm.mul %5, %arg2  : i32
      %8 = llvm.add %6, %7  : i32
      %9 = llvm.icmp "ult" %8, %arg3 : i32
      llvm.cond_br %9, ^bb2, ^bb28
    ^bb2:  // pred: ^bb1
      %10 = llvm.srem %8, %arg4  : i32
      %11 = llvm.sdiv %8, %arg4  : i32
      %12 = llvm.mul %10, %2  : i32
      %13 = llvm.mul %11, %3  : i32
      %14 = llvm.add %13, %3  : i32
      %15 = llvm.icmp "slt" %14, %arg1 : i32
      %16 = llvm.urem %arg1, %3  : i32
      %17 = llvm.icmp "eq" %16, %0 : i32
      %18 = llvm.or %17, %15  : i1
      %19 = llvm.add %12, %2  : i32
      %20 = llvm.icmp "slt" %19, %arg5 : i32
      %21 = llvm.urem %arg5, %2  : i32
      %22 = llvm.icmp "eq" %21, %0 : i32
      %23 = llvm.or %22, %20  : i1
      %24 = llvm.and %18, %23  : i1
      llvm.cond_br %24, ^bb3, ^bb7
    ^bb3:  // pred: ^bb2
      %25 = llvm.add %12, %1  : i32
      llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
    ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
      %29 = llvm.icmp "slt" %26, %3 : i32
      llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
    ^bb5:  // pred: ^bb4
      %30 = llvm.add %13, %26  : i32
      %31 = llvm.mul %30, %arg5  : i32
      %32 = llvm.add %31, %12  : i32
      %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %34 = llvm.load %33 : !llvm.ptr<f32>
      %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
      %36 = llvm.fcmp "oge" %27, %35 : f32
      %37 = llvm.select %36, %27, %35 : i1, f32
      %38 = llvm.add %31, %25  : i32
      %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %40 = llvm.load %39 : !llvm.ptr<f32>
      %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
      %42 = llvm.fcmp "oge" %28, %41 : f32
      %43 = llvm.select %42, %28, %41 : i1, f32
      %44 = llvm.add %26, %1  : i32
      llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
    ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
      llvm.br ^bb18(%45, %46 : f32, f32)
    ^bb7:  // pred: ^bb2
      %47 = llvm.icmp "slt" %12, %arg5 : i32
      %48 = llvm.add %12, %1  : i32
      %49 = llvm.icmp "slt" %48, %arg5 : i32
      llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
    ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
      %53 = llvm.icmp "slt" %50, %3 : i32
      llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
    ^bb9:  // pred: ^bb8
      %54 = llvm.add %13, %50  : i32
      %55 = llvm.icmp "slt" %54, %arg1 : i32
      %56 = llvm.and %55, %47  : i1
      llvm.cond_br %56, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %57 = llvm.mul %54, %arg5  : i32
      %58 = llvm.add %57, %12  : i32
      %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %60 = llvm.load %59 : !llvm.ptr<f32>
      %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
      %62 = llvm.fcmp "oge" %51, %61 : f32
      %63 = llvm.select %62, %51, %61 : i1, f32
      llvm.br ^bb12(%63 : f32)
    ^bb11:  // pred: ^bb9
      llvm.br ^bb12(%51 : f32)
    ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
      llvm.br ^bb13
    ^bb13:  // pred: ^bb12
      %65 = llvm.and %55, %49  : i1
      llvm.cond_br %65, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %66 = llvm.mul %54, %arg5  : i32
      %67 = llvm.add %66, %48  : i32
      %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %69 = llvm.load %68 : !llvm.ptr<f32>
      %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
      %71 = llvm.fcmp "oge" %52, %70 : f32
      %72 = llvm.select %71, %52, %70 : i1, f32
      llvm.br ^bb16(%72 : f32)
    ^bb15:  // pred: ^bb13
      llvm.br ^bb16(%52 : f32)
    ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
      llvm.br ^bb17
    ^bb17:  // pred: ^bb16
      %74 = llvm.add %50, %1  : i32
      llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
    ^bb18(%75: f32, %76: f32):  // pred: ^bb6
      llvm.br ^bb19
    ^bb19:  // pred: ^bb18
      %77 = llvm.icmp "slt" %12, %arg5 : i32
      llvm.cond_br %77, ^bb20, ^bb23
    ^bb20:  // pred: ^bb19
      %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %79 = llvm.load %78 : !llvm.ptr<f32>
      llvm.br ^bb21(%79 : f32)
    ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
      %81 = llvm.fcmp "ogt" %80, %75 : f32
      %82 = llvm.select %81, %80, %75 : i1, f32
      %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %84 = llvm.bitcast %80 : f32 to i32
      %85 = llvm.bitcast %82 : f32 to i32
      %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
      %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
      %88 = llvm.bitcast %87 : i32 to f32
      %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
    ^bb22:  // pred: ^bb21
      llvm.br ^bb23
    ^bb23:  // 2 preds: ^bb19, ^bb22
      %90 = llvm.add %12, %1  : i32
      %91 = llvm.icmp "slt" %90, %arg5 : i32
      llvm.cond_br %91, ^bb24, ^bb27
    ^bb24:  // pred: ^bb23
      %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %93 = llvm.load %92 : !llvm.ptr<f32>
      llvm.br ^bb25(%93 : f32)
    ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
      %95 = llvm.fcmp "ogt" %94, %76 : f32
      %96 = llvm.select %95, %94, %76 : i1, f32
      %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %98 = llvm.bitcast %94 : f32 to i32
      %99 = llvm.bitcast %96 : f32 to i32
      %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
      %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
      %102 = llvm.bitcast %101 : i32 to f32
      %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
    ^bb26:  // pred: ^bb25
      llvm.br ^bb27
    ^bb27:  // 2 preds: ^bb23, ^bb26
      llvm.br ^bb28
    ^bb28:  // 2 preds: ^bb1, ^bb27
      llvm.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c-1 = arith.constant -1 : index
  %c128 = arith.constant 128 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %c256 = arith.constant 256 : index
  %c108 = arith.constant 108 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
  %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
  %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
  %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
  %2 = arith.index_cast %dim_0 : index to i32
  %3 = arith.index_cast %dim : index to i32
  %4 = arith.muli %2, %3 : i32
  %5 = arith.index_cast %4 : i32 to index
  %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
  %6 = arith.muli %dim_1, %5 : index
  %7 = arith.addi %6, %c-1 : index
  %8 = arith.divsi %7, %c256 : index
  %9 = arith.addi %8, %c1 : index
  %10 = arith.subi %c0, %6 : index
  %11 = arith.divsi %10, %c256 : index
  %12 = arith.subi %c0, %11 : index
  %13 = arith.cmpi sgt, %6, %c0 : index
  %14 = arith.select %13, %9, %12 : index
  %15 = arith.cmpi sgt, %14, %c108 : index
  cf.cond_br %15, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %16 = affine.apply affine_map<()[s0] -> (s0 ceildiv 256)>()[%5]
  gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%16, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
  %17 = arith.ceildivsi %dim_1, %c128 : index
  %18 = arith.ceildivsi %5, %c2 : index
  %19 = arith.muli %17, %18 : index
  %20 = affine.apply affine_map<()[s0] -> (s0 ceildiv 256)>()[%19]
  gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%20, %c1, %c1) threads in (%c256, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c256 : index, %19 : index, %18 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
  cf.br ^bb3
^bb2:  // pred: ^bb0
  %21 = affine.apply affine_map<()[s0] -> (s0 ceildiv 128)>()[%5]
  gpu.launch_func  @main_kernel_1::@main_kColReduction_reduce__4_1_0___8w16h blocks in (%21, %c1, %c1) threads in (%c128, %c1, %c1) args(%c128 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
  %22 = arith.ceildivsi %dim_1, %c128 : index
  %23 = arith.ceildivsi %5, %c2 : index
  %24 = arith.muli %22, %23 : index
  %25 = affine.apply affine_map<()[s0] -> (s0 ceildiv 128)>()[%24]
  gpu.launch_func  @main_kernel_2::@main_kColReduction_reduce__4_1_0___8w16h_1 blocks in (%25, %c1, %c1) threads in (%c128, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c128 : index, %24 : index, %23 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
  cf.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  %26 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
  %27 = "disc_ral.dispatch"(%arg0, %26, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %27 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
  memref.dealloc %alloc : memref<?xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c256 = arith.constant 256 : index
    %c108 = arith.constant 108 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
    %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
    %2 = arith.index_cast %dim_0 : index to i32
    %3 = arith.index_cast %dim : index to i32
    %4 = arith.muli %2, %3 : i32
    %5 = arith.index_cast %4 : i32 to index
    %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
    %6 = arith.muli %dim_1, %5 : index
    %7 = arith.addi %6, %c-1 : index
    %8 = arith.divsi %7, %c256 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.subi %c0, %6 : index
    %11 = arith.divsi %10, %c256 : index
    %12 = arith.subi %c0, %11 : index
    %13 = arith.cmpi sgt, %6, %c0 : index
    %14 = arith.select %13, %9, %12 : index
    %15 = arith.cmpi sgt, %14, %c108 : index
    cf.cond_br %15, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %c256_2 = arith.constant 256 : index
    %c0_3 = arith.constant 0 : index
    %c1_4 = arith.constant 1 : index
    %16 = arith.cmpi sle, %5, %c0_3 : index
    %17 = arith.subi %c0_3, %5 : index
    %18 = arith.subi %5, %c1_4 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c256_2 : index
    %21 = arith.subi %c0_3, %20 : index
    %22 = arith.addi %20, %c1_4 : index
    %23 = arith.select %16, %21, %22 : index
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%23, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %24 = arith.ceildivsi %dim_1, %c128 : index
    %25 = arith.ceildivsi %5, %c2 : index
    %26 = arith.muli %24, %25 : index
    %c256_5 = arith.constant 256 : index
    %c0_6 = arith.constant 0 : index
    %c1_7 = arith.constant 1 : index
    %27 = arith.cmpi sle, %26, %c0_6 : index
    %28 = arith.subi %c0_6, %26 : index
    %29 = arith.subi %26, %c1_7 : index
    %30 = arith.select %27, %28, %29 : index
    %31 = arith.divsi %30, %c256_5 : index
    %32 = arith.subi %c0_6, %31 : index
    %33 = arith.addi %31, %c1_7 : index
    %34 = arith.select %27, %32, %33 : index
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%34, %c1, %c1) threads in (%c256, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c256 : index, %26 : index, %25 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    %c128_8 = arith.constant 128 : index
    %c0_9 = arith.constant 0 : index
    %c1_10 = arith.constant 1 : index
    %35 = arith.cmpi sle, %5, %c0_9 : index
    %36 = arith.subi %c0_9, %5 : index
    %37 = arith.subi %5, %c1_10 : index
    %38 = arith.select %35, %36, %37 : index
    %39 = arith.divsi %38, %c128_8 : index
    %40 = arith.subi %c0_9, %39 : index
    %41 = arith.addi %39, %c1_10 : index
    %42 = arith.select %35, %40, %41 : index
    gpu.launch_func  @main_kernel_1::@main_kColReduction_reduce__4_1_0___8w16h blocks in (%42, %c1, %c1) threads in (%c128, %c1, %c1) args(%c128 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %43 = arith.ceildivsi %dim_1, %c128 : index
    %44 = arith.ceildivsi %5, %c2 : index
    %45 = arith.muli %43, %44 : index
    %c128_11 = arith.constant 128 : index
    %c0_12 = arith.constant 0 : index
    %c1_13 = arith.constant 1 : index
    %46 = arith.cmpi sle, %45, %c0_12 : index
    %47 = arith.subi %c0_12, %45 : index
    %48 = arith.subi %45, %c1_13 : index
    %49 = arith.select %46, %47, %48 : index
    %50 = arith.divsi %49, %c128_11 : index
    %51 = arith.subi %c0_12, %50 : index
    %52 = arith.addi %50, %c1_13 : index
    %53 = arith.select %46, %51, %52 : index
    gpu.launch_func  @main_kernel_2::@main_kColReduction_reduce__4_1_0___8w16h_1 blocks in (%53, %c1, %c1) threads in (%c128, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c128 : index, %45 : index, %44 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    %54 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
    %55 = "disc_ral.dispatch"(%arg0, %54, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %55 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
    memref.dealloc %alloc : memref<?xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary = "P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %1 = nvvm.read.ptx.sreg.ctaid.x : i32
      %2 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %3 = llvm.mul %1, %arg0  : i32
      %4 = llvm.add %2, %3  : i32
      %5 = llvm.icmp "ult" %4, %arg1 : i32
      llvm.cond_br %5, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %0, %6 : !llvm.ptr<f32>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary = "P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @__nv_fabsf(f32) -> f32
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0 : index) : i32
      %1 = llvm.mlir.constant(1 : index) : i32
      %2 = llvm.mlir.constant(2 : index) : i32
      %3 = llvm.mlir.constant(128 : index) : i32
      %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %5 = nvvm.read.ptx.sreg.ctaid.x : i32
      %6 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %7 = llvm.mul %5, %arg2  : i32
      %8 = llvm.add %6, %7  : i32
      %9 = llvm.icmp "ult" %8, %arg3 : i32
      llvm.cond_br %9, ^bb2, ^bb28
    ^bb2:  // pred: ^bb1
      %10 = llvm.srem %8, %arg4  : i32
      %11 = llvm.sdiv %8, %arg4  : i32
      %12 = llvm.mul %10, %2  : i32
      %13 = llvm.mul %11, %3  : i32
      %14 = llvm.add %13, %3  : i32
      %15 = llvm.icmp "slt" %14, %arg1 : i32
      %16 = llvm.urem %arg1, %3  : i32
      %17 = llvm.icmp "eq" %16, %0 : i32
      %18 = llvm.or %17, %15  : i1
      %19 = llvm.add %12, %2  : i32
      %20 = llvm.icmp "slt" %19, %arg5 : i32
      %21 = llvm.urem %arg5, %2  : i32
      %22 = llvm.icmp "eq" %21, %0 : i32
      %23 = llvm.or %22, %20  : i1
      %24 = llvm.and %18, %23  : i1
      llvm.cond_br %24, ^bb3, ^bb7
    ^bb3:  // pred: ^bb2
      %25 = llvm.add %12, %1  : i32
      llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
    ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
      %29 = llvm.icmp "slt" %26, %3 : i32
      llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
    ^bb5:  // pred: ^bb4
      %30 = llvm.add %13, %26  : i32
      %31 = llvm.mul %30, %arg5  : i32
      %32 = llvm.add %31, %12  : i32
      %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %34 = llvm.load %33 : !llvm.ptr<f32>
      %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
      %36 = llvm.fcmp "oge" %27, %35 : f32
      %37 = llvm.select %36, %27, %35 : i1, f32
      %38 = llvm.add %31, %25  : i32
      %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %40 = llvm.load %39 : !llvm.ptr<f32>
      %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
      %42 = llvm.fcmp "oge" %28, %41 : f32
      %43 = llvm.select %42, %28, %41 : i1, f32
      %44 = llvm.add %26, %1  : i32
      llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
    ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
      llvm.br ^bb18(%45, %46 : f32, f32)
    ^bb7:  // pred: ^bb2
      %47 = llvm.icmp "slt" %12, %arg5 : i32
      %48 = llvm.add %12, %1  : i32
      %49 = llvm.icmp "slt" %48, %arg5 : i32
      llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
    ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
      %53 = llvm.icmp "slt" %50, %3 : i32
      llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
    ^bb9:  // pred: ^bb8
      %54 = llvm.add %13, %50  : i32
      %55 = llvm.icmp "slt" %54, %arg1 : i32
      %56 = llvm.and %55, %47  : i1
      llvm.cond_br %56, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %57 = llvm.mul %54, %arg5  : i32
      %58 = llvm.add %57, %12  : i32
      %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %60 = llvm.load %59 : !llvm.ptr<f32>
      %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
      %62 = llvm.fcmp "oge" %51, %61 : f32
      %63 = llvm.select %62, %51, %61 : i1, f32
      llvm.br ^bb12(%63 : f32)
    ^bb11:  // pred: ^bb9
      llvm.br ^bb12(%51 : f32)
    ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
      llvm.br ^bb13
    ^bb13:  // pred: ^bb12
      %65 = llvm.and %55, %49  : i1
      llvm.cond_br %65, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %66 = llvm.mul %54, %arg5  : i32
      %67 = llvm.add %66, %48  : i32
      %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %69 = llvm.load %68 : !llvm.ptr<f32>
      %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
      %71 = llvm.fcmp "oge" %52, %70 : f32
      %72 = llvm.select %71, %52, %70 : i1, f32
      llvm.br ^bb16(%72 : f32)
    ^bb15:  // pred: ^bb13
      llvm.br ^bb16(%52 : f32)
    ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
      llvm.br ^bb17
    ^bb17:  // pred: ^bb16
      %74 = llvm.add %50, %1  : i32
      llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
    ^bb18(%75: f32, %76: f32):  // pred: ^bb6
      llvm.br ^bb19
    ^bb19:  // pred: ^bb18
      %77 = llvm.icmp "slt" %12, %arg5 : i32
      llvm.cond_br %77, ^bb20, ^bb23
    ^bb20:  // pred: ^bb19
      %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %79 = llvm.load %78 : !llvm.ptr<f32>
      llvm.br ^bb21(%79 : f32)
    ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
      %81 = llvm.fcmp "ogt" %80, %75 : f32
      %82 = llvm.select %81, %80, %75 : i1, f32
      %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %84 = llvm.bitcast %80 : f32 to i32
      %85 = llvm.bitcast %82 : f32 to i32
      %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
      %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
      %88 = llvm.bitcast %87 : i32 to f32
      %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
    ^bb22:  // pred: ^bb21
      llvm.br ^bb23
    ^bb23:  // 2 preds: ^bb19, ^bb22
      %90 = llvm.add %12, %1  : i32
      %91 = llvm.icmp "slt" %90, %arg5 : i32
      llvm.cond_br %91, ^bb24, ^bb27
    ^bb24:  // pred: ^bb23
      %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %93 = llvm.load %92 : !llvm.ptr<f32>
      llvm.br ^bb25(%93 : f32)
    ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
      %95 = llvm.fcmp "ogt" %94, %76 : f32
      %96 = llvm.select %95, %94, %76 : i1, f32
      %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %98 = llvm.bitcast %94 : f32 to i32
      %99 = llvm.bitcast %96 : f32 to i32
      %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
      %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
      %102 = llvm.bitcast %101 : i32 to f32
      %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
    ^bb26:  // pred: ^bb25
      llvm.br ^bb27
    ^bb27:  // 2 preds: ^bb23, ^bb26
      llvm.br ^bb28
    ^bb28:  // 2 preds: ^bb1, ^bb27
      llvm.return
    }
  }
  gpu.module @main_kernel_1 attributes {gpu.binary = "P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w16h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %1 = nvvm.read.ptx.sreg.ctaid.x : i32
      %2 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %3 = llvm.mul %1, %arg0  : i32
      %4 = llvm.add %2, %3  : i32
      %5 = llvm.icmp "ult" %4, %arg1 : i32
      llvm.cond_br %5, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %0, %6 : !llvm.ptr<f32>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_2 attributes {gpu.binary = "P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w16h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @__nv_fabsf(f32) -> f32
    llvm.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0 : index) : i32
      %1 = llvm.mlir.constant(1 : index) : i32
      %2 = llvm.mlir.constant(2 : index) : i32
      %3 = llvm.mlir.constant(128 : index) : i32
      %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %5 = nvvm.read.ptx.sreg.ctaid.x : i32
      %6 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %7 = llvm.mul %5, %arg2  : i32
      %8 = llvm.add %6, %7  : i32
      %9 = llvm.icmp "ult" %8, %arg3 : i32
      llvm.cond_br %9, ^bb2, ^bb28
    ^bb2:  // pred: ^bb1
      %10 = llvm.srem %8, %arg4  : i32
      %11 = llvm.sdiv %8, %arg4  : i32
      %12 = llvm.mul %10, %2  : i32
      %13 = llvm.mul %11, %3  : i32
      %14 = llvm.add %13, %3  : i32
      %15 = llvm.icmp "slt" %14, %arg1 : i32
      %16 = llvm.urem %arg1, %3  : i32
      %17 = llvm.icmp "eq" %16, %0 : i32
      %18 = llvm.or %17, %15  : i1
      %19 = llvm.add %12, %2  : i32
      %20 = llvm.icmp "slt" %19, %arg5 : i32
      %21 = llvm.urem %arg5, %2  : i32
      %22 = llvm.icmp "eq" %21, %0 : i32
      %23 = llvm.or %22, %20  : i1
      %24 = llvm.and %18, %23  : i1
      llvm.cond_br %24, ^bb3, ^bb7
    ^bb3:  // pred: ^bb2
      %25 = llvm.add %12, %1  : i32
      llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
    ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
      %29 = llvm.icmp "slt" %26, %3 : i32
      llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
    ^bb5:  // pred: ^bb4
      %30 = llvm.add %13, %26  : i32
      %31 = llvm.mul %30, %arg5  : i32
      %32 = llvm.add %31, %12  : i32
      %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %34 = llvm.load %33 : !llvm.ptr<f32>
      %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
      %36 = llvm.fcmp "oge" %27, %35 : f32
      %37 = llvm.select %36, %27, %35 : i1, f32
      %38 = llvm.add %31, %25  : i32
      %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %40 = llvm.load %39 : !llvm.ptr<f32>
      %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
      %42 = llvm.fcmp "oge" %28, %41 : f32
      %43 = llvm.select %42, %28, %41 : i1, f32
      %44 = llvm.add %26, %1  : i32
      llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
    ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
      llvm.br ^bb18(%45, %46 : f32, f32)
    ^bb7:  // pred: ^bb2
      %47 = llvm.icmp "slt" %12, %arg5 : i32
      %48 = llvm.add %12, %1  : i32
      %49 = llvm.icmp "slt" %48, %arg5 : i32
      llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
    ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
      %53 = llvm.icmp "slt" %50, %3 : i32
      llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
    ^bb9:  // pred: ^bb8
      %54 = llvm.add %13, %50  : i32
      %55 = llvm.icmp "slt" %54, %arg1 : i32
      %56 = llvm.and %55, %47  : i1
      llvm.cond_br %56, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %57 = llvm.mul %54, %arg5  : i32
      %58 = llvm.add %57, %12  : i32
      %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %60 = llvm.load %59 : !llvm.ptr<f32>
      %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
      %62 = llvm.fcmp "oge" %51, %61 : f32
      %63 = llvm.select %62, %51, %61 : i1, f32
      llvm.br ^bb12(%63 : f32)
    ^bb11:  // pred: ^bb9
      llvm.br ^bb12(%51 : f32)
    ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
      llvm.br ^bb13
    ^bb13:  // pred: ^bb12
      %65 = llvm.and %55, %49  : i1
      llvm.cond_br %65, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %66 = llvm.mul %54, %arg5  : i32
      %67 = llvm.add %66, %48  : i32
      %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %69 = llvm.load %68 : !llvm.ptr<f32>
      %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
      %71 = llvm.fcmp "oge" %52, %70 : f32
      %72 = llvm.select %71, %52, %70 : i1, f32
      llvm.br ^bb16(%72 : f32)
    ^bb15:  // pred: ^bb13
      llvm.br ^bb16(%52 : f32)
    ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
      llvm.br ^bb17
    ^bb17:  // pred: ^bb16
      %74 = llvm.add %50, %1  : i32
      llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
    ^bb18(%75: f32, %76: f32):  // pred: ^bb6
      llvm.br ^bb19
    ^bb19:  // pred: ^bb18
      %77 = llvm.icmp "slt" %12, %arg5 : i32
      llvm.cond_br %77, ^bb20, ^bb23
    ^bb20:  // pred: ^bb19
      %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %79 = llvm.load %78 : !llvm.ptr<f32>
      llvm.br ^bb21(%79 : f32)
    ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
      %81 = llvm.fcmp "ogt" %80, %75 : f32
      %82 = llvm.select %81, %80, %75 : i1, f32
      %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %84 = llvm.bitcast %80 : f32 to i32
      %85 = llvm.bitcast %82 : f32 to i32
      %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
      %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
      %88 = llvm.bitcast %87 : i32 to f32
      %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
    ^bb22:  // pred: ^bb21
      llvm.br ^bb23
    ^bb23:  // 2 preds: ^bb19, ^bb22
      %90 = llvm.add %12, %1  : i32
      %91 = llvm.icmp "slt" %90, %arg5 : i32
      llvm.cond_br %91, ^bb24, ^bb27
    ^bb24:  // pred: ^bb23
      %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %93 = llvm.load %92 : !llvm.ptr<f32>
      llvm.br ^bb25(%93 : f32)
    ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
      %95 = llvm.fcmp "ogt" %94, %76 : f32
      %96 = llvm.select %95, %94, %76 : i1, f32
      %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %98 = llvm.bitcast %94 : f32 to i32
      %99 = llvm.bitcast %96 : f32 to i32
      %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
      %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
      %102 = llvm.bitcast %101 : i32 to f32
      %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
    ^bb26:  // pred: ^bb25
      llvm.br ^bb27
    ^bb27:  // 2 preds: ^bb23, ^bb26
      llvm.br ^bb28
    ^bb28:  // 2 preds: ^bb1, ^bb27
      llvm.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c256 = arith.constant 256 : index
    %c108 = arith.constant 108 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
    %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
    %2 = arith.index_cast %dim_0 : index to i32
    %3 = arith.index_cast %dim : index to i32
    %4 = arith.muli %2, %3 : i32
    %5 = arith.index_cast %4 : i32 to index
    %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
    %6 = arith.muli %dim_1, %5 : index
    %7 = arith.addi %6, %c-1 : index
    %8 = arith.divsi %7, %c256 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.subi %c0, %6 : index
    %11 = arith.divsi %10, %c256 : index
    %12 = arith.subi %c0, %11 : index
    %13 = arith.cmpi sgt, %6, %c0 : index
    %14 = arith.select %13, %9, %12 : index
    %15 = arith.cmpi sgt, %14, %c108 : index
    cf.cond_br %15, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %c256_2 = arith.constant 256 : index
    %c0_3 = arith.constant 0 : index
    %c1_4 = arith.constant 1 : index
    %16 = arith.cmpi sle, %5, %c0_3 : index
    %17 = arith.subi %c0_3, %5 : index
    %18 = arith.subi %5, %c1_4 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c256_2 : index
    %21 = arith.subi %c0_3, %20 : index
    %22 = arith.addi %20, %c1_4 : index
    %23 = arith.select %16, %21, %22 : index
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%23, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %24 = arith.ceildivsi %dim_1, %c128 : index
    %25 = arith.ceildivsi %5, %c2 : index
    %26 = arith.muli %24, %25 : index
    %c256_5 = arith.constant 256 : index
    %c0_6 = arith.constant 0 : index
    %c1_7 = arith.constant 1 : index
    %27 = arith.cmpi sle, %26, %c0_6 : index
    %28 = arith.subi %c0_6, %26 : index
    %29 = arith.subi %26, %c1_7 : index
    %30 = arith.select %27, %28, %29 : index
    %31 = arith.divsi %30, %c256_5 : index
    %32 = arith.subi %c0_6, %31 : index
    %33 = arith.addi %31, %c1_7 : index
    %34 = arith.select %27, %32, %33 : index
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%34, %c1, %c1) threads in (%c256, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c256 : index, %26 : index, %25 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    %c128_8 = arith.constant 128 : index
    %c0_9 = arith.constant 0 : index
    %c1_10 = arith.constant 1 : index
    %35 = arith.cmpi sle, %5, %c0_9 : index
    %36 = arith.subi %c0_9, %5 : index
    %37 = arith.subi %5, %c1_10 : index
    %38 = arith.select %35, %36, %37 : index
    %39 = arith.divsi %38, %c128_8 : index
    %40 = arith.subi %c0_9, %39 : index
    %41 = arith.addi %39, %c1_10 : index
    %42 = arith.select %35, %40, %41 : index
    gpu.launch_func  @main_kernel_1::@main_kColReduction_reduce__4_1_0___8w16h blocks in (%42, %c1, %c1) threads in (%c128, %c1, %c1) args(%c128 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %43 = arith.ceildivsi %dim_1, %c128 : index
    %44 = arith.ceildivsi %5, %c2 : index
    %45 = arith.muli %43, %44 : index
    %c128_11 = arith.constant 128 : index
    %c0_12 = arith.constant 0 : index
    %c1_13 = arith.constant 1 : index
    %46 = arith.cmpi sle, %45, %c0_12 : index
    %47 = arith.subi %c0_12, %45 : index
    %48 = arith.subi %45, %c1_13 : index
    %49 = arith.select %46, %47, %48 : index
    %50 = arith.divsi %49, %c128_11 : index
    %51 = arith.subi %c0_12, %50 : index
    %52 = arith.addi %50, %c1_13 : index
    %53 = arith.select %46, %51, %52 : index
    gpu.launch_func  @main_kernel_2::@main_kColReduction_reduce__4_1_0___8w16h_1 blocks in (%53, %c1, %c1) threads in (%c128, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c128 : index, %45 : index, %44 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    %54 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
    %55 = "disc_ral.dispatch"(%arg0, %54, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %55 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
    memref.dealloc %alloc : memref<?xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary = "P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %1 = nvvm.read.ptx.sreg.ctaid.x : i32
      %2 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %3 = llvm.mul %1, %arg0  : i32
      %4 = llvm.add %2, %3  : i32
      %5 = llvm.icmp "ult" %4, %arg1 : i32
      llvm.cond_br %5, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %0, %6 : !llvm.ptr<f32>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary = "P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @__nv_fabsf(f32) -> f32
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0 : index) : i32
      %1 = llvm.mlir.constant(1 : index) : i32
      %2 = llvm.mlir.constant(2 : index) : i32
      %3 = llvm.mlir.constant(128 : index) : i32
      %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %5 = nvvm.read.ptx.sreg.ctaid.x : i32
      %6 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %7 = llvm.mul %5, %arg2  : i32
      %8 = llvm.add %6, %7  : i32
      %9 = llvm.icmp "ult" %8, %arg3 : i32
      llvm.cond_br %9, ^bb2, ^bb28
    ^bb2:  // pred: ^bb1
      %10 = llvm.srem %8, %arg4  : i32
      %11 = llvm.sdiv %8, %arg4  : i32
      %12 = llvm.mul %10, %2  : i32
      %13 = llvm.mul %11, %3  : i32
      %14 = llvm.add %13, %3  : i32
      %15 = llvm.icmp "slt" %14, %arg1 : i32
      %16 = llvm.urem %arg1, %3  : i32
      %17 = llvm.icmp "eq" %16, %0 : i32
      %18 = llvm.or %17, %15  : i1
      %19 = llvm.add %12, %2  : i32
      %20 = llvm.icmp "slt" %19, %arg5 : i32
      %21 = llvm.urem %arg5, %2  : i32
      %22 = llvm.icmp "eq" %21, %0 : i32
      %23 = llvm.or %22, %20  : i1
      %24 = llvm.and %18, %23  : i1
      llvm.cond_br %24, ^bb3, ^bb7
    ^bb3:  // pred: ^bb2
      %25 = llvm.add %12, %1  : i32
      llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
    ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
      %29 = llvm.icmp "slt" %26, %3 : i32
      llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
    ^bb5:  // pred: ^bb4
      %30 = llvm.add %13, %26  : i32
      %31 = llvm.mul %30, %arg5  : i32
      %32 = llvm.add %31, %12  : i32
      %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %34 = llvm.load %33 : !llvm.ptr<f32>
      %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
      %36 = llvm.fcmp "oge" %27, %35 : f32
      %37 = llvm.select %36, %27, %35 : i1, f32
      %38 = llvm.add %31, %25  : i32
      %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %40 = llvm.load %39 : !llvm.ptr<f32>
      %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
      %42 = llvm.fcmp "oge" %28, %41 : f32
      %43 = llvm.select %42, %28, %41 : i1, f32
      %44 = llvm.add %26, %1  : i32
      llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
    ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
      llvm.br ^bb18(%45, %46 : f32, f32)
    ^bb7:  // pred: ^bb2
      %47 = llvm.icmp "slt" %12, %arg5 : i32
      %48 = llvm.add %12, %1  : i32
      %49 = llvm.icmp "slt" %48, %arg5 : i32
      llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
    ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
      %53 = llvm.icmp "slt" %50, %3 : i32
      llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
    ^bb9:  // pred: ^bb8
      %54 = llvm.add %13, %50  : i32
      %55 = llvm.icmp "slt" %54, %arg1 : i32
      %56 = llvm.and %55, %47  : i1
      llvm.cond_br %56, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %57 = llvm.mul %54, %arg5  : i32
      %58 = llvm.add %57, %12  : i32
      %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %60 = llvm.load %59 : !llvm.ptr<f32>
      %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
      %62 = llvm.fcmp "oge" %51, %61 : f32
      %63 = llvm.select %62, %51, %61 : i1, f32
      llvm.br ^bb12(%63 : f32)
    ^bb11:  // pred: ^bb9
      llvm.br ^bb12(%51 : f32)
    ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
      llvm.br ^bb13
    ^bb13:  // pred: ^bb12
      %65 = llvm.and %55, %49  : i1
      llvm.cond_br %65, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %66 = llvm.mul %54, %arg5  : i32
      %67 = llvm.add %66, %48  : i32
      %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %69 = llvm.load %68 : !llvm.ptr<f32>
      %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
      %71 = llvm.fcmp "oge" %52, %70 : f32
      %72 = llvm.select %71, %52, %70 : i1, f32
      llvm.br ^bb16(%72 : f32)
    ^bb15:  // pred: ^bb13
      llvm.br ^bb16(%52 : f32)
    ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
      llvm.br ^bb17
    ^bb17:  // pred: ^bb16
      %74 = llvm.add %50, %1  : i32
      llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
    ^bb18(%75: f32, %76: f32):  // pred: ^bb6
      llvm.br ^bb19
    ^bb19:  // pred: ^bb18
      %77 = llvm.icmp "slt" %12, %arg5 : i32
      llvm.cond_br %77, ^bb20, ^bb23
    ^bb20:  // pred: ^bb19
      %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %79 = llvm.load %78 : !llvm.ptr<f32>
      llvm.br ^bb21(%79 : f32)
    ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
      %81 = llvm.fcmp "ogt" %80, %75 : f32
      %82 = llvm.select %81, %80, %75 : i1, f32
      %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %84 = llvm.bitcast %80 : f32 to i32
      %85 = llvm.bitcast %82 : f32 to i32
      %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
      %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
      %88 = llvm.bitcast %87 : i32 to f32
      %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
    ^bb22:  // pred: ^bb21
      llvm.br ^bb23
    ^bb23:  // 2 preds: ^bb19, ^bb22
      %90 = llvm.add %12, %1  : i32
      %91 = llvm.icmp "slt" %90, %arg5 : i32
      llvm.cond_br %91, ^bb24, ^bb27
    ^bb24:  // pred: ^bb23
      %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %93 = llvm.load %92 : !llvm.ptr<f32>
      llvm.br ^bb25(%93 : f32)
    ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
      %95 = llvm.fcmp "ogt" %94, %76 : f32
      %96 = llvm.select %95, %94, %76 : i1, f32
      %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %98 = llvm.bitcast %94 : f32 to i32
      %99 = llvm.bitcast %96 : f32 to i32
      %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
      %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
      %102 = llvm.bitcast %101 : i32 to f32
      %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
    ^bb26:  // pred: ^bb25
      llvm.br ^bb27
    ^bb27:  // 2 preds: ^bb23, ^bb26
      llvm.br ^bb28
    ^bb28:  // 2 preds: ^bb1, ^bb27
      llvm.return
    }
  }
  gpu.module @main_kernel_1 attributes {gpu.binary = "P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w16h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %1 = nvvm.read.ptx.sreg.ctaid.x : i32
      %2 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %3 = llvm.mul %1, %arg0  : i32
      %4 = llvm.add %2, %3  : i32
      %5 = llvm.icmp "ult" %4, %arg1 : i32
      llvm.cond_br %5, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %0, %6 : !llvm.ptr<f32>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_2 attributes {gpu.binary = "P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w16h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @__nv_fabsf(f32) -> f32
    llvm.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0 : index) : i32
      %1 = llvm.mlir.constant(1 : index) : i32
      %2 = llvm.mlir.constant(2 : index) : i32
      %3 = llvm.mlir.constant(128 : index) : i32
      %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %5 = nvvm.read.ptx.sreg.ctaid.x : i32
      %6 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %7 = llvm.mul %5, %arg2  : i32
      %8 = llvm.add %6, %7  : i32
      %9 = llvm.icmp "ult" %8, %arg3 : i32
      llvm.cond_br %9, ^bb2, ^bb28
    ^bb2:  // pred: ^bb1
      %10 = llvm.srem %8, %arg4  : i32
      %11 = llvm.sdiv %8, %arg4  : i32
      %12 = llvm.mul %10, %2  : i32
      %13 = llvm.mul %11, %3  : i32
      %14 = llvm.add %13, %3  : i32
      %15 = llvm.icmp "slt" %14, %arg1 : i32
      %16 = llvm.urem %arg1, %3  : i32
      %17 = llvm.icmp "eq" %16, %0 : i32
      %18 = llvm.or %17, %15  : i1
      %19 = llvm.add %12, %2  : i32
      %20 = llvm.icmp "slt" %19, %arg5 : i32
      %21 = llvm.urem %arg5, %2  : i32
      %22 = llvm.icmp "eq" %21, %0 : i32
      %23 = llvm.or %22, %20  : i1
      %24 = llvm.and %18, %23  : i1
      llvm.cond_br %24, ^bb3, ^bb7
    ^bb3:  // pred: ^bb2
      %25 = llvm.add %12, %1  : i32
      llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
    ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
      %29 = llvm.icmp "slt" %26, %3 : i32
      llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
    ^bb5:  // pred: ^bb4
      %30 = llvm.add %13, %26  : i32
      %31 = llvm.mul %30, %arg5  : i32
      %32 = llvm.add %31, %12  : i32
      %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %34 = llvm.load %33 : !llvm.ptr<f32>
      %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
      %36 = llvm.fcmp "oge" %27, %35 : f32
      %37 = llvm.select %36, %27, %35 : i1, f32
      %38 = llvm.add %31, %25  : i32
      %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %40 = llvm.load %39 : !llvm.ptr<f32>
      %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
      %42 = llvm.fcmp "oge" %28, %41 : f32
      %43 = llvm.select %42, %28, %41 : i1, f32
      %44 = llvm.add %26, %1  : i32
      llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
    ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
      llvm.br ^bb18(%45, %46 : f32, f32)
    ^bb7:  // pred: ^bb2
      %47 = llvm.icmp "slt" %12, %arg5 : i32
      %48 = llvm.add %12, %1  : i32
      %49 = llvm.icmp "slt" %48, %arg5 : i32
      llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
    ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
      %53 = llvm.icmp "slt" %50, %3 : i32
      llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
    ^bb9:  // pred: ^bb8
      %54 = llvm.add %13, %50  : i32
      %55 = llvm.icmp "slt" %54, %arg1 : i32
      %56 = llvm.and %55, %47  : i1
      llvm.cond_br %56, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %57 = llvm.mul %54, %arg5  : i32
      %58 = llvm.add %57, %12  : i32
      %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %60 = llvm.load %59 : !llvm.ptr<f32>
      %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
      %62 = llvm.fcmp "oge" %51, %61 : f32
      %63 = llvm.select %62, %51, %61 : i1, f32
      llvm.br ^bb12(%63 : f32)
    ^bb11:  // pred: ^bb9
      llvm.br ^bb12(%51 : f32)
    ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
      llvm.br ^bb13
    ^bb13:  // pred: ^bb12
      %65 = llvm.and %55, %49  : i1
      llvm.cond_br %65, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %66 = llvm.mul %54, %arg5  : i32
      %67 = llvm.add %66, %48  : i32
      %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %69 = llvm.load %68 : !llvm.ptr<f32>
      %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
      %71 = llvm.fcmp "oge" %52, %70 : f32
      %72 = llvm.select %71, %52, %70 : i1, f32
      llvm.br ^bb16(%72 : f32)
    ^bb15:  // pred: ^bb13
      llvm.br ^bb16(%52 : f32)
    ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
      llvm.br ^bb17
    ^bb17:  // pred: ^bb16
      %74 = llvm.add %50, %1  : i32
      llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
    ^bb18(%75: f32, %76: f32):  // pred: ^bb6
      llvm.br ^bb19
    ^bb19:  // pred: ^bb18
      %77 = llvm.icmp "slt" %12, %arg5 : i32
      llvm.cond_br %77, ^bb20, ^bb23
    ^bb20:  // pred: ^bb19
      %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %79 = llvm.load %78 : !llvm.ptr<f32>
      llvm.br ^bb21(%79 : f32)
    ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
      %81 = llvm.fcmp "ogt" %80, %75 : f32
      %82 = llvm.select %81, %80, %75 : i1, f32
      %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %84 = llvm.bitcast %80 : f32 to i32
      %85 = llvm.bitcast %82 : f32 to i32
      %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
      %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
      %88 = llvm.bitcast %87 : i32 to f32
      %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
    ^bb22:  // pred: ^bb21
      llvm.br ^bb23
    ^bb23:  // 2 preds: ^bb19, ^bb22
      %90 = llvm.add %12, %1  : i32
      %91 = llvm.icmp "slt" %90, %arg5 : i32
      llvm.cond_br %91, ^bb24, ^bb27
    ^bb24:  // pred: ^bb23
      %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %93 = llvm.load %92 : !llvm.ptr<f32>
      llvm.br ^bb25(%93 : f32)
    ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
      %95 = llvm.fcmp "ogt" %94, %76 : f32
      %96 = llvm.select %95, %94, %76 : i1, f32
      %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %98 = llvm.bitcast %94 : f32 to i32
      %99 = llvm.bitcast %96 : f32 to i32
      %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
      %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
      %102 = llvm.bitcast %101 : i32 to f32
      %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
    ^bb26:  // pred: ^bb25
      llvm.br ^bb27
    ^bb27:  // 2 preds: ^bb23, ^bb26
      llvm.br ^bb28
    ^bb28:  // 2 preds: ^bb1, ^bb27
      llvm.return
    }
  }
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S0", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S1", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S2", value = -9223372036854775808 : i64} : () -> ()
  "disc_shape.SymbolicDim"() {knownNegativeOne = false, knownNonNegative = true, knownNonSizeOne = false, knownNonSizeZero = false, sym_name = "S3", value = -9223372036854775808 : i64} : () -> ()
  func.func @shape_constraint_graph() {
    %0 = "disc_shape.dim"() {name = @S3} : () -> index
    %1 = "disc_shape.dim"() {name = @S1} : () -> index
    %2 = "disc_shape.dim"() {name = @S2} : () -> index
    "disc_shape.tie_product_equal"(%0, %1, %2) {operand_segment_sizes = array<i32: 1, 2>} : (index, index, index) -> ()
    return
  }
}


// -----// IR Dump After DiscStripShapeConstraintOpsPass (disc-strip-shape-constraint-ops) //----- //
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c-1 = arith.constant -1 : index
    %c128 = arith.constant 128 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c256 = arith.constant 256 : index
    %c108 = arith.constant 108 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<?x?x?xf32, "gpu">
    %dim = memref.dim %1, %c2 : memref<?x?x?xf32, "gpu">
    %dim_0 = memref.dim %1, %c1 : memref<?x?x?xf32, "gpu">
    %dim_1 = memref.dim %1, %c0 : memref<?x?x?xf32, "gpu">
    %2 = arith.index_cast %dim_0 : index to i32
    %3 = arith.index_cast %dim : index to i32
    %4 = arith.muli %2, %3 : i32
    %5 = arith.index_cast %4 : i32 to index
    %alloc = memref.alloc(%5) {kDiscSymbolicDimAttr = [@S3]} : memref<?xf32, "gpu">
    %6 = arith.muli %dim_1, %5 : index
    %7 = arith.addi %6, %c-1 : index
    %8 = arith.divsi %7, %c256 : index
    %9 = arith.addi %8, %c1 : index
    %10 = arith.subi %c0, %6 : index
    %11 = arith.divsi %10, %c256 : index
    %12 = arith.subi %c0, %11 : index
    %13 = arith.cmpi sgt, %6, %c0 : index
    %14 = arith.select %13, %9, %12 : index
    %15 = arith.cmpi sgt, %14, %c108 : index
    cf.cond_br %15, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %c256_2 = arith.constant 256 : index
    %c0_3 = arith.constant 0 : index
    %c1_4 = arith.constant 1 : index
    %16 = arith.cmpi sle, %5, %c0_3 : index
    %17 = arith.subi %c0_3, %5 : index
    %18 = arith.subi %5, %c1_4 : index
    %19 = arith.select %16, %17, %18 : index
    %20 = arith.divsi %19, %c256_2 : index
    %21 = arith.subi %c0_3, %20 : index
    %22 = arith.addi %20, %c1_4 : index
    %23 = arith.select %16, %21, %22 : index
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__4_1_0___8w32h blocks in (%23, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %24 = arith.ceildivsi %dim_1, %c128 : index
    %25 = arith.ceildivsi %5, %c2 : index
    %26 = arith.muli %24, %25 : index
    %c256_5 = arith.constant 256 : index
    %c0_6 = arith.constant 0 : index
    %c1_7 = arith.constant 1 : index
    %27 = arith.cmpi sle, %26, %c0_6 : index
    %28 = arith.subi %c0_6, %26 : index
    %29 = arith.subi %26, %c1_7 : index
    %30 = arith.select %27, %28, %29 : index
    %31 = arith.divsi %30, %c256_5 : index
    %32 = arith.subi %c0_6, %31 : index
    %33 = arith.addi %31, %c1_7 : index
    %34 = arith.select %27, %32, %33 : index
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__4_1_0___8w32h_1 blocks in (%34, %c1, %c1) threads in (%c256, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c256 : index, %26 : index, %25 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    %c128_8 = arith.constant 128 : index
    %c0_9 = arith.constant 0 : index
    %c1_10 = arith.constant 1 : index
    %35 = arith.cmpi sle, %5, %c0_9 : index
    %36 = arith.subi %c0_9, %5 : index
    %37 = arith.subi %5, %c1_10 : index
    %38 = arith.select %35, %36, %37 : index
    %39 = arith.divsi %38, %c128_8 : index
    %40 = arith.subi %c0_9, %39 : index
    %41 = arith.addi %39, %c1_10 : index
    %42 = arith.select %35, %40, %41 : index
    gpu.launch_func  @main_kernel_1::@main_kColReduction_reduce__4_1_0___8w16h blocks in (%42, %c1, %c1) threads in (%c128, %c1, %c1) args(%c128 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    %43 = arith.ceildivsi %dim_1, %c128 : index
    %44 = arith.ceildivsi %5, %c2 : index
    %45 = arith.muli %43, %44 : index
    %c128_11 = arith.constant 128 : index
    %c0_12 = arith.constant 0 : index
    %c1_13 = arith.constant 1 : index
    %46 = arith.cmpi sle, %45, %c0_12 : index
    %47 = arith.subi %c0_12, %45 : index
    %48 = arith.subi %45, %c1_13 : index
    %49 = arith.select %46, %47, %48 : index
    %50 = arith.divsi %49, %c128_11 : index
    %51 = arith.subi %c0_12, %50 : index
    %52 = arith.addi %50, %c1_13 : index
    %53 = arith.select %46, %51, %52 : index
    gpu.launch_func  @main_kernel_2::@main_kColReduction_reduce__4_1_0___8w16h_1 blocks in (%53, %c1, %c1) threads in (%c128, %c1, %c1) args(%1 : memref<?x?x?xf32, "gpu">, %c128 : index, %45 : index, %44 : index, %5 : index, %alloc : memref<?xf32, "gpu">)
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    %54 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %dim_0, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %dim, %alloca[%c1] : memref<2xindex, "cpu">
    %55 = "disc_ral.dispatch"(%arg0, %54, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<?xf32, "gpu">, memref<2xindex, "cpu">) -> memref<?x?xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %55 to offset: [0], sizes: [%dim_0, %dim], strides: [%dim, 1] {kDiscSymbolicDimAttr = [@S1, @S2]} : memref<?x?xf32, "gpu"> to memref<?x?xf32, "gpu">
    memref.dealloc %alloc : memref<?xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<?x?xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary = "P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %1 = nvvm.read.ptx.sreg.ctaid.x : i32
      %2 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %3 = llvm.mul %1, %arg0  : i32
      %4 = llvm.add %2, %3  : i32
      %5 = llvm.icmp "ult" %4, %arg1 : i32
      llvm.cond_br %5, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %0, %6 : !llvm.ptr<f32>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary = "P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @__nv_fabsf(f32) -> f32
    llvm.func @main_kColReduction_reduce__4_1_0___8w32h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0 : index) : i32
      %1 = llvm.mlir.constant(1 : index) : i32
      %2 = llvm.mlir.constant(2 : index) : i32
      %3 = llvm.mlir.constant(128 : index) : i32
      %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %5 = nvvm.read.ptx.sreg.ctaid.x : i32
      %6 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %7 = llvm.mul %5, %arg2  : i32
      %8 = llvm.add %6, %7  : i32
      %9 = llvm.icmp "ult" %8, %arg3 : i32
      llvm.cond_br %9, ^bb2, ^bb28
    ^bb2:  // pred: ^bb1
      %10 = llvm.srem %8, %arg4  : i32
      %11 = llvm.sdiv %8, %arg4  : i32
      %12 = llvm.mul %10, %2  : i32
      %13 = llvm.mul %11, %3  : i32
      %14 = llvm.add %13, %3  : i32
      %15 = llvm.icmp "slt" %14, %arg1 : i32
      %16 = llvm.urem %arg1, %3  : i32
      %17 = llvm.icmp "eq" %16, %0 : i32
      %18 = llvm.or %17, %15  : i1
      %19 = llvm.add %12, %2  : i32
      %20 = llvm.icmp "slt" %19, %arg5 : i32
      %21 = llvm.urem %arg5, %2  : i32
      %22 = llvm.icmp "eq" %21, %0 : i32
      %23 = llvm.or %22, %20  : i1
      %24 = llvm.and %18, %23  : i1
      llvm.cond_br %24, ^bb3, ^bb7
    ^bb3:  // pred: ^bb2
      %25 = llvm.add %12, %1  : i32
      llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
    ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
      %29 = llvm.icmp "slt" %26, %3 : i32
      llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
    ^bb5:  // pred: ^bb4
      %30 = llvm.add %13, %26  : i32
      %31 = llvm.mul %30, %arg5  : i32
      %32 = llvm.add %31, %12  : i32
      %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %34 = llvm.load %33 : !llvm.ptr<f32>
      %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
      %36 = llvm.fcmp "oge" %27, %35 : f32
      %37 = llvm.select %36, %27, %35 : i1, f32
      %38 = llvm.add %31, %25  : i32
      %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %40 = llvm.load %39 : !llvm.ptr<f32>
      %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
      %42 = llvm.fcmp "oge" %28, %41 : f32
      %43 = llvm.select %42, %28, %41 : i1, f32
      %44 = llvm.add %26, %1  : i32
      llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
    ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
      llvm.br ^bb18(%45, %46 : f32, f32)
    ^bb7:  // pred: ^bb2
      %47 = llvm.icmp "slt" %12, %arg5 : i32
      %48 = llvm.add %12, %1  : i32
      %49 = llvm.icmp "slt" %48, %arg5 : i32
      llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
    ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
      %53 = llvm.icmp "slt" %50, %3 : i32
      llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
    ^bb9:  // pred: ^bb8
      %54 = llvm.add %13, %50  : i32
      %55 = llvm.icmp "slt" %54, %arg1 : i32
      %56 = llvm.and %55, %47  : i1
      llvm.cond_br %56, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %57 = llvm.mul %54, %arg5  : i32
      %58 = llvm.add %57, %12  : i32
      %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %60 = llvm.load %59 : !llvm.ptr<f32>
      %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
      %62 = llvm.fcmp "oge" %51, %61 : f32
      %63 = llvm.select %62, %51, %61 : i1, f32
      llvm.br ^bb12(%63 : f32)
    ^bb11:  // pred: ^bb9
      llvm.br ^bb12(%51 : f32)
    ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
      llvm.br ^bb13
    ^bb13:  // pred: ^bb12
      %65 = llvm.and %55, %49  : i1
      llvm.cond_br %65, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %66 = llvm.mul %54, %arg5  : i32
      %67 = llvm.add %66, %48  : i32
      %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %69 = llvm.load %68 : !llvm.ptr<f32>
      %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
      %71 = llvm.fcmp "oge" %52, %70 : f32
      %72 = llvm.select %71, %52, %70 : i1, f32
      llvm.br ^bb16(%72 : f32)
    ^bb15:  // pred: ^bb13
      llvm.br ^bb16(%52 : f32)
    ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
      llvm.br ^bb17
    ^bb17:  // pred: ^bb16
      %74 = llvm.add %50, %1  : i32
      llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
    ^bb18(%75: f32, %76: f32):  // pred: ^bb6
      llvm.br ^bb19
    ^bb19:  // pred: ^bb18
      %77 = llvm.icmp "slt" %12, %arg5 : i32
      llvm.cond_br %77, ^bb20, ^bb23
    ^bb20:  // pred: ^bb19
      %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %79 = llvm.load %78 : !llvm.ptr<f32>
      llvm.br ^bb21(%79 : f32)
    ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
      %81 = llvm.fcmp "ogt" %80, %75 : f32
      %82 = llvm.select %81, %80, %75 : i1, f32
      %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %84 = llvm.bitcast %80 : f32 to i32
      %85 = llvm.bitcast %82 : f32 to i32
      %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
      %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
      %88 = llvm.bitcast %87 : i32 to f32
      %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
    ^bb22:  // pred: ^bb21
      llvm.br ^bb23
    ^bb23:  // 2 preds: ^bb19, ^bb22
      %90 = llvm.add %12, %1  : i32
      %91 = llvm.icmp "slt" %90, %arg5 : i32
      llvm.cond_br %91, ^bb24, ^bb27
    ^bb24:  // pred: ^bb23
      %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %93 = llvm.load %92 : !llvm.ptr<f32>
      llvm.br ^bb25(%93 : f32)
    ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
      %95 = llvm.fcmp "ogt" %94, %76 : f32
      %96 = llvm.select %95, %94, %76 : i1, f32
      %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %98 = llvm.bitcast %94 : f32 to i32
      %99 = llvm.bitcast %96 : f32 to i32
      %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
      %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
      %102 = llvm.bitcast %101 : i32 to f32
      %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
    ^bb26:  // pred: ^bb25
      llvm.br ^bb27
    ^bb27:  // 2 preds: ^bb23, ^bb26
      llvm.br ^bb28
    ^bb28:  // 2 preds: ^bb1, ^bb27
      llvm.return
    }
  }
  gpu.module @main_kernel_1 attributes {gpu.binary = "P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w16h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__4_1_0___8w16h(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %1 = nvvm.read.ptx.sreg.ctaid.x : i32
      %2 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %3 = llvm.mul %1, %arg0  : i32
      %4 = llvm.add %2, %3  : i32
      %5 = llvm.icmp "ult" %4, %arg1 : i32
      llvm.cond_br %5, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %6 = llvm.getelementptr %arg2[%4] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %0, %6 : !llvm.ptr<f32>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_2 attributes {gpu.binary = "P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w16h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @__nv_fabsf(f32) -> f32
    llvm.func @main_kColReduction_reduce__4_1_0___8w16h_1(%arg0: !llvm.ptr<f32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: !llvm.ptr<f32>) attributes {disc.elimargs = [0 : index, 2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 13 : index, 15 : index, 16 : index, 17 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0 : index) : i32
      %1 = llvm.mlir.constant(1 : index) : i32
      %2 = llvm.mlir.constant(2 : index) : i32
      %3 = llvm.mlir.constant(128 : index) : i32
      %4 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %5 = nvvm.read.ptx.sreg.ctaid.x : i32
      %6 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %7 = llvm.mul %5, %arg2  : i32
      %8 = llvm.add %6, %7  : i32
      %9 = llvm.icmp "ult" %8, %arg3 : i32
      llvm.cond_br %9, ^bb2, ^bb28
    ^bb2:  // pred: ^bb1
      %10 = llvm.srem %8, %arg4  : i32
      %11 = llvm.sdiv %8, %arg4  : i32
      %12 = llvm.mul %10, %2  : i32
      %13 = llvm.mul %11, %3  : i32
      %14 = llvm.add %13, %3  : i32
      %15 = llvm.icmp "slt" %14, %arg1 : i32
      %16 = llvm.urem %arg1, %3  : i32
      %17 = llvm.icmp "eq" %16, %0 : i32
      %18 = llvm.or %17, %15  : i1
      %19 = llvm.add %12, %2  : i32
      %20 = llvm.icmp "slt" %19, %arg5 : i32
      %21 = llvm.urem %arg5, %2  : i32
      %22 = llvm.icmp "eq" %21, %0 : i32
      %23 = llvm.or %22, %20  : i1
      %24 = llvm.and %18, %23  : i1
      llvm.cond_br %24, ^bb3, ^bb7
    ^bb3:  // pred: ^bb2
      %25 = llvm.add %12, %1  : i32
      llvm.br ^bb4(%0, %4, %4 : i32, f32, f32)
    ^bb4(%26: i32, %27: f32, %28: f32):  // 2 preds: ^bb3, ^bb5
      %29 = llvm.icmp "slt" %26, %3 : i32
      llvm.cond_br %29, ^bb5, ^bb6(%27, %28 : f32, f32)
    ^bb5:  // pred: ^bb4
      %30 = llvm.add %13, %26  : i32
      %31 = llvm.mul %30, %arg5  : i32
      %32 = llvm.add %31, %12  : i32
      %33 = llvm.getelementptr %arg0[%32] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %34 = llvm.load %33 : !llvm.ptr<f32>
      %35 = llvm.call @__nv_fabsf(%34) : (f32) -> f32
      %36 = llvm.fcmp "oge" %27, %35 : f32
      %37 = llvm.select %36, %27, %35 : i1, f32
      %38 = llvm.add %31, %25  : i32
      %39 = llvm.getelementptr %arg0[%38] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %40 = llvm.load %39 : !llvm.ptr<f32>
      %41 = llvm.call @__nv_fabsf(%40) : (f32) -> f32
      %42 = llvm.fcmp "oge" %28, %41 : f32
      %43 = llvm.select %42, %28, %41 : i1, f32
      %44 = llvm.add %26, %1  : i32
      llvm.br ^bb4(%44, %37, %43 : i32, f32, f32)
    ^bb6(%45: f32, %46: f32):  // 2 preds: ^bb4, ^bb8
      llvm.br ^bb18(%45, %46 : f32, f32)
    ^bb7:  // pred: ^bb2
      %47 = llvm.icmp "slt" %12, %arg5 : i32
      %48 = llvm.add %12, %1  : i32
      %49 = llvm.icmp "slt" %48, %arg5 : i32
      llvm.br ^bb8(%0, %4, %4 : i32, f32, f32)
    ^bb8(%50: i32, %51: f32, %52: f32):  // 2 preds: ^bb7, ^bb17
      %53 = llvm.icmp "slt" %50, %3 : i32
      llvm.cond_br %53, ^bb9, ^bb6(%51, %52 : f32, f32)
    ^bb9:  // pred: ^bb8
      %54 = llvm.add %13, %50  : i32
      %55 = llvm.icmp "slt" %54, %arg1 : i32
      %56 = llvm.and %55, %47  : i1
      llvm.cond_br %56, ^bb10, ^bb11
    ^bb10:  // pred: ^bb9
      %57 = llvm.mul %54, %arg5  : i32
      %58 = llvm.add %57, %12  : i32
      %59 = llvm.getelementptr %arg0[%58] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %60 = llvm.load %59 : !llvm.ptr<f32>
      %61 = llvm.call @__nv_fabsf(%60) : (f32) -> f32
      %62 = llvm.fcmp "oge" %51, %61 : f32
      %63 = llvm.select %62, %51, %61 : i1, f32
      llvm.br ^bb12(%63 : f32)
    ^bb11:  // pred: ^bb9
      llvm.br ^bb12(%51 : f32)
    ^bb12(%64: f32):  // 2 preds: ^bb10, ^bb11
      llvm.br ^bb13
    ^bb13:  // pred: ^bb12
      %65 = llvm.and %55, %49  : i1
      llvm.cond_br %65, ^bb14, ^bb15
    ^bb14:  // pred: ^bb13
      %66 = llvm.mul %54, %arg5  : i32
      %67 = llvm.add %66, %48  : i32
      %68 = llvm.getelementptr %arg0[%67] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %69 = llvm.load %68 : !llvm.ptr<f32>
      %70 = llvm.call @__nv_fabsf(%69) : (f32) -> f32
      %71 = llvm.fcmp "oge" %52, %70 : f32
      %72 = llvm.select %71, %52, %70 : i1, f32
      llvm.br ^bb16(%72 : f32)
    ^bb15:  // pred: ^bb13
      llvm.br ^bb16(%52 : f32)
    ^bb16(%73: f32):  // 2 preds: ^bb14, ^bb15
      llvm.br ^bb17
    ^bb17:  // pred: ^bb16
      %74 = llvm.add %50, %1  : i32
      llvm.br ^bb8(%74, %64, %73 : i32, f32, f32)
    ^bb18(%75: f32, %76: f32):  // pred: ^bb6
      llvm.br ^bb19
    ^bb19:  // pred: ^bb18
      %77 = llvm.icmp "slt" %12, %arg5 : i32
      llvm.cond_br %77, ^bb20, ^bb23
    ^bb20:  // pred: ^bb19
      %78 = llvm.getelementptr %arg6[%12] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %79 = llvm.load %78 : !llvm.ptr<f32>
      llvm.br ^bb21(%79 : f32)
    ^bb21(%80: f32):  // 2 preds: ^bb20, ^bb21
      %81 = llvm.fcmp "ogt" %80, %75 : f32
      %82 = llvm.select %81, %80, %75 : i1, f32
      %83 = llvm.bitcast %78 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %84 = llvm.bitcast %80 : f32 to i32
      %85 = llvm.bitcast %82 : f32 to i32
      %86 = llvm.cmpxchg %83, %84, %85 acq_rel monotonic : !llvm.ptr<i32>, i32
      %87 = llvm.extractvalue %86[0] : !llvm.struct<(i32, i1)> 
      %88 = llvm.bitcast %87 : i32 to f32
      %89 = llvm.extractvalue %86[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %89, ^bb22, ^bb21(%88 : f32)
    ^bb22:  // pred: ^bb21
      llvm.br ^bb23
    ^bb23:  // 2 preds: ^bb19, ^bb22
      %90 = llvm.add %12, %1  : i32
      %91 = llvm.icmp "slt" %90, %arg5 : i32
      llvm.cond_br %91, ^bb24, ^bb27
    ^bb24:  // pred: ^bb23
      %92 = llvm.getelementptr %arg6[%90] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %93 = llvm.load %92 : !llvm.ptr<f32>
      llvm.br ^bb25(%93 : f32)
    ^bb25(%94: f32):  // 2 preds: ^bb24, ^bb25
      %95 = llvm.fcmp "ogt" %94, %76 : f32
      %96 = llvm.select %95, %94, %76 : i1, f32
      %97 = llvm.bitcast %92 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %98 = llvm.bitcast %94 : f32 to i32
      %99 = llvm.bitcast %96 : f32 to i32
      %100 = llvm.cmpxchg %97, %98, %99 acq_rel monotonic : !llvm.ptr<i32>, i32
      %101 = llvm.extractvalue %100[0] : !llvm.struct<(i32, i1)> 
      %102 = llvm.bitcast %101 : i32 to f32
      %103 = llvm.extractvalue %100[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %103, ^bb26, ^bb25(%102 : f32)
    ^bb26:  // pred: ^bb25
      llvm.br ^bb27
    ^bb27:  // 2 preds: ^bb23, ^bb26
      llvm.br ^bb28
    ^bb28:  // 2 preds: ^bb1, ^bb27
      llvm.return
    }
  }
}


// -----// IR Dump After DiscToLLVMPass (disc-to-llvm) //----- //
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name("main_kColReduction_reduce__4_1_0___8w32h_1\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_0_blob_gpu.binary("P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name("main_kColReduction_reduce__4_1_0___8w32h\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_blob_gpu.binary("P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_send_output___cpu___pvoid_i64_m2df32___void("ral_send_output___cpu___pvoid_i64_m2df32___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @dealloc___gpu___pvoid_pvoid___void("dealloc___gpu___pvoid_pvoid___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32("inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_2_main_kColReduction_reduce__4_1_0___8w16h_1_kernel_name("main_kColReduction_reduce__4_1_0___8w16h_1\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_2_blob_gpu.binary("P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w16h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void("ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_1_main_kColReduction_reduce__4_1_0___8w16h_kernel_name("main_kColReduction_reduce__4_1_0___8w16h\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_1_blob_gpu.binary("P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w16h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @alloc___gpu___pvoid_i64___pvoid("alloc___gpu___pvoid_i64___pvoid\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_recv_input___cpu___pvoid_i64___m3df32("ral_recv_input___cpu___pvoid_i64___m3df32\00") {addr_space = 0 : i32}
  llvm.func @disc_ral_call(!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>)
  llvm.func @main(%arg0: !llvm.ptr<i8>) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = llvm.mlir.constant(-1 : index) : i64
    %1 = llvm.mlir.constant(128 : index) : i64
    %2 = llvm.mlir.constant(0 : i32) : i32
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.constant(1 : index) : i64
    %5 = llvm.mlir.constant(2 : index) : i64
    %6 = llvm.mlir.constant(256 : index) : i64
    %7 = llvm.mlir.constant(108 : index) : i64
    %8 = llvm.mlir.constant(0 : i32) : i32
    %9 = llvm.mlir.constant(1 : i32) : i32
    %10 = llvm.alloca %9 x !llvm.struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>)> : (i32) -> !llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>)>>
    %11 = llvm.mlir.constant(3 : i32) : i32
    %12 = llvm.alloca %11 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %13 = llvm.mlir.constant(0 : i32) : i32
    %14 = llvm.getelementptr %10[%8, 0] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %14 : !llvm.ptr<ptr<i8>>
    %15 = llvm.getelementptr %12[%13] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %16 = llvm.bitcast %14 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %16, %15 : !llvm.ptr<ptr<i8>>
    %17 = llvm.mlir.constant(1 : i32) : i32
    %18 = llvm.getelementptr %10[%8, 1] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %3, %18 : !llvm.ptr<i64>
    %19 = llvm.getelementptr %12[%17] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %20 = llvm.bitcast %18 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %20, %19 : !llvm.ptr<ptr<i8>>
    %21 = llvm.mlir.constant(2 : i32) : i32
    %22 = llvm.getelementptr %10[%8, 2] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>>
    %23 = llvm.getelementptr %12[%21] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %24 = llvm.bitcast %22 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>> to !llvm.ptr<i8>
    llvm.store %24, %23 : !llvm.ptr<ptr<i8>>
    %25 = llvm.mlir.addressof @ral_recv_input___cpu___pvoid_i64___m3df32 : !llvm.ptr<array<42 x i8>>
    %26 = llvm.mlir.constant(0 : index) : i64
    %27 = llvm.getelementptr %25[%26, %26] : (!llvm.ptr<array<42 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %27, %12) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %28 = llvm.load %22 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>>
    %29 = llvm.extractvalue %28[3, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %30 = llvm.extractvalue %28[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %31 = llvm.extractvalue %28[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %32 = llvm.trunc %30 : i64 to i32
    %33 = llvm.trunc %29 : i64 to i32
    %34 = llvm.mul %32, %33  : i32
    %35 = llvm.sext %34 : i32 to i64
    %36 = llvm.mlir.constant(1 : index) : i64
    %37 = llvm.mlir.null : !llvm.ptr<f32>
    %38 = llvm.getelementptr %37[%35] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %39 = llvm.ptrtoint %38 : !llvm.ptr<f32> to i64
    %40 = llvm.mlir.constant(0 : i32) : i32
    %41 = llvm.mlir.constant(1 : i32) : i32
    %42 = llvm.alloca %41 x !llvm.struct<".1", (ptr<i8>, i64, ptr<i8>)> : (i32) -> !llvm.ptr<struct<".1", (ptr<i8>, i64, ptr<i8>)>>
    %43 = llvm.mlir.constant(3 : i32) : i32
    %44 = llvm.alloca %43 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %45 = llvm.mlir.constant(0 : i32) : i32
    %46 = llvm.getelementptr %42[%40, 0] : (!llvm.ptr<struct<".1", (ptr<i8>, i64, ptr<i8>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %46 : !llvm.ptr<ptr<i8>>
    %47 = llvm.getelementptr %44[%45] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %48 = llvm.bitcast %46 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %48, %47 : !llvm.ptr<ptr<i8>>
    %49 = llvm.mlir.constant(1 : i32) : i32
    %50 = llvm.getelementptr %42[%40, 1] : (!llvm.ptr<struct<".1", (ptr<i8>, i64, ptr<i8>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %39, %50 : !llvm.ptr<i64>
    %51 = llvm.getelementptr %44[%49] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %52 = llvm.bitcast %50 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %52, %51 : !llvm.ptr<ptr<i8>>
    %53 = llvm.mlir.constant(2 : i32) : i32
    %54 = llvm.getelementptr %42[%40, 2] : (!llvm.ptr<struct<".1", (ptr<i8>, i64, ptr<i8>)>>, i32) -> !llvm.ptr<ptr<i8>>
    %55 = llvm.getelementptr %44[%53] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %56 = llvm.bitcast %54 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %56, %55 : !llvm.ptr<ptr<i8>>
    %57 = llvm.mlir.addressof @alloc___gpu___pvoid_i64___pvoid : !llvm.ptr<array<32 x i8>>
    %58 = llvm.mlir.constant(0 : index) : i64
    %59 = llvm.getelementptr %57[%58, %58] : (!llvm.ptr<array<32 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %59, %44) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %60 = llvm.load %54 : !llvm.ptr<ptr<i8>>
    %61 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>
    %62 = llvm.bitcast %60 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %63 = llvm.insertvalue %62, %61[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %64 = llvm.insertvalue %62, %63[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %65 = llvm.mlir.constant(0 : index) : i64
    %66 = llvm.insertvalue %65, %64[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %67 = llvm.mlir.constant(1 : index) : i64
    %68 = llvm.insertvalue %35, %66[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %69 = llvm.insertvalue %67, %68[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %70 = llvm.mul %31, %35  : i64
    %71 = llvm.add %70, %0  : i64
    %72 = llvm.sdiv %71, %6  : i64
    %73 = llvm.add %72, %4  : i64
    %74 = llvm.sub %3, %70  : i64
    %75 = llvm.sdiv %74, %6  : i64
    %76 = llvm.sub %3, %75  : i64
    %77 = llvm.icmp "sgt" %70, %3 : i64
    %78 = llvm.select %77, %73, %76 : i1, i64
    %79 = llvm.icmp "sgt" %78, %7 : i64
    llvm.cond_br %79, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %80 = llvm.icmp "sle" %35, %3 : i64
    %81 = llvm.sub %3, %35  : i64
    %82 = llvm.sub %35, %4  : i64
    %83 = llvm.select %80, %81, %82 : i1, i64
    %84 = llvm.sdiv %83, %6  : i64
    %85 = llvm.sub %3, %84  : i64
    %86 = llvm.add %84, %4  : i64
    %87 = llvm.select %80, %85, %86 : i1, i64
    %88 = llvm.mlir.addressof @main_kernel_blob_gpu.binary : !llvm.ptr<array<1096 x i8>>
    %89 = llvm.mlir.constant(0 : index) : i64
    %90 = llvm.getelementptr %88[%89, %89] : (!llvm.ptr<array<1096 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %91 = llvm.mlir.constant(1 : i32) : i32
    %92 = llvm.alloca %91 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %93 = llvm.mlir.constant(0 : i32) : i32
    %94 = llvm.getelementptr %92[%93] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %90, %94 : !llvm.ptr<ptr<i8>>
    %95 = llvm.mlir.constant(1 : i64) : i64
    %96 = llvm.mlir.addressof @main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name : !llvm.ptr<array<41 x i8>>
    %97 = llvm.mlir.constant(0 : index) : i64
    %98 = llvm.getelementptr %96[%97, %97] : (!llvm.ptr<array<41 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %99 = llvm.extractvalue %69[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %100 = llvm.extractvalue %69[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %101 = llvm.extractvalue %69[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %102 = llvm.extractvalue %69[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %103 = llvm.extractvalue %69[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %104 = llvm.mlir.constant(1 : i32) : i32
    %105 = llvm.alloca %104 x !llvm.struct<".9", (i64, i64, ptr<f32>)> : (i32) -> !llvm.ptr<struct<".9", (i64, i64, ptr<f32>)>>
    %106 = llvm.mlir.constant(3 : i32) : i32
    %107 = llvm.alloca %106 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %108 = llvm.mlir.constant(0 : i32) : i32
    %109 = llvm.mlir.constant(0 : i32) : i32
    %110 = llvm.getelementptr %105[%108, 0] : (!llvm.ptr<struct<".9", (i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %6, %110 : !llvm.ptr<i64>
    %111 = llvm.getelementptr %107[%109] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %112 = llvm.bitcast %110 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %112, %111 : !llvm.ptr<ptr<i8>>
    %113 = llvm.mlir.constant(1 : i32) : i32
    %114 = llvm.getelementptr %105[%108, 1] : (!llvm.ptr<struct<".9", (i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %35, %114 : !llvm.ptr<i64>
    %115 = llvm.getelementptr %107[%113] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %116 = llvm.bitcast %114 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %116, %115 : !llvm.ptr<ptr<i8>>
    %117 = llvm.mlir.constant(2 : i32) : i32
    %118 = llvm.getelementptr %105[%108, 2] : (!llvm.ptr<struct<".9", (i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %100, %118 : !llvm.ptr<ptr<f32>>
    %119 = llvm.getelementptr %107[%117] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %120 = llvm.bitcast %118 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %120, %119 : !llvm.ptr<ptr<i8>>
    %121 = llvm.mlir.constant(0 : i32) : i32
    %122 = llvm.mlir.constant(3 : i32) : i32
    %123 = llvm.inttoptr %121 : i32 to !llvm.ptr<i8>
    %124 = llvm.mlir.constant(0 : i32) : i32
    %125 = llvm.mlir.constant(1 : i32) : i32
    %126 = llvm.alloca %125 x !llvm.struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %127 = llvm.mlir.constant(14 : i32) : i32
    %128 = llvm.alloca %127 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %129 = llvm.mlir.constant(0 : i32) : i32
    %130 = llvm.getelementptr %126[%124, 0] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %130 : !llvm.ptr<ptr<i8>>
    %131 = llvm.getelementptr %128[%129] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %132 = llvm.bitcast %130 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %132, %131 : !llvm.ptr<ptr<i8>>
    %133 = llvm.mlir.constant(1 : i32) : i32
    %134 = llvm.getelementptr %126[%124, 1] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %92, %134 : !llvm.ptr<ptr<ptr<i8>>>
    %135 = llvm.getelementptr %128[%133] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %136 = llvm.bitcast %134 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %136, %135 : !llvm.ptr<ptr<i8>>
    %137 = llvm.mlir.constant(2 : i32) : i32
    %138 = llvm.getelementptr %126[%124, 2] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %95, %138 : !llvm.ptr<i64>
    %139 = llvm.getelementptr %128[%137] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %140 = llvm.bitcast %138 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %140, %139 : !llvm.ptr<ptr<i8>>
    %141 = llvm.mlir.constant(3 : i32) : i32
    %142 = llvm.getelementptr %126[%124, 3] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %98, %142 : !llvm.ptr<ptr<i8>>
    %143 = llvm.getelementptr %128[%141] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %144 = llvm.bitcast %142 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %144, %143 : !llvm.ptr<ptr<i8>>
    %145 = llvm.mlir.constant(4 : i32) : i32
    %146 = llvm.getelementptr %126[%124, 4] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %87, %146 : !llvm.ptr<i64>
    %147 = llvm.getelementptr %128[%145] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %148 = llvm.bitcast %146 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %148, %147 : !llvm.ptr<ptr<i8>>
    %149 = llvm.mlir.constant(5 : i32) : i32
    %150 = llvm.getelementptr %126[%124, 5] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %150 : !llvm.ptr<i64>
    %151 = llvm.getelementptr %128[%149] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %152 = llvm.bitcast %150 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %152, %151 : !llvm.ptr<ptr<i8>>
    %153 = llvm.mlir.constant(6 : i32) : i32
    %154 = llvm.getelementptr %126[%124, 6] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %154 : !llvm.ptr<i64>
    %155 = llvm.getelementptr %128[%153] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %156 = llvm.bitcast %154 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %156, %155 : !llvm.ptr<ptr<i8>>
    %157 = llvm.mlir.constant(7 : i32) : i32
    %158 = llvm.getelementptr %126[%124, 7] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %6, %158 : !llvm.ptr<i64>
    %159 = llvm.getelementptr %128[%157] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %160 = llvm.bitcast %158 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %160, %159 : !llvm.ptr<ptr<i8>>
    %161 = llvm.mlir.constant(8 : i32) : i32
    %162 = llvm.getelementptr %126[%124, 8] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %162 : !llvm.ptr<i64>
    %163 = llvm.getelementptr %128[%161] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %164 = llvm.bitcast %162 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %164, %163 : !llvm.ptr<ptr<i8>>
    %165 = llvm.mlir.constant(9 : i32) : i32
    %166 = llvm.getelementptr %126[%124, 9] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %166 : !llvm.ptr<i64>
    %167 = llvm.getelementptr %128[%165] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %168 = llvm.bitcast %166 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %168, %167 : !llvm.ptr<ptr<i8>>
    %169 = llvm.mlir.constant(10 : i32) : i32
    %170 = llvm.getelementptr %126[%124, 10] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %121, %170 : !llvm.ptr<i32>
    %171 = llvm.getelementptr %128[%169] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %172 = llvm.bitcast %170 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %172, %171 : !llvm.ptr<ptr<i8>>
    %173 = llvm.mlir.constant(11 : i32) : i32
    %174 = llvm.getelementptr %126[%124, 11] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %123, %174 : !llvm.ptr<ptr<i8>>
    %175 = llvm.getelementptr %128[%173] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %176 = llvm.bitcast %174 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %176, %175 : !llvm.ptr<ptr<i8>>
    %177 = llvm.mlir.constant(12 : i32) : i32
    %178 = llvm.getelementptr %126[%124, 12] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %122, %178 : !llvm.ptr<i32>
    %179 = llvm.getelementptr %128[%177] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %180 = llvm.bitcast %178 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %180, %179 : !llvm.ptr<ptr<i8>>
    %181 = llvm.mlir.constant(13 : i32) : i32
    %182 = llvm.getelementptr %126[%124, 13] : (!llvm.ptr<struct<".10", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %107, %182 : !llvm.ptr<ptr<ptr<i8>>>
    %183 = llvm.getelementptr %128[%181] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %184 = llvm.bitcast %182 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %184, %183 : !llvm.ptr<ptr<i8>>
    %185 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %186 = llvm.mlir.constant(0 : index) : i64
    %187 = llvm.getelementptr %185[%186, %186] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %187, %128) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %188 = llvm.mlir.constant(1 : index) : i64
    %189 = llvm.mlir.constant(0 : index) : i64
    %190 = llvm.mlir.constant(-1 : index) : i64
    %191 = llvm.mlir.constant(true) : i1
    %192 = llvm.select %191, %190, %188 : i1, i64
    %193 = llvm.add %192, %31  : i64
    %194 = llvm.sdiv %193, %1  : i64
    %195 = llvm.add %188, %194  : i64
    %196 = llvm.sub %189, %31  : i64
    %197 = llvm.sdiv %196, %1  : i64
    %198 = llvm.sub %189, %197  : i64
    %199 = llvm.icmp "slt" %31, %189 : i64
    %200 = llvm.icmp "sgt" %31, %189 : i64
    %201 = llvm.mlir.constant(false) : i1
    %202 = llvm.mlir.constant(true) : i1
    %203 = llvm.and %199, %201  : i1
    %204 = llvm.and %200, %202  : i1
    %205 = llvm.or %203, %204  : i1
    %206 = llvm.select %205, %195, %198 : i1, i64
    %207 = llvm.mlir.constant(1 : index) : i64
    %208 = llvm.mlir.constant(0 : index) : i64
    %209 = llvm.mlir.constant(-1 : index) : i64
    %210 = llvm.mlir.constant(true) : i1
    %211 = llvm.select %210, %209, %207 : i1, i64
    %212 = llvm.add %211, %35  : i64
    %213 = llvm.sdiv %212, %5  : i64
    %214 = llvm.add %207, %213  : i64
    %215 = llvm.sub %208, %35  : i64
    %216 = llvm.sdiv %215, %5  : i64
    %217 = llvm.sub %208, %216  : i64
    %218 = llvm.icmp "slt" %35, %208 : i64
    %219 = llvm.icmp "sgt" %35, %208 : i64
    %220 = llvm.mlir.constant(false) : i1
    %221 = llvm.mlir.constant(true) : i1
    %222 = llvm.and %218, %220  : i1
    %223 = llvm.and %219, %221  : i1
    %224 = llvm.or %222, %223  : i1
    %225 = llvm.select %224, %214, %217 : i1, i64
    %226 = llvm.mul %206, %225  : i64
    %227 = llvm.icmp "sle" %226, %3 : i64
    %228 = llvm.sub %3, %226  : i64
    %229 = llvm.sub %226, %4  : i64
    %230 = llvm.select %227, %228, %229 : i1, i64
    %231 = llvm.sdiv %230, %6  : i64
    %232 = llvm.sub %3, %231  : i64
    %233 = llvm.add %231, %4  : i64
    %234 = llvm.select %227, %232, %233 : i1, i64
    %235 = llvm.mlir.addressof @main_kernel_0_blob_gpu.binary : !llvm.ptr<array<4464 x i8>>
    %236 = llvm.mlir.constant(0 : index) : i64
    %237 = llvm.getelementptr %235[%236, %236] : (!llvm.ptr<array<4464 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %238 = llvm.mlir.constant(1 : i32) : i32
    %239 = llvm.alloca %238 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %240 = llvm.mlir.constant(0 : i32) : i32
    %241 = llvm.getelementptr %239[%240] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %237, %241 : !llvm.ptr<ptr<i8>>
    %242 = llvm.mlir.constant(1 : i64) : i64
    %243 = llvm.mlir.addressof @main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name : !llvm.ptr<array<43 x i8>>
    %244 = llvm.mlir.constant(0 : index) : i64
    %245 = llvm.getelementptr %243[%244, %244] : (!llvm.ptr<array<43 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %246 = llvm.extractvalue %28[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %247 = llvm.extractvalue %28[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %248 = llvm.extractvalue %28[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %249 = llvm.extractvalue %28[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %250 = llvm.extractvalue %28[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %251 = llvm.extractvalue %28[3, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %252 = llvm.extractvalue %28[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %253 = llvm.extractvalue %28[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %254 = llvm.extractvalue %28[4, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %255 = llvm.extractvalue %69[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %256 = llvm.extractvalue %69[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %257 = llvm.extractvalue %69[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %258 = llvm.extractvalue %69[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %259 = llvm.extractvalue %69[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %260 = llvm.mlir.constant(1 : i32) : i32
    %261 = llvm.alloca %260 x !llvm.struct<".11", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)> : (i32) -> !llvm.ptr<struct<".11", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>
    %262 = llvm.mlir.constant(7 : i32) : i32
    %263 = llvm.alloca %262 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %264 = llvm.mlir.constant(0 : i32) : i32
    %265 = llvm.mlir.constant(0 : i32) : i32
    %266 = llvm.getelementptr %261[%264, 0] : (!llvm.ptr<struct<".11", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %247, %266 : !llvm.ptr<ptr<f32>>
    %267 = llvm.getelementptr %263[%265] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %268 = llvm.bitcast %266 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %268, %267 : !llvm.ptr<ptr<i8>>
    %269 = llvm.mlir.constant(1 : i32) : i32
    %270 = llvm.getelementptr %261[%264, 1] : (!llvm.ptr<struct<".11", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %249, %270 : !llvm.ptr<i64>
    %271 = llvm.getelementptr %263[%269] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %272 = llvm.bitcast %270 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %272, %271 : !llvm.ptr<ptr<i8>>
    %273 = llvm.mlir.constant(2 : i32) : i32
    %274 = llvm.getelementptr %261[%264, 2] : (!llvm.ptr<struct<".11", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %6, %274 : !llvm.ptr<i64>
    %275 = llvm.getelementptr %263[%273] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %276 = llvm.bitcast %274 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %276, %275 : !llvm.ptr<ptr<i8>>
    %277 = llvm.mlir.constant(3 : i32) : i32
    %278 = llvm.getelementptr %261[%264, 3] : (!llvm.ptr<struct<".11", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %226, %278 : !llvm.ptr<i64>
    %279 = llvm.getelementptr %263[%277] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %280 = llvm.bitcast %278 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %280, %279 : !llvm.ptr<ptr<i8>>
    %281 = llvm.mlir.constant(4 : i32) : i32
    %282 = llvm.getelementptr %261[%264, 4] : (!llvm.ptr<struct<".11", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %225, %282 : !llvm.ptr<i64>
    %283 = llvm.getelementptr %263[%281] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %284 = llvm.bitcast %282 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %284, %283 : !llvm.ptr<ptr<i8>>
    %285 = llvm.mlir.constant(5 : i32) : i32
    %286 = llvm.getelementptr %261[%264, 5] : (!llvm.ptr<struct<".11", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %35, %286 : !llvm.ptr<i64>
    %287 = llvm.getelementptr %263[%285] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %288 = llvm.bitcast %286 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %288, %287 : !llvm.ptr<ptr<i8>>
    %289 = llvm.mlir.constant(6 : i32) : i32
    %290 = llvm.getelementptr %261[%264, 6] : (!llvm.ptr<struct<".11", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %256, %290 : !llvm.ptr<ptr<f32>>
    %291 = llvm.getelementptr %263[%289] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %292 = llvm.bitcast %290 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %292, %291 : !llvm.ptr<ptr<i8>>
    %293 = llvm.mlir.constant(0 : i32) : i32
    %294 = llvm.mlir.constant(7 : i32) : i32
    %295 = llvm.inttoptr %293 : i32 to !llvm.ptr<i8>
    %296 = llvm.mlir.constant(0 : i32) : i32
    %297 = llvm.mlir.constant(1 : i32) : i32
    %298 = llvm.alloca %297 x !llvm.struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %299 = llvm.mlir.constant(14 : i32) : i32
    %300 = llvm.alloca %299 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %301 = llvm.mlir.constant(0 : i32) : i32
    %302 = llvm.getelementptr %298[%296, 0] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %302 : !llvm.ptr<ptr<i8>>
    %303 = llvm.getelementptr %300[%301] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %304 = llvm.bitcast %302 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %304, %303 : !llvm.ptr<ptr<i8>>
    %305 = llvm.mlir.constant(1 : i32) : i32
    %306 = llvm.getelementptr %298[%296, 1] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %239, %306 : !llvm.ptr<ptr<ptr<i8>>>
    %307 = llvm.getelementptr %300[%305] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %308 = llvm.bitcast %306 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %308, %307 : !llvm.ptr<ptr<i8>>
    %309 = llvm.mlir.constant(2 : i32) : i32
    %310 = llvm.getelementptr %298[%296, 2] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %242, %310 : !llvm.ptr<i64>
    %311 = llvm.getelementptr %300[%309] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %312 = llvm.bitcast %310 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %312, %311 : !llvm.ptr<ptr<i8>>
    %313 = llvm.mlir.constant(3 : i32) : i32
    %314 = llvm.getelementptr %298[%296, 3] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %245, %314 : !llvm.ptr<ptr<i8>>
    %315 = llvm.getelementptr %300[%313] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %316 = llvm.bitcast %314 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %316, %315 : !llvm.ptr<ptr<i8>>
    %317 = llvm.mlir.constant(4 : i32) : i32
    %318 = llvm.getelementptr %298[%296, 4] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %234, %318 : !llvm.ptr<i64>
    %319 = llvm.getelementptr %300[%317] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %320 = llvm.bitcast %318 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %320, %319 : !llvm.ptr<ptr<i8>>
    %321 = llvm.mlir.constant(5 : i32) : i32
    %322 = llvm.getelementptr %298[%296, 5] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %322 : !llvm.ptr<i64>
    %323 = llvm.getelementptr %300[%321] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %324 = llvm.bitcast %322 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %324, %323 : !llvm.ptr<ptr<i8>>
    %325 = llvm.mlir.constant(6 : i32) : i32
    %326 = llvm.getelementptr %298[%296, 6] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %326 : !llvm.ptr<i64>
    %327 = llvm.getelementptr %300[%325] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %328 = llvm.bitcast %326 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %328, %327 : !llvm.ptr<ptr<i8>>
    %329 = llvm.mlir.constant(7 : i32) : i32
    %330 = llvm.getelementptr %298[%296, 7] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %6, %330 : !llvm.ptr<i64>
    %331 = llvm.getelementptr %300[%329] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %332 = llvm.bitcast %330 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %332, %331 : !llvm.ptr<ptr<i8>>
    %333 = llvm.mlir.constant(8 : i32) : i32
    %334 = llvm.getelementptr %298[%296, 8] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %334 : !llvm.ptr<i64>
    %335 = llvm.getelementptr %300[%333] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %336 = llvm.bitcast %334 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %336, %335 : !llvm.ptr<ptr<i8>>
    %337 = llvm.mlir.constant(9 : i32) : i32
    %338 = llvm.getelementptr %298[%296, 9] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %338 : !llvm.ptr<i64>
    %339 = llvm.getelementptr %300[%337] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %340 = llvm.bitcast %338 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %340, %339 : !llvm.ptr<ptr<i8>>
    %341 = llvm.mlir.constant(10 : i32) : i32
    %342 = llvm.getelementptr %298[%296, 10] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %293, %342 : !llvm.ptr<i32>
    %343 = llvm.getelementptr %300[%341] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %344 = llvm.bitcast %342 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %344, %343 : !llvm.ptr<ptr<i8>>
    %345 = llvm.mlir.constant(11 : i32) : i32
    %346 = llvm.getelementptr %298[%296, 11] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %295, %346 : !llvm.ptr<ptr<i8>>
    %347 = llvm.getelementptr %300[%345] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %348 = llvm.bitcast %346 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %348, %347 : !llvm.ptr<ptr<i8>>
    %349 = llvm.mlir.constant(12 : i32) : i32
    %350 = llvm.getelementptr %298[%296, 12] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %294, %350 : !llvm.ptr<i32>
    %351 = llvm.getelementptr %300[%349] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %352 = llvm.bitcast %350 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %352, %351 : !llvm.ptr<ptr<i8>>
    %353 = llvm.mlir.constant(13 : i32) : i32
    %354 = llvm.getelementptr %298[%296, 13] : (!llvm.ptr<struct<".12", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %263, %354 : !llvm.ptr<ptr<ptr<i8>>>
    %355 = llvm.getelementptr %300[%353] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %356 = llvm.bitcast %354 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %356, %355 : !llvm.ptr<ptr<i8>>
    %357 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %358 = llvm.mlir.constant(0 : index) : i64
    %359 = llvm.getelementptr %357[%358, %358] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %359, %300) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    llvm.br ^bb3
  ^bb2:  // pred: ^bb0
    %360 = llvm.icmp "sle" %35, %3 : i64
    %361 = llvm.sub %3, %35  : i64
    %362 = llvm.sub %35, %4  : i64
    %363 = llvm.select %360, %361, %362 : i1, i64
    %364 = llvm.sdiv %363, %1  : i64
    %365 = llvm.sub %3, %364  : i64
    %366 = llvm.add %364, %4  : i64
    %367 = llvm.select %360, %365, %366 : i1, i64
    %368 = llvm.mlir.addressof @main_kernel_1_blob_gpu.binary : !llvm.ptr<array<1096 x i8>>
    %369 = llvm.mlir.constant(0 : index) : i64
    %370 = llvm.getelementptr %368[%369, %369] : (!llvm.ptr<array<1096 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %371 = llvm.mlir.constant(1 : i32) : i32
    %372 = llvm.alloca %371 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %373 = llvm.mlir.constant(0 : i32) : i32
    %374 = llvm.getelementptr %372[%373] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %370, %374 : !llvm.ptr<ptr<i8>>
    %375 = llvm.mlir.constant(1 : i64) : i64
    %376 = llvm.mlir.addressof @main_kernel_1_main_kColReduction_reduce__4_1_0___8w16h_kernel_name : !llvm.ptr<array<41 x i8>>
    %377 = llvm.mlir.constant(0 : index) : i64
    %378 = llvm.getelementptr %376[%377, %377] : (!llvm.ptr<array<41 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %379 = llvm.extractvalue %69[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %380 = llvm.extractvalue %69[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %381 = llvm.extractvalue %69[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %382 = llvm.extractvalue %69[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %383 = llvm.extractvalue %69[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %384 = llvm.mlir.constant(1 : i32) : i32
    %385 = llvm.alloca %384 x !llvm.struct<".2", (i64, i64, ptr<f32>)> : (i32) -> !llvm.ptr<struct<".2", (i64, i64, ptr<f32>)>>
    %386 = llvm.mlir.constant(3 : i32) : i32
    %387 = llvm.alloca %386 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %388 = llvm.mlir.constant(0 : i32) : i32
    %389 = llvm.mlir.constant(0 : i32) : i32
    %390 = llvm.getelementptr %385[%388, 0] : (!llvm.ptr<struct<".2", (i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1, %390 : !llvm.ptr<i64>
    %391 = llvm.getelementptr %387[%389] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %392 = llvm.bitcast %390 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %392, %391 : !llvm.ptr<ptr<i8>>
    %393 = llvm.mlir.constant(1 : i32) : i32
    %394 = llvm.getelementptr %385[%388, 1] : (!llvm.ptr<struct<".2", (i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %35, %394 : !llvm.ptr<i64>
    %395 = llvm.getelementptr %387[%393] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %396 = llvm.bitcast %394 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %396, %395 : !llvm.ptr<ptr<i8>>
    %397 = llvm.mlir.constant(2 : i32) : i32
    %398 = llvm.getelementptr %385[%388, 2] : (!llvm.ptr<struct<".2", (i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %380, %398 : !llvm.ptr<ptr<f32>>
    %399 = llvm.getelementptr %387[%397] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %400 = llvm.bitcast %398 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %400, %399 : !llvm.ptr<ptr<i8>>
    %401 = llvm.mlir.constant(0 : i32) : i32
    %402 = llvm.mlir.constant(3 : i32) : i32
    %403 = llvm.inttoptr %401 : i32 to !llvm.ptr<i8>
    %404 = llvm.mlir.constant(0 : i32) : i32
    %405 = llvm.mlir.constant(1 : i32) : i32
    %406 = llvm.alloca %405 x !llvm.struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %407 = llvm.mlir.constant(14 : i32) : i32
    %408 = llvm.alloca %407 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %409 = llvm.mlir.constant(0 : i32) : i32
    %410 = llvm.getelementptr %406[%404, 0] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %410 : !llvm.ptr<ptr<i8>>
    %411 = llvm.getelementptr %408[%409] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %412 = llvm.bitcast %410 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %412, %411 : !llvm.ptr<ptr<i8>>
    %413 = llvm.mlir.constant(1 : i32) : i32
    %414 = llvm.getelementptr %406[%404, 1] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %372, %414 : !llvm.ptr<ptr<ptr<i8>>>
    %415 = llvm.getelementptr %408[%413] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %416 = llvm.bitcast %414 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %416, %415 : !llvm.ptr<ptr<i8>>
    %417 = llvm.mlir.constant(2 : i32) : i32
    %418 = llvm.getelementptr %406[%404, 2] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %375, %418 : !llvm.ptr<i64>
    %419 = llvm.getelementptr %408[%417] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %420 = llvm.bitcast %418 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %420, %419 : !llvm.ptr<ptr<i8>>
    %421 = llvm.mlir.constant(3 : i32) : i32
    %422 = llvm.getelementptr %406[%404, 3] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %378, %422 : !llvm.ptr<ptr<i8>>
    %423 = llvm.getelementptr %408[%421] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %424 = llvm.bitcast %422 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %424, %423 : !llvm.ptr<ptr<i8>>
    %425 = llvm.mlir.constant(4 : i32) : i32
    %426 = llvm.getelementptr %406[%404, 4] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %367, %426 : !llvm.ptr<i64>
    %427 = llvm.getelementptr %408[%425] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %428 = llvm.bitcast %426 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %428, %427 : !llvm.ptr<ptr<i8>>
    %429 = llvm.mlir.constant(5 : i32) : i32
    %430 = llvm.getelementptr %406[%404, 5] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %430 : !llvm.ptr<i64>
    %431 = llvm.getelementptr %408[%429] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %432 = llvm.bitcast %430 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %432, %431 : !llvm.ptr<ptr<i8>>
    %433 = llvm.mlir.constant(6 : i32) : i32
    %434 = llvm.getelementptr %406[%404, 6] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %434 : !llvm.ptr<i64>
    %435 = llvm.getelementptr %408[%433] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %436 = llvm.bitcast %434 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %436, %435 : !llvm.ptr<ptr<i8>>
    %437 = llvm.mlir.constant(7 : i32) : i32
    %438 = llvm.getelementptr %406[%404, 7] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1, %438 : !llvm.ptr<i64>
    %439 = llvm.getelementptr %408[%437] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %440 = llvm.bitcast %438 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %440, %439 : !llvm.ptr<ptr<i8>>
    %441 = llvm.mlir.constant(8 : i32) : i32
    %442 = llvm.getelementptr %406[%404, 8] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %442 : !llvm.ptr<i64>
    %443 = llvm.getelementptr %408[%441] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %444 = llvm.bitcast %442 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %444, %443 : !llvm.ptr<ptr<i8>>
    %445 = llvm.mlir.constant(9 : i32) : i32
    %446 = llvm.getelementptr %406[%404, 9] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %446 : !llvm.ptr<i64>
    %447 = llvm.getelementptr %408[%445] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %448 = llvm.bitcast %446 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %448, %447 : !llvm.ptr<ptr<i8>>
    %449 = llvm.mlir.constant(10 : i32) : i32
    %450 = llvm.getelementptr %406[%404, 10] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %401, %450 : !llvm.ptr<i32>
    %451 = llvm.getelementptr %408[%449] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %452 = llvm.bitcast %450 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %452, %451 : !llvm.ptr<ptr<i8>>
    %453 = llvm.mlir.constant(11 : i32) : i32
    %454 = llvm.getelementptr %406[%404, 11] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %403, %454 : !llvm.ptr<ptr<i8>>
    %455 = llvm.getelementptr %408[%453] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %456 = llvm.bitcast %454 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %456, %455 : !llvm.ptr<ptr<i8>>
    %457 = llvm.mlir.constant(12 : i32) : i32
    %458 = llvm.getelementptr %406[%404, 12] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %402, %458 : !llvm.ptr<i32>
    %459 = llvm.getelementptr %408[%457] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %460 = llvm.bitcast %458 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %460, %459 : !llvm.ptr<ptr<i8>>
    %461 = llvm.mlir.constant(13 : i32) : i32
    %462 = llvm.getelementptr %406[%404, 13] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %387, %462 : !llvm.ptr<ptr<ptr<i8>>>
    %463 = llvm.getelementptr %408[%461] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %464 = llvm.bitcast %462 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %464, %463 : !llvm.ptr<ptr<i8>>
    %465 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %466 = llvm.mlir.constant(0 : index) : i64
    %467 = llvm.getelementptr %465[%466, %466] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %467, %408) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %468 = llvm.mlir.constant(1 : index) : i64
    %469 = llvm.mlir.constant(0 : index) : i64
    %470 = llvm.mlir.constant(-1 : index) : i64
    %471 = llvm.mlir.constant(true) : i1
    %472 = llvm.select %471, %470, %468 : i1, i64
    %473 = llvm.add %472, %31  : i64
    %474 = llvm.sdiv %473, %1  : i64
    %475 = llvm.add %468, %474  : i64
    %476 = llvm.sub %469, %31  : i64
    %477 = llvm.sdiv %476, %1  : i64
    %478 = llvm.sub %469, %477  : i64
    %479 = llvm.icmp "slt" %31, %469 : i64
    %480 = llvm.icmp "sgt" %31, %469 : i64
    %481 = llvm.mlir.constant(false) : i1
    %482 = llvm.mlir.constant(true) : i1
    %483 = llvm.and %479, %481  : i1
    %484 = llvm.and %480, %482  : i1
    %485 = llvm.or %483, %484  : i1
    %486 = llvm.select %485, %475, %478 : i1, i64
    %487 = llvm.mlir.constant(1 : index) : i64
    %488 = llvm.mlir.constant(0 : index) : i64
    %489 = llvm.mlir.constant(-1 : index) : i64
    %490 = llvm.mlir.constant(true) : i1
    %491 = llvm.select %490, %489, %487 : i1, i64
    %492 = llvm.add %491, %35  : i64
    %493 = llvm.sdiv %492, %5  : i64
    %494 = llvm.add %487, %493  : i64
    %495 = llvm.sub %488, %35  : i64
    %496 = llvm.sdiv %495, %5  : i64
    %497 = llvm.sub %488, %496  : i64
    %498 = llvm.icmp "slt" %35, %488 : i64
    %499 = llvm.icmp "sgt" %35, %488 : i64
    %500 = llvm.mlir.constant(false) : i1
    %501 = llvm.mlir.constant(true) : i1
    %502 = llvm.and %498, %500  : i1
    %503 = llvm.and %499, %501  : i1
    %504 = llvm.or %502, %503  : i1
    %505 = llvm.select %504, %494, %497 : i1, i64
    %506 = llvm.mul %486, %505  : i64
    %507 = llvm.icmp "sle" %506, %3 : i64
    %508 = llvm.sub %3, %506  : i64
    %509 = llvm.sub %506, %4  : i64
    %510 = llvm.select %507, %508, %509 : i1, i64
    %511 = llvm.sdiv %510, %1  : i64
    %512 = llvm.sub %3, %511  : i64
    %513 = llvm.add %511, %4  : i64
    %514 = llvm.select %507, %512, %513 : i1, i64
    %515 = llvm.mlir.addressof @main_kernel_2_blob_gpu.binary : !llvm.ptr<array<4464 x i8>>
    %516 = llvm.mlir.constant(0 : index) : i64
    %517 = llvm.getelementptr %515[%516, %516] : (!llvm.ptr<array<4464 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %518 = llvm.mlir.constant(1 : i32) : i32
    %519 = llvm.alloca %518 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %520 = llvm.mlir.constant(0 : i32) : i32
    %521 = llvm.getelementptr %519[%520] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %517, %521 : !llvm.ptr<ptr<i8>>
    %522 = llvm.mlir.constant(1 : i64) : i64
    %523 = llvm.mlir.addressof @main_kernel_2_main_kColReduction_reduce__4_1_0___8w16h_1_kernel_name : !llvm.ptr<array<43 x i8>>
    %524 = llvm.mlir.constant(0 : index) : i64
    %525 = llvm.getelementptr %523[%524, %524] : (!llvm.ptr<array<43 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %526 = llvm.extractvalue %28[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %527 = llvm.extractvalue %28[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %528 = llvm.extractvalue %28[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %529 = llvm.extractvalue %28[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %530 = llvm.extractvalue %28[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %531 = llvm.extractvalue %28[3, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %532 = llvm.extractvalue %28[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %533 = llvm.extractvalue %28[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %534 = llvm.extractvalue %28[4, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %535 = llvm.extractvalue %69[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %536 = llvm.extractvalue %69[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %537 = llvm.extractvalue %69[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %538 = llvm.extractvalue %69[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %539 = llvm.extractvalue %69[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %540 = llvm.mlir.constant(1 : i32) : i32
    %541 = llvm.alloca %540 x !llvm.struct<".4", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)> : (i32) -> !llvm.ptr<struct<".4", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>
    %542 = llvm.mlir.constant(7 : i32) : i32
    %543 = llvm.alloca %542 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %544 = llvm.mlir.constant(0 : i32) : i32
    %545 = llvm.mlir.constant(0 : i32) : i32
    %546 = llvm.getelementptr %541[%544, 0] : (!llvm.ptr<struct<".4", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %527, %546 : !llvm.ptr<ptr<f32>>
    %547 = llvm.getelementptr %543[%545] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %548 = llvm.bitcast %546 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %548, %547 : !llvm.ptr<ptr<i8>>
    %549 = llvm.mlir.constant(1 : i32) : i32
    %550 = llvm.getelementptr %541[%544, 1] : (!llvm.ptr<struct<".4", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %529, %550 : !llvm.ptr<i64>
    %551 = llvm.getelementptr %543[%549] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %552 = llvm.bitcast %550 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %552, %551 : !llvm.ptr<ptr<i8>>
    %553 = llvm.mlir.constant(2 : i32) : i32
    %554 = llvm.getelementptr %541[%544, 2] : (!llvm.ptr<struct<".4", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1, %554 : !llvm.ptr<i64>
    %555 = llvm.getelementptr %543[%553] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %556 = llvm.bitcast %554 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %556, %555 : !llvm.ptr<ptr<i8>>
    %557 = llvm.mlir.constant(3 : i32) : i32
    %558 = llvm.getelementptr %541[%544, 3] : (!llvm.ptr<struct<".4", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %506, %558 : !llvm.ptr<i64>
    %559 = llvm.getelementptr %543[%557] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %560 = llvm.bitcast %558 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %560, %559 : !llvm.ptr<ptr<i8>>
    %561 = llvm.mlir.constant(4 : i32) : i32
    %562 = llvm.getelementptr %541[%544, 4] : (!llvm.ptr<struct<".4", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %505, %562 : !llvm.ptr<i64>
    %563 = llvm.getelementptr %543[%561] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %564 = llvm.bitcast %562 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %564, %563 : !llvm.ptr<ptr<i8>>
    %565 = llvm.mlir.constant(5 : i32) : i32
    %566 = llvm.getelementptr %541[%544, 5] : (!llvm.ptr<struct<".4", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %35, %566 : !llvm.ptr<i64>
    %567 = llvm.getelementptr %543[%565] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %568 = llvm.bitcast %566 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %568, %567 : !llvm.ptr<ptr<i8>>
    %569 = llvm.mlir.constant(6 : i32) : i32
    %570 = llvm.getelementptr %541[%544, 6] : (!llvm.ptr<struct<".4", (ptr<f32>, i64, i64, i64, i64, i64, ptr<f32>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %536, %570 : !llvm.ptr<ptr<f32>>
    %571 = llvm.getelementptr %543[%569] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %572 = llvm.bitcast %570 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %572, %571 : !llvm.ptr<ptr<i8>>
    %573 = llvm.mlir.constant(0 : i32) : i32
    %574 = llvm.mlir.constant(7 : i32) : i32
    %575 = llvm.inttoptr %573 : i32 to !llvm.ptr<i8>
    %576 = llvm.mlir.constant(0 : i32) : i32
    %577 = llvm.mlir.constant(1 : i32) : i32
    %578 = llvm.alloca %577 x !llvm.struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %579 = llvm.mlir.constant(14 : i32) : i32
    %580 = llvm.alloca %579 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %581 = llvm.mlir.constant(0 : i32) : i32
    %582 = llvm.getelementptr %578[%576, 0] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %582 : !llvm.ptr<ptr<i8>>
    %583 = llvm.getelementptr %580[%581] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %584 = llvm.bitcast %582 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %584, %583 : !llvm.ptr<ptr<i8>>
    %585 = llvm.mlir.constant(1 : i32) : i32
    %586 = llvm.getelementptr %578[%576, 1] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %519, %586 : !llvm.ptr<ptr<ptr<i8>>>
    %587 = llvm.getelementptr %580[%585] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %588 = llvm.bitcast %586 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %588, %587 : !llvm.ptr<ptr<i8>>
    %589 = llvm.mlir.constant(2 : i32) : i32
    %590 = llvm.getelementptr %578[%576, 2] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %522, %590 : !llvm.ptr<i64>
    %591 = llvm.getelementptr %580[%589] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %592 = llvm.bitcast %590 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %592, %591 : !llvm.ptr<ptr<i8>>
    %593 = llvm.mlir.constant(3 : i32) : i32
    %594 = llvm.getelementptr %578[%576, 3] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %525, %594 : !llvm.ptr<ptr<i8>>
    %595 = llvm.getelementptr %580[%593] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %596 = llvm.bitcast %594 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %596, %595 : !llvm.ptr<ptr<i8>>
    %597 = llvm.mlir.constant(4 : i32) : i32
    %598 = llvm.getelementptr %578[%576, 4] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %514, %598 : !llvm.ptr<i64>
    %599 = llvm.getelementptr %580[%597] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %600 = llvm.bitcast %598 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %600, %599 : !llvm.ptr<ptr<i8>>
    %601 = llvm.mlir.constant(5 : i32) : i32
    %602 = llvm.getelementptr %578[%576, 5] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %602 : !llvm.ptr<i64>
    %603 = llvm.getelementptr %580[%601] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %604 = llvm.bitcast %602 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %604, %603 : !llvm.ptr<ptr<i8>>
    %605 = llvm.mlir.constant(6 : i32) : i32
    %606 = llvm.getelementptr %578[%576, 6] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %606 : !llvm.ptr<i64>
    %607 = llvm.getelementptr %580[%605] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %608 = llvm.bitcast %606 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %608, %607 : !llvm.ptr<ptr<i8>>
    %609 = llvm.mlir.constant(7 : i32) : i32
    %610 = llvm.getelementptr %578[%576, 7] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1, %610 : !llvm.ptr<i64>
    %611 = llvm.getelementptr %580[%609] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %612 = llvm.bitcast %610 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %612, %611 : !llvm.ptr<ptr<i8>>
    %613 = llvm.mlir.constant(8 : i32) : i32
    %614 = llvm.getelementptr %578[%576, 8] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %614 : !llvm.ptr<i64>
    %615 = llvm.getelementptr %580[%613] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %616 = llvm.bitcast %614 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %616, %615 : !llvm.ptr<ptr<i8>>
    %617 = llvm.mlir.constant(9 : i32) : i32
    %618 = llvm.getelementptr %578[%576, 9] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %4, %618 : !llvm.ptr<i64>
    %619 = llvm.getelementptr %580[%617] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %620 = llvm.bitcast %618 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %620, %619 : !llvm.ptr<ptr<i8>>
    %621 = llvm.mlir.constant(10 : i32) : i32
    %622 = llvm.getelementptr %578[%576, 10] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %573, %622 : !llvm.ptr<i32>
    %623 = llvm.getelementptr %580[%621] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %624 = llvm.bitcast %622 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %624, %623 : !llvm.ptr<ptr<i8>>
    %625 = llvm.mlir.constant(11 : i32) : i32
    %626 = llvm.getelementptr %578[%576, 11] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %575, %626 : !llvm.ptr<ptr<i8>>
    %627 = llvm.getelementptr %580[%625] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %628 = llvm.bitcast %626 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %628, %627 : !llvm.ptr<ptr<i8>>
    %629 = llvm.mlir.constant(12 : i32) : i32
    %630 = llvm.getelementptr %578[%576, 12] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %574, %630 : !llvm.ptr<i32>
    %631 = llvm.getelementptr %580[%629] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %632 = llvm.bitcast %630 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %632, %631 : !llvm.ptr<ptr<i8>>
    %633 = llvm.mlir.constant(13 : i32) : i32
    %634 = llvm.getelementptr %578[%576, 13] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %543, %634 : !llvm.ptr<ptr<ptr<i8>>>
    %635 = llvm.getelementptr %580[%633] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %636 = llvm.bitcast %634 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %636, %635 : !llvm.ptr<ptr<i8>>
    %637 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %638 = llvm.mlir.constant(0 : index) : i64
    %639 = llvm.getelementptr %637[%638, %638] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %639, %580) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    %640 = llvm.inttoptr %2 : i32 to !llvm.ptr<i8>
    %641 = llvm.mlir.constant(2 : index) : i64
    %642 = llvm.mlir.constant(1 : index) : i64
    %643 = llvm.mlir.null : !llvm.ptr<i64>
    %644 = llvm.getelementptr %643[%641] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>
    %645 = llvm.ptrtoint %644 : !llvm.ptr<i64> to i64
    %646 = llvm.alloca %645 x i64 : (i64) -> !llvm.ptr<i64>
    %647 = llvm.mlir.undef : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>
    %648 = llvm.insertvalue %646, %647[0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %649 = llvm.insertvalue %646, %648[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %650 = llvm.mlir.constant(0 : index) : i64
    %651 = llvm.insertvalue %650, %649[2] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %652 = llvm.insertvalue %641, %651[3, 0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %653 = llvm.insertvalue %642, %652[4, 0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %654 = llvm.extractvalue %653[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %655 = llvm.getelementptr %654[%3] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>
    llvm.store %30, %655 : !llvm.ptr<i64>
    %656 = llvm.extractvalue %653[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %657 = llvm.getelementptr %656[%4] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>
    llvm.store %29, %657 : !llvm.ptr<i64>
    %658 = llvm.mlir.constant(0 : i32) : i32
    %659 = llvm.mlir.constant(1 : i32) : i32
    %660 = llvm.extractvalue %69[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %661 = llvm.extractvalue %69[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %662 = llvm.extractvalue %69[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %663 = llvm.extractvalue %69[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %664 = llvm.extractvalue %69[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %665 = llvm.extractvalue %653[0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %666 = llvm.extractvalue %653[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %667 = llvm.extractvalue %653[2] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %668 = llvm.extractvalue %653[3, 0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %669 = llvm.extractvalue %653[4, 0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %670 = llvm.alloca %659 x !llvm.struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)> : (i32) -> !llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>
    %671 = llvm.mlir.constant(13 : i32) : i32
    %672 = llvm.alloca %671 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %673 = llvm.mlir.constant(0 : i32) : i32
    %674 = llvm.getelementptr %670[%658, 0] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %674 : !llvm.ptr<ptr<i8>>
    %675 = llvm.getelementptr %672[%673] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %676 = llvm.bitcast %674 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %676, %675 : !llvm.ptr<ptr<i8>>
    %677 = llvm.mlir.constant(1 : i32) : i32
    %678 = llvm.getelementptr %670[%658, 1] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %640, %678 : !llvm.ptr<ptr<i8>>
    %679 = llvm.getelementptr %672[%677] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %680 = llvm.bitcast %678 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %680, %679 : !llvm.ptr<ptr<i8>>
    %681 = llvm.mlir.constant(2 : i32) : i32
    %682 = llvm.getelementptr %670[%658, 2] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %660, %682 : !llvm.ptr<ptr<f32>>
    %683 = llvm.getelementptr %672[%681] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %684 = llvm.bitcast %682 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %684, %683 : !llvm.ptr<ptr<i8>>
    %685 = llvm.mlir.constant(3 : i32) : i32
    %686 = llvm.getelementptr %670[%658, 3] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %661, %686 : !llvm.ptr<ptr<f32>>
    %687 = llvm.getelementptr %672[%685] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %688 = llvm.bitcast %686 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %688, %687 : !llvm.ptr<ptr<i8>>
    %689 = llvm.mlir.constant(4 : i32) : i32
    %690 = llvm.getelementptr %670[%658, 4] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %662, %690 : !llvm.ptr<i64>
    %691 = llvm.getelementptr %672[%689] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %692 = llvm.bitcast %690 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %692, %691 : !llvm.ptr<ptr<i8>>
    %693 = llvm.mlir.constant(5 : i32) : i32
    %694 = llvm.getelementptr %670[%658, 5] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %663, %694 : !llvm.ptr<i64>
    %695 = llvm.getelementptr %672[%693] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %696 = llvm.bitcast %694 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %696, %695 : !llvm.ptr<ptr<i8>>
    %697 = llvm.mlir.constant(6 : i32) : i32
    %698 = llvm.getelementptr %670[%658, 6] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %664, %698 : !llvm.ptr<i64>
    %699 = llvm.getelementptr %672[%697] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %700 = llvm.bitcast %698 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %700, %699 : !llvm.ptr<ptr<i8>>
    %701 = llvm.mlir.constant(7 : i32) : i32
    %702 = llvm.getelementptr %670[%658, 7] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i64>>
    llvm.store %665, %702 : !llvm.ptr<ptr<i64>>
    %703 = llvm.getelementptr %672[%701] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %704 = llvm.bitcast %702 : !llvm.ptr<ptr<i64>> to !llvm.ptr<i8>
    llvm.store %704, %703 : !llvm.ptr<ptr<i8>>
    %705 = llvm.mlir.constant(8 : i32) : i32
    %706 = llvm.getelementptr %670[%658, 8] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i64>>
    llvm.store %666, %706 : !llvm.ptr<ptr<i64>>
    %707 = llvm.getelementptr %672[%705] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %708 = llvm.bitcast %706 : !llvm.ptr<ptr<i64>> to !llvm.ptr<i8>
    llvm.store %708, %707 : !llvm.ptr<ptr<i8>>
    %709 = llvm.mlir.constant(9 : i32) : i32
    %710 = llvm.getelementptr %670[%658, 9] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %667, %710 : !llvm.ptr<i64>
    %711 = llvm.getelementptr %672[%709] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %712 = llvm.bitcast %710 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %712, %711 : !llvm.ptr<ptr<i8>>
    %713 = llvm.mlir.constant(10 : i32) : i32
    %714 = llvm.getelementptr %670[%658, 10] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %668, %714 : !llvm.ptr<i64>
    %715 = llvm.getelementptr %672[%713] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %716 = llvm.bitcast %714 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %716, %715 : !llvm.ptr<ptr<i8>>
    %717 = llvm.mlir.constant(11 : i32) : i32
    %718 = llvm.getelementptr %670[%658, 11] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %669, %718 : !llvm.ptr<i64>
    %719 = llvm.getelementptr %672[%717] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %720 = llvm.bitcast %718 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %720, %719 : !llvm.ptr<ptr<i8>>
    %721 = llvm.mlir.constant(12 : i32) : i32
    %722 = llvm.getelementptr %670[%658, 12] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>>
    %723 = llvm.getelementptr %672[%721] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %724 = llvm.bitcast %722 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>> to !llvm.ptr<i8>
    llvm.store %724, %723 : !llvm.ptr<ptr<i8>>
    %725 = llvm.mlir.addressof @inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32 : !llvm.ptr<array<51 x i8>>
    %726 = llvm.mlir.constant(0 : index) : i64
    %727 = llvm.getelementptr %725[%726, %726] : (!llvm.ptr<array<51 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %727, %672) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %728 = llvm.load %722 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>>
    %729 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>
    %730 = llvm.extractvalue %728[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %731 = llvm.extractvalue %728[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %732 = llvm.insertvalue %730, %729[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %733 = llvm.insertvalue %731, %732[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %734 = llvm.mlir.constant(0 : index) : i64
    %735 = llvm.insertvalue %734, %733[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %736 = llvm.insertvalue %30, %735[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %737 = llvm.insertvalue %29, %736[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %738 = llvm.insertvalue %29, %737[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %739 = llvm.mlir.constant(1 : index) : i64
    %740 = llvm.insertvalue %739, %738[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %741 = llvm.extractvalue %69[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %742 = llvm.bitcast %741 : !llvm.ptr<f32> to !llvm.ptr<i8>
    %743 = llvm.mlir.constant(0 : i32) : i32
    %744 = llvm.mlir.constant(1 : i32) : i32
    %745 = llvm.alloca %744 x !llvm.struct<".7", (ptr<i8>, ptr<i8>)> : (i32) -> !llvm.ptr<struct<".7", (ptr<i8>, ptr<i8>)>>
    %746 = llvm.mlir.constant(2 : i32) : i32
    %747 = llvm.alloca %746 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %748 = llvm.mlir.constant(0 : i32) : i32
    %749 = llvm.getelementptr %745[%743, 0] : (!llvm.ptr<struct<".7", (ptr<i8>, ptr<i8>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %749 : !llvm.ptr<ptr<i8>>
    %750 = llvm.getelementptr %747[%748] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %751 = llvm.bitcast %749 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %751, %750 : !llvm.ptr<ptr<i8>>
    %752 = llvm.mlir.constant(1 : i32) : i32
    %753 = llvm.getelementptr %745[%743, 1] : (!llvm.ptr<struct<".7", (ptr<i8>, ptr<i8>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %742, %753 : !llvm.ptr<ptr<i8>>
    %754 = llvm.getelementptr %747[%752] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %755 = llvm.bitcast %753 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %755, %754 : !llvm.ptr<ptr<i8>>
    %756 = llvm.mlir.addressof @dealloc___gpu___pvoid_pvoid___void : !llvm.ptr<array<35 x i8>>
    %757 = llvm.mlir.constant(0 : index) : i64
    %758 = llvm.getelementptr %756[%757, %757] : (!llvm.ptr<array<35 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %758, %747) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %759 = llvm.mlir.constant(0 : i32) : i32
    %760 = llvm.mlir.constant(1 : i32) : i32
    %761 = llvm.extractvalue %740[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %762 = llvm.extractvalue %740[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %763 = llvm.extractvalue %740[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %764 = llvm.extractvalue %740[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %765 = llvm.extractvalue %740[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %766 = llvm.extractvalue %740[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %767 = llvm.extractvalue %740[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %768 = llvm.alloca %760 x !llvm.struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)> : (i32) -> !llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>
    %769 = llvm.mlir.constant(9 : i32) : i32
    %770 = llvm.alloca %769 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %771 = llvm.mlir.constant(0 : i32) : i32
    %772 = llvm.getelementptr %768[%759, 0] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %772 : !llvm.ptr<ptr<i8>>
    %773 = llvm.getelementptr %770[%771] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %774 = llvm.bitcast %772 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %774, %773 : !llvm.ptr<ptr<i8>>
    %775 = llvm.mlir.constant(1 : i32) : i32
    %776 = llvm.getelementptr %768[%759, 1] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %3, %776 : !llvm.ptr<i64>
    %777 = llvm.getelementptr %770[%775] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %778 = llvm.bitcast %776 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %778, %777 : !llvm.ptr<ptr<i8>>
    %779 = llvm.mlir.constant(2 : i32) : i32
    %780 = llvm.getelementptr %768[%759, 2] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %761, %780 : !llvm.ptr<ptr<f32>>
    %781 = llvm.getelementptr %770[%779] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %782 = llvm.bitcast %780 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %782, %781 : !llvm.ptr<ptr<i8>>
    %783 = llvm.mlir.constant(3 : i32) : i32
    %784 = llvm.getelementptr %768[%759, 3] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %762, %784 : !llvm.ptr<ptr<f32>>
    %785 = llvm.getelementptr %770[%783] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %786 = llvm.bitcast %784 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %786, %785 : !llvm.ptr<ptr<i8>>
    %787 = llvm.mlir.constant(4 : i32) : i32
    %788 = llvm.getelementptr %768[%759, 4] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %763, %788 : !llvm.ptr<i64>
    %789 = llvm.getelementptr %770[%787] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %790 = llvm.bitcast %788 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %790, %789 : !llvm.ptr<ptr<i8>>
    %791 = llvm.mlir.constant(5 : i32) : i32
    %792 = llvm.getelementptr %768[%759, 5] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %764, %792 : !llvm.ptr<i64>
    %793 = llvm.getelementptr %770[%791] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %794 = llvm.bitcast %792 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %794, %793 : !llvm.ptr<ptr<i8>>
    %795 = llvm.mlir.constant(6 : i32) : i32
    %796 = llvm.getelementptr %768[%759, 6] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %765, %796 : !llvm.ptr<i64>
    %797 = llvm.getelementptr %770[%795] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %798 = llvm.bitcast %796 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %798, %797 : !llvm.ptr<ptr<i8>>
    %799 = llvm.mlir.constant(7 : i32) : i32
    %800 = llvm.getelementptr %768[%759, 7] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %766, %800 : !llvm.ptr<i64>
    %801 = llvm.getelementptr %770[%799] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %802 = llvm.bitcast %800 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %802, %801 : !llvm.ptr<ptr<i8>>
    %803 = llvm.mlir.constant(8 : i32) : i32
    %804 = llvm.getelementptr %768[%759, 8] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %767, %804 : !llvm.ptr<i64>
    %805 = llvm.getelementptr %770[%803] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %806 = llvm.bitcast %804 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %806, %805 : !llvm.ptr<ptr<i8>>
    %807 = llvm.mlir.addressof @ral_send_output___cpu___pvoid_i64_m2df32___void : !llvm.ptr<array<48 x i8>>
    %808 = llvm.mlir.constant(0 : index) : i64
    %809 = llvm.getelementptr %807[%808, %808] : (!llvm.ptr<array<48 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %809, %770) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    llvm.return
  }
}


===-------------------------------------------------------------------------===
                         ... Execution time report ...
===-------------------------------------------------------------------------===
  Total Execution Time: 0.5925 seconds

  ----Wall Time----  ----Name----
    0.0004 (  0.1%)  Inliner
    0.0000 (  0.0%)    (A) CallGraph
    0.0001 (  0.0%)  'func.func' Pipeline
    0.0001 (  0.0%)    Canonicalizer
    0.0003 (  0.1%)  'func.func' Pipeline
    0.0000 (  0.0%)    MhloDecompositionRewriterPass
    0.0000 (  0.0%)    RemoveShapeConstraintsPass
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    DiscCustomCallRewriterPass
    0.0000 (  0.0%)    DiscConvertFakeQuantOpPass
    0.0000 (  0.0%)    DiscLowerGpuQuantizeAndDequantizePass
    0.0000 (  0.0%)    ConvertShapeToStandardPass
    0.0013 (  0.2%)  DiscShapeOptimizationPass
    0.0013 (  0.2%)  'builtin.func' Pipeline
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0010 (  0.2%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0004 (  0.1%)  'func.func' Pipeline
    0.0000 (  0.0%)    ConvertTensorToStandardPass
    0.0000 (  0.0%)    ConvertHloToStandardPass
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    DiscAlgebraicSimplifierPass
    0.0000 (  0.0%)    SplitLargeOpsPass
    0.0000 (  0.0%)    DotRewriterPass
    0.0011 (  0.2%)  DiscShapeOptimizationPass
    0.0001 (  0.0%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscDotMergePass
    0.0010 (  0.2%)  DiscShapeOptimizationPass
    0.0005 (  0.1%)  'func.func' Pipeline
    0.0005 (  0.1%)    HloCanonicalizeReductionPass
    0.0024 (  0.4%)  DiscShapeOptimizationPass
    0.0006 (  0.1%)  DiscMarkShapeCalculationPass
    0.0006 (  0.1%)  PlaceOpsPass
    0.0004 (  0.1%)  'func.func' Pipeline
    0.0002 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    ElementTypeConverterPass
    0.0016 (  0.3%)  DiscShapeOptimizationPass
    0.0002 (  0.0%)  'func.func' Pipeline
    0.0001 (  0.0%)    ReductionRewriterPass
    0.0000 (  0.0%)    ConvRewriterPass
    0.0000 (  0.0%)    ConvRewriterPass
    0.0000 (  0.0%)    QuantizedDotRewriterPass
    0.0016 (  0.3%)  DiscShapeOptimizationPass
    0.0017 (  0.3%)  'func.func' Pipeline
    0.0002 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0013 (  0.2%)    TransposeSimplifierPass
    0.0000 (  0.0%)    GpuConvPaddingLegalizationPass
    0.0017 (  0.3%)  DiscShapeOptimizationPass
    0.0001 (  0.0%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscAlgebraicSimplifierPass
    0.0017 (  0.3%)  DiscShapeOptimizationPass
    0.0010 (  0.2%)  'func.func' Pipeline
    0.0007 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0003 (  0.0%)    Canonicalizer
    0.0009 (  0.1%)  FuncBufferize
    0.0012 (  0.2%)  DiscHloLegalizeToLhloPass
    0.0019 (  0.3%)  HloLegalizeToLhloPass
    0.0011 (  0.2%)  'func.func' Pipeline
    0.0011 (  0.2%)    Canonicalizer
    0.0001 (  0.0%)  DiscLhloRewriterPass
    0.0031 (  0.5%)  'func.func' Pipeline
    0.0002 (  0.0%)    Canonicalizer
    0.0001 (  0.0%)    ConvertShapeToStandardPass
    0.0002 (  0.0%)    Canonicalizer
    0.0008 (  0.1%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0008 (  0.1%)    LegalizeToTensorOpPass
    0.0008 (  0.1%)    Canonicalizer
    0.0001 (  0.0%)    StdBufferizePass
    0.0001 (  0.0%)  ArithBufferize
    0.0033 (  0.6%)  'func.func' Pipeline
    0.0008 (  0.1%)    TensorBufferize
    0.0001 (  0.0%)    FinalizingBufferize
    0.0009 (  0.1%)    Canonicalizer
    0.0007 (  0.1%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0006 (  0.1%)    DiscMemrefCanonicalizer
    0.0010 (  0.2%)  DiscAssignMemorySpacePass
    0.0065 (  1.1%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscDuplicateComputationForFusionPass
    0.0007 (  0.1%)    PromoteBuffersToStack
    0.0001 (  0.0%)    DiscMemRefLoadStoreSimplifierPass
    0.0011 (  0.2%)    DiscFusionPass
    0.0000 (  0.0%)    DiscFuseSplatConstPass
    0.0013 (  0.2%)    DiscSpecializeFusionWithSpeculationPass
    0.0013 (  0.2%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0002 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0012 (  0.2%)    BufferDeallocation
    0.0001 (  0.0%)    DiscBufferDeallocationPass
    0.0014 (  0.2%)  RalInjectExecutionContextPass
    0.0015 (  0.3%)  'func.func' Pipeline
    0.0015 (  0.3%)    DiscLowerToLibraryCallPass
    0.0002 (  0.0%)  DiscConstToRALPass
    0.0512 (  8.6%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscMemRefLoadStoreSimplifierPass
    0.0031 (  0.5%)    DiscLhloLegalizeRootsToParallelLoopsPass
    0.0026 (  0.4%)    ExpandOps
    0.0003 (  0.1%)    UnhandledAtomicRMWConverterPass
    0.0035 (  0.6%)    InputInlineFusionPass
    0.0002 (  0.0%)    ForLoopUnrollInterleave
    0.0030 (  0.5%)    ArithExpandOps
    0.0033 (  0.6%)    DiscBF16ExpansionPass
    0.0004 (  0.1%)    FoldMemRefAliasOps
    0.0051 (  0.9%)    DiscFlattenMemrefAccessPass
    0.0036 (  0.6%)    Canonicalizer
    0.0028 (  0.5%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0005 (  0.1%)    Canonicalizer
    0.0005 (  0.1%)    DiscMemRefCSEPass
    0.0028 (  0.5%)    ConvertShapeToStandardPass
    0.0030 (  0.5%)    Canonicalizer
    0.0027 (  0.5%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0005 (  0.1%)    Canonicalizer
    0.0028 (  0.5%)    ParallelLoopCollapsing
    0.0032 (  0.5%)    SCFParallelLoopTiling
    0.0033 (  0.6%)    GpuMapParallelLoopsPass
    0.0038 (  0.6%)    ConvertParallelLoopToGpu
    0.0004 (  0.1%)  'func' Pipeline
    0.0003 (  0.1%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0041 (  0.7%)  GpuLaunchSinkIndexComputations
    0.0049 (  0.8%)  GpuKernelOutlining
    0.0046 (  0.8%)  AssignKernelNamePass
    0.0012 (  0.2%)  'func.func' Pipeline
    0.0012 (  0.2%)    LhloFusionInlinerPass
    0.0003 (  0.1%)  DiscCompIntensFusionToCUDASourcePass
    0.0003 (  0.1%)  ReviseGpuKernelOutliningPass
    0.3721 ( 62.8%)  'gpu.module' Pipeline
    0.0029 (  0.5%)    LoopInvariantCodeMotion
    0.0034 (  0.6%)    'gpu.func' Pipeline
    0.0034 (  0.6%)      SideEffectLoopInvariantCodeMotionPass
    0.0002 (  0.0%)    LoopInvariantCodeMotion
    0.0028 (  0.5%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0033 (  0.6%)    SCFToControlFlow
    0.0032 (  0.5%)    ConvertAffineToStandard
    0.0030 (  0.5%)    StripDebugInfo
    0.0078 (  1.3%)    DiscLowerGpuOpsToNVVMOpsPass
    0.0036 (  0.6%)    'llvm.func' Pipeline
    0.0036 (  0.6%)      LLVMInsertValueSimplifierPass
    0.0035 (  0.6%)    FunctionDeadArgumentEliminationPass
    0.3381 ( 57.1%)    GpuKernelToBlobPass
    0.0004 (  0.1%)  DiscGPUSourceToLibPass
    0.0019 (  0.3%)  'func.func' Pipeline
    0.0014 (  0.2%)    Canonicalizer
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    RemoveDeadBufferPass
    0.0001 (  0.0%)    LinalgLowerToLoops
    0.0182 (  3.1%)  SCFToControlFlow
    0.0017 (  0.3%)  'func.func' Pipeline
    0.0002 (  0.0%)    ExpandStridedMetadata
    0.0012 (  0.2%)    Canonicalizer
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.0%)    Canonicalizer
    0.0181 (  3.1%)  ConvertAffineToStandard
    0.0182 (  3.1%)  StripDebugInfo
    0.0180 (  3.0%)  DiscStripShapeConstraintOpsPass
    0.0282 (  4.8%)  DiscToLLVMPass
    0.0060 (  1.0%)  Rest
    0.5925 (100.0%)  Total
[DISC] LowerHLOToLLVM takes: 5.935420e-01 s.
before optimize llvm module:
; ModuleID = 'LLVMDialectModule'
source_filename = "LLVMDialectModule"

%0 = type { ptr, i64, { ptr, ptr, i64, [3 x i64], [3 x i64] } }
%.1 = type { ptr, i64, ptr }
%.9 = type { i64, i64, ptr }
%.10 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.11 = type { ptr, i64, i64, i64, i64, i64, ptr }
%.12 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.2 = type { i64, i64, ptr }
%.3 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.4 = type { ptr, i64, i64, i64, i64, i64, ptr }
%.5 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.6 = type { ptr, ptr, ptr, ptr, i64, i64, i64, ptr, ptr, i64, i64, i64, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.7 = type { ptr, ptr }
%.8 = type { ptr, i64, ptr, ptr, i64, i64, i64, i64, i64 }

@main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name = internal constant [43 x i8] c"main_kColReduction_reduce__4_1_0___8w32h_1\00"
@main_kernel_0_blob_gpu.binary = internal constant [4464 x i8] c"P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"
@main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name = internal constant [41 x i8] c"main_kColReduction_reduce__4_1_0___8w32h\00"
@main_kernel_blob_gpu.binary = internal constant [1096 x i8] c"P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"
@ral_send_output___cpu___pvoid_i64_m2df32___void = internal constant [48 x i8] c"ral_send_output___cpu___pvoid_i64_m2df32___void\00"
@dealloc___gpu___pvoid_pvoid___void = internal constant [35 x i8] c"dealloc___gpu___pvoid_pvoid___void\00"
@inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32 = internal constant [51 x i8] c"inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32\00"
@main_kernel_2_main_kColReduction_reduce__4_1_0___8w16h_1_kernel_name = internal constant [43 x i8] c"main_kColReduction_reduce__4_1_0___8w16h_1\00"
@main_kernel_2_blob_gpu.binary = internal constant [4464 x i8] c"P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w16h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"
@ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void = internal constant [101 x i8] c"ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00"
@main_kernel_1_main_kColReduction_reduce__4_1_0___8w16h_kernel_name = internal constant [41 x i8] c"main_kColReduction_reduce__4_1_0___8w16h\00"
@main_kernel_1_blob_gpu.binary = internal constant [1096 x i8] c"P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w16h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"
@alloc___gpu___pvoid_i64___pvoid = internal constant [32 x i8] c"alloc___gpu___pvoid_i64___pvoid\00"
@ral_recv_input___cpu___pvoid_i64___m3df32 = internal constant [42 x i8] c"ral_recv_input___cpu___pvoid_i64___m3df32\00"

declare ptr @malloc(i64)

declare void @free(ptr)

declare void @disc_ral_call(ptr, ptr, ptr)

define void @main(ptr %0) {
  %2 = alloca %0, align 8
  %3 = alloca ptr, i32 3, align 8
  %4 = getelementptr %0, ptr %2, i32 0, i32 0
  store ptr %0, ptr %4, align 8
  %5 = getelementptr ptr, ptr %3, i32 0
  store ptr %4, ptr %5, align 8
  %6 = getelementptr %0, ptr %2, i32 0, i32 1
  store i64 0, ptr %6, align 4
  %7 = getelementptr ptr, ptr %3, i32 1
  store ptr %6, ptr %7, align 8
  %8 = getelementptr %0, ptr %2, i32 0, i32 2
  %9 = getelementptr ptr, ptr %3, i32 2
  store ptr %8, ptr %9, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_recv_input___cpu___pvoid_i64___m3df32, ptr %3)
  %10 = load { ptr, ptr, i64, [3 x i64], [3 x i64] }, ptr %8, align 8
  %11 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 2
  %12 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 1
  %13 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 0
  %14 = trunc i64 %12 to i32
  %15 = trunc i64 %11 to i32
  %16 = mul i32 %14, %15
  %17 = sext i32 %16 to i64
  %18 = getelementptr float, ptr null, i64 %17
  %19 = ptrtoint ptr %18 to i64
  %20 = alloca %.1, align 8
  %21 = alloca ptr, i32 3, align 8
  %22 = getelementptr %.1, ptr %20, i32 0, i32 0
  store ptr %0, ptr %22, align 8
  %23 = getelementptr ptr, ptr %21, i32 0
  store ptr %22, ptr %23, align 8
  %24 = getelementptr %.1, ptr %20, i32 0, i32 1
  store i64 %19, ptr %24, align 4
  %25 = getelementptr ptr, ptr %21, i32 1
  store ptr %24, ptr %25, align 8
  %26 = getelementptr %.1, ptr %20, i32 0, i32 2
  %27 = getelementptr ptr, ptr %21, i32 2
  store ptr %26, ptr %27, align 8
  call void @disc_ral_call(ptr %0, ptr @alloc___gpu___pvoid_i64___pvoid, ptr %21)
  %28 = load ptr, ptr %26, align 8
  %29 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } undef, ptr %28, 0
  %30 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %29, ptr %28, 1
  %31 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %30, i64 0, 2
  %32 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %31, i64 %17, 3, 0
  %33 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %32, i64 1, 4, 0
  %34 = mul i64 %13, %17
  %35 = add i64 %34, -1
  %36 = sdiv i64 %35, 256
  %37 = add i64 %36, 1
  %38 = sub i64 0, %34
  %39 = sdiv i64 %38, 256
  %40 = sub i64 0, %39
  %41 = icmp sgt i64 %34, 0
  %42 = select i1 %41, i64 %37, i64 %40
  %43 = icmp sgt i64 %42, 108
  br i1 %43, label %44, label %193

44:                                               ; preds = %1
  %45 = icmp sle i64 %17, 0
  %46 = sub i64 0, %17
  %47 = sub i64 %17, 1
  %48 = select i1 %45, i64 %46, i64 %47
  %49 = sdiv i64 %48, 256
  %50 = sub i64 0, %49
  %51 = add i64 %49, 1
  %52 = select i1 %45, i64 %50, i64 %51
  %53 = alloca ptr, align 8
  %54 = getelementptr ptr, ptr %53, i32 0
  store ptr @main_kernel_blob_gpu.binary, ptr %54, align 8
  %55 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 0
  %56 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 1
  %57 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 2
  %58 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 3, 0
  %59 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 4, 0
  %60 = alloca %.9, align 8
  %61 = alloca ptr, i32 3, align 8
  %62 = getelementptr %.9, ptr %60, i32 0, i32 0
  store i64 256, ptr %62, align 4
  %63 = getelementptr ptr, ptr %61, i32 0
  store ptr %62, ptr %63, align 8
  %64 = getelementptr %.9, ptr %60, i32 0, i32 1
  store i64 %17, ptr %64, align 4
  %65 = getelementptr ptr, ptr %61, i32 1
  store ptr %64, ptr %65, align 8
  %66 = getelementptr %.9, ptr %60, i32 0, i32 2
  store ptr %56, ptr %66, align 8
  %67 = getelementptr ptr, ptr %61, i32 2
  store ptr %66, ptr %67, align 8
  %68 = alloca %.10, align 8
  %69 = alloca ptr, i32 14, align 8
  %70 = getelementptr %.10, ptr %68, i32 0, i32 0
  store ptr %0, ptr %70, align 8
  %71 = getelementptr ptr, ptr %69, i32 0
  store ptr %70, ptr %71, align 8
  %72 = getelementptr %.10, ptr %68, i32 0, i32 1
  store ptr %53, ptr %72, align 8
  %73 = getelementptr ptr, ptr %69, i32 1
  store ptr %72, ptr %73, align 8
  %74 = getelementptr %.10, ptr %68, i32 0, i32 2
  store i64 1, ptr %74, align 4
  %75 = getelementptr ptr, ptr %69, i32 2
  store ptr %74, ptr %75, align 8
  %76 = getelementptr %.10, ptr %68, i32 0, i32 3
  store ptr @main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name, ptr %76, align 8
  %77 = getelementptr ptr, ptr %69, i32 3
  store ptr %76, ptr %77, align 8
  %78 = getelementptr %.10, ptr %68, i32 0, i32 4
  store i64 %52, ptr %78, align 4
  %79 = getelementptr ptr, ptr %69, i32 4
  store ptr %78, ptr %79, align 8
  %80 = getelementptr %.10, ptr %68, i32 0, i32 5
  store i64 1, ptr %80, align 4
  %81 = getelementptr ptr, ptr %69, i32 5
  store ptr %80, ptr %81, align 8
  %82 = getelementptr %.10, ptr %68, i32 0, i32 6
  store i64 1, ptr %82, align 4
  %83 = getelementptr ptr, ptr %69, i32 6
  store ptr %82, ptr %83, align 8
  %84 = getelementptr %.10, ptr %68, i32 0, i32 7
  store i64 256, ptr %84, align 4
  %85 = getelementptr ptr, ptr %69, i32 7
  store ptr %84, ptr %85, align 8
  %86 = getelementptr %.10, ptr %68, i32 0, i32 8
  store i64 1, ptr %86, align 4
  %87 = getelementptr ptr, ptr %69, i32 8
  store ptr %86, ptr %87, align 8
  %88 = getelementptr %.10, ptr %68, i32 0, i32 9
  store i64 1, ptr %88, align 4
  %89 = getelementptr ptr, ptr %69, i32 9
  store ptr %88, ptr %89, align 8
  %90 = getelementptr %.10, ptr %68, i32 0, i32 10
  store i32 0, ptr %90, align 4
  %91 = getelementptr ptr, ptr %69, i32 10
  store ptr %90, ptr %91, align 8
  %92 = getelementptr %.10, ptr %68, i32 0, i32 11
  store ptr null, ptr %92, align 8
  %93 = getelementptr ptr, ptr %69, i32 11
  store ptr %92, ptr %93, align 8
  %94 = getelementptr %.10, ptr %68, i32 0, i32 12
  store i32 3, ptr %94, align 4
  %95 = getelementptr ptr, ptr %69, i32 12
  store ptr %94, ptr %95, align 8
  %96 = getelementptr %.10, ptr %68, i32 0, i32 13
  store ptr %61, ptr %96, align 8
  %97 = getelementptr ptr, ptr %69, i32 13
  store ptr %96, ptr %97, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %69)
  %98 = add i64 -1, %13
  %99 = sdiv i64 %98, 128
  %100 = add i64 1, %99
  %101 = sub i64 0, %13
  %102 = sdiv i64 %101, 128
  %103 = sub i64 0, %102
  %104 = icmp slt i64 %13, 0
  %105 = icmp sgt i64 %13, 0
  %106 = and i1 %104, false
  %107 = and i1 %105, true
  %108 = or i1 %106, %107
  %109 = select i1 %108, i64 %100, i64 %103
  %110 = add i64 -1, %17
  %111 = sdiv i64 %110, 2
  %112 = add i64 1, %111
  %113 = sub i64 0, %17
  %114 = sdiv i64 %113, 2
  %115 = sub i64 0, %114
  %116 = icmp slt i64 %17, 0
  %117 = icmp sgt i64 %17, 0
  %118 = and i1 %116, false
  %119 = and i1 %117, true
  %120 = or i1 %118, %119
  %121 = select i1 %120, i64 %112, i64 %115
  %122 = mul i64 %109, %121
  %123 = icmp sle i64 %122, 0
  %124 = sub i64 0, %122
  %125 = sub i64 %122, 1
  %126 = select i1 %123, i64 %124, i64 %125
  %127 = sdiv i64 %126, 256
  %128 = sub i64 0, %127
  %129 = add i64 %127, 1
  %130 = select i1 %123, i64 %128, i64 %129
  %131 = alloca ptr, align 8
  %132 = getelementptr ptr, ptr %131, i32 0
  store ptr @main_kernel_0_blob_gpu.binary, ptr %132, align 8
  %133 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 0
  %134 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 1
  %135 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 2
  %136 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 0
  %137 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 1
  %138 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 2
  %139 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 4, 0
  %140 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 4, 1
  %141 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 4, 2
  %142 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 0
  %143 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 1
  %144 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 2
  %145 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 3, 0
  %146 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 4, 0
  %147 = alloca %.11, align 8
  %148 = alloca ptr, i32 7, align 8
  %149 = getelementptr %.11, ptr %147, i32 0, i32 0
  store ptr %134, ptr %149, align 8
  %150 = getelementptr ptr, ptr %148, i32 0
  store ptr %149, ptr %150, align 8
  %151 = getelementptr %.11, ptr %147, i32 0, i32 1
  store i64 %136, ptr %151, align 4
  %152 = getelementptr ptr, ptr %148, i32 1
  store ptr %151, ptr %152, align 8
  %153 = getelementptr %.11, ptr %147, i32 0, i32 2
  store i64 256, ptr %153, align 4
  %154 = getelementptr ptr, ptr %148, i32 2
  store ptr %153, ptr %154, align 8
  %155 = getelementptr %.11, ptr %147, i32 0, i32 3
  store i64 %122, ptr %155, align 4
  %156 = getelementptr ptr, ptr %148, i32 3
  store ptr %155, ptr %156, align 8
  %157 = getelementptr %.11, ptr %147, i32 0, i32 4
  store i64 %121, ptr %157, align 4
  %158 = getelementptr ptr, ptr %148, i32 4
  store ptr %157, ptr %158, align 8
  %159 = getelementptr %.11, ptr %147, i32 0, i32 5
  store i64 %17, ptr %159, align 4
  %160 = getelementptr ptr, ptr %148, i32 5
  store ptr %159, ptr %160, align 8
  %161 = getelementptr %.11, ptr %147, i32 0, i32 6
  store ptr %143, ptr %161, align 8
  %162 = getelementptr ptr, ptr %148, i32 6
  store ptr %161, ptr %162, align 8
  %163 = alloca %.12, align 8
  %164 = alloca ptr, i32 14, align 8
  %165 = getelementptr %.12, ptr %163, i32 0, i32 0
  store ptr %0, ptr %165, align 8
  %166 = getelementptr ptr, ptr %164, i32 0
  store ptr %165, ptr %166, align 8
  %167 = getelementptr %.12, ptr %163, i32 0, i32 1
  store ptr %131, ptr %167, align 8
  %168 = getelementptr ptr, ptr %164, i32 1
  store ptr %167, ptr %168, align 8
  %169 = getelementptr %.12, ptr %163, i32 0, i32 2
  store i64 1, ptr %169, align 4
  %170 = getelementptr ptr, ptr %164, i32 2
  store ptr %169, ptr %170, align 8
  %171 = getelementptr %.12, ptr %163, i32 0, i32 3
  store ptr @main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name, ptr %171, align 8
  %172 = getelementptr ptr, ptr %164, i32 3
  store ptr %171, ptr %172, align 8
  %173 = getelementptr %.12, ptr %163, i32 0, i32 4
  store i64 %130, ptr %173, align 4
  %174 = getelementptr ptr, ptr %164, i32 4
  store ptr %173, ptr %174, align 8
  %175 = getelementptr %.12, ptr %163, i32 0, i32 5
  store i64 1, ptr %175, align 4
  %176 = getelementptr ptr, ptr %164, i32 5
  store ptr %175, ptr %176, align 8
  %177 = getelementptr %.12, ptr %163, i32 0, i32 6
  store i64 1, ptr %177, align 4
  %178 = getelementptr ptr, ptr %164, i32 6
  store ptr %177, ptr %178, align 8
  %179 = getelementptr %.12, ptr %163, i32 0, i32 7
  store i64 256, ptr %179, align 4
  %180 = getelementptr ptr, ptr %164, i32 7
  store ptr %179, ptr %180, align 8
  %181 = getelementptr %.12, ptr %163, i32 0, i32 8
  store i64 1, ptr %181, align 4
  %182 = getelementptr ptr, ptr %164, i32 8
  store ptr %181, ptr %182, align 8
  %183 = getelementptr %.12, ptr %163, i32 0, i32 9
  store i64 1, ptr %183, align 4
  %184 = getelementptr ptr, ptr %164, i32 9
  store ptr %183, ptr %184, align 8
  %185 = getelementptr %.12, ptr %163, i32 0, i32 10
  store i32 0, ptr %185, align 4
  %186 = getelementptr ptr, ptr %164, i32 10
  store ptr %185, ptr %186, align 8
  %187 = getelementptr %.12, ptr %163, i32 0, i32 11
  store ptr null, ptr %187, align 8
  %188 = getelementptr ptr, ptr %164, i32 11
  store ptr %187, ptr %188, align 8
  %189 = getelementptr %.12, ptr %163, i32 0, i32 12
  store i32 7, ptr %189, align 4
  %190 = getelementptr ptr, ptr %164, i32 12
  store ptr %189, ptr %190, align 8
  %191 = getelementptr %.12, ptr %163, i32 0, i32 13
  store ptr %148, ptr %191, align 8
  %192 = getelementptr ptr, ptr %164, i32 13
  store ptr %191, ptr %192, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %164)
  br label %342

193:                                              ; preds = %1
  %194 = icmp sle i64 %17, 0
  %195 = sub i64 0, %17
  %196 = sub i64 %17, 1
  %197 = select i1 %194, i64 %195, i64 %196
  %198 = sdiv i64 %197, 128
  %199 = sub i64 0, %198
  %200 = add i64 %198, 1
  %201 = select i1 %194, i64 %199, i64 %200
  %202 = alloca ptr, align 8
  %203 = getelementptr ptr, ptr %202, i32 0
  store ptr @main_kernel_1_blob_gpu.binary, ptr %203, align 8
  %204 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 0
  %205 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 1
  %206 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 2
  %207 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 3, 0
  %208 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 4, 0
  %209 = alloca %.2, align 8
  %210 = alloca ptr, i32 3, align 8
  %211 = getelementptr %.2, ptr %209, i32 0, i32 0
  store i64 128, ptr %211, align 4
  %212 = getelementptr ptr, ptr %210, i32 0
  store ptr %211, ptr %212, align 8
  %213 = getelementptr %.2, ptr %209, i32 0, i32 1
  store i64 %17, ptr %213, align 4
  %214 = getelementptr ptr, ptr %210, i32 1
  store ptr %213, ptr %214, align 8
  %215 = getelementptr %.2, ptr %209, i32 0, i32 2
  store ptr %205, ptr %215, align 8
  %216 = getelementptr ptr, ptr %210, i32 2
  store ptr %215, ptr %216, align 8
  %217 = alloca %.3, align 8
  %218 = alloca ptr, i32 14, align 8
  %219 = getelementptr %.3, ptr %217, i32 0, i32 0
  store ptr %0, ptr %219, align 8
  %220 = getelementptr ptr, ptr %218, i32 0
  store ptr %219, ptr %220, align 8
  %221 = getelementptr %.3, ptr %217, i32 0, i32 1
  store ptr %202, ptr %221, align 8
  %222 = getelementptr ptr, ptr %218, i32 1
  store ptr %221, ptr %222, align 8
  %223 = getelementptr %.3, ptr %217, i32 0, i32 2
  store i64 1, ptr %223, align 4
  %224 = getelementptr ptr, ptr %218, i32 2
  store ptr %223, ptr %224, align 8
  %225 = getelementptr %.3, ptr %217, i32 0, i32 3
  store ptr @main_kernel_1_main_kColReduction_reduce__4_1_0___8w16h_kernel_name, ptr %225, align 8
  %226 = getelementptr ptr, ptr %218, i32 3
  store ptr %225, ptr %226, align 8
  %227 = getelementptr %.3, ptr %217, i32 0, i32 4
  store i64 %201, ptr %227, align 4
  %228 = getelementptr ptr, ptr %218, i32 4
  store ptr %227, ptr %228, align 8
  %229 = getelementptr %.3, ptr %217, i32 0, i32 5
  store i64 1, ptr %229, align 4
  %230 = getelementptr ptr, ptr %218, i32 5
  store ptr %229, ptr %230, align 8
  %231 = getelementptr %.3, ptr %217, i32 0, i32 6
  store i64 1, ptr %231, align 4
  %232 = getelementptr ptr, ptr %218, i32 6
  store ptr %231, ptr %232, align 8
  %233 = getelementptr %.3, ptr %217, i32 0, i32 7
  store i64 128, ptr %233, align 4
  %234 = getelementptr ptr, ptr %218, i32 7
  store ptr %233, ptr %234, align 8
  %235 = getelementptr %.3, ptr %217, i32 0, i32 8
  store i64 1, ptr %235, align 4
  %236 = getelementptr ptr, ptr %218, i32 8
  store ptr %235, ptr %236, align 8
  %237 = getelementptr %.3, ptr %217, i32 0, i32 9
  store i64 1, ptr %237, align 4
  %238 = getelementptr ptr, ptr %218, i32 9
  store ptr %237, ptr %238, align 8
  %239 = getelementptr %.3, ptr %217, i32 0, i32 10
  store i32 0, ptr %239, align 4
  %240 = getelementptr ptr, ptr %218, i32 10
  store ptr %239, ptr %240, align 8
  %241 = getelementptr %.3, ptr %217, i32 0, i32 11
  store ptr null, ptr %241, align 8
  %242 = getelementptr ptr, ptr %218, i32 11
  store ptr %241, ptr %242, align 8
  %243 = getelementptr %.3, ptr %217, i32 0, i32 12
  store i32 3, ptr %243, align 4
  %244 = getelementptr ptr, ptr %218, i32 12
  store ptr %243, ptr %244, align 8
  %245 = getelementptr %.3, ptr %217, i32 0, i32 13
  store ptr %210, ptr %245, align 8
  %246 = getelementptr ptr, ptr %218, i32 13
  store ptr %245, ptr %246, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %218)
  %247 = add i64 -1, %13
  %248 = sdiv i64 %247, 128
  %249 = add i64 1, %248
  %250 = sub i64 0, %13
  %251 = sdiv i64 %250, 128
  %252 = sub i64 0, %251
  %253 = icmp slt i64 %13, 0
  %254 = icmp sgt i64 %13, 0
  %255 = and i1 %253, false
  %256 = and i1 %254, true
  %257 = or i1 %255, %256
  %258 = select i1 %257, i64 %249, i64 %252
  %259 = add i64 -1, %17
  %260 = sdiv i64 %259, 2
  %261 = add i64 1, %260
  %262 = sub i64 0, %17
  %263 = sdiv i64 %262, 2
  %264 = sub i64 0, %263
  %265 = icmp slt i64 %17, 0
  %266 = icmp sgt i64 %17, 0
  %267 = and i1 %265, false
  %268 = and i1 %266, true
  %269 = or i1 %267, %268
  %270 = select i1 %269, i64 %261, i64 %264
  %271 = mul i64 %258, %270
  %272 = icmp sle i64 %271, 0
  %273 = sub i64 0, %271
  %274 = sub i64 %271, 1
  %275 = select i1 %272, i64 %273, i64 %274
  %276 = sdiv i64 %275, 128
  %277 = sub i64 0, %276
  %278 = add i64 %276, 1
  %279 = select i1 %272, i64 %277, i64 %278
  %280 = alloca ptr, align 8
  %281 = getelementptr ptr, ptr %280, i32 0
  store ptr @main_kernel_2_blob_gpu.binary, ptr %281, align 8
  %282 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 0
  %283 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 1
  %284 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 2
  %285 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 0
  %286 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 1
  %287 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 2
  %288 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 4, 0
  %289 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 4, 1
  %290 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 4, 2
  %291 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 0
  %292 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 1
  %293 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 2
  %294 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 3, 0
  %295 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 4, 0
  %296 = alloca %.4, align 8
  %297 = alloca ptr, i32 7, align 8
  %298 = getelementptr %.4, ptr %296, i32 0, i32 0
  store ptr %283, ptr %298, align 8
  %299 = getelementptr ptr, ptr %297, i32 0
  store ptr %298, ptr %299, align 8
  %300 = getelementptr %.4, ptr %296, i32 0, i32 1
  store i64 %285, ptr %300, align 4
  %301 = getelementptr ptr, ptr %297, i32 1
  store ptr %300, ptr %301, align 8
  %302 = getelementptr %.4, ptr %296, i32 0, i32 2
  store i64 128, ptr %302, align 4
  %303 = getelementptr ptr, ptr %297, i32 2
  store ptr %302, ptr %303, align 8
  %304 = getelementptr %.4, ptr %296, i32 0, i32 3
  store i64 %271, ptr %304, align 4
  %305 = getelementptr ptr, ptr %297, i32 3
  store ptr %304, ptr %305, align 8
  %306 = getelementptr %.4, ptr %296, i32 0, i32 4
  store i64 %270, ptr %306, align 4
  %307 = getelementptr ptr, ptr %297, i32 4
  store ptr %306, ptr %307, align 8
  %308 = getelementptr %.4, ptr %296, i32 0, i32 5
  store i64 %17, ptr %308, align 4
  %309 = getelementptr ptr, ptr %297, i32 5
  store ptr %308, ptr %309, align 8
  %310 = getelementptr %.4, ptr %296, i32 0, i32 6
  store ptr %292, ptr %310, align 8
  %311 = getelementptr ptr, ptr %297, i32 6
  store ptr %310, ptr %311, align 8
  %312 = alloca %.5, align 8
  %313 = alloca ptr, i32 14, align 8
  %314 = getelementptr %.5, ptr %312, i32 0, i32 0
  store ptr %0, ptr %314, align 8
  %315 = getelementptr ptr, ptr %313, i32 0
  store ptr %314, ptr %315, align 8
  %316 = getelementptr %.5, ptr %312, i32 0, i32 1
  store ptr %280, ptr %316, align 8
  %317 = getelementptr ptr, ptr %313, i32 1
  store ptr %316, ptr %317, align 8
  %318 = getelementptr %.5, ptr %312, i32 0, i32 2
  store i64 1, ptr %318, align 4
  %319 = getelementptr ptr, ptr %313, i32 2
  store ptr %318, ptr %319, align 8
  %320 = getelementptr %.5, ptr %312, i32 0, i32 3
  store ptr @main_kernel_2_main_kColReduction_reduce__4_1_0___8w16h_1_kernel_name, ptr %320, align 8
  %321 = getelementptr ptr, ptr %313, i32 3
  store ptr %320, ptr %321, align 8
  %322 = getelementptr %.5, ptr %312, i32 0, i32 4
  store i64 %279, ptr %322, align 4
  %323 = getelementptr ptr, ptr %313, i32 4
  store ptr %322, ptr %323, align 8
  %324 = getelementptr %.5, ptr %312, i32 0, i32 5
  store i64 1, ptr %324, align 4
  %325 = getelementptr ptr, ptr %313, i32 5
  store ptr %324, ptr %325, align 8
  %326 = getelementptr %.5, ptr %312, i32 0, i32 6
  store i64 1, ptr %326, align 4
  %327 = getelementptr ptr, ptr %313, i32 6
  store ptr %326, ptr %327, align 8
  %328 = getelementptr %.5, ptr %312, i32 0, i32 7
  store i64 128, ptr %328, align 4
  %329 = getelementptr ptr, ptr %313, i32 7
  store ptr %328, ptr %329, align 8
  %330 = getelementptr %.5, ptr %312, i32 0, i32 8
  store i64 1, ptr %330, align 4
  %331 = getelementptr ptr, ptr %313, i32 8
  store ptr %330, ptr %331, align 8
  %332 = getelementptr %.5, ptr %312, i32 0, i32 9
  store i64 1, ptr %332, align 4
  %333 = getelementptr ptr, ptr %313, i32 9
  store ptr %332, ptr %333, align 8
  %334 = getelementptr %.5, ptr %312, i32 0, i32 10
  store i32 0, ptr %334, align 4
  %335 = getelementptr ptr, ptr %313, i32 10
  store ptr %334, ptr %335, align 8
  %336 = getelementptr %.5, ptr %312, i32 0, i32 11
  store ptr null, ptr %336, align 8
  %337 = getelementptr ptr, ptr %313, i32 11
  store ptr %336, ptr %337, align 8
  %338 = getelementptr %.5, ptr %312, i32 0, i32 12
  store i32 7, ptr %338, align 4
  %339 = getelementptr ptr, ptr %313, i32 12
  store ptr %338, ptr %339, align 8
  %340 = getelementptr %.5, ptr %312, i32 0, i32 13
  store ptr %297, ptr %340, align 8
  %341 = getelementptr ptr, ptr %313, i32 13
  store ptr %340, ptr %341, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %313)
  br label %342

342:                                              ; preds = %44, %193
  %343 = alloca i64, i64 ptrtoint (ptr getelementptr (i64, ptr null, i64 2) to i64), align 8
  %344 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } undef, ptr %343, 0
  %345 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %344, ptr %343, 1
  %346 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %345, i64 0, 2
  %347 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %346, i64 2, 3, 0
  %348 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %347, i64 1, 4, 0
  %349 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %348, 1
  %350 = getelementptr i64, ptr %349, i64 0
  store i64 %12, ptr %350, align 4
  %351 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %348, 1
  %352 = getelementptr i64, ptr %351, i64 1
  store i64 %11, ptr %352, align 4
  %353 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 0
  %354 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 1
  %355 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 2
  %356 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 3, 0
  %357 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 4, 0
  %358 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %348, 0
  %359 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %348, 1
  %360 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %348, 2
  %361 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %348, 3, 0
  %362 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %348, 4, 0
  %363 = alloca %.6, align 8
  %364 = alloca ptr, i32 13, align 8
  %365 = getelementptr %.6, ptr %363, i32 0, i32 0
  store ptr %0, ptr %365, align 8
  %366 = getelementptr ptr, ptr %364, i32 0
  store ptr %365, ptr %366, align 8
  %367 = getelementptr %.6, ptr %363, i32 0, i32 1
  store ptr null, ptr %367, align 8
  %368 = getelementptr ptr, ptr %364, i32 1
  store ptr %367, ptr %368, align 8
  %369 = getelementptr %.6, ptr %363, i32 0, i32 2
  store ptr %353, ptr %369, align 8
  %370 = getelementptr ptr, ptr %364, i32 2
  store ptr %369, ptr %370, align 8
  %371 = getelementptr %.6, ptr %363, i32 0, i32 3
  store ptr %354, ptr %371, align 8
  %372 = getelementptr ptr, ptr %364, i32 3
  store ptr %371, ptr %372, align 8
  %373 = getelementptr %.6, ptr %363, i32 0, i32 4
  store i64 %355, ptr %373, align 4
  %374 = getelementptr ptr, ptr %364, i32 4
  store ptr %373, ptr %374, align 8
  %375 = getelementptr %.6, ptr %363, i32 0, i32 5
  store i64 %356, ptr %375, align 4
  %376 = getelementptr ptr, ptr %364, i32 5
  store ptr %375, ptr %376, align 8
  %377 = getelementptr %.6, ptr %363, i32 0, i32 6
  store i64 %357, ptr %377, align 4
  %378 = getelementptr ptr, ptr %364, i32 6
  store ptr %377, ptr %378, align 8
  %379 = getelementptr %.6, ptr %363, i32 0, i32 7
  store ptr %358, ptr %379, align 8
  %380 = getelementptr ptr, ptr %364, i32 7
  store ptr %379, ptr %380, align 8
  %381 = getelementptr %.6, ptr %363, i32 0, i32 8
  store ptr %359, ptr %381, align 8
  %382 = getelementptr ptr, ptr %364, i32 8
  store ptr %381, ptr %382, align 8
  %383 = getelementptr %.6, ptr %363, i32 0, i32 9
  store i64 %360, ptr %383, align 4
  %384 = getelementptr ptr, ptr %364, i32 9
  store ptr %383, ptr %384, align 8
  %385 = getelementptr %.6, ptr %363, i32 0, i32 10
  store i64 %361, ptr %385, align 4
  %386 = getelementptr ptr, ptr %364, i32 10
  store ptr %385, ptr %386, align 8
  %387 = getelementptr %.6, ptr %363, i32 0, i32 11
  store i64 %362, ptr %387, align 4
  %388 = getelementptr ptr, ptr %364, i32 11
  store ptr %387, ptr %388, align 8
  %389 = getelementptr %.6, ptr %363, i32 0, i32 12
  %390 = getelementptr ptr, ptr %364, i32 12
  store ptr %389, ptr %390, align 8
  call void @disc_ral_call(ptr %0, ptr @inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32, ptr %364)
  %391 = load { ptr, ptr, i64, [2 x i64], [2 x i64] }, ptr %389, align 8
  %392 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %391, 0
  %393 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %391, 1
  %394 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } undef, ptr %392, 0
  %395 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %394, ptr %393, 1
  %396 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %395, i64 0, 2
  %397 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %396, i64 %12, 3, 0
  %398 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %397, i64 %11, 4, 0
  %399 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %398, i64 %11, 3, 1
  %400 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %399, i64 1, 4, 1
  %401 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %33, 0
  %402 = alloca %.7, align 8
  %403 = alloca ptr, i32 2, align 8
  %404 = getelementptr %.7, ptr %402, i32 0, i32 0
  store ptr %0, ptr %404, align 8
  %405 = getelementptr ptr, ptr %403, i32 0
  store ptr %404, ptr %405, align 8
  %406 = getelementptr %.7, ptr %402, i32 0, i32 1
  store ptr %401, ptr %406, align 8
  %407 = getelementptr ptr, ptr %403, i32 1
  store ptr %406, ptr %407, align 8
  call void @disc_ral_call(ptr %0, ptr @dealloc___gpu___pvoid_pvoid___void, ptr %403)
  %408 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %400, 0
  %409 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %400, 1
  %410 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %400, 2
  %411 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %400, 3, 0
  %412 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %400, 3, 1
  %413 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %400, 4, 0
  %414 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %400, 4, 1
  %415 = alloca %.8, align 8
  %416 = alloca ptr, i32 9, align 8
  %417 = getelementptr %.8, ptr %415, i32 0, i32 0
  store ptr %0, ptr %417, align 8
  %418 = getelementptr ptr, ptr %416, i32 0
  store ptr %417, ptr %418, align 8
  %419 = getelementptr %.8, ptr %415, i32 0, i32 1
  store i64 0, ptr %419, align 4
  %420 = getelementptr ptr, ptr %416, i32 1
  store ptr %419, ptr %420, align 8
  %421 = getelementptr %.8, ptr %415, i32 0, i32 2
  store ptr %408, ptr %421, align 8
  %422 = getelementptr ptr, ptr %416, i32 2
  store ptr %421, ptr %422, align 8
  %423 = getelementptr %.8, ptr %415, i32 0, i32 3
  store ptr %409, ptr %423, align 8
  %424 = getelementptr ptr, ptr %416, i32 3
  store ptr %423, ptr %424, align 8
  %425 = getelementptr %.8, ptr %415, i32 0, i32 4
  store i64 %410, ptr %425, align 4
  %426 = getelementptr ptr, ptr %416, i32 4
  store ptr %425, ptr %426, align 8
  %427 = getelementptr %.8, ptr %415, i32 0, i32 5
  store i64 %411, ptr %427, align 4
  %428 = getelementptr ptr, ptr %416, i32 5
  store ptr %427, ptr %428, align 8
  %429 = getelementptr %.8, ptr %415, i32 0, i32 6
  store i64 %412, ptr %429, align 4
  %430 = getelementptr ptr, ptr %416, i32 6
  store ptr %429, ptr %430, align 8
  %431 = getelementptr %.8, ptr %415, i32 0, i32 7
  store i64 %413, ptr %431, align 4
  %432 = getelementptr ptr, ptr %416, i32 7
  store ptr %431, ptr %432, align 8
  %433 = getelementptr %.8, ptr %415, i32 0, i32 8
  store i64 %414, ptr %433, align 4
  %434 = getelementptr ptr, ptr %416, i32 8
  store ptr %433, ptr %434, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_send_output___cpu___pvoid_i64_m2df32___void, ptr %416)
  ret void
}

host default target triple: x86_64-unknown-linux-gnu
host cpu name: icelake-server
host cpu features: -avx512pf,-tsxldtrk,+cx16,+sahf,-tbm,+avx512ifma,+sha,+crc32,-fma4,+vpclmulqdq,+prfchw,+bmi2,-cldemote,+fsgsbase,-avx512bf16,-amx-tile,-raoint,-uintr,+gfni,+popcnt,-ptwrite,+aes,+avx512bitalg,-movdiri,-widekl,+xsaves,-avx512er,-avxvnni,-avx512fp16,+avx512vnni,-amx-bf16,-avxvnniint8,+avx512vpopcntdq,-pconfig,+clwb,-cmpccxadd,+avx512f,+xsavec,-clzero,-pku,-amx-fp16,+mmx,-lwp,+rdpid,-xop,+rdseed,-waitpkg,-prefetchi,-kl,-movdir64b,-sse4a,+avx512bw,-avxneconvert,+clflushopt,+xsave,+avx512vbmi2,+64bit,+avx512vl,-serialize,-hreset,+invpcid,+avx512cd,+avx,+vaes,-amx-int8,+cx8,+fma,-rtm,+bmi,-enqcmd,+rdrnd,-mwaitx,+sse4.1,+sse4.2,+avx2,+fxsr,+wbnoinvd,+sse,+lzcnt,+pclmul,-rdpru,-avxifma,+f16c,+ssse3,-sgx,-prefetchwt1,+cmov,+avx512vbmi,-shstk,+movbe,-avx512vp2intersect,+xsaveopt,+avx512dq,+sse2,+adx,+sse3
after optimize llvm module:
; ModuleID = 'LLVMDialectModule'
source_filename = "LLVMDialectModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%0 = type { ptr, i64, { ptr, ptr, i64, [3 x i64], [3 x i64] } }
%.1 = type { ptr, i64, ptr }
%.9 = type { i64, i64, ptr }
%.10 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.11 = type { ptr, i64, i64, i64, i64, i64, ptr }
%.12 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.2 = type { i64, i64, ptr }
%.3 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.4 = type { ptr, i64, i64, i64, i64, i64, ptr }
%.5 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.6 = type { ptr, ptr, ptr, ptr, i64, i64, i64, ptr, ptr, i64, i64, i64, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.7 = type { ptr, ptr }
%.8 = type { ptr, i64, ptr, ptr, i64, i64, i64, i64, i64 }

@main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name = internal constant [43 x i8] c"main_kColReduction_reduce__4_1_0___8w32h_1\00"
@main_kernel_0_blob_gpu.binary = internal constant [4464 x i8] c"P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w32h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"
@main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name = internal constant [41 x i8] c"main_kColReduction_reduce__4_1_0___8w32h\00"
@main_kernel_blob_gpu.binary = internal constant [1096 x i8] c"P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w32h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"
@ral_send_output___cpu___pvoid_i64_m2df32___void = internal constant [48 x i8] c"ral_send_output___cpu___pvoid_i64_m2df32___void\00"
@dealloc___gpu___pvoid_pvoid___void = internal constant [35 x i8] c"dealloc___gpu___pvoid_pvoid___void\00"
@inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32 = internal constant [51 x i8] c"inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32\00"
@main_kernel_2_main_kColReduction_reduce__4_1_0___8w16h_1_kernel_name = internal constant [43 x i8] c"main_kColReduction_reduce__4_1_0___8w16h_1\00"
@main_kernel_2_blob_gpu.binary = internal constant [4464 x i8] c"P\EDU\BA\01\00\10\00`\11\00\00\00\00\00\00\02\00\01\01@\00\00\00 \11\00\00\00\00\00\00\19\11\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h(\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0'\00\01\00\11%\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\03e__4_1_0___8w16h_1:\00\0F4\00\1Doshared6\00\1AOrela\A0\00\1F?rel\D5\00\22\9Fconstant09\00\1A\B2debug_frame{\00\09\11\00!nv\14\00\11aE\00\0F\9E\01 \0F\8A\00\17\0F\C9\01\FF.o_param\D0\01\1C\0F\01\00\06\8C]\00\00\00\03\00\0A\00\01\00 c\01\18\00,\09\00\01\00\11\A3\18\00,\04\00\01\00\11\C1\18\00,\07\00\01\00g2\00\00\00\12\10`\00\11\1D\06\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03!\F0\1C\07\00 \00\04\9B\00R\04\14\00\00\00E\002\04\F8\06\18\00\80/\08\00\05\00\00\00 \0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\D0\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01(\00\03\19(\00\04\17\0C$\00\10\06N\00%\F0!\10\00u\05\00\18\00\00\F0\11\10\009\04\00\14\10\009\03\00\10\10\009\02\00\0C\10\009\01\00\08\10\00\01\01\00\F2\0A\F0!\00\03\1B\FF\00\04\1C\0C\00P\00\00\00p\1B\00\00@\1C\00\00\04\1E\84\01#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08\84\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00x\01/\05\00\01\00\FF\80@$v\01\FF7\04\B6\FF\00\8E\07\00\C4\0F\00\19y\03\F0\07b(\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00[\D1\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00\\\00\00p`\F0\03\00\DA\0F\00Mk\04\92\80\03\00\EA\0F\00\13z\07\9D\04\00\01\00\D2\E2\0F\00\B9z\06\00\00F\00\00\00\0A\10\00\10E`\00\13\1A0\00b\E4\0F\00\06s\00~\04\A2\94 \00\000\0E\00\08s\00\01\00\10\10\80\00\F3\08\1E\00\10x\04\00\FE\FF\FF\0F\FF\E0\FF\07\00\CC\1F\00\05s\05\00\04`\03\A3\00d\00\00$r\04\FF\FF\00\D0\00a\E4\1F\00$r\02\10\00\C0\05\0A\8E\07\00\C8/\00$r\09\02`\00\10\FF\C0\00s\E2\0F\00\13r\02\00\F2\00\A1\00\00\C6\0F\00'r\05\05\09\F4\03@\8E\07\00\CC\10\004\0A\05\02P\00a\C8\0F\00$r\00P\00%\0A\0A\10\00\12\07\B7\03\00p\00t\0F\00$t\02\FF\010\00C\C6\0F\00\0C \001p@\F2\E0\00\F0\03\12z\02\02\00^\00\00\FF\C0\8E\07\00\D6\0F\00$\98t\03B\00\00\07\0A\90\00A\10\98\0A\0A@\00!\E0\FFP\00@\0Cz\00\FF@\01\22pR@\00\22\0Cr \01\01p\01\93\E2\0F\00$v\07\FF\00Zp\00\10\E2`\00 \00\030\00\22\FF<\A0\00\000\00\00\B0\00\AApb\F4\03\00\CE\0F\00\10\08`\00P\12x\FF\07\7F\10\00\22\C0\80\D0\00&\A2\0A\E0\00\00P\00!\9A\0A\80\00 \FF3\F0\01\83\0F\00$z\06\0A\00]@\01\84\E4\0F\04$x\05\0A\80\F0\00\00\00\010x\00\03`\002\06\0A\8EP\00\12x\FC\03\22\FF\00@\00\00\C0\01\16\02\80\00s\04\0Cz\00\00\00^\A0\00\02\F0\00\12\04\10\00\02\F0\00W\10x\04\05\80\B0\00@\0Cx\00\02`\00EpT\F2\040\00pZ\00\00p\16p\04\C0\02W\10x\02\00\010\001\1Cx\00\01\00@p\10\F0\00\A0\02fG\89\00\00p\14\A0\022$v\04\E0\00\03@\01E\10x\08\05@\00\98\E2\0F\04$v\09\FF\00^ \006\1A\05\02 \00s\00$x\04\04\02\00 \00\01\00\01*\03\03\10\00 \07\09\C0\00$\04\0A\10\00F\0B\06\02\00p\03@$r\11\0A\D0\01\14\03@\020z\08\08p\00\14\0B0\00Xt\04\FF\04\00\80\009\19\11\01\80\00\11\0Fp\01\13\08@\00\A4%v\10\11\00X\00\00\04\020\004\1C\05\030\00\10\C6`\00(\1A\1A`\00G%v\18\190\00X\08\10x\0D\0F`\00A\81y\06\10z\07\A1\19\1E\0C\00\A4\00\00$x\13p\00\13\1Ap\00E\81y\18\18 \00u\E2\02\00%v\0E\0FP\00\00\00\025z\1C\1Cp\00\01\90\00(\0B\13`\00H%v\0C\0D\80\00E\81y\17\0EP\00 f\09\D0\00\16\0B \00f\1F\00\81y\16\0C \00h\01\00$x\05\09 \016\81y\14\B0\00\10b \00\11\0B\B0\00\22\1C\02p\01E%v\12\13P\00\10\C6\90\00&\19\0B\90\00Q/\04$r\0A\90\01$\05\02P\00&\15\12P\00\10\03\E0\00\17\0B\E0\00\14\01`\00$\0A\02P\01\16\0CP\01!\C8\1F\00\02\14\04\A0\01\1C\E2p\00\00\C0\014\08\09\04P\01\01p\00\16\13\00\01a\22!\00$x\1A`\00\13\07\B0\006\81y\12\00\01\10\22\90\00%\10\1Ap\00u\E2\0F\04\10x\1B\1A`\00\10\C6\90\00\19\0E\90\006%v\0C\C0\00f\E4/\08\81y\0B0\01\10$0\01\19\19P\029\81y\0Dp\00T$x\09\09\04P\01\01\A0\03%\1D\19p\00w\E2\0F\04%v\10\19\B0\01F\08\81y\0C\D0\00z(!\00\81y\19\10\C0\00*\0E\1B\A0\00&\10\1D@\00\00\A0\00\16\1A@\00\10&\A0\00\11\1D\A0\00\15\090\01\16\1BP\00\11&P\00\07@\00e\1F\04\10x\11\1D\A0\00x\C8/\00\81y\1C\0E\F0\006%v\0E0\03\10\CA`\02\16\1D \00\10\22\A0\01(\09\05p\00\F0\00\0Bx\00\06\00\00\80\FF\00\C2\F0\03\00\E4O\10\00\12\18\10\00\00\B0\04R\8F\00\08x\06 \00\00\E5\03b\E4\0F\00\08x\18 \00!\02\80\10\00\90\0Br\00\06\17\00\00@\00\C0\05\81\C4\0F\02\0Br\00\18\16\10\00\01\F0\04B\08\08r\06 \00\13\00@\00\22r\11 \00Q\00\80\00\00\C8@\00&\11\140\00\10\0CP\00\14\15P\00\84\E4\0F\0C\08r\11\11\140\00\01@\004\06\06\15P\00\02@\00&\06\130\00\10\0DP\00\17\12P\00\000\00\1A\13\80\00'\11\12P\00\00@\00\14\0D@\00\12\C8`\00\17\0D0\00\00P\00\14\0CP\00\12\C8@\00\1B\0C@\00\1B\0B@\00\1B\0B@\00\19\1A@\00;\1A\11\1A@\00\16\19\C0\00\00\10\00&\1A\1B\C0\00g\00\08r\19\06\19P\00Z\08r\06\1A\1B@\00$\19\1C@\00\01\80\03%\16\05`\03\00\90\05Gt\0B\FFxP\04T\08r\0C\19\1CP\00\010\00'\15\05 \03U\04$x\07\05\00\04\11\E2`\00)\06\1D\C0\004\06\06\1D\80\00\00`\00&x\0D\D0\03\10\C8\A0\03*\1A\0D\C0\03&\13\0D\B0\02\00\E0\02%\17\1A\90\02*\A2\00\C0\04\10\CC \00(\12\12\80\05\04\10\06\15\16`\00\16\18\90\05\10\CA0\00\16\0D\B0\05ib\09\00\10x\11\F0\05\04`\03\15\15\E0\00\16\1Bp\03*\E4\1F`\06+\C8\0Fp\03h\0F\0C\10x\1D\1DP\006\81y\0A\A0\03 h\01\A0\05\18\0EP\05\04@\01\16\07 \05\17\1B@\00K\05%v\10 \04*\0E\1D\C0\04\1B\10\C0\04\16\1B`\01\1C\E4P\05\1A\03\F0\06\01\A0\08%\08\050\01\01\B0\00\16\11 \01*\22\11\A0\04 \E2/`\05\06\A0\00\01\A0\01\16\16`\00\1B$\D0\04\10\CAp\04(\18\0EP\00\04\A0\00\16\08@\01\1A\1B\B0\04\0C`\00\17\19@\00\15\01\80\02\03\A0\01\0D@\05\04`\00\13\15\F0\01J\10x\1D\1B\E0\01\0B\D0\045r\00\0C\90\04 \C8O\F0\02'\0C\17@\03\09\90\07!\A2\00\E0\02\15\120\00\11\8F\E0\02\02 \04\02 \03\0A\00\01\00P\05\16\12@\00*\E4\00\C0\01\10\CC \00\16\0E \00\11\E2`\00&\0C\0D\A0\03\19\02\80\02\10\C6P\039\1D\0C\0Dp\00*\0C\1B\10\03(\0C\0C`\02\00\B0\00\14\0AP\00\03\90\03\17\0A\E0\00L\0Br\00\1DP\05\08 \05W\08r\1A\1D\14@\04Z\08r\14\06\13@\00$\1A\10@\00\11\C4\10\00&\14\11\C0\00H\08$x\0A\E0\02d\04\08r\10\1A\10P\00\01\90\01\16\13P\04\01p\047\11\14\11\E0\00\04\90\03\04`\04\09 \02\01\D0\01\11\1C \00\13\13 \00E\0Br\00\10P\06\01 \01\16\06p\01\01`\04\07\A0\03\02\B0\00&\11\18\B0\00\00\90\04\17\1B0\00g\00\08r\08\10\16\B0\000\81y\0F\E1\06\05\D0\02W\08r\18\11\18\B0\00E%v\10\1C@\00\10\E4\D0\09\16\0D\C0\04-$#\C0\02\09\C0\03+\22\03\B0\00\10\1F\A0\00\15\08\F0\05\11\C6\B0\05\06\E0\02\02\10\01\16\1C\10\01\00p\03*\14\060\03\19\11\F0\02W\08r\19\08\19\C0\016%v\08\F0\00%\C8\0Fp\09\13\11\A0\00G%v\06\16\90\00\00\E0\04\16\16p\00\00\C0\00%\08\08p\00\10(\E0\04*\1B\06\10\04*\06\1A\10\04*\09\06\10\04\16\0A@\06-\E4\0F\00\01J\10x\1D\1A\10\04*\16\06\C0\08*\06\1D\00\04(\1D\03P\00\04`\02\07 \02\1A\18\F0\037\17\18\17\10\01\00 \07\0A\E0\037\19\19\12 \00K\81y\12\06\10\04$\17\0E0\00\0Cp\02\89\C6\1F\00\08r\0E\17\0E@\00(\17\06\F0\03\09\90\02/\CA\0F\00\02\01%\19\0C\90\00h\0F\02\81y\18\06\E0\0BW\08r\1A\19\0C\80\026$x\0C\10\03\01`\05*\06\0C\90\04\19\19@\00\00\C0\03\16\0F\00\04f\01\0Br\00\0E\0D\00\04d\00\08r\0F\1A\0F\00\03\01\10\009\0D\0E\0Dp\00\07\D0\02\02`\01\15\0F\10\04%\E2\0F\80\02\16\11 \00&\0D\14\00\0Ag\00\08r\10\0F\10`\03\04\C0\07\15\15\B0\029\0D\0D\14p\00(\0E\03P\00E\10x\1D\0C@\01\02\80\01\1B\0F@\01&\0D\08\D0\00F\08\10x\14\F0\07\02\F0\01&\10\1B\B0\00\1A\08\E0\03\00`\017\08\0D\08\80\00F%v\0C\0E`\00\00\A0\007\1B\10\1B\A0\0AO\81y\10\0C\D0\03\08[\08\10x\0E\0E\80\00&\1B\09\80\00W\0C%v\0C\14\E0\07\0D\D0\03Y\08r\1A\1B\090\01\09@\03\1C\04\F0\02\09\10\06\02\C0\0C\06 \03\02\90\01$\08\16 \01\02@\01\1A\0E\C0\029\1D\08\16\80\01*\16\03`\00*\0D\06\B0\0D\0A\E0\04J%v\06\09\80\02\1F\0E\A0\04\02\07 \02)\1D\12\A0\037\12\1D\12@\03\00\B0\02\14\170\01\01\A0\037\1A\1A\17\A0\02E\10x\17\09`\01\01\D0\00+\08\16\00\06\1A\16 \0E%\06\17 \00\10\E4\A0\00+\17\08\E0\03&\12\18\80\05\19\02\E0\04 \E2\02\A0\00)\12\18 \01\16\08\C0\02\01\B0\09*\06\08@\09*\18\08\80\00\17\08 \02)\0F\08\E0\04\01\E0\0F\16\1D\F0\02\1B\E4p\05\01\90\0F+\06\18\F0\02$\1A\19 \01\01\10\01\19\1C\F0\06\0E@\047\19\1A\19P\02\09\B0\02\01\B0\01\16\1A0\00\11dp\05\1A\1C \00\1C\1CP\04&\12\14\B0\04j\01\08r\1D\12\14\C0\01'\19\0F\90\03\00\F0\01\19\0C\00\0E7\0F\19\0F0\00W\08r\0C\1D\0C\E0\01\06`\04\02@\04\060\09\04\C0\0D:\0F\0F\10@\00)\0C\0D \020\0B\0B\EC\81\19\00\10\01\03P\00\19\0E \097\0E\0F\0E@\00A\0Cr\00\0B@\14!R\F6 \03\09\F0\0C;\E4\1F\04\F0\02\14\04`\0A\02\D0\02\11/\A0\00\19\1B\B0\02:\1B\0C\1B\D0\00*\0E\17\90\06'\0E\17\80\00\00 \04\15\08@\00z\0F\02\08r\1B\1B\08@\00\15\17\C0\03\030\00\16\18\10\01\00P\00'\17\16P\00\00@\00\17\18\F0\01\04\00\0E\16\13\80\03)\17\1A\10\01;\0C\17\1A\90\00\16\1C\90\00\00P\0A'\1B\1CP\00`G9\00\00\10\F2a\01\11\83`\14fGy\00\00\10\03p\14@\B9z\04\00p\14\01^\19b\E2\0F\00\11x\10\90\15\128\80\00@\99x\04\04\10\00C?\06\00\08p\01\060\14\01@\17\11\050\15\04@\00W$r\05\FF\FF \00\C1\91r\04\05\04\00\00\80?8\8E\0F \00Sz\10\10\00^`\16\01P\14 \06\FF\90\10\010\00\01\F0\0E\16\0C\10\00\00 \00B|\04\0A\04 \17\11\0F \00Dx\07\0A\80\10\13\12\E4\E0\03#\02\00\00\03\01\F0\01\11\12\10\00\22\10\02\80\00A\0Cz\00\07\90\15\11b\90\01U\04\10x\07\07\80\03\02\B0\15\02\F0\15!fv\10\0FB\0Cz\00\02\10\00\11p`\01\06@\00\02`\01\060\00\14\F8 \00\030\00\11\F2\B0\176$\B4\09 \15\00\E0\02&\88\0E`\04\00\C0\15)\84\0F \001%\B6\08\90\04\14\09 \08!\86\0E\F0\05$\0F\02\80\17(\14\12@\006\81\B9\09p\04i\A4\0E\00$\C4\13P\006$\94\15\10\00\00\10\06'\89\0F\D0\0C\87\0E\00%\C6\12\12\00X\90\08!\96\14\E0\06\030\03F\00\81\C9\13\C0\0Fu(\0F\00\81\99\15\14\10\00\10b\B0\03\1A\05p\16&v\07\90\16\01\B0\0A%\10\07\80\01\01\90\01%\04\07\A0\01\00\D0\022\B2\00\0C`\07\12\FA`\03\22\B2\0C\10\003\00\80\02P\17\01`\171pR\FA0\03B\0B\82\00\06\A0\04\12\FC\B0\03\22\82\06\10\00\22\00\00 \007\C2\00\0C \0D4\01\0B\92\80\12\10\F6\10\00g\02\08\C2\0C\0C\130\03$\08\92\80\12 \80\01\90\00fGY\00\00\A0\FD \03\14A`\1A\03 \03\00\10\1A\14\D0\10\00\17\E2\F0\01!b\F2\10\00TG)\00\00\A0 \00\10\CE\C0\02\16\03\80\01\00`\01Sv\02\00\00`P\17\01\F0\10(\04\02\C0\05A\0Br\00\04\96\1D @\F0P\00(\0EF\80\00\10\E6\D0\03\12\05 \00\00\01\00p\CC\0F\00\A9s\05\02`\00@\05\E1\1E\00\00\02Q\0Cr\00\05\040\01\00@\00\15Op\1A\10\05\80\00\9F\D8\0F\00G\09\00\00\90\FF\E0\00\079M\19\00\10\00\0A\C0\00\1F\1F\C0\00\03\16\04`\06\00 \01&\80\000\1B\00\D0\00\1F\06\D0\00\0C+\06\00\D0\00\1F\04\D0\008\0B\10\00\00\F0\04\14\F00\00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\11\01\19\03\0E\01\00\02\01\03]\00\00\9E\01\000\00\08\01\00\1F\0B@\00\04\13\DE)\00\1F\D0@\00\0C\10\13|\1C\1E\00\01\00\13\B0U\00\11\90\06\00\02$\00\13\047\06\00\01\00\22\18\00\01\00.q\01T\00\00\01\001@\04\00\01\00/p\00\80\00\0B\1F)'\00\03#\00\B0@\00\04\E8!\04\E4\00*\04\00\01\00\1Fc@\00\04\13\E0)\00&\A8\00@\00\1F\0A@\00\00!\8F\01D\01\0D@\00\13\88m *\D8\00\01\00\1B\08\08\00?~\01\00\1E#\00F\00\00`\06w\1E\04\80\00\17\048\00\04\18\00\138@\01\0C\84\01\13p@\00\17\881\01\0F\C0\00\01\132T\01+\06\00\01\00\1A\08h#\11\03\94\03J\00 \80\00\01\00\12\06\18\00\15\00\A8'\0B\01\00\1B\A8\08\00\04W\00\13\018\00\04\A8\00\0C\01\00*\90\1E\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00\00"
@ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void = internal constant [101 x i8] c"ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00"
@main_kernel_1_main_kColReduction_reduce__4_1_0___8w16h_kernel_name = internal constant [41 x i8] c"main_kColReduction_reduce__4_1_0___8w16h\00"
@main_kernel_1_blob_gpu.binary = internal constant [1096 x i8] c"P\EDU\BA\01\00\10\008\04\00\00\00\00\00\00\02\00\01\01@\00\00\00\F8\03\00\00\00\00\00\00\F8\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00\E8\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\00!@\0B\07\001\00\80\08\07\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\F5\01e__4_1_0___8w16h8\00\0F2\00\1Boshared4\00\1B\9Fconstant07\00\18\FA\01debug_frame\00.rel\11\00!nv\14\00\11aC\00\0F+\01 \0F\88\00\15\0FT\01\BAo_param[\01\1C\0F\01\00\06\8C[\00\00\00\03\00\0A\00\01\00\11\F0\18\00,\09\00\01\00 .\01\18\00,\04\00\01\00\11L\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00p/\08\00\05\00\00\00\A7\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\E8\03\F3\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C\0C\04U\08\00\00\F0!\10\00\10\01\18\01%\F0\11\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00s\02\02\08\10\0A/\22\9B\00\00\07\00\03\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\000\01/\05\00\01\00\FF\B0A\02z\01\00\1F\04\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%\8B\02Q\0E\00\19y\03\0F\00\F5\1A\00!\00\00\00$\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cz\00\02\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\A0\80\03\00\EA\0F\005t\03\FF\B3\03\10\FF\C0\03P\E2\0F\00\02x6\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\94\D0\0F\00%v\02\02\00Z`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F09\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=+\01\000\00\08\01\00\1F\0B@\00\04\13k)\00\1F[@\00\0C\13\13\0C\04\0C\01\00\13\C8\15\00&\90\000\04#\04\00\85\04\00\F6\04\12\00\01\00\1F\FET\00\00\00\01\00\13X\95\00/p\00\80\00\0B\1F)'\00\03#\00\C8@\00\04P\06\04\E4\00*\04\00\01\00\1Fa@\00\04\13\F81\00&\\\00@\00\1F\0A@\00\00!\1C\01D\01\0D@\00\13X)\00*\D8\00\01\00\1B\08\08\00?\0B\01\00\86\07\00Q\00\000\05\00\01\00&\10\00\80\00\17\048\00\04\18\00\13\C7\14\01\0C\84\01*@\058\07\1F\00\C0\00\04\132@\00+\06\00\01\00\1A\07\D0\07\12\03\F0\05:\08\80\00\01\00\13\06\08\06\04(\0B\0C\01\00*\A8\00\08\00\04\F8\00\14\018\00/\05\00\01\00\029@\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"
@alloc___gpu___pvoid_i64___pvoid = internal constant [32 x i8] c"alloc___gpu___pvoid_i64___pvoid\00"
@ral_recv_input___cpu___pvoid_i64___m3df32 = internal constant [42 x i8] c"ral_recv_input___cpu___pvoid_i64___m3df32\00"

define void @disc_ral_call(ptr nocapture readonly %0, ptr %1, ptr %2) local_unnamed_addr {
entry:
  %3 = load ptr, ptr %0, align 8
  %4 = getelementptr ptr, ptr %0, i64 1
  %5 = load ptr, ptr %4, align 8
  %6 = load ptr, ptr %2, align 8
  store ptr %3, ptr %6, align 8
  tail call void %5(ptr %3, ptr %1, ptr nonnull %2)
  ret void
}

define void @main(ptr %0) local_unnamed_addr {
  %2 = alloca %0, align 8
  %3 = alloca [3 x ptr], align 8
  store ptr %2, ptr %3, align 8
  %4 = getelementptr inbounds %0, ptr %2, i64 0, i32 1
  store i64 0, ptr %4, align 8
  %5 = getelementptr inbounds ptr, ptr %3, i64 1
  store ptr %4, ptr %5, align 8
  %6 = getelementptr inbounds %0, ptr %2, i64 0, i32 2
  %7 = getelementptr inbounds ptr, ptr %3, i64 2
  store ptr %6, ptr %7, align 8
  %8 = load ptr, ptr %0, align 8
  %9 = getelementptr ptr, ptr %0, i64 1
  %10 = load ptr, ptr %9, align 8
  store ptr %8, ptr %2, align 8
  call void %10(ptr %8, ptr nonnull @ral_recv_input___cpu___pvoid_i64___m3df32, ptr nonnull %3)
  %.fca.1.gep = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 1
  %.fca.1.load = load ptr, ptr %.fca.1.gep, align 8
  %.fca.3.0.gep = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 3
  %.fca.3.0.load = load i64, ptr %.fca.3.0.gep, align 8
  %.fca.3.1.gep = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 3, i64 1
  %.fca.3.1.load = load i64, ptr %.fca.3.1.gep, align 8
  %.fca.3.2.gep = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 3, i64 2
  %.fca.3.2.load = load i64, ptr %.fca.3.2.gep, align 8
  %11 = mul i64 %.fca.3.2.load, %.fca.3.1.load
  %sext = shl i64 %11, 32
  %12 = ashr exact i64 %sext, 32
  %.idx = ashr exact i64 %sext, 30
  %13 = alloca %.1, align 8
  %14 = alloca [3 x ptr], align 8
  store ptr %13, ptr %14, align 8
  %15 = getelementptr inbounds %.1, ptr %13, i64 0, i32 1
  store i64 %.idx, ptr %15, align 8
  %16 = getelementptr inbounds ptr, ptr %14, i64 1
  store ptr %15, ptr %16, align 8
  %17 = getelementptr inbounds %.1, ptr %13, i64 0, i32 2
  %18 = getelementptr inbounds ptr, ptr %14, i64 2
  store ptr %17, ptr %18, align 8
  %19 = load ptr, ptr %0, align 8
  %20 = load ptr, ptr %9, align 8
  store ptr %19, ptr %13, align 8
  call void %20(ptr %19, ptr nonnull @alloc___gpu___pvoid_i64___pvoid, ptr nonnull %14)
  %21 = load ptr, ptr %17, align 8
  %22 = mul i64 %12, %.fca.3.0.load
  %23 = add i64 %22, -1
  %24 = lshr i64 %23, 8
  %25 = add nuw nsw i64 %24, 1
  %26 = sub i64 0, %22
  %.neg = sdiv i64 %26, -256
  %27 = icmp sgt i64 %22, 0
  %28 = select i1 %27, i64 %25, i64 %.neg
  %29 = icmp sgt i64 %28, 108
  %30 = icmp slt i64 %sext, 4294967296
  %31 = sub nsw i64 0, %12
  %32 = add nsw i64 %12, -1
  %33 = select i1 %30, i64 %31, i64 %32
  %34 = alloca ptr, align 8
  %35 = alloca [3 x ptr], align 8
  %36 = getelementptr inbounds ptr, ptr %35, i64 1
  %37 = getelementptr inbounds ptr, ptr %35, i64 2
  %38 = alloca [14 x ptr], align 8
  %39 = getelementptr inbounds ptr, ptr %38, i64 1
  br i1 %29, label %40, label %140

40:                                               ; preds = %1
  %41 = sdiv i64 %33, 256
  %42 = sub nsw i64 0, %41
  %43 = add nsw i64 %41, 1
  %44 = select i1 %30, i64 %42, i64 %43
  store ptr @main_kernel_blob_gpu.binary, ptr %34, align 8
  %45 = alloca %.9, align 8
  store i64 256, ptr %45, align 8
  store ptr %45, ptr %35, align 8
  %46 = getelementptr inbounds %.9, ptr %45, i64 0, i32 1
  store i64 %12, ptr %46, align 8
  store ptr %46, ptr %36, align 8
  %47 = getelementptr inbounds %.9, ptr %45, i64 0, i32 2
  store ptr %21, ptr %47, align 8
  store ptr %47, ptr %37, align 8
  %48 = alloca %.10, align 8
  store ptr %48, ptr %38, align 8
  %49 = getelementptr inbounds %.10, ptr %48, i64 0, i32 1
  store ptr %34, ptr %49, align 8
  store ptr %49, ptr %39, align 8
  %50 = getelementptr inbounds %.10, ptr %48, i64 0, i32 2
  store i64 1, ptr %50, align 8
  %51 = getelementptr inbounds ptr, ptr %38, i64 2
  store ptr %50, ptr %51, align 8
  %52 = getelementptr inbounds %.10, ptr %48, i64 0, i32 3
  store ptr @main_kernel_main_kColReduction_reduce__4_1_0___8w32h_kernel_name, ptr %52, align 8
  %53 = getelementptr inbounds ptr, ptr %38, i64 3
  store ptr %52, ptr %53, align 8
  %54 = getelementptr inbounds %.10, ptr %48, i64 0, i32 4
  store i64 %44, ptr %54, align 8
  %55 = getelementptr inbounds ptr, ptr %38, i64 4
  store ptr %54, ptr %55, align 8
  %56 = getelementptr inbounds %.10, ptr %48, i64 0, i32 5
  store i64 1, ptr %56, align 8
  %57 = getelementptr inbounds ptr, ptr %38, i64 5
  store ptr %56, ptr %57, align 8
  %58 = getelementptr inbounds %.10, ptr %48, i64 0, i32 6
  store i64 1, ptr %58, align 8
  %59 = getelementptr inbounds ptr, ptr %38, i64 6
  store ptr %58, ptr %59, align 8
  %60 = getelementptr inbounds %.10, ptr %48, i64 0, i32 7
  store i64 256, ptr %60, align 8
  %61 = getelementptr inbounds ptr, ptr %38, i64 7
  store ptr %60, ptr %61, align 8
  %62 = getelementptr inbounds %.10, ptr %48, i64 0, i32 8
  store i64 1, ptr %62, align 8
  %63 = getelementptr inbounds ptr, ptr %38, i64 8
  store ptr %62, ptr %63, align 8
  %64 = getelementptr inbounds %.10, ptr %48, i64 0, i32 9
  store i64 1, ptr %64, align 8
  %65 = getelementptr inbounds ptr, ptr %38, i64 9
  store ptr %64, ptr %65, align 8
  %66 = getelementptr inbounds %.10, ptr %48, i64 0, i32 10
  store i32 0, ptr %66, align 8
  %67 = getelementptr inbounds ptr, ptr %38, i64 10
  store ptr %66, ptr %67, align 8
  %68 = getelementptr inbounds %.10, ptr %48, i64 0, i32 11
  store ptr null, ptr %68, align 8
  %69 = getelementptr inbounds ptr, ptr %38, i64 11
  store ptr %68, ptr %69, align 8
  %70 = getelementptr inbounds %.10, ptr %48, i64 0, i32 12
  store i32 3, ptr %70, align 8
  %71 = getelementptr inbounds ptr, ptr %38, i64 12
  store ptr %70, ptr %71, align 8
  %72 = getelementptr inbounds %.10, ptr %48, i64 0, i32 13
  store ptr %35, ptr %72, align 8
  %73 = getelementptr inbounds ptr, ptr %38, i64 13
  store ptr %72, ptr %73, align 8
  %74 = load ptr, ptr %0, align 8
  %75 = load ptr, ptr %9, align 8
  store ptr %74, ptr %48, align 8
  call void %75(ptr %74, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %38)
  %76 = add i64 %.fca.3.0.load, -1
  %77 = lshr i64 %76, 7
  %78 = add nuw nsw i64 %77, 1
  %79 = sub i64 0, %.fca.3.0.load
  %.neg17 = sdiv i64 %79, -128
  %80 = icmp sgt i64 %.fca.3.0.load, 0
  %81 = select i1 %80, i64 %78, i64 %.neg17
  %82 = sdiv i64 %32, 2
  %83 = add nsw i64 %82, 1
  %.neg18.lhs.trunc = trunc i64 %11 to i32
  %.neg1819 = sdiv i32 %.neg18.lhs.trunc, 2
  %.neg18.sext = sext i32 %.neg1819 to i64
  %84 = icmp sgt i64 %sext, 0
  %85 = select i1 %84, i64 %83, i64 %.neg18.sext
  %86 = mul i64 %85, %81
  %87 = icmp slt i64 %86, 1
  %88 = sub i64 0, %86
  %89 = add i64 %86, -1
  %90 = select i1 %87, i64 %88, i64 %89
  %91 = sdiv i64 %90, 256
  %92 = sub nsw i64 0, %91
  %93 = add nsw i64 %91, 1
  %94 = select i1 %87, i64 %92, i64 %93
  %95 = alloca ptr, align 8
  store ptr @main_kernel_0_blob_gpu.binary, ptr %95, align 8
  %96 = alloca %.11, align 8
  %97 = alloca [7 x ptr], align 8
  store ptr %.fca.1.load, ptr %96, align 8
  store ptr %96, ptr %97, align 8
  %98 = getelementptr inbounds %.11, ptr %96, i64 0, i32 1
  store i64 %.fca.3.0.load, ptr %98, align 8
  %99 = getelementptr inbounds ptr, ptr %97, i64 1
  store ptr %98, ptr %99, align 8
  %100 = getelementptr inbounds %.11, ptr %96, i64 0, i32 2
  store i64 256, ptr %100, align 8
  %101 = getelementptr inbounds ptr, ptr %97, i64 2
  store ptr %100, ptr %101, align 8
  %102 = getelementptr inbounds %.11, ptr %96, i64 0, i32 3
  store i64 %86, ptr %102, align 8
  %103 = getelementptr inbounds ptr, ptr %97, i64 3
  store ptr %102, ptr %103, align 8
  %104 = getelementptr inbounds %.11, ptr %96, i64 0, i32 4
  store i64 %85, ptr %104, align 8
  %105 = getelementptr inbounds ptr, ptr %97, i64 4
  store ptr %104, ptr %105, align 8
  %106 = getelementptr inbounds %.11, ptr %96, i64 0, i32 5
  store i64 %12, ptr %106, align 8
  %107 = getelementptr inbounds ptr, ptr %97, i64 5
  store ptr %106, ptr %107, align 8
  %108 = getelementptr inbounds %.11, ptr %96, i64 0, i32 6
  store ptr %21, ptr %108, align 8
  %109 = getelementptr inbounds ptr, ptr %97, i64 6
  store ptr %108, ptr %109, align 8
  %110 = alloca %.12, align 8
  %111 = alloca [14 x ptr], align 8
  store ptr %110, ptr %111, align 8
  %112 = getelementptr inbounds %.12, ptr %110, i64 0, i32 1
  store ptr %95, ptr %112, align 8
  %113 = getelementptr inbounds ptr, ptr %111, i64 1
  store ptr %112, ptr %113, align 8
  %114 = getelementptr inbounds %.12, ptr %110, i64 0, i32 2
  store i64 1, ptr %114, align 8
  %115 = getelementptr inbounds ptr, ptr %111, i64 2
  store ptr %114, ptr %115, align 8
  %116 = getelementptr inbounds %.12, ptr %110, i64 0, i32 3
  store ptr @main_kernel_0_main_kColReduction_reduce__4_1_0___8w32h_1_kernel_name, ptr %116, align 8
  %117 = getelementptr inbounds ptr, ptr %111, i64 3
  store ptr %116, ptr %117, align 8
  %118 = getelementptr inbounds %.12, ptr %110, i64 0, i32 4
  store i64 %94, ptr %118, align 8
  %119 = getelementptr inbounds ptr, ptr %111, i64 4
  store ptr %118, ptr %119, align 8
  %120 = getelementptr inbounds %.12, ptr %110, i64 0, i32 5
  store i64 1, ptr %120, align 8
  %121 = getelementptr inbounds ptr, ptr %111, i64 5
  store ptr %120, ptr %121, align 8
  %122 = getelementptr inbounds %.12, ptr %110, i64 0, i32 6
  store i64 1, ptr %122, align 8
  %123 = getelementptr inbounds ptr, ptr %111, i64 6
  store ptr %122, ptr %123, align 8
  %124 = getelementptr inbounds %.12, ptr %110, i64 0, i32 7
  store i64 256, ptr %124, align 8
  %125 = getelementptr inbounds ptr, ptr %111, i64 7
  store ptr %124, ptr %125, align 8
  %126 = getelementptr inbounds %.12, ptr %110, i64 0, i32 8
  store i64 1, ptr %126, align 8
  %127 = getelementptr inbounds ptr, ptr %111, i64 8
  store ptr %126, ptr %127, align 8
  %128 = getelementptr inbounds %.12, ptr %110, i64 0, i32 9
  store i64 1, ptr %128, align 8
  %129 = getelementptr inbounds ptr, ptr %111, i64 9
  store ptr %128, ptr %129, align 8
  %130 = getelementptr inbounds %.12, ptr %110, i64 0, i32 10
  store i32 0, ptr %130, align 8
  %131 = getelementptr inbounds ptr, ptr %111, i64 10
  store ptr %130, ptr %131, align 8
  %132 = getelementptr inbounds %.12, ptr %110, i64 0, i32 11
  store ptr null, ptr %132, align 8
  %133 = getelementptr inbounds ptr, ptr %111, i64 11
  store ptr %132, ptr %133, align 8
  %134 = getelementptr inbounds %.12, ptr %110, i64 0, i32 12
  store i32 7, ptr %134, align 8
  %135 = getelementptr inbounds ptr, ptr %111, i64 12
  store ptr %134, ptr %135, align 8
  %136 = getelementptr inbounds %.12, ptr %110, i64 0, i32 13
  store ptr %97, ptr %136, align 8
  %137 = getelementptr inbounds ptr, ptr %111, i64 13
  store ptr %136, ptr %137, align 8
  %138 = load ptr, ptr %0, align 8
  %139 = load ptr, ptr %9, align 8
  store ptr %138, ptr %110, align 8
  call void %139(ptr %138, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %111)
  br label %240

140:                                              ; preds = %1
  %141 = sdiv i64 %33, 128
  %142 = sub nsw i64 0, %141
  %143 = add nsw i64 %141, 1
  %144 = select i1 %30, i64 %142, i64 %143
  store ptr @main_kernel_1_blob_gpu.binary, ptr %34, align 8
  %145 = alloca %.2, align 8
  store i64 128, ptr %145, align 8
  store ptr %145, ptr %35, align 8
  %146 = getelementptr inbounds %.2, ptr %145, i64 0, i32 1
  store i64 %12, ptr %146, align 8
  store ptr %146, ptr %36, align 8
  %147 = getelementptr inbounds %.2, ptr %145, i64 0, i32 2
  store ptr %21, ptr %147, align 8
  store ptr %147, ptr %37, align 8
  %148 = alloca %.3, align 8
  store ptr %148, ptr %38, align 8
  %149 = getelementptr inbounds %.3, ptr %148, i64 0, i32 1
  store ptr %34, ptr %149, align 8
  store ptr %149, ptr %39, align 8
  %150 = getelementptr inbounds %.3, ptr %148, i64 0, i32 2
  store i64 1, ptr %150, align 8
  %151 = getelementptr inbounds ptr, ptr %38, i64 2
  store ptr %150, ptr %151, align 8
  %152 = getelementptr inbounds %.3, ptr %148, i64 0, i32 3
  store ptr @main_kernel_1_main_kColReduction_reduce__4_1_0___8w16h_kernel_name, ptr %152, align 8
  %153 = getelementptr inbounds ptr, ptr %38, i64 3
  store ptr %152, ptr %153, align 8
  %154 = getelementptr inbounds %.3, ptr %148, i64 0, i32 4
  store i64 %144, ptr %154, align 8
  %155 = getelementptr inbounds ptr, ptr %38, i64 4
  store ptr %154, ptr %155, align 8
  %156 = getelementptr inbounds %.3, ptr %148, i64 0, i32 5
  store i64 1, ptr %156, align 8
  %157 = getelementptr inbounds ptr, ptr %38, i64 5
  store ptr %156, ptr %157, align 8
  %158 = getelementptr inbounds %.3, ptr %148, i64 0, i32 6
  store i64 1, ptr %158, align 8
  %159 = getelementptr inbounds ptr, ptr %38, i64 6
  store ptr %158, ptr %159, align 8
  %160 = getelementptr inbounds %.3, ptr %148, i64 0, i32 7
  store i64 128, ptr %160, align 8
  %161 = getelementptr inbounds ptr, ptr %38, i64 7
  store ptr %160, ptr %161, align 8
  %162 = getelementptr inbounds %.3, ptr %148, i64 0, i32 8
  store i64 1, ptr %162, align 8
  %163 = getelementptr inbounds ptr, ptr %38, i64 8
  store ptr %162, ptr %163, align 8
  %164 = getelementptr inbounds %.3, ptr %148, i64 0, i32 9
  store i64 1, ptr %164, align 8
  %165 = getelementptr inbounds ptr, ptr %38, i64 9
  store ptr %164, ptr %165, align 8
  %166 = getelementptr inbounds %.3, ptr %148, i64 0, i32 10
  store i32 0, ptr %166, align 8
  %167 = getelementptr inbounds ptr, ptr %38, i64 10
  store ptr %166, ptr %167, align 8
  %168 = getelementptr inbounds %.3, ptr %148, i64 0, i32 11
  store ptr null, ptr %168, align 8
  %169 = getelementptr inbounds ptr, ptr %38, i64 11
  store ptr %168, ptr %169, align 8
  %170 = getelementptr inbounds %.3, ptr %148, i64 0, i32 12
  store i32 3, ptr %170, align 8
  %171 = getelementptr inbounds ptr, ptr %38, i64 12
  store ptr %170, ptr %171, align 8
  %172 = getelementptr inbounds %.3, ptr %148, i64 0, i32 13
  store ptr %35, ptr %172, align 8
  %173 = getelementptr inbounds ptr, ptr %38, i64 13
  store ptr %172, ptr %173, align 8
  %174 = load ptr, ptr %0, align 8
  %175 = load ptr, ptr %9, align 8
  store ptr %174, ptr %148, align 8
  call void %175(ptr %174, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %38)
  %176 = add i64 %.fca.3.0.load, -1
  %177 = lshr i64 %176, 7
  %178 = add nuw nsw i64 %177, 1
  %179 = sub i64 0, %.fca.3.0.load
  %.neg1 = sdiv i64 %179, -128
  %180 = icmp sgt i64 %.fca.3.0.load, 0
  %181 = select i1 %180, i64 %178, i64 %.neg1
  %182 = sdiv i64 %32, 2
  %183 = add nsw i64 %182, 1
  %.neg2.lhs.trunc = trunc i64 %11 to i32
  %.neg220 = sdiv i32 %.neg2.lhs.trunc, 2
  %.neg2.sext = sext i32 %.neg220 to i64
  %184 = icmp sgt i64 %sext, 0
  %185 = select i1 %184, i64 %183, i64 %.neg2.sext
  %186 = mul i64 %185, %181
  %187 = icmp slt i64 %186, 1
  %188 = sub i64 0, %186
  %189 = add i64 %186, -1
  %190 = select i1 %187, i64 %188, i64 %189
  %191 = sdiv i64 %190, 128
  %192 = sub nsw i64 0, %191
  %193 = add nsw i64 %191, 1
  %194 = select i1 %187, i64 %192, i64 %193
  %195 = alloca ptr, align 8
  store ptr @main_kernel_2_blob_gpu.binary, ptr %195, align 8
  %196 = alloca %.4, align 8
  %197 = alloca [7 x ptr], align 8
  store ptr %.fca.1.load, ptr %196, align 8
  store ptr %196, ptr %197, align 8
  %198 = getelementptr inbounds %.4, ptr %196, i64 0, i32 1
  store i64 %.fca.3.0.load, ptr %198, align 8
  %199 = getelementptr inbounds ptr, ptr %197, i64 1
  store ptr %198, ptr %199, align 8
  %200 = getelementptr inbounds %.4, ptr %196, i64 0, i32 2
  store i64 128, ptr %200, align 8
  %201 = getelementptr inbounds ptr, ptr %197, i64 2
  store ptr %200, ptr %201, align 8
  %202 = getelementptr inbounds %.4, ptr %196, i64 0, i32 3
  store i64 %186, ptr %202, align 8
  %203 = getelementptr inbounds ptr, ptr %197, i64 3
  store ptr %202, ptr %203, align 8
  %204 = getelementptr inbounds %.4, ptr %196, i64 0, i32 4
  store i64 %185, ptr %204, align 8
  %205 = getelementptr inbounds ptr, ptr %197, i64 4
  store ptr %204, ptr %205, align 8
  %206 = getelementptr inbounds %.4, ptr %196, i64 0, i32 5
  store i64 %12, ptr %206, align 8
  %207 = getelementptr inbounds ptr, ptr %197, i64 5
  store ptr %206, ptr %207, align 8
  %208 = getelementptr inbounds %.4, ptr %196, i64 0, i32 6
  store ptr %21, ptr %208, align 8
  %209 = getelementptr inbounds ptr, ptr %197, i64 6
  store ptr %208, ptr %209, align 8
  %210 = alloca %.5, align 8
  %211 = alloca [14 x ptr], align 8
  store ptr %210, ptr %211, align 8
  %212 = getelementptr inbounds %.5, ptr %210, i64 0, i32 1
  store ptr %195, ptr %212, align 8
  %213 = getelementptr inbounds ptr, ptr %211, i64 1
  store ptr %212, ptr %213, align 8
  %214 = getelementptr inbounds %.5, ptr %210, i64 0, i32 2
  store i64 1, ptr %214, align 8
  %215 = getelementptr inbounds ptr, ptr %211, i64 2
  store ptr %214, ptr %215, align 8
  %216 = getelementptr inbounds %.5, ptr %210, i64 0, i32 3
  store ptr @main_kernel_2_main_kColReduction_reduce__4_1_0___8w16h_1_kernel_name, ptr %216, align 8
  %217 = getelementptr inbounds ptr, ptr %211, i64 3
  store ptr %216, ptr %217, align 8
  %218 = getelementptr inbounds %.5, ptr %210, i64 0, i32 4
  store i64 %194, ptr %218, align 8
  %219 = getelementptr inbounds ptr, ptr %211, i64 4
  store ptr %218, ptr %219, align 8
  %220 = getelementptr inbounds %.5, ptr %210, i64 0, i32 5
  store i64 1, ptr %220, align 8
  %221 = getelementptr inbounds ptr, ptr %211, i64 5
  store ptr %220, ptr %221, align 8
  %222 = getelementptr inbounds %.5, ptr %210, i64 0, i32 6
  store i64 1, ptr %222, align 8
  %223 = getelementptr inbounds ptr, ptr %211, i64 6
  store ptr %222, ptr %223, align 8
  %224 = getelementptr inbounds %.5, ptr %210, i64 0, i32 7
  store i64 128, ptr %224, align 8
  %225 = getelementptr inbounds ptr, ptr %211, i64 7
  store ptr %224, ptr %225, align 8
  %226 = getelementptr inbounds %.5, ptr %210, i64 0, i32 8
  store i64 1, ptr %226, align 8
  %227 = getelementptr inbounds ptr, ptr %211, i64 8
  store ptr %226, ptr %227, align 8
  %228 = getelementptr inbounds %.5, ptr %210, i64 0, i32 9
  store i64 1, ptr %228, align 8
  %229 = getelementptr inbounds ptr, ptr %211, i64 9
  store ptr %228, ptr %229, align 8
  %230 = getelementptr inbounds %.5, ptr %210, i64 0, i32 10
  store i32 0, ptr %230, align 8
  %231 = getelementptr inbounds ptr, ptr %211, i64 10
  store ptr %230, ptr %231, align 8
  %232 = getelementptr inbounds %.5, ptr %210, i64 0, i32 11
  store ptr null, ptr %232, align 8
  %233 = getelementptr inbounds ptr, ptr %211, i64 11
  store ptr %232, ptr %233, align 8
  %234 = getelementptr inbounds %.5, ptr %210, i64 0, i32 12
  store i32 7, ptr %234, align 8
  %235 = getelementptr inbounds ptr, ptr %211, i64 12
  store ptr %234, ptr %235, align 8
  %236 = getelementptr inbounds %.5, ptr %210, i64 0, i32 13
  store ptr %197, ptr %236, align 8
  %237 = getelementptr inbounds ptr, ptr %211, i64 13
  store ptr %236, ptr %237, align 8
  %238 = load ptr, ptr %0, align 8
  %239 = load ptr, ptr %9, align 8
  store ptr %238, ptr %210, align 8
  call void %239(ptr %238, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %211)
  br label %240

240:                                              ; preds = %40, %140
  %241 = alloca [16 x i64], align 8
  store i64 %.fca.3.1.load, ptr %241, align 8
  %242 = getelementptr inbounds i64, ptr %241, i64 1
  store i64 %.fca.3.2.load, ptr %242, align 8
  %243 = alloca %.6, align 8
  %244 = alloca [13 x ptr], align 8
  store ptr %243, ptr %244, align 8
  %245 = getelementptr inbounds %.6, ptr %243, i64 0, i32 1
  store ptr null, ptr %245, align 8
  %246 = getelementptr inbounds ptr, ptr %244, i64 1
  store ptr %245, ptr %246, align 8
  %247 = getelementptr inbounds %.6, ptr %243, i64 0, i32 2
  store ptr %21, ptr %247, align 8
  %248 = getelementptr inbounds ptr, ptr %244, i64 2
  store ptr %247, ptr %248, align 8
  %249 = getelementptr inbounds %.6, ptr %243, i64 0, i32 3
  store ptr %21, ptr %249, align 8
  %250 = getelementptr inbounds ptr, ptr %244, i64 3
  store ptr %249, ptr %250, align 8
  %251 = getelementptr inbounds %.6, ptr %243, i64 0, i32 4
  store i64 0, ptr %251, align 8
  %252 = getelementptr inbounds ptr, ptr %244, i64 4
  store ptr %251, ptr %252, align 8
  %253 = getelementptr inbounds %.6, ptr %243, i64 0, i32 5
  store i64 %12, ptr %253, align 8
  %254 = getelementptr inbounds ptr, ptr %244, i64 5
  store ptr %253, ptr %254, align 8
  %255 = getelementptr inbounds %.6, ptr %243, i64 0, i32 6
  store i64 1, ptr %255, align 8
  %256 = getelementptr inbounds ptr, ptr %244, i64 6
  store ptr %255, ptr %256, align 8
  %257 = getelementptr inbounds %.6, ptr %243, i64 0, i32 7
  store ptr %241, ptr %257, align 8
  %258 = getelementptr inbounds ptr, ptr %244, i64 7
  store ptr %257, ptr %258, align 8
  %259 = getelementptr inbounds %.6, ptr %243, i64 0, i32 8
  store ptr %241, ptr %259, align 8
  %260 = getelementptr inbounds ptr, ptr %244, i64 8
  store ptr %259, ptr %260, align 8
  %261 = getelementptr inbounds %.6, ptr %243, i64 0, i32 9
  store i64 0, ptr %261, align 8
  %262 = getelementptr inbounds ptr, ptr %244, i64 9
  store ptr %261, ptr %262, align 8
  %263 = getelementptr inbounds %.6, ptr %243, i64 0, i32 10
  store i64 2, ptr %263, align 8
  %264 = getelementptr inbounds ptr, ptr %244, i64 10
  store ptr %263, ptr %264, align 8
  %265 = getelementptr inbounds %.6, ptr %243, i64 0, i32 11
  store i64 1, ptr %265, align 8
  %266 = getelementptr inbounds ptr, ptr %244, i64 11
  store ptr %265, ptr %266, align 8
  %267 = getelementptr inbounds %.6, ptr %243, i64 0, i32 12
  %268 = getelementptr inbounds ptr, ptr %244, i64 12
  store ptr %267, ptr %268, align 8
  %269 = load ptr, ptr %0, align 8
  %270 = load ptr, ptr %9, align 8
  store ptr %269, ptr %243, align 8
  call void %270(ptr %269, ptr nonnull @inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32, ptr nonnull %244)
  %.unpack = load ptr, ptr %267, align 8
  %.elt3 = getelementptr inbounds %.6, ptr %243, i64 0, i32 12, i32 1
  %.unpack4 = load ptr, ptr %.elt3, align 8
  %271 = alloca %.7, align 8
  %272 = alloca [2 x ptr], align 8
  store ptr %271, ptr %272, align 8
  %273 = getelementptr inbounds %.7, ptr %271, i64 0, i32 1
  store ptr %21, ptr %273, align 8
  %274 = getelementptr inbounds ptr, ptr %272, i64 1
  store ptr %273, ptr %274, align 8
  %275 = load ptr, ptr %0, align 8
  %276 = load ptr, ptr %9, align 8
  store ptr %275, ptr %271, align 8
  call void %276(ptr %275, ptr nonnull @dealloc___gpu___pvoid_pvoid___void, ptr nonnull %272)
  %277 = alloca %.8, align 8
  %278 = alloca [9 x ptr], align 8
  store ptr %277, ptr %278, align 8
  %279 = getelementptr inbounds %.8, ptr %277, i64 0, i32 1
  store i64 0, ptr %279, align 8
  %280 = getelementptr inbounds ptr, ptr %278, i64 1
  store ptr %279, ptr %280, align 8
  %281 = getelementptr inbounds %.8, ptr %277, i64 0, i32 2
  store ptr %.unpack, ptr %281, align 8
  %282 = getelementptr inbounds ptr, ptr %278, i64 2
  store ptr %281, ptr %282, align 8
  %283 = getelementptr inbounds %.8, ptr %277, i64 0, i32 3
  store ptr %.unpack4, ptr %283, align 8
  %284 = getelementptr inbounds ptr, ptr %278, i64 3
  store ptr %283, ptr %284, align 8
  %285 = getelementptr inbounds %.8, ptr %277, i64 0, i32 4
  store i64 0, ptr %285, align 8
  %286 = getelementptr inbounds ptr, ptr %278, i64 4
  store ptr %285, ptr %286, align 8
  %287 = getelementptr inbounds %.8, ptr %277, i64 0, i32 5
  store i64 %.fca.3.1.load, ptr %287, align 8
  %288 = getelementptr inbounds ptr, ptr %278, i64 5
  store ptr %287, ptr %288, align 8
  %289 = getelementptr inbounds %.8, ptr %277, i64 0, i32 6
  store i64 %.fca.3.2.load, ptr %289, align 8
  %290 = getelementptr inbounds ptr, ptr %278, i64 6
  store ptr %289, ptr %290, align 8
  %291 = getelementptr inbounds %.8, ptr %277, i64 0, i32 7
  store i64 %.fca.3.2.load, ptr %291, align 8
  %292 = getelementptr inbounds ptr, ptr %278, i64 7
  store ptr %291, ptr %292, align 8
  %293 = getelementptr inbounds %.8, ptr %277, i64 0, i32 8
  store i64 1, ptr %293, align 8
  %294 = getelementptr inbounds ptr, ptr %278, i64 8
  store ptr %293, ptr %294, align 8
  %295 = load ptr, ptr %0, align 8
  %296 = load ptr, ptr %9, align 8
  store ptr %295, ptr %277, align 8
  call void %296(ptr %295, ptr nonnull @ral_send_output___cpu___pvoid_i64_m2df32___void, ptr nonnull %278)
  ret void
}

[DISC] LowerLLVMToBinary takes: 2.634800e-02 s.
object file to shared library command: gcc --shared -o /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceFullyDynamicShape3DF32_0.so /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceFullyDynamicShape3DF32_0.so.o
save shared lib file to : /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceFullyDynamicShape3DF32_0.so
[DISC] BinaryStrToSharedLibrary takes: 9.379000e-03 s.
[DISC] LowerHLOToSharedLibrary takes: 8.053700e-01 s.

============ END ============

2023-06-08 04:48:06.283471: I mlir/disc/tests/mlir_test.cc:275] ret: 0

2023-06-08 04:48:06.283548: I mlir/disc/tests/mlir_test.cc:241] run compiled program

2023-06-08 04:48:06.478892: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:06.483383: I mlir/disc/tests/mlir_test.cc:932] --- MLIR Execution uses: 4.518 ms
2023-06-08 04:48:06.483476: I mlir/disc/tests/mlir_test.cc:183] out buffer = 0x7fb8a328bc00
2023-06-08 04:48:06.483483: I mlir/disc/tests/mlir_test.cc:184] out shape:
2023-06-08 04:48:06.483487: I mlir/disc/tests/mlir_test.cc:186]   dim #0: 100
2023-06-08 04:48:06.483490: I mlir/disc/tests/mlir_test.cc:186]   dim #1: 13
2023-06-08 04:48:06.483532: I mlir/disc/tests/mlir_test.cc:244] run golden tf

2023-06-08 04:48:06.483541: I mlir/disc/tests/mlir_test.cc:257] program_path: external/org_tensorflow/tensorflow/compiler/mlir/tf-mlir-translate

2023-06-08 04:48:06.541405: I mlir/disc/tests/mlir_test.cc:269] Executed: external/org_tensorflow/tensorflow/compiler/mlir/tf-mlir-translate -mlir-to-graphdef /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617bea/tempfile-adf59ec6ac82-11dd47f9-244707-5fd96f5436371 -o /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceFullyDynamicShape3DF32_0.pbtxt 
2023-06-08 04:48:06.541415: I mlir/disc/tests/mlir_test.cc:270] external/org_tensorflow/tensorflow/compiler/mlir/tf-mlir-translate: 0
2023-06-08 04:48:06.541418: I mlir/disc/tests/mlir_test.cc:271] -- stdout:

============ END ============

2023-06-08 04:48:06.541421: I mlir/disc/tests/mlir_test.cc:273] -- stderr:

============ END ============

2023-06-08 04:48:06.541424: I mlir/disc/tests/mlir_test.cc:275] ret: 0

2023-06-08 04:48:06.541432: I mlir/disc/tests/mlir_test.cc:391] graphdef_path: /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceFullyDynamicShape3DF32_0.pbtxt
2023-06-08 04:48:06.542800: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-08 04:48:07.350279: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.352747: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.355102: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.357446: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.359776: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.362087: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.364398: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.366713: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.482984: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.485375: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.487716: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.490054: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.492366: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.494670: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.496984: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.499310: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.501612: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.504639: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.506944: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.509267: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.511569: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.513862: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.516173: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:07.518569: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.029277: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.031801: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.034214: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.036595: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.038951: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.041288: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.043627: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.045966: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.048325: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.050648: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.052971: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.055310: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.057620: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.059951: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.062252: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.064777: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.067112: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.069421: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79147 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:07.0, compute capability: 8.0
2023-06-08 04:48:10.070513: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.072793: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79149 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:08.0, compute capability: 8.0
2023-06-08 04:48:10.073344: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.075628: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79149 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:09.0, compute capability: 8.0
2023-06-08 04:48:10.076160: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.078424: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 79149 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:0a.0, compute capability: 8.0
2023-06-08 04:48:10.078975: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.081243: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 79149 MB memory:  -> device: 4, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:0b.0, compute capability: 8.0
2023-06-08 04:48:10.081769: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.084046: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 79149 MB memory:  -> device: 5, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:0c.0, compute capability: 8.0
2023-06-08 04:48:10.084572: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.086838: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 79149 MB memory:  -> device: 6, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:0d.0, compute capability: 8.0
2023-06-08 04:48:10.087349: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-08 04:48:10.089604: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 79149 MB memory:  -> device: 7, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:0e.0, compute capability: 8.0
2023-06-08 04:48:10.130536: I mlir/disc/tests/mlir_test.cc:467] --- TF Execution uses: 22.278 ms
2023-06-08 04:48:10.130559: I mlir/disc/tests/mlir_test.cc:474] 	output shape #0: [100,13]
2023-06-08 04:48:10.130856: I mlir/disc/tests/mlir_test.cc:467] --- TF Execution uses: 0.289 ms
2023-06-08 04:48:10.130862: I mlir/disc/tests/mlir_test.cc:474] 	output shape #0: [100,13]
2023-06-08 04:48:10.131144: I mlir/disc/tests/mlir_test.cc:467] --- TF Execution uses: 0.277 ms
2023-06-08 04:48:10.131148: I mlir/disc/tests/mlir_test.cc:474] 	output shape #0: [100,13]
2023-06-08 04:48:10.131413: I mlir/disc/tests/mlir_test.cc:467] --- TF Execution uses: 0.26 ms
2023-06-08 04:48:10.131417: I mlir/disc/tests/mlir_test.cc:474] 	output shape #0: [100,13]
2023-06-08 04:48:10.131791: I mlir/disc/tests/mlir_test.cc:467] --- TF Execution uses: 0.369 ms
2023-06-08 04:48:10.131795: I mlir/disc/tests/mlir_test.cc:474] 	output shape #0: [100,13]
2023-06-08 04:48:10.131804: I mlir/disc/tests/mlir_test.cc:484] processing output 0
2023-06-08 04:48:10.133527: I ./mlir/disc/tests/mlir_feature_test.h:37] Unset env setting:
[       OK ] TFMaxOpTest.ColReduceFullyDynamicShape3DF32 (4824 ms)
[----------] 1 test from TFMaxOpTest (4824 ms total)

[----------] Global test environment tear-down
[==========] 1 test from 1 test suite ran. (4824 ms total)
[  PASSED  ] 1 test.
