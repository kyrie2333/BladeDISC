exec ${PAGER:-/usr/bin/less} "$0" || exit 1
Executing tests from //mlir/disc/tests/tensorflow_ops:max.cpp.test
-----------------------------------------------------------------------------
[==========] Running 1 test from 1 test suite.
[----------] Global test environment set-up.
[----------] 1 test from TFMaxOpTest
[ RUN      ] TFMaxOpTest.ColReduceStaticShape3DF32
2023-06-09 07:26:15.783357: I ./mlir/disc/tests/mlir_feature_test.h:29] Apply env setting:
2023-06-09 07:26:15.783406: I ./mlir/disc/tests/mlir_feature_test.h:31] 	DISC_MEM_INTENSIVE_OPT_EXPERIMENTAL = true
2023-06-09 07:26:15.783410: I ./mlir/disc/tests/mlir_feature_test.h:31] 	DISC_ENABLE_STITCH = true
2023-06-09 07:26:15.783413: I mlir/disc/tests/mlir_feature_test.cc:271] Testing for CUDA backend
2023-06-09 07:26:15.783464: I mlir/disc/tests/mlir_feature_test.cc:145] Original TF code: func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {inputs = "{{INPUTS}}", outputs = "{{OUTPUTS}}", input_placements="{{INPUT_PLACEMENTS}}", output_placements="{{OUTPUT_PLACEMENTS}}"}} {
  %graph = tf_executor.graph {
    %1:2 = tf_executor.island wraps "tf.Const"() {value = dense<[0]> : tensor<1xi32>} : () -> tensor<1xi32>
    %2:2 = tf_executor.island wraps "tf.Max"(%arg0, %1) {keep_dims = false} : (tensor<110x100x13xf32>, tensor<1xi32>) -> tensor<100x13xf32>
    tf_executor.fetch %2 : tensor<100x13xf32>
  }
  return %graph : tensor<100x13xf32>
}
2023-06-09 07:26:15.783479: I mlir/disc/tests/mlir_feature_test.cc:149] New TF code: func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {inputs = "input0", outputs = "output0", input_placements="gpu", output_placements="gpu"}} {
  %graph = tf_executor.graph {
    %1:2 = tf_executor.island wraps "tf.Const"() {value = dense<[0]> : tensor<1xi32>} : () -> tensor<1xi32>
    %2:2 = tf_executor.island wraps "tf.Max"(%arg0, %1) {keep_dims = false} : (tensor<110x100x13xf32>, tensor<1xi32>) -> tensor<100x13xf32>
    tf_executor.fetch %2 : tensor<100x13xf32>
  }
  return %graph : tensor<100x13xf32>
}
2023-06-09 07:26:15.783560: I mlir/disc/tests/mlir_test.cc:233] tf_opt_pat: external/org_tensorflow/tensorflow/compiler/mlir/tf-opt
2023-06-09 07:26:15.783564: I mlir/disc/tests/mlir_test.cc:234] mlir_file_path: /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617bea/tempfile-adf59ec6ac82-b50697a0-360183-5fdad48c7e849
2023-06-09 07:26:15.783580: I mlir/disc/tests/mlir_test.cc:235] tmp_dir: /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617bea
2023-06-09 07:26:15.783583: I mlir/disc/tests/mlir_test.cc:236] test_name: ColReduceStaticShape3DF32_0
2023-06-09 07:26:15.783590: I mlir/disc/tests/mlir_test.cc:284] tf_opt_path: external/org_tensorflow/tensorflow/compiler/mlir/tf-opt

2023-06-09 07:26:15.783597: I mlir/disc/tests/mlir_test.cc:257] program_path: external/org_tensorflow/tensorflow/compiler/mlir/tf-opt

2023-06-09 07:26:15.843852: I mlir/disc/tests/mlir_test.cc:269] Executed: external/org_tensorflow/tensorflow/compiler/mlir/tf-opt --tf-standard-pipeline /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617bea/tempfile-adf59ec6ac82-b50697a0-360183-5fdad48c7e849 -o /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceStaticShape3DF32_0_tf_dialect.mlir 
2023-06-09 07:26:15.843868: I mlir/disc/tests/mlir_test.cc:270] external/org_tensorflow/tensorflow/compiler/mlir/tf-opt: 0
2023-06-09 07:26:15.843871: I mlir/disc/tests/mlir_test.cc:271] -- stdout:

============ END ============

2023-06-09 07:26:15.843875: I mlir/disc/tests/mlir_test.cc:273] -- stderr:
2023-06-09 07:26:15.829917: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.

============ END ============

2023-06-09 07:26:15.843884: I mlir/disc/tests/mlir_test.cc:275] ret: 0

2023-06-09 07:26:15.843898: I mlir/disc/tests/mlir_test.cc:257] program_path: mlir/disc/disc_compiler_main

2023-06-09 07:26:16.352182: I mlir/disc/tests/mlir_test.cc:269] Executed: mlir/disc/disc_compiler_main --mlir-print-elementsattrs-with-hex-if-larger -1 --mlir-elide-elementsattrs-if-larger 8 /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceStaticShape3DF32_0_tf_dialect.mlir /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceStaticShape3DF32_0.so 
2023-06-09 07:26:16.352210: I mlir/disc/tests/mlir_test.cc:270] mlir/disc/disc_compiler_main: 0
2023-06-09 07:26:16.352213: I mlir/disc/tests/mlir_test.cc:271] -- stdout:

============ END ============

2023-06-09 07:26:16.352704: I mlir/disc/tests/mlir_test.cc:273] -- stderr:
======== BEGIN Original Module =========
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %cst = "tf.Const"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
    %0 = "tf.Max"(%arg0, %cst) {keep_dims = false} : (tensor<110x100x13xf32>, tensor<1xi32>) -> tensor<100x13xf32>
    return %0 : tensor<100x13xf32>
  }
}

======= END Original Module ==========
[DISC] Load Input IR takes: 1.999000e-03 s.
[[ INFO ]] Running TF2XLA
2023-06-09 07:26:15.892314: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
// -----// IR Dump After SCCP (sccp) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %cst = "tf.Const"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
    %0 = "tf.Max"(%arg0, %cst) {keep_dims = false} : (tensor<110x100x13xf32>, tensor<1xi32>) -> tensor<100x13xf32>
    return %0 : tensor<100x13xf32>
  }
}


// -----// IR Dump After SCCP (sccp) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %cst = "tf.Const"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
    %0 = "tf.Max"(%arg0, %cst) {keep_dims = false} : (tensor<110x100x13xf32>, tensor<1xi32>) -> tensor<100x13xf32>
    return %0 : tensor<100x13xf32>
  }
}


// -----// IR Dump After LegalizeTF (xla-legalize-tf) //----- //
func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %0 = mhlo.constant dense<0> : tensor<1xi32>
  %1 = mhlo.convert %arg0 : tensor<110x100x13xf32>
  %2 = mhlo.constant dense<0xFF800000> : tensor<f32>
  %3 = mhlo.reduce(%1 init: %2) applies mhlo.maximum across dimensions = [0] : (tensor<110x100x13xf32>, tensor<f32>) -> tensor<100x13xf32>
  %4 = mhlo.convert %3 : tensor<100x13xf32>
  return %4 : tensor<100x13xf32>
}

// -----// IR Dump After DiscLowerTfPass (disc-lower-tf) //----- //
func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
  %1 = mhlo.reduce(%arg0 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x100x13xf32>, tensor<f32>) -> tensor<100x13xf32>
  return %1 : tensor<100x13xf32>
}

===-------------------------------------------------------------------------===
                         ... Execution time report ...
===-------------------------------------------------------------------------===
  Total Execution Time: 0.0086 seconds

  ----Wall Time----  ----Name----
    0.0000 (  0.4%)  ReviseArgumentsForStaticRankPass
    0.0000 (  0.1%)  FunctionalControlFlowToRegionsPass
    0.0044 ( 51.7%)  Inliner
    0.0000 (  0.1%)    (A) CallGraph
    0.0042 ( 49.3%)  'func.func' Pipeline
    0.0042 ( 49.3%)    Canonicalizer
    0.0001 (  1.1%)  'func.func' Pipeline
    0.0000 (  0.0%)    DropWhileShapeInvariantPass
    0.0000 (  0.0%)    ReplicateTensorListInitOpsPass
    0.0001 (  1.0%)    Canonicalizer
    0.0002 (  2.8%)  SCCP
    0.0000 (  0.2%)  GuaranteeAllFuncsOneUsePass
    0.0000 (  0.0%)    (A) CallGraph
    0.0000 (  0.1%)  TensorFlowShapeInferencePass
    0.0001 (  1.5%)  SCCP
    0.0000 (  0.1%)  TensorListOpsDecompositionPass
    0.0000 (  0.1%)  StackOpsDecompositionPass
    0.0000 (  0.1%)  TensorArrayOpsDecompositionPass
    0.0001 (  0.6%)  'func.func' Pipeline
    0.0000 (  0.6%)    DecomposeResourceOpsPass
    0.0000 (  0.2%)  PromoteResourcesToArgsPass
    0.0000 (  0.1%)  SymbolDCE
    0.0000 (  0.1%)  'func.func' Pipeline
    0.0000 (  0.0%)    SinkConstantsToControlFlowPass
    0.0000 (  0.0%)  TensorFlowShapeInferencePass
    0.0002 (  2.6%)  StablehloLegalizeToHloPass
    0.0000 (  0.6%)  'func.func' Pipeline
    0.0000 (  0.4%)    DiscLowerTfPass
    0.0000 (  0.2%)    LowerQuantizedPass
    0.0000 (  0.1%)  LegalizeTfTypesPass
    0.0010 ( 11.2%)  'func.func' Pipeline
    0.0008 (  9.3%)    LegalizeTF
    0.0001 (  1.7%)    DiscLowerTfPass
    0.0000 (  0.1%)    mlir::mhlo::{anonymous}::AdjustLayout
    0.0000 (  0.2%)  LegalizeTFCollective
    0.0001 (  0.8%)  'func.func' Pipeline
    0.0001 (  0.8%)    Canonicalizer
    0.0000 (  0.1%)  TensorFlowShapeInferencePass
    0.0004 (  4.3%)  'func.func' Pipeline
    0.0004 (  4.2%)    LegalizeTF
    0.0000 (  0.1%)  LegalizeTFCommunicationPass
    0.0000 (  0.5%)  'func.func' Pipeline
    0.0000 (  0.4%)    DiscDynamicSliceConverterPass
    0.0000 (  0.1%)    SinkConstantsToControlFlowPass
   -0.0025 (-29.2%)  Rest
    0.0086 (100.0%)  Total
======== BEGIN After TF2HLO =========
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %1 = mhlo.reduce(%arg0 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x100x13xf32>, tensor<f32>) -> tensor<100x13xf32>
    return %1 : tensor<100x13xf32>
  }
}

======= END After TF2HLO ==========
[DISC] tf2hlo takes: 8.855000e-03 s.
SymbolicDimMgr::save walkRankedTensorValue takes: 1 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 11 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %1 = mhlo.reduce(%arg0 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x100x13xf32>, tensor<f32>) -> tensor<100x13xf32>
    return %1 : tensor<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 14 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %1 = mhlo.reduce(%arg0 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x100x13xf32>, tensor<f32>) -> tensor<100x13xf32>
    return %1 : tensor<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 12 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %1 = mhlo.reduce(%arg0 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x100x13xf32>, tensor<f32>) -> tensor<100x13xf32>
    return %1 : tensor<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After HloCanonicalizeReductionPass (hlo-canonicalize-reduction) //----- //
func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
  %c1_i32 = arith.constant 1 : i32
  %c0 = arith.constant 0 : index
  %dim = tensor.dim %arg0, %c0 : tensor<110x100x13xf32>
  %1 = arith.index_cast %dim : index to i32
  %2 = arith.muli %c1_i32, %1 : i32
  %c1 = arith.constant 1 : index
  %dim_0 = tensor.dim %arg0, %c1 : tensor<110x100x13xf32>
  %3 = arith.index_cast %dim_0 : index to i32
  %4 = arith.muli %c1_i32, %3 : i32
  %c2 = arith.constant 2 : index
  %dim_1 = tensor.dim %arg0, %c2 : tensor<110x100x13xf32>
  %5 = arith.index_cast %dim_1 : index to i32
  %6 = arith.muli %4, %5 : i32
  %from_elements = tensor.from_elements %2, %6 : tensor<2xi32>
  %7 = mhlo.dynamic_reshape %arg0, %from_elements : (tensor<110x100x13xf32>, tensor<2xi32>) -> tensor<?x?xf32>
  %8 = mhlo.reduce(%7 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<?x?xf32>, tensor<f32>) -> tensor<?xf32>
  %c1_2 = arith.constant 1 : index
  %dim_3 = tensor.dim %arg0, %c1_2 : tensor<110x100x13xf32>
  %9 = arith.index_cast %dim_3 : index to i32
  %c2_4 = arith.constant 2 : index
  %dim_5 = tensor.dim %arg0, %c2_4 : tensor<110x100x13xf32>
  %10 = arith.index_cast %dim_5 : index to i32
  %from_elements_6 = tensor.from_elements %9, %10 : tensor<2xi32>
  %11 = mhlo.dynamic_reshape %8, %from_elements_6 : (tensor<?xf32>, tensor<2xi32>) -> tensor<100x13xf32>
  return %11 : tensor<100x13xf32>
}

SymbolicDimMgr::save walkRankedTensorValue takes: 1 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 2 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 17 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 1 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 12 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant dense<0xFF800000> : tensor<f32>
    %1 = mhlo.reshape %arg0 : (tensor<110x100x13xf32>) -> tensor<110x1300xf32>
    %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x1300xf32>, tensor<f32>) -> tensor<1300xf32>
    %3 = mhlo.reshape %2 : (tensor<1300xf32>) -> tensor<100x13xf32>
    return %3 : tensor<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After PlaceOpsPass (mhlo-place-ops) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %1 = mhlo.reshape %arg0 {disc.device = "gpu"} : (tensor<110x100x13xf32>) -> tensor<110x1300xf32>
    %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x1300xf32>, tensor<f32>) -> tensor<1300xf32>
    %3 = mhlo.reshape %2 {disc.device = "gpu"} : (tensor<1300xf32>) -> tensor<100x13xf32>
    return %3 : tensor<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 12 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %1 = mhlo.reshape %arg0 {disc.device = "gpu"} : (tensor<110x100x13xf32>) -> tensor<110x1300xf32>
    %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x1300xf32>, tensor<f32>) -> tensor<1300xf32>
    %3 = mhlo.reshape %2 {disc.device = "gpu"} : (tensor<1300xf32>) -> tensor<100x13xf32>
    return %3 : tensor<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 14 us
SymbolicDimMgr::save updateFunctionType takes: 11 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 1 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %1 = mhlo.reshape %arg0 {disc.device = "gpu"} : (tensor<110x100x13xf32>) -> tensor<110x1300xf32>
    %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x1300xf32>, tensor<f32>) -> tensor<1300xf32>
    %3 = mhlo.reshape %2 {disc.device = "gpu"} : (tensor<1300xf32>) -> tensor<100x13xf32>
    return %3 : tensor<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 11 us
SymbolicDimMgr::save updateFunctionType takes: 1 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 1 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %1 = mhlo.reshape %arg0 {disc.device = "gpu"} : (tensor<110x100x13xf32>) -> tensor<110x1300xf32>
    %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x1300xf32>, tensor<f32>) -> tensor<1300xf32>
    %3 = mhlo.reshape %2 {disc.device = "gpu"} : (tensor<1300xf32>) -> tensor<100x13xf32>
    return %3 : tensor<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 1 us
SymbolicDimMgr::updateProductEqualityMap simplifySymbolicDimProductPair takes: 0 us
productSet.size() = 0
SymbolicDimMgr::updateProductEqualityMap propagate graph takes: 1 us
SymbolicDimMgr::updateProductEqualityMap remove multiply takes: 0 us
SymbolicDimMgr::updateProductEqualityMap build toRemove  takes: 0 us
SymbolicDimMgr::updateProductEqualityMap apply toRemove  takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 12 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 1 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscShapeOptimizationPass (disc-shape-optimization) //----- //
module {
  func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c110 = arith.constant 110 : index
    %c100 = arith.constant 100 : index
    %c13 = arith.constant 13 : index
    %c1300 = arith.constant 1300 : index
    %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %1 = "disc_shape.tie_shape"(%arg0, %c110, %c100, %c13) : (tensor<110x100x13xf32>, index, index, index) -> tensor<110x100x13xf32>
    %2 = mhlo.reshape %1 {disc.device = "gpu"} : (tensor<110x100x13xf32>) -> tensor<110x1300xf32>
    %3 = "disc_shape.tie_shape"(%2, %c110, %c1300) : (tensor<110x1300xf32>, index, index) -> tensor<110x1300xf32>
    %4 = mhlo.reduce(%3 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x1300xf32>, tensor<f32>) -> tensor<1300xf32>
    %5 = "disc_shape.tie_shape"(%4, %c1300) : (tensor<1300xf32>, index) -> tensor<1300xf32>
    %6 = mhlo.reshape %5 {disc.device = "gpu"} : (tensor<1300xf32>) -> tensor<100x13xf32>
    %7 = "disc_shape.tie_shape"(%6, %c100, %c13) : (tensor<100x13xf32>, index, index) -> tensor<100x13xf32>
    return %7 : tensor<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: tensor<110x100x13xf32>) -> tensor<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %0 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
  %1 = mhlo.reshape %arg0 {disc.device = "gpu"} : (tensor<110x100x13xf32>) -> tensor<110x1300xf32>
  %2 = mhlo.reduce(%1 init: %0) applies mhlo.maximum across dimensions = [0] : (tensor<110x1300xf32>, tensor<f32>) -> tensor<1300xf32>
  %3 = mhlo.reshape %2 {disc.device = "gpu"} : (tensor<1300xf32>) -> tensor<100x13xf32>
  return %3 : tensor<100x13xf32>
}

// -----// IR Dump After FuncBufferize (func-bufferize) //----- //
module {
  func.func @main(%arg0: memref<110x100x13xf32>) -> memref<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = bufferization.to_tensor %arg0 : memref<110x100x13xf32>
    %1 = mhlo.constant {disc.device = "gpu"} dense<0xFF800000> : tensor<f32>
    %2 = mhlo.reshape %0 {disc.device = "gpu"} : (tensor<110x100x13xf32>) -> tensor<110x1300xf32>
    %3 = mhlo.reduce(%2 init: %1) applies mhlo.maximum across dimensions = [0] : (tensor<110x1300xf32>, tensor<f32>) -> tensor<1300xf32>
    %4 = mhlo.reshape %3 {disc.device = "gpu"} : (tensor<1300xf32>) -> tensor<100x13xf32>
    %5 = bufferization.to_memref %4 : memref<100x13xf32>
    return %5 : memref<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After HloLegalizeToLhloPass (hlo-legalize-to-lhlo) //----- //
module {
  func.func @main(%arg0: memref<110x100x13xf32>) -> memref<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = bufferization.to_tensor %arg0 : memref<110x100x13xf32>
    %1 = bufferization.to_memref %0 : memref<110x100x13xf32>
    %alloc = memref.alloc() : memref<f32>
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
    %alloc_0 = memref.alloc() : memref<110x1300xf32>
    "lmhlo.reshape"(%1, %alloc_0) {disc.device = "gpu"} : (memref<110x100x13xf32>, memref<110x1300xf32>) -> ()
    %alloc_1 = memref.alloc() : memref<1300xf32>
    "lmhlo.reduce"(%alloc_0, %alloc, %alloc_1) ({
    ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
      %alloc_3 = memref.alloc() : memref<f32>
      "lmhlo.maximum"(%arg1, %arg2, %alloc_3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.copy"(%alloc_3, %arg3) : (memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<110x1300xf32>, memref<f32>, memref<1300xf32>) -> ()
    %alloc_2 = memref.alloc() : memref<100x13xf32>
    "lmhlo.reshape"(%alloc_1, %alloc_2) {disc.device = "gpu"} : (memref<1300xf32>, memref<100x13xf32>) -> ()
    %2 = bufferization.to_tensor %alloc_2 : memref<100x13xf32>
    %3 = bufferization.to_memref %2 : memref<100x13xf32>
    return %3 : memref<100x13xf32>
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: memref<110x100x13xf32>) -> memref<100x13xf32> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %alloc = memref.alloc() : memref<f32>
  "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32>) -> ()
  %alloc_0 = memref.alloc() : memref<110x1300xf32>
  "lmhlo.reshape"(%arg0, %alloc_0) {disc.device = "gpu"} : (memref<110x100x13xf32>, memref<110x1300xf32>) -> ()
  %alloc_1 = memref.alloc() : memref<1300xf32>
  "lmhlo.reduce"(%alloc_0, %alloc, %alloc_1) ({
  ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
    "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<110x1300xf32>, memref<f32>, memref<1300xf32>) -> ()
  %alloc_2 = memref.alloc() : memref<100x13xf32>
  "lmhlo.reshape"(%alloc_1, %alloc_2) {disc.device = "gpu"} : (memref<1300xf32>, memref<100x13xf32>) -> ()
  return %alloc_2 : memref<100x13xf32>
}

// -----// IR Dump After DiscAssignMemorySpacePass (disc-assign-memory-space) //----- //
module {
  func.func @main(%arg0: memref<110x100x13xf32, "gpu">) -> memref<100x13xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %alloc = memref.alloc() : memref<f32, "gpu">
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    %alloc_0 = memref.alloc() : memref<110x1300xf32, "gpu">
    "lmhlo.reshape"(%arg0, %alloc_0) {disc.device = "gpu"} : (memref<110x100x13xf32, "gpu">, memref<110x1300xf32, "gpu">) -> ()
    %alloc_1 = memref.alloc() : memref<1300xf32, "gpu">
    "lmhlo.reduce"(%alloc_0, %alloc, %alloc_1) ({
    ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
      "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<110x1300xf32, "gpu">, memref<f32, "gpu">, memref<1300xf32, "gpu">) -> ()
    %alloc_2 = memref.alloc() : memref<100x13xf32, "gpu">
    "lmhlo.reshape"(%alloc_1, %alloc_2) {disc.device = "gpu"} : (memref<1300xf32, "gpu">, memref<100x13xf32, "gpu">) -> ()
    return %alloc_2 : memref<100x13xf32, "gpu">
  }
  func.func @shape_constraint_graph() {
    return
  }
}


SymbolicDimMgr::save walkRankedTensorValue takes: 1 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 2 us
SymbolicDimMgr::save collect symbolicDim ops takes: 1 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscFusionPass (disc-fusion) //----- //
func.func @main(%arg0: memref<110x100x13xf32, "gpu">) -> memref<100x13xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<110x1300xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.reshape"(%arg0, %alloc_0) {disc.device = "gpu"} : (memref<110x100x13xf32, "gpu">, memref<110x1300xf32, "gpu">) -> ()
    "lmhlo.reduce"(%alloc_0, %alloc, %alloc_1) ({
    ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
      "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<110x1300xf32, "gpu">, memref<f32, "gpu">, memref<1300xf32, "gpu">) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  %alloc_2 = memref.alloc() : memref<100x13xf32, "gpu">
  "lmhlo.reshape"(%alloc_1, %alloc_2) {disc.device = "gpu"} : (memref<1300xf32, "gpu">, memref<100x13xf32, "gpu">) -> ()
  return %alloc_2 : memref<100x13xf32, "gpu">
}

SymbolicDimMgr::save walkRankedTensorValue takes: 0 us
SymbolicDimMgr::save update attributes takes: 0 us
SymbolicDimMgr::save updateProductEqualityMap takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
SymbolicDimMgr::save collect symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After BufferDeallocation (buffer-deallocation) //----- //
func.func @main(%arg0: memref<110x100x13xf32, "gpu">) -> memref<100x13xf32, "gpu"> attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<110x1300xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.reshape"(%arg0, %alloc_0) {disc.device = "gpu"} : (memref<110x100x13xf32, "gpu">, memref<110x1300xf32, "gpu">) -> ()
    "lmhlo.reduce"(%alloc_0, %alloc, %alloc_1) ({
    ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
      "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<110x1300xf32, "gpu">, memref<f32, "gpu">, memref<1300xf32, "gpu">) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  memref.dealloc %alloc_0 : memref<110x1300xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %alloc_2 = memref.alloc() : memref<100x13xf32, "gpu">
  "lmhlo.reshape"(%alloc_1, %alloc_2) {disc.device = "gpu"} : (memref<1300xf32, "gpu">, memref<100x13xf32, "gpu">) -> ()
  memref.dealloc %alloc_1 : memref<1300xf32, "gpu">
  return %alloc_2 : memref<100x13xf32, "gpu">
}

// -----// IR Dump After RalInjectExecutionContextPass (disc-ral-inject-execution-context) //----- //
module {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c0 = arith.constant 0 : index
    %0 = "disc_ral.recv_input"(%arg0, %c0) : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
    %alloc = memref.alloc() : memref<f32, "gpu">
    %alloc_0 = memref.alloc() : memref<110x1300xf32, "gpu">
    %alloc_1 = memref.alloc() : memref<1300xf32, "gpu">
    "lmhlo.fusion"() ({
      "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
      "lmhlo.reshape"(%0, %alloc_0) {disc.device = "gpu"} : (memref<110x100x13xf32, "gpu">, memref<110x1300xf32, "gpu">) -> ()
      "lmhlo.reduce"(%alloc_0, %alloc, %alloc_1) ({
      ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
        "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
        "lmhlo.terminator"() : () -> ()
      }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<110x1300xf32, "gpu">, memref<f32, "gpu">, memref<1300xf32, "gpu">) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
    memref.dealloc %alloc_0 : memref<110x1300xf32, "gpu">
    memref.dealloc %alloc : memref<f32, "gpu">
    %alloc_2 = memref.alloc() : memref<100x13xf32, "gpu">
    "lmhlo.reshape"(%alloc_1, %alloc_2) {disc.device = "gpu"} : (memref<1300xf32, "gpu">, memref<100x13xf32, "gpu">) -> ()
    memref.dealloc %alloc_1 : memref<1300xf32, "gpu">
    %c0_3 = arith.constant 0 : index
    "disc_ral.send_output"(%arg0, %c0_3, %alloc_2) : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
    return
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscLowerToLibraryCallPass (disc-lower-to-library-call) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<110x1300xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.reshape"(%1, %alloc_0) {disc.device = "gpu"} : (memref<110x100x13xf32, "gpu">, memref<110x1300xf32, "gpu">) -> ()
    "lmhlo.reduce"(%alloc_0, %alloc, %alloc_1) ({
    ^bb0(%arg1: memref<f32>, %arg2: memref<f32>, %arg3: memref<f32>):
      "lmhlo.maximum"(%arg1, %arg2, %arg3) {disc.device = "gpu"} : (memref<f32>, memref<f32>, memref<f32>) -> ()
      "lmhlo.terminator"() : () -> ()
    }) {dimensions = dense<0> : tensor<1xi64>, disc.device = "gpu"} : (memref<110x1300xf32, "gpu">, memref<f32, "gpu">, memref<1300xf32, "gpu">) -> ()
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  memref.dealloc %alloc_0 : memref<110x1300xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc_1, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc_1 : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

kColReduction <main_kColReduction_reduce__3_1_0>, use_new: 0 schedule_hint: 1
SymbolicDimMgr::save walkRankedTensorValue takes: 2 us
SymbolicDimMgr::save update attributes takes: 2 us
SymbolicDimMgr::save updateProductEqualityMap takes: 0 us
SymbolicDimMgr::save updateFunctionType takes: 3 us
SymbolicDimMgr::save collect symbolicDim ops takes: 3 us
SymbolicDimMgr::save remove symbolicDim ops takes: 0 us
SymbolicDimMgr::save remove unused production takes: 0 us
SymbolicDimMgr::save remove unused production #2 takes: 0 us
SymbolicDimMgr::save canonicalize the name takes: 0 us
SymbolicDimMgr::save replace the name takes: 2 us
SymbolicDimMgr::save updateFunctionType takes: 0 us
// -----// IR Dump After DiscLhloLegalizeRootsToParallelLoopsPass (disc-lhlo-legalize-roots-to-parallel-loops) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c24 = arith.constant 24 : index //var_blocks
  %c110 = arith.constant 110 : index // var_rows
  %c6 = arith.constant 6 : index //num_blocks_col
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index // var_cols
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<110x1300xf32, "gpu">  // input
  %alloc_1 = memref.alloc() : memref<1300xf32, "gpu">  //output
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.reshape"(%1, %alloc_0) {disc.device = "gpu"} : (memref<110x100x13xf32, "gpu">, memref<110x1300xf32, "gpu">) -> ()
    scf.parallel (%arg1) = (%c0) to (%c1300) step (%c1) { // init_values
      %4 = "disc_shape.delinearize"(%arg1, %c1300) : (index, index) -> index
      %5 = memref.load %alloc[] : memref<f32, "gpu">
      memref.store %5, %alloc_1[%4] : memref<1300xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c24, %c256) step (%c1, %c1) {
      %4 = memref.load %alloc[] : memref<f32, "gpu"> // init_value ?
      %5 = arith.divui %arg1, %c6 : index // block_row_index = m / num_blocks_col;
      %6 = arith.remui %arg1, %c6 : index // block_col_index = m % num_blocks_col;
      %7 = arith.muli %6, %c256 : index
      %8 = arith.addi %7, %arg2 : index //col_index
      %9 = arith.cmpi ult, %8, %c1300 : index
      %10 = scf.if %9 -> (f32) {  // col_index < var_cols
        %11 = scf.for %arg3 = %c0 to %c32 step %c1 iter_args(%arg4 = %4) -> (f32) {//for_op_l
          %12 = arith.muli %5, %c32 : index 
          %13 = arith.addi %12, %arg3 : index  //row_index, %arg3->var_l 
          %14 = arith.cmpi ult, %13, %c110 : index
          %15 = scf.if %14 -> (f32) {
            %16 = memref.load %alloc_0[%13, %8] : memref<110x1300xf32, "gpu"> //global[row_index, col_index]
            %17 = arith.cmpf oge, %arg4, %16 : f32 // ordered and greater than or equal 
            %18 = arith.select %17, %arg4, %16 : f32
            scf.yield %18 : f32
          } else {
            scf.yield %4 : f32
          }
          scf.yield %15 : f32
        }
        scf.yield %11 : f32
      } else {
        scf.yield %4 : f32
      }
      scf.if %9 {
        %11 = memref.atomic_rmw maxf %10, %alloc_1[%8] : (f32, memref<1300xf32, "gpu">) -> f32
      } else {
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  memref.dealloc %alloc_0 : memref<110x1300xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc_1, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc_1 : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<110x1300xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    "lmhlo.constant"(%alloc) {disc.device = "gpu", value = dense<0xFF800000> : tensor<f32>} : (memref<f32, "gpu">) -> ()
    "lmhlo.reshape"(%1, %alloc_0) {disc.device = "gpu"} : (memref<110x100x13xf32, "gpu">, memref<110x1300xf32, "gpu">) -> ()
    scf.parallel (%arg1) = (%c0) to (%c1300) step (%c1) {
      %4 = "disc_shape.delinearize"(%arg1, %c1300) : (index, index) -> index
      %5 = memref.load %alloc[] : memref<f32, "gpu">
      memref.store %5, %alloc_1[%4] : memref<1300xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c24, %c256) step (%c1, %c1) {
      %4 = memref.load %alloc[] : memref<f32, "gpu">
      %5 = arith.divui %arg1, %c6 : index
      %6 = arith.remui %arg1, %c6 : index
      %7 = arith.muli %6, %c256 : index
      %8 = arith.addi %7, %arg2 : index
      %9 = arith.cmpi ult, %8, %c1300 : index
      %10 = scf.if %9 -> (f32) {
        %11 = scf.for %arg3 = %c0 to %c32 step %c1 iter_args(%arg4 = %4) -> (f32) {
          %12 = arith.muli %5, %c32 : index
          %13 = arith.addi %12, %arg3 : index
          %14 = arith.cmpi ult, %13, %c110 : index
          %15 = scf.if %14 -> (f32) {
            %16 = memref.load %alloc_0[%13, %8] : memref<110x1300xf32, "gpu">
            %17 = arith.cmpf oge, %arg4, %16 : f32
            %18 = arith.select %17, %arg4, %16 : f32
            scf.yield %18 : f32
          } else {
            scf.yield %4 : f32
          }
          scf.yield %15 : f32
        }
        scf.yield %11 : f32
      } else {
        scf.yield %4 : f32
      }
      scf.if %9 {
        %11 = memref.generic_atomic_rmw %alloc_1[%8] : memref<1300xf32, "gpu"> {
        ^bb0(%arg3: f32):
          %12 = arith.cmpf ogt, %arg3, %10 : f32
          %13 = arith.select %12, %arg3, %10 : f32
          memref.atomic_yield %13 : f32
        }
      } else {
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  memref.dealloc %alloc_0 : memref<110x1300xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc_1, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc_1 : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After InputInlineFusionPass (disc-input-inline-fusion) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<110x1300xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c1300) step (%c1) {
      %4 = "disc_shape.delinearize"(%arg1, %c1300) : (index, index) -> index
      memref.store %cst, %alloc_1[%4] : memref<1300xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c24, %c256) step (%c1, %c1) {
      %4 = arith.divui %arg1, %c6 : index
      %5 = arith.remui %arg1, %c6 : index
      %6 = arith.muli %5, %c256 : index
      %7 = arith.addi %6, %arg2 : index
      %8 = arith.cmpi ult, %7, %c1300 : index
      %9 = scf.if %8 -> (f32) {
        %10 = scf.for %arg3 = %c0 to %c32 step %c1 iter_args(%arg4 = %cst) -> (f32) {
          %11 = arith.muli %4, %c32 : index
          %12 = arith.addi %11, %arg3 : index
          %13 = arith.cmpi ult, %12, %c110 : index
          %14 = scf.if %13 -> (f32) {
            %15 = "disc_shape.linearize"(%12, %7, %c110, %c1300) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %16:3 = "disc_shape.delinearize"(%15, %c110, %c100, %c13) : (index, index, index, index) -> (index, index, index)
            %17 = memref.load %1[%16#0, %16#1, %16#2] : memref<110x100x13xf32, "gpu">
            %18 = arith.cmpf oge, %arg4, %17 : f32
            %19 = arith.select %18, %arg4, %17 : f32
            scf.yield %19 : f32
          } else {
            scf.yield %cst : f32
          }
          scf.yield %14 : f32
        }
        scf.yield %10 : f32
      } else {
        scf.yield %cst : f32
      }
      scf.if %8 {
        %10 = memref.generic_atomic_rmw %alloc_1[%7] : memref<1300xf32, "gpu"> {
        ^bb0(%arg3: f32):
          %11 = arith.cmpf ogt, %arg3, %9 : f32
          %12 = arith.select %11, %arg3, %9 : f32
          memref.atomic_yield %12 : f32
        }
      } else {
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  memref.dealloc %alloc_0 : memref<110x1300xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc_1, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc_1 : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After DiscFlattenMemrefAccessPass (disc-flatten-memref-access) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<f32, "gpu">
  %alloc_0 = memref.alloc() : memref<110x1300xf32, "gpu">
  %alloc_1 = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c1300) step (%c1) {
      %4 = "disc_shape.delinearize"(%arg1, %c1300) : (index, index) -> index
      %c1300_2 = arith.constant 1300 : index
      %5 = "disc_shape.linearize"(%4, %c1300_2) {operand_segment_sizes = array<i32: 1, 1>} : (index, index) -> index
      %reinterpret_cast_3 = memref.reinterpret_cast %alloc_1 to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
      memref.store %cst, %reinterpret_cast_3[%5] : memref<1300xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c24, %c256) step (%c1, %c1) {
      %4 = arith.divui %arg1, %c6 : index
      %5 = arith.remui %arg1, %c6 : index
      %6 = arith.muli %5, %c256 : index
      %7 = arith.addi %6, %arg2 : index
      %8 = arith.cmpi ult, %7, %c1300 : index
      %9 = scf.if %8 -> (f32) {
        %10 = scf.for %arg3 = %c0 to %c32 step %c1 iter_args(%arg4 = %cst) -> (f32) {
          %11 = arith.muli %4, %c32 : index
          %12 = arith.addi %11, %arg3 : index
          %13 = arith.cmpi ult, %12, %c110 : index
          %14 = scf.if %13 -> (f32) {
            %15 = "disc_shape.linearize"(%12, %7, %c110, %c1300) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %16:3 = "disc_shape.delinearize"(%15, %c110, %c100, %c13) : (index, index, index, index) -> (index, index, index)
            %c110_2 = arith.constant 110 : index
            %c100_3 = arith.constant 100 : index
            %c13_4 = arith.constant 13 : index
            %17 = "disc_shape.linearize"(%16#0, %16#1, %16#2, %c110_2, %c100_3, %c13_4) {operand_segment_sizes = array<i32: 3, 3>} : (index, index, index, index, index, index) -> index
            %reinterpret_cast_5 = memref.reinterpret_cast %1 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
            %18 = memref.load %reinterpret_cast_5[%17] : memref<143000xf32, "gpu">
            %19 = arith.cmpf oge, %arg4, %18 : f32
            %20 = arith.select %19, %arg4, %18 : f32
            scf.yield %20 : f32
          } else {
            scf.yield %cst : f32
          }
          scf.yield %14 : f32
        }
        scf.yield %10 : f32
      } else {
        scf.yield %cst : f32
      }
      scf.if %8 {
        %10 = memref.generic_atomic_rmw %alloc_1[%7] : memref<1300xf32, "gpu"> {
        ^bb0(%arg3: f32):
          %11 = arith.cmpf ogt, %arg3, %9 : f32
          %12 = arith.select %11, %arg3, %9 : f32
          memref.atomic_yield %12 : f32
        }
      } else {
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  memref.dealloc %alloc_0 : memref<110x1300xf32, "gpu">
  memref.dealloc %alloc : memref<f32, "gpu">
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc_1, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc_1 : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After Canonicalizer (disc-canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c1300) step (%c1) {
      %reinterpret_cast_0 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
      memref.store %cst, %reinterpret_cast_0[%arg1] : memref<1300xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c24, %c256) step (%c1, %c1) {
      %4 = arith.divui %arg1, %c6 : index
      %5 = arith.remui %arg1, %c6 : index
      %6 = arith.muli %5, %c256 : index
      %7 = arith.addi %6, %arg2 : index
      %8 = arith.cmpi ult, %7, %c1300 : index
      scf.if %8 {
        %9 = scf.for %arg3 = %c0 to %c32 step %c1 iter_args(%arg4 = %cst) -> (f32) {
          %11 = arith.muli %4, %c32 : index
          %12 = arith.addi %11, %arg3 : index
          %13 = arith.cmpi ult, %12, %c110 : index
          %14 = scf.if %13 -> (f32) {
            %15 = "disc_shape.linearize"(%12, %7, %c110, %c1300) {operand_segment_sizes = array<i32: 2, 2>} : (index, index, index, index) -> index
            %reinterpret_cast_0 = memref.reinterpret_cast %1 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
            %16 = memref.load %reinterpret_cast_0[%15] : memref<143000xf32, "gpu">
            %17 = arith.cmpf oge, %arg4, %16 : f32
            %18 = arith.select %17, %arg4, %16 : f32
            scf.yield %18 : f32
          } else {
            scf.yield %cst : f32
          }
          scf.yield %14 : f32
        }
        %10 = memref.generic_atomic_rmw %alloc[%7] : memref<1300xf32, "gpu"> {
        ^bb0(%arg3: f32):
          %11 = arith.cmpf ogt, %arg3, %9 : f32
          %12 = arith.select %11, %arg3, %9 : f32
          memref.atomic_yield %12 : f32
        }
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ConvertShapeToStandardPass (disc-convert-shape-to-std) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c1300) step (%c1) {
      %reinterpret_cast_0 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
      memref.store %cst, %reinterpret_cast_0[%arg1] : memref<1300xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c24, %c256) step (%c1, %c1) {
      %4 = arith.divui %arg1, %c6 : index
      %5 = arith.remui %arg1, %c6 : index
      %6 = arith.muli %5, %c256 : index
      %7 = arith.addi %6, %arg2 : index
      %8 = arith.cmpi ult, %7, %c1300 : index
      scf.if %8 {
        %9 = scf.for %arg3 = %c0 to %c32 step %c1 iter_args(%arg4 = %cst) -> (f32) {
          %11 = arith.muli %4, %c32 : index
          %12 = arith.addi %11, %arg3 : index
          %13 = arith.cmpi ult, %12, %c110 : index
          %14 = scf.if %13 -> (f32) {
            %c0_0 = arith.constant 0 : index
            %15 = arith.muli %12, %c1300 : index
            %16 = arith.addi %15, %7 : index
            %reinterpret_cast_1 = memref.reinterpret_cast %1 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
            %17 = memref.load %reinterpret_cast_1[%16] : memref<143000xf32, "gpu">
            %18 = arith.cmpf oge, %arg4, %17 : f32
            %19 = arith.select %18, %arg4, %17 : f32
            scf.yield %19 : f32
          } else {
            scf.yield %cst : f32
          }
          scf.yield %14 : f32
        }
        %10 = memref.generic_atomic_rmw %alloc[%7] : memref<1300xf32, "gpu"> {
        ^bb0(%arg3: f32):
          %11 = arith.cmpf ogt, %arg3, %9 : f32
          %12 = arith.select %11, %arg3, %9 : f32
          memref.atomic_yield %12 : f32
        }
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After Canonicalizer (disc-canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c1300) step (%c1) {
      %reinterpret_cast_0 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
      memref.store %cst, %reinterpret_cast_0[%arg1] : memref<1300xf32, "gpu">
      scf.yield
    }
    scf.parallel (%arg1, %arg2) = (%c0, %c0) to (%c24, %c256) step (%c1, %c1) {
      %4 = arith.divui %arg1, %c6 : index
      %5 = arith.remui %arg1, %c6 : index
      %6 = arith.muli %5, %c256 : index
      %7 = arith.addi %6, %arg2 : index
      %8 = arith.cmpi ult, %7, %c1300 : index
      scf.if %8 {
        %9 = scf.for %arg3 = %c0 to %c32 step %c1 iter_args(%arg4 = %cst) -> (f32) {
          %11 = arith.muli %4, %c32 : index
          %12 = arith.addi %11, %arg3 : index
          %13 = arith.cmpi ult, %12, %c110 : index
          %14 = scf.if %13 -> (f32) {
            %15 = arith.muli %12, %c1300 : index
            %16 = arith.addi %15, %7 : index
            %reinterpret_cast_0 = memref.reinterpret_cast %1 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
            %17 = memref.load %reinterpret_cast_0[%16] : memref<143000xf32, "gpu">
            %18 = arith.cmpf oge, %arg4, %17 : f32
            %19 = arith.select %18, %arg4, %17 : f32
            scf.yield %19 : f32
          } else {
            scf.yield %cst : f32
          }
          scf.yield %14 : f32
        }
        %10 = memref.generic_atomic_rmw %alloc[%7] : memref<1300xf32, "gpu"> {
        ^bb0(%arg3: f32):
          %11 = arith.cmpf ogt, %arg3, %9 : f32
          %12 = arith.select %11, %arg3, %9 : f32
          memref.atomic_yield %12 : f32
        }
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ParallelLoopCollapsing (disc-parallel-loop-collapsing) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    scf.parallel (%arg1) = (%c0) to (%c1300) step (%c1) {
      %reinterpret_cast_3 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
      memref.store %cst, %reinterpret_cast_3[%arg1] : memref<1300xf32, "gpu">
      scf.yield
    }
    %c0_0 = arith.constant 0 : index
    %c1_1 = arith.constant 1 : index
    %c1_2 = arith.constant 1 : index
    %4 = arith.muli %c1_2, %c24 : index
    %5 = arith.muli %4, %c256 : index
    scf.parallel (%arg1) = (%c0_0) to (%5) step (%c1_1) {
      %6 = arith.remsi %arg1, %c256 : index
      %7 = arith.divsi %arg1, %c256 : index
      %8 = arith.divui %7, %c6 : index
      %9 = arith.remui %7, %c6 : index
      %10 = arith.muli %9, %c256 : index
      %11 = arith.addi %10, %6 : index
      %12 = arith.cmpi ult, %11, %c1300 : index
      scf.if %12 {
        %13 = scf.for %arg2 = %c0 to %c32 step %c1 iter_args(%arg3 = %cst) -> (f32) {
          %15 = arith.muli %8, %c32 : index
          %16 = arith.addi %15, %arg2 : index
          %17 = arith.cmpi ult, %16, %c110 : index
          %18 = scf.if %17 -> (f32) {
            %19 = arith.muli %16, %c1300 : index
            %20 = arith.addi %19, %11 : index
            %reinterpret_cast_3 = memref.reinterpret_cast %1 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
            %21 = memref.load %reinterpret_cast_3[%20] : memref<143000xf32, "gpu">
            %22 = arith.cmpf oge, %arg3, %21 : f32
            %23 = arith.select %22, %arg3, %21 : f32
            scf.yield %23 : f32
          } else {
            scf.yield %cst : f32
          }
          scf.yield %18 : f32
        }
        %14 = memref.generic_atomic_rmw %alloc[%11] : memref<1300xf32, "gpu"> {
        ^bb0(%arg2: f32):
          %15 = arith.cmpf ogt, %arg2, %13 : f32
          %16 = arith.select %15, %arg2, %13 : f32
          memref.atomic_yield %16 : f32
        }
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After SCFParallelLoopTiling (disc-parallel-loop-tiling) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    %c0_0 = arith.constant 0 : index
    %c256_1 = arith.constant 256 : index
    %4 = arith.muli %c1, %c256_1 : index
    scf.parallel (%arg1) = (%c0) to (%c1300) step (%4) {
      scf.parallel (%arg2) = (%c0_0) to (%4) step (%c1) {
        %8 = arith.addi %arg2, %arg1 : index
        %true = arith.constant true
        %9 = arith.muli %arg2, %c1 : index
        %10 = arith.addi %9, %arg1 : index
        %11 = arith.cmpi ult, %10, %c1300 : index
        %12 = arith.andi %true, %11 : i1
        scf.if %12 {
          %reinterpret_cast_7 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
          memref.store %cst, %reinterpret_cast_7[%8] : memref<1300xf32, "gpu">
        }
        scf.yield
      }
      scf.yield
    }
    %c0_2 = arith.constant 0 : index
    %c1_3 = arith.constant 1 : index
    %c1_4 = arith.constant 1 : index
    %5 = arith.muli %c1_4, %c24 : index
    %6 = arith.muli %5, %c256 : index
    %c0_5 = arith.constant 0 : index
    %c256_6 = arith.constant 256 : index
    %7 = arith.muli %c1_3, %c256_6 : index
    scf.parallel (%arg1) = (%c0_2) to (%6) step (%7) {
      scf.parallel (%arg2) = (%c0_5) to (%7) step (%c1_3) {
        %8 = arith.addi %arg2, %arg1 : index
        %true = arith.constant true
        %9 = arith.muli %arg2, %c1_3 : index
        %10 = arith.addi %9, %arg1 : index
        %11 = arith.cmpi ult, %10, %6 : index
        %12 = arith.andi %true, %11 : i1
        scf.if %12 {
          %13 = arith.remsi %8, %c256 : index
          %14 = arith.divsi %8, %c256 : index
          %15 = arith.divui %14, %c6 : index
          %16 = arith.remui %14, %c6 : index
          %17 = arith.muli %16, %c256 : index
          %18 = arith.addi %17, %13 : index
          %19 = arith.cmpi ult, %18, %c1300 : index
          scf.if %19 {
            %20 = scf.for %arg3 = %c0 to %c32 step %c1 iter_args(%arg4 = %cst) -> (f32) {
              %22 = arith.muli %15, %c32 : index
              %23 = arith.addi %22, %arg3 : index
              %24 = arith.cmpi ult, %23, %c110 : index
              %25 = scf.if %24 -> (f32) {
                %26 = arith.muli %23, %c1300 : index
                %27 = arith.addi %26, %18 : index
                %reinterpret_cast_7 = memref.reinterpret_cast %1 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
                %28 = memref.load %reinterpret_cast_7[%27] : memref<143000xf32, "gpu">
                %29 = arith.cmpf oge, %arg4, %28 : f32
                %30 = arith.select %29, %arg4, %28 : f32
                scf.yield %30 : f32
              } else {
                scf.yield %cst : f32
              }
              scf.yield %25 : f32
            }
            %21 = memref.generic_atomic_rmw %alloc[%18] : memref<1300xf32, "gpu"> {
            ^bb0(%arg3: f32):
              %22 = arith.cmpf ogt, %arg3, %20 : f32
              %23 = arith.select %22, %arg3, %20 : f32
              memref.atomic_yield %23 : f32
            }
          }
        }
        scf.yield
      }
      scf.yield
    }
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After GpuMapParallelLoopsPass (gpu-map-parallel-loops) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    %c0_0 = arith.constant 0 : index
    %c256_1 = arith.constant 256 : index
    %4 = arith.muli %c1, %c256_1 : index
    scf.parallel (%arg1) = (%c0) to (%c1300) step (%4) {
      scf.parallel (%arg2) = (%c0_0) to (%4) step (%c1) {
        %8 = arith.addi %arg2, %arg1 : index
        %true = arith.constant true
        %9 = arith.muli %arg2, %c1 : index
        %10 = arith.addi %9, %arg1 : index
        %11 = arith.cmpi ult, %10, %c1300 : index
        %12 = arith.andi %true, %11 : i1
        scf.if %12 {
          %reinterpret_cast_7 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
          memref.store %cst, %reinterpret_cast_7[%8] : memref<1300xf32, "gpu">
        }
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      scf.yield
    } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
    %c0_2 = arith.constant 0 : index
    %c1_3 = arith.constant 1 : index
    %c1_4 = arith.constant 1 : index
    %5 = arith.muli %c1_4, %c24 : index
    %6 = arith.muli %5, %c256 : index
    %c0_5 = arith.constant 0 : index
    %c256_6 = arith.constant 256 : index
    %7 = arith.muli %c1_3, %c256_6 : index
    scf.parallel (%arg1) = (%c0_2) to (%6) step (%7) {
      scf.parallel (%arg2) = (%c0_5) to (%7) step (%c1_3) {
        %8 = arith.addi %arg2, %arg1 : index
        %true = arith.constant true
        %9 = arith.muli %arg2, %c1_3 : index
        %10 = arith.addi %9, %arg1 : index
        %11 = arith.cmpi ult, %10, %6 : index
        %12 = arith.andi %true, %11 : i1
        scf.if %12 {
          %13 = arith.remsi %8, %c256 : index
          %14 = arith.divsi %8, %c256 : index
          %15 = arith.divui %14, %c6 : index
          %16 = arith.remui %14, %c6 : index
          %17 = arith.muli %16, %c256 : index
          %18 = arith.addi %17, %13 : index
          %19 = arith.cmpi ult, %18, %c1300 : index
          scf.if %19 {
            %20 = scf.for %arg3 = %c0 to %c32 step %c1 iter_args(%arg4 = %cst) -> (f32) {
              %22 = arith.muli %15, %c32 : index
              %23 = arith.addi %22, %arg3 : index
              %24 = arith.cmpi ult, %23, %c110 : index
              %25 = scf.if %24 -> (f32) {
                %26 = arith.muli %23, %c1300 : index
                %27 = arith.addi %26, %18 : index
                %reinterpret_cast_7 = memref.reinterpret_cast %1 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
                %28 = memref.load %reinterpret_cast_7[%27] : memref<143000xf32, "gpu">
                %29 = arith.cmpf oge, %arg4, %28 : f32
                %30 = arith.select %29, %arg4, %28 : f32
                scf.yield %30 : f32
              } else {
                scf.yield %cst : f32
              }
              scf.yield %25 : f32
            }
            %21 = memref.generic_atomic_rmw %alloc[%18] : memref<1300xf32, "gpu"> {
            ^bb0(%arg3: f32):
              %22 = arith.cmpf ogt, %arg3, %20 : f32
              %23 = arith.select %22, %arg3, %20 : f32
              memref.atomic_yield %23 : f32
            }
          }
        }
        scf.yield
      } {mapping = [#gpu.loop_dim_map<processor = thread_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
      scf.yield
    } {mapping = [#gpu.loop_dim_map<processor = block_x, map = (d0) -> (d0), bound = (d0) -> (d0)>]}
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After ConvertParallelLoopToGpu (convert-parallel-loops-to-gpu) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<1300xf32, "gpu">
  "lmhlo.fusion"() ({
    %c0_0 = arith.constant 0 : index
    %c256_1 = arith.constant 256 : index
    %4 = arith.muli %c1, %c256_1 : index
    %c1_2 = arith.constant 1 : index
    %5 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%c1300)[%c0, %4]
    %6 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%4)[%c0_0, %c1]
    gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %5, %arg8 = %c1_2, %arg9 = %c1_2) threads(%arg4, %arg5, %arg6) in (%arg10 = %6, %arg11 = %c1_2, %arg12 = %c1_2) {
      %12 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%4, %c0]
      %13 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %c1300 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %reinterpret_cast_9 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
        memref.store %cst, %reinterpret_cast_9[%14] : memref<1300xf32, "gpu">
      }
      gpu.terminator
    } {SCFToGPU_visited}
    %c0_3 = arith.constant 0 : index
    %c1_4 = arith.constant 1 : index
    %c1_5 = arith.constant 1 : index
    %7 = arith.muli %c1_5, %c24 : index
    %8 = arith.muli %7, %c256 : index
    %c0_6 = arith.constant 0 : index
    %c256_7 = arith.constant 256 : index
    %9 = arith.muli %c1_4, %c256_7 : index
    %c1_8 = arith.constant 1 : index
    %10 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%8)[%c0_3, %9]
    %11 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%9)[%c0_6, %c1_4]
    gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %10, %arg8 = %c1_8, %arg9 = %c1_8) threads(%arg4, %arg5, %arg6) in (%arg10 = %11, %arg11 = %c1_8, %arg12 = %c1_8) {
      %12 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg1)[%9, %c0_3]
      %13 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%arg4)[%c1_4, %c0_6]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1_4 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %8 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remsi %14, %c256 : index
        %20 = arith.divsi %14, %c256 : index
        %21 = arith.divui %20, %c6 : index
        %22 = arith.remui %20, %c6 : index
        %23 = arith.muli %22, %c256 : index
        %24 = arith.addi %23, %19 : index
        %25 = arith.cmpi ult, %24, %c1300 : index
        scf.if %25 {
          %26 = scf.for %arg13 = %c0 to %c32 step %c1 iter_args(%arg14 = %cst) -> (f32) {
            %28 = arith.muli %21, %c32 : index
            %29 = arith.addi %28, %arg13 : index
            %30 = arith.cmpi ult, %29, %c110 : index
            %31 = scf.if %30 -> (f32) {
              %32 = arith.muli %29, %c1300 : index
              %33 = arith.addi %32, %24 : index
              %reinterpret_cast_9 = memref.reinterpret_cast %1 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
              %34 = memref.load %reinterpret_cast_9[%33] : memref<143000xf32, "gpu">
              %35 = arith.cmpf oge, %arg14, %34 : f32
              %36 = arith.select %35, %arg14, %34 : f32
              scf.yield %36 : f32
            } else {
              scf.yield %cst : f32
            }
            scf.yield %31 : f32
          }
          %27 = memref.generic_atomic_rmw %alloc[%24] : memref<1300xf32, "gpu"> {
          ^bb0(%arg13: f32):
            %28 = arith.cmpf ogt, %arg13, %26 : f32
            %29 = arith.select %28, %arg13, %26 : f32
            memref.atomic_yield %29 : f32
          }
        }
      }
      gpu.terminator
    } {SCFToGPU_visited}
    "lmhlo.terminator"() : () -> ()
  }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After GpuLaunchSinkIndexComputations (gpu-launch-sink-index-computations) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %cst = arith.constant 0xFF800000 : f32
    %c24 = arith.constant 24 : index
    %c110 = arith.constant 110 : index
    %c6 = arith.constant 6 : index
    %c32 = arith.constant 32 : index
    %c256 = arith.constant 256 : index
    %c1300 = arith.constant 1300 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c100 = arith.constant 100 : index
    %c1 = arith.constant 1 : index
    %c13 = arith.constant 13 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
    %alloc = memref.alloc() : memref<1300xf32, "gpu">
    "lmhlo.fusion"() ({
      %c0_0 = arith.constant 0 : index
      %c256_1 = arith.constant 256 : index
      %4 = arith.muli %c1, %c256_1 : index
      %c1_2 = arith.constant 1 : index
      %5 = affine.apply #map(%c1300)[%c0, %4]
      %6 = affine.apply #map(%4)[%c0_0, %c1]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %5, %arg8 = %c1_2, %arg9 = %c1_2) threads(%arg4, %arg5, %arg6) in (%arg10 = %6, %arg11 = %c1_2, %arg12 = %c1_2) {
        %c0_9 = arith.constant 0 : index
        %c1_10 = arith.constant 1 : index
        %c0_11 = arith.constant 0 : index
        %c1300_12 = arith.constant 1300 : index
        %cst_13 = arith.constant 0xFF800000 : f32
        %12 = affine.apply #map1(%arg1)[%4, %c0_9]
        %13 = affine.apply #map1(%arg4)[%c1_10, %c0_11]
        %14 = arith.addi %13, %12 : index
        %true = arith.constant true
        %15 = arith.muli %13, %c1_10 : index
        %16 = arith.addi %15, %12 : index
        %17 = arith.cmpi ult, %16, %c1300_12 : index
        %18 = arith.andi %true, %17 : i1
        scf.if %18 {
          %reinterpret_cast_14 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
          memref.store %cst_13, %reinterpret_cast_14[%14] : memref<1300xf32, "gpu">
        }
        gpu.terminator
      } {SCFToGPU_visited}
      %c0_3 = arith.constant 0 : index
      %c1_4 = arith.constant 1 : index
      %c1_5 = arith.constant 1 : index
      %7 = arith.muli %c1_5, %c24 : index
      %8 = arith.muli %7, %c256 : index
      %c0_6 = arith.constant 0 : index
      %c256_7 = arith.constant 256 : index
      %9 = arith.muli %c1_4, %c256_7 : index
      %c1_8 = arith.constant 1 : index
      %10 = affine.apply #map(%8)[%c0_3, %9]
      %11 = affine.apply #map(%9)[%c0_6, %c1_4]
      gpu.launch blocks(%arg1, %arg2, %arg3) in (%arg7 = %10, %arg8 = %c1_8, %arg9 = %c1_8) threads(%arg4, %arg5, %arg6) in (%arg10 = %11, %arg11 = %c1_8, %arg12 = %c1_8) {
        %c0_9 = arith.constant 0 : index
        %c1_10 = arith.constant 1 : index
        %c0_11 = arith.constant 0 : index
        %c256_12 = arith.constant 256 : index
        %c6_13 = arith.constant 6 : index
        %c1300_14 = arith.constant 1300 : index
        %c32_15 = arith.constant 32 : index
        %c110_16 = arith.constant 110 : index
        %cst_17 = arith.constant 0xFF800000 : f32
        %c0_18 = arith.constant 0 : index
        %c1_19 = arith.constant 1 : index
        %12 = affine.apply #map1(%arg1)[%9, %c0_9]
        %13 = affine.apply #map1(%arg4)[%c1_10, %c0_11]
        %14 = arith.addi %13, %12 : index
        %true = arith.constant true
        %15 = arith.muli %13, %c1_10 : index
        %16 = arith.addi %15, %12 : index
        %17 = arith.cmpi ult, %16, %8 : index
        %18 = arith.andi %true, %17 : i1
        scf.if %18 {
          %19 = arith.remsi %14, %c256_12 : index
          %20 = arith.divsi %14, %c256_12 : index
          %21 = arith.divui %20, %c6_13 : index
          %22 = arith.remui %20, %c6_13 : index
          %23 = arith.muli %22, %c256_12 : index
          %24 = arith.addi %23, %19 : index
          %25 = arith.cmpi ult, %24, %c1300_14 : index
          scf.if %25 {
            %26 = scf.for %arg13 = %c0_18 to %c32_15 step %c1_19 iter_args(%arg14 = %cst_17) -> (f32) {
              %28 = arith.muli %21, %c32_15 : index
              %29 = arith.addi %28, %arg13 : index
              %30 = arith.cmpi ult, %29, %c110_16 : index
              %31 = scf.if %30 -> (f32) {
                %32 = arith.muli %29, %c1300_14 : index
                %33 = arith.addi %32, %24 : index
                %reinterpret_cast_20 = memref.reinterpret_cast %1 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
                %34 = memref.load %reinterpret_cast_20[%33] : memref<143000xf32, "gpu">
                %35 = arith.cmpf oge, %arg14, %34 : f32
                %36 = arith.select %35, %arg14, %34 : f32
                scf.yield %36 : f32
              } else {
                scf.yield %cst_17 : f32
              }
              scf.yield %31 : f32
            }
            %27 = memref.generic_atomic_rmw %alloc[%24] : memref<1300xf32, "gpu"> {
            ^bb0(%arg13: f32):
              %28 = arith.cmpf ogt, %arg13, %26 : f32
              %29 = arith.select %28, %arg13, %26 : f32
              memref.atomic_yield %29 : f32
            }
          }
        }
        gpu.terminator
      } {SCFToGPU_visited}
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
    %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
    %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
    memref.dealloc %alloc : memref<1300xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
    return
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After GpuKernelOutlining (gpu-kernel-outlining) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %cst = arith.constant 0xFF800000 : f32
    %c24 = arith.constant 24 : index
    %c110 = arith.constant 110 : index
    %c6 = arith.constant 6 : index
    %c32 = arith.constant 32 : index
    %c256 = arith.constant 256 : index
    %c1300 = arith.constant 1300 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c100 = arith.constant 100 : index
    %c1 = arith.constant 1 : index
    %c13 = arith.constant 13 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
    %alloc = memref.alloc() : memref<1300xf32, "gpu">
    "lmhlo.fusion"() ({
      %c0_0 = arith.constant 0 : index
      %c256_1 = arith.constant 256 : index
      %4 = arith.muli %c1, %c256_1 : index
      %c1_2 = arith.constant 1 : index
      %5 = affine.apply #map(%c1300)[%c0, %4]
      %6 = affine.apply #map(%4)[%c0_0, %c1]
      gpu.launch_func  @main_kernel::@main_kernel blocks in (%5, %c1_2, %c1_2) threads in (%6, %c1_2, %c1_2) args(%4 : index, %alloc : memref<1300xf32, "gpu">)
      %c0_3 = arith.constant 0 : index
      %c1_4 = arith.constant 1 : index
      %c1_5 = arith.constant 1 : index
      %7 = arith.muli %c1_5, %c24 : index
      %8 = arith.muli %7, %c256 : index
      %c0_6 = arith.constant 0 : index
      %c256_7 = arith.constant 256 : index
      %9 = arith.muli %c1_4, %c256_7 : index
      %c1_8 = arith.constant 1 : index
      %10 = affine.apply #map(%8)[%c0_3, %9]
      %11 = affine.apply #map(%9)[%c0_6, %c1_4]
      gpu.launch_func  @main_kernel_0::@main_kernel blocks in (%10, %c1_8, %c1_8) threads in (%11, %c1_8, %c1_8) args(%9 : index, %8 : index, %1 : memref<110x100x13xf32, "gpu">, %alloc : memref<1300xf32, "gpu">)
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
    %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
    %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
    memref.dealloc %alloc : memref<1300xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel {
    gpu.func @main_kernel(%arg0: index, %arg1: memref<1300xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c1300 = arith.constant 1300 : index
      %cst = arith.constant 0xFF800000 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %c1300 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
        memref.store %cst, %reinterpret_cast[%14] : memref<1300xf32, "gpu">
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_0 {
    gpu.func @main_kernel(%arg0: index, %arg1: index, %arg2: memref<110x100x13xf32, "gpu">, %arg3: memref<1300xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %c6 = arith.constant 6 : index
      %c1300 = arith.constant 1300 : index
      %c32 = arith.constant 32 : index
      %c110 = arith.constant 110 : index
      %cst = arith.constant 0xFF800000 : f32
      %c0_1 = arith.constant 0 : index
      %c1_2 = arith.constant 1 : index
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remsi %14, %c256 : index
        %20 = arith.divsi %14, %c256 : index
        %21 = arith.divui %20, %c6 : index
        %22 = arith.remui %20, %c6 : index
        %23 = arith.muli %22, %c256 : index
        %24 = arith.addi %23, %19 : index
        %25 = arith.cmpi ult, %24, %c1300 : index
        scf.if %25 {
          %26 = scf.for %arg4 = %c0_1 to %c32 step %c1_2 iter_args(%arg5 = %cst) -> (f32) {
            %28 = arith.muli %21, %c32 : index
            %29 = arith.addi %28, %arg4 : index
            %30 = arith.cmpi ult, %29, %c110 : index
            %31 = scf.if %30 -> (f32) {
              %32 = arith.muli %29, %c1300 : index
              %33 = arith.addi %32, %24 : index
              %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
              %34 = memref.load %reinterpret_cast[%33] : memref<143000xf32, "gpu">
              %35 = arith.cmpf oge, %arg5, %34 : f32
              %36 = arith.select %35, %arg5, %34 : f32
              scf.yield %36 : f32
            } else {
              scf.yield %cst : f32
            }
            scf.yield %31 : f32
          }
          %27 = memref.generic_atomic_rmw %arg3[%24] : memref<1300xf32, "gpu"> {
          ^bb0(%arg4: f32):
            %28 = arith.cmpf ogt, %arg4, %26 : f32
            %29 = arith.select %28, %arg4, %26 : f32
            memref.atomic_yield %29 : f32
          }
        }
      }
      gpu.return
    }
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After AssignKernelNamePass (disc-assign-kernel-name) //----- //
#map = affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>
#map1 = affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %cst = arith.constant 0xFF800000 : f32
    %c24 = arith.constant 24 : index
    %c110 = arith.constant 110 : index
    %c6 = arith.constant 6 : index
    %c32 = arith.constant 32 : index
    %c256 = arith.constant 256 : index
    %c1300 = arith.constant 1300 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c100 = arith.constant 100 : index
    %c1 = arith.constant 1 : index
    %c13 = arith.constant 13 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
    %alloc = memref.alloc() : memref<1300xf32, "gpu">
    "lmhlo.fusion"() ({
      %c0_0 = arith.constant 0 : index
      %c256_1 = arith.constant 256 : index
      %4 = arith.muli %c1, %c256_1 : index
      %c1_2 = arith.constant 1 : index
      %5 = affine.apply #map(%c1300)[%c0, %4]
      %6 = affine.apply #map(%4)[%c0_0, %c1]
      gpu.launch_func  @main_kernel::@main_kColReduction_reduce__3_1_0 blocks in (%5, %c1_2, %c1_2) threads in (%6, %c1_2, %c1_2) args(%4 : index, %alloc : memref<1300xf32, "gpu">)
      %c0_3 = arith.constant 0 : index
      %c1_4 = arith.constant 1 : index
      %c1_5 = arith.constant 1 : index
      %7 = arith.muli %c1_5, %c24 : index
      %8 = arith.muli %7, %c256 : index
      %c0_6 = arith.constant 0 : index
      %c256_7 = arith.constant 256 : index
      %9 = arith.muli %c1_4, %c256_7 : index
      %c1_8 = arith.constant 1 : index
      %10 = affine.apply #map(%8)[%c0_3, %9]
      %11 = affine.apply #map(%9)[%c0_6, %c1_4]
      gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__3_1_0_1 blocks in (%10, %c1_8, %c1_8) threads in (%11, %c1_8, %c1_8) args(%9 : index, %8 : index, %1 : memref<110x100x13xf32, "gpu">, %alloc : memref<1300xf32, "gpu">)
      "lmhlo.terminator"() : () -> ()
    }) {disc.device = "gpu", disc.fusion.name = "main_kColReduction_reduce__3_1_0", disc.fusion_type = "kColReduction"} : () -> ()
    %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
    %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
    memref.dealloc %alloc : memref<1300xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel {
    gpu.func @main_kColReduction_reduce__3_1_0(%arg0: index, %arg1: memref<1300xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c1300 = arith.constant 1300 : index
      %cst = arith.constant 0xFF800000 : f32
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %c1300 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
        memref.store %cst, %reinterpret_cast[%14] : memref<1300xf32, "gpu">
      }
      gpu.return
    }
  }
  gpu.module @main_kernel_0 {
    gpu.func @main_kColReduction_reduce__3_1_0_1(%arg0: index, %arg1: index, %arg2: memref<110x100x13xf32, "gpu">, %arg3: memref<1300xf32, "gpu">) kernel {
      %0 = gpu.block_id  x
      %1 = gpu.block_id  y
      %2 = gpu.block_id  z
      %3 = gpu.thread_id  x
      %4 = gpu.thread_id  y
      %5 = gpu.thread_id  z
      %6 = gpu.grid_dim  x
      %7 = gpu.grid_dim  y
      %8 = gpu.grid_dim  z
      %9 = gpu.block_dim  x
      %10 = gpu.block_dim  y
      %11 = gpu.block_dim  z
      cf.br ^bb1
    ^bb1:  // pred: ^bb0
      %c0 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c0_0 = arith.constant 0 : index
      %c256 = arith.constant 256 : index
      %c6 = arith.constant 6 : index
      %c1300 = arith.constant 1300 : index
      %c32 = arith.constant 32 : index
      %c110 = arith.constant 110 : index
      %cst = arith.constant 0xFF800000 : f32
      %c0_1 = arith.constant 0 : index
      %c1_2 = arith.constant 1 : index
      %12 = affine.apply #map1(%0)[%arg0, %c0]
      %13 = affine.apply #map1(%3)[%c1, %c0_0]
      %14 = arith.addi %13, %12 : index
      %true = arith.constant true
      %15 = arith.muli %13, %c1 : index
      %16 = arith.addi %15, %12 : index
      %17 = arith.cmpi ult, %16, %arg1 : index
      %18 = arith.andi %true, %17 : i1
      scf.if %18 {
        %19 = arith.remsi %14, %c256 : index
        %20 = arith.divsi %14, %c256 : index
        %21 = arith.divui %20, %c6 : index
        %22 = arith.remui %20, %c6 : index
        %23 = arith.muli %22, %c256 : index
        %24 = arith.addi %23, %19 : index
        %25 = arith.cmpi ult, %24, %c1300 : index
        scf.if %25 {
          %26 = scf.for %arg4 = %c0_1 to %c32 step %c1_2 iter_args(%arg5 = %cst) -> (f32) {
            %28 = arith.muli %21, %c32 : index
            %29 = arith.addi %28, %arg4 : index
            %30 = arith.cmpi ult, %29, %c110 : index
            %31 = scf.if %30 -> (f32) {
              %32 = arith.muli %29, %c1300 : index
              %33 = arith.addi %32, %24 : index
              %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
              %34 = memref.load %reinterpret_cast[%33] : memref<143000xf32, "gpu">
              %35 = arith.cmpf oge, %arg5, %34 : f32
              %36 = arith.select %35, %arg5, %34 : f32
              scf.yield %36 : f32
            } else {
              scf.yield %cst : f32
            }
            scf.yield %31 : f32
          }
          %27 = memref.generic_atomic_rmw %arg3[%24] : memref<1300xf32, "gpu"> {
          ^bb0(%arg4: f32):
            %28 = arith.cmpf ogt, %arg4, %26 : f32
            %29 = arith.select %28, %arg4, %26 : f32
            memref.atomic_yield %29 : f32
          }
        }
      }
      gpu.return
    }
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After LhloFusionInlinerPass (lhlo-fusion-inliner) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %cst = arith.constant 0xFF800000 : f32
  %c24 = arith.constant 24 : index
  %c110 = arith.constant 110 : index
  %c6 = arith.constant 6 : index
  %c32 = arith.constant 32 : index
  %c256 = arith.constant 256 : index
  %c1300 = arith.constant 1300 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<1300xf32, "gpu">
  %c0_0 = arith.constant 0 : index
  %c256_1 = arith.constant 256 : index
  %2 = arith.muli %c1, %c256_1 : index
  %c1_2 = arith.constant 1 : index
  %3 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%c1300)[%c0, %2]
  %4 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%2)[%c0_0, %c1]
  gpu.launch_func  @main_kernel::@main_kColReduction_reduce__3_1_0 blocks in (%3, %c1_2, %c1_2) threads in (%4, %c1_2, %c1_2) args(%2 : index, %alloc : memref<1300xf32, "gpu">)
  %c0_3 = arith.constant 0 : index
  %c1_4 = arith.constant 1 : index
  %c1_5 = arith.constant 1 : index
  %5 = arith.muli %c1_5, %c24 : index
  %6 = arith.muli %5, %c256 : index
  %c0_6 = arith.constant 0 : index
  %c256_7 = arith.constant 256 : index
  %7 = arith.muli %c1_4, %c256_7 : index
  %c1_8 = arith.constant 1 : index
  %8 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%6)[%c0_3, %7]
  %9 = affine.apply affine_map<(d0)[s0, s1] -> ((d0 - s0) ceildiv s1)>(%7)[%c0_6, %c1_4]
  gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__3_1_0_1 blocks in (%8, %c1_8, %c1_8) threads in (%9, %c1_8, %c1_8) args(%7 : index, %6 : index, %1 : memref<110x100x13xf32, "gpu">, %alloc : memref<1300xf32, "gpu">)
  %10 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %11 = "disc_ral.dispatch"(%arg0, %10, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %11 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After SideEffectLoopInvariantCodeMotionPass (disc-side-effect-loop-invariant-code-motion) //----- //
gpu.func @main_kColReduction_reduce__3_1_0(%arg0: index, %arg1: memref<1300xf32, "gpu">) kernel {
  %cst = arith.constant 0xFF800000 : f32
  %c1300 = arith.constant 1300 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = gpu.block_id  x
  %1 = gpu.thread_id  x
  cf.br ^bb1
^bb1:  // pred: ^bb0
  %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
  %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
  %4 = arith.addi %3, %2 : index
  %5 = arith.addi %3, %2 : index
  %6 = arith.cmpi ult, %5, %c1300 : index
  scf.if %6 {
    %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%4] : memref<1300xf32, "gpu">
  }
  gpu.return
}

// -----// IR Dump After CSE (cse) //----- //
gpu.module @main_kernel {
  gpu.func @main_kColReduction_reduce__3_1_0(%arg0: index, %arg1: memref<1300xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1300 = arith.constant 1300 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %c1300 : index
    scf.if %5 {
      %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
      memref.store %cst, %reinterpret_cast[%4] : memref<1300xf32, "gpu">
    }
    gpu.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel {
  gpu.func @main_kColReduction_reduce__3_1_0(%arg0: index, %arg1: memref<1300xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1300 = arith.constant 1300 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %c1300 : index
    cf.cond_br %5, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%4] : memref<1300xf32, "gpu">
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel {
  gpu.func @main_kColReduction_reduce__3_1_0(%arg0: index, %arg1: memref<1300xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1300 = arith.constant 1300 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %c1300 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%6] : memref<1300xf32, "gpu">
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel {
  gpu.func @main_kColReduction_reduce__3_1_0(%arg0: index, %arg1: memref<1300xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c1300 = arith.constant 1300 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %c1300 : index
    cf.cond_br %7, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1300], strides: [1] : memref<1300xf32, "gpu"> to memref<1300xf32, "gpu">
    memref.store %cst, %reinterpret_cast[%6] : memref<1300xf32, "gpu">
    cf.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel {
  llvm.func @main_kColReduction_reduce__3_1_0(%arg0: i32, %arg1: !llvm.ptr<f32>, %arg2: !llvm.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %1 = llvm.insertvalue %arg1, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %2 = llvm.insertvalue %arg2, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %3 = llvm.insertvalue %arg3, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %4 = llvm.insertvalue %arg4, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %5 = llvm.insertvalue %arg5, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %6 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %7 = llvm.mlir.constant(1300 : index) : i32
    %8 = nvvm.read.ptx.sreg.ctaid.x : i32
    %9 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %10 = llvm.mul %8, %arg0  : i32
    %11 = llvm.add %9, %10  : i32
    %12 = llvm.icmp "ult" %11, %7 : i32
    llvm.cond_br %12, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %13 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %14 = llvm.extractvalue %5[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %15 = llvm.extractvalue %5[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %16 = llvm.insertvalue %14, %13[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %17 = llvm.insertvalue %15, %16[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %18 = llvm.mlir.constant(0 : index) : i32
    %19 = llvm.insertvalue %18, %17[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %20 = llvm.mlir.constant(1300 : index) : i32
    %21 = llvm.insertvalue %20, %19[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %22 = llvm.mlir.constant(1 : index) : i32
    %23 = llvm.insertvalue %22, %21[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %24 = llvm.extractvalue %23[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %25 = llvm.getelementptr %24[%11] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %6, %25 : !llvm.ptr<f32>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After LLVMInsertValueSimplifierPass (disc-llvm-insert-value-simplifier) //----- //
llvm.func @main_kColReduction_reduce__3_1_0(%arg0: i32, %arg1: !llvm.ptr<f32>, %arg2: !llvm.ptr<f32>, %arg3: i32, %arg4: i32, %arg5: i32) attributes {gpu.kernel, nvvm.kernel} {
  %0 = llvm.mlir.constant(1300 : index) : i32
  %1 = llvm.mlir.constant(0xFF800000 : f32) : f32
  %2 = nvvm.read.ptx.sreg.ctaid.x : i32
  %3 = nvvm.read.ptx.sreg.tid.x : i32
  llvm.br ^bb1
^bb1:  // pred: ^bb0
  %4 = llvm.mul %2, %arg0  : i32
  %5 = llvm.add %3, %4  : i32
  %6 = llvm.icmp "ult" %5, %0 : i32
  llvm.cond_br %6, ^bb2, ^bb3
^bb2:  // pred: ^bb1
  %7 = llvm.getelementptr %arg2[%5] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  llvm.store %1, %7 : !llvm.ptr<f32>
  llvm.br ^bb3
^bb3:  // 2 preds: ^bb1, ^bb2
  llvm.return
}

// -----// IR Dump After FunctionDeadArgumentEliminationPass (disc-function-dead-argument-elimination) //----- //
gpu.module @main_kernel {
  llvm.func @main_kColReduction_reduce__3_1_0(%arg0: i32, %arg1: !llvm.ptr<f32>) attributes {disc.elimargs = [1 : index, 3 : index, 4 : index, 5 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(1300 : index) : i32
    %1 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %2 = nvvm.read.ptx.sreg.ctaid.x : i32
    %3 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.mul %2, %arg0  : i32
    %5 = llvm.add %3, %4  : i32
    %6 = llvm.icmp "ult" %5, %0 : i32
    llvm.cond_br %6, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %7 = llvm.getelementptr %arg1[%5] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %1, %7 : !llvm.ptr<f32>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel attributes {gpu.binary = "P\EDU\BA\01\00\10\00 \04\00\00\00\00\00\00\02\00\01\01@\00\00\00\E0\03\00\00\00\00\00\00\E0\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\0A\00\01\00\11\08\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\85e__3_1_00\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FA\01debug_frame\00.rel\11\00!nv\14\00\11a;\00\0F\0B\01 \0F\80\00\0D\0F,\01\9Ao_param3\01\1C\0F\01\00\06\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\11$\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00C/\08\00\05_\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\A0\03\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C$\00\10\01N\00%\F0!\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00v\02\02\08\10\0A/\22\EA\03\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00 \01/\05\00\01\00\FF\88A\02z\01\00\E7\03\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%c\02Q\0E\00\19y\03\0F\00 \00!\CD\03\F5\14\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cx\00\02\13\05\00\00p@\F0\03\00\DA\0F\00M\1B\04\A0\80\03\00\EA\0F\005t\03\FF{\03\10\FF\88\03P\E2\0F\00\02x\0E\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\90\D0\0F\00%v\02\02\00Z4\04\00`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F0\01\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=\0B\01\000\00\08\01\00\1F\0B@\00\04\13K)\00\1F3@\00\0C\13\13\E4\03\0C\01\00\13\80\15\00&\90\00\08\04#\04\00]\04\00\CE\04\12\00\01\00\1F\DET\00\00\00\01\00\13\10\95\00/p\00\80\00\0B\1F)'\00\03#\00\80@\00\04\18\06\04\E4\00*\04\00\01\00\1FY@\00\04\13\B01\00&L\00@\00\1F\0A@\00\00\12\FCD\01\0D@\00\04)\00*\D8\00\01\00\1B\08\08\00?\EB\00\00N\07\003\00\00\D8@\00&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01*\E8\04\00\07\1F\00\C0\00\04\132@\00*\06\00\01\00*\80\06\98\07\12\03\C8\05:\08\80\00\01\00\13\06\E0\05\05\A8\0A\0B\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009\18\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
  llvm.func @main_kColReduction_reduce__3_1_0(%arg0: i32, %arg1: !llvm.ptr<f32>) attributes {disc.elimargs = [1 : index, 3 : index, 4 : index, 5 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(1300 : index) : i32
    %1 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %2 = nvvm.read.ptx.sreg.ctaid.x : i32
    %3 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.mul %2, %arg0  : i32
    %5 = llvm.add %3, %4  : i32
    %6 = llvm.icmp "ult" %5, %0 : i32
    llvm.cond_br %6, ^bb2, ^bb3
  ^bb2:  // pred: ^bb1
    %7 = llvm.getelementptr %arg1[%5] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    llvm.store %1, %7 : !llvm.ptr<f32>
    llvm.br ^bb3
  ^bb3:  // 2 preds: ^bb1, ^bb2
    llvm.return
  }
}

// -----// IR Dump After SideEffectLoopInvariantCodeMotionPass (disc-side-effect-loop-invariant-code-motion) //----- //
gpu.func @main_kColReduction_reduce__3_1_0_1(%arg0: index, %arg1: index, %arg2: memref<110x100x13xf32, "gpu">, %arg3: memref<1300xf32, "gpu">) kernel {
  %cst = arith.constant 0xFF800000 : f32
  %c110 = arith.constant 110 : index
  %c32 = arith.constant 32 : index
  %c1300 = arith.constant 1300 : index
  %c6 = arith.constant 6 : index
  %c256 = arith.constant 256 : index
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = gpu.block_id  x
  %1 = gpu.thread_id  x
  cf.br ^bb1
^bb1:  // pred: ^bb0
  %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
  %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
  %4 = arith.addi %3, %2 : index
  %5 = arith.addi %3, %2 : index
  %6 = arith.cmpi ult, %5, %arg1 : index
  scf.if %6 {
    %7 = arith.remsi %4, %c256 : index
    %8 = arith.divsi %4, %c256 : index
    %9 = arith.divui %8, %c6 : index
    %10 = arith.remui %8, %c6 : index
    %11 = arith.muli %10, %c256 : index
    %12 = arith.addi %11, %7 : index
    %13 = arith.cmpi ult, %12, %c1300 : index
    scf.if %13 {
      %14 = arith.muli %9, %c32 : index
      %15 = scf.for %arg4 = %c0 to %c32 step %c1 iter_args(%arg5 = %cst) -> (f32) {
        %17 = arith.addi %14, %arg4 : index
        %18 = arith.cmpi ult, %17, %c110 : index
        %19 = scf.if %18 -> (f32) {
          %20 = arith.muli %17, %c1300 : index
          %21 = arith.addi %20, %12 : index
          %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
          %22 = memref.load %reinterpret_cast[%21] : memref<143000xf32, "gpu">
          %23 = arith.cmpf oge, %arg5, %22 : f32
          %24 = arith.select %23, %arg5, %22 : f32
          scf.yield %24 : f32
        } else {
          scf.yield %cst : f32
        }
        scf.yield %19 : f32
      }
      %16 = memref.generic_atomic_rmw %arg3[%12] : memref<1300xf32, "gpu"> {
      ^bb0(%arg4: f32):
        %17 = arith.cmpf ogt, %arg4, %15 : f32
        %18 = arith.select %17, %arg4, %15 : f32
        memref.atomic_yield %18 : f32
      }
    }
  }
  gpu.return
}

// -----// IR Dump After CSE (cse) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__3_1_0_1(%arg0: index, %arg1: index, %arg2: memref<110x100x13xf32, "gpu">, %arg3: memref<1300xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c110 = arith.constant 110 : index
    %c32 = arith.constant 32 : index
    %c1300 = arith.constant 1300 : index
    %c6 = arith.constant 6 : index
    %c256 = arith.constant 256 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    scf.if %5 {
      %6 = arith.remsi %4, %c256 : index
      %7 = arith.divsi %4, %c256 : index
      %8 = arith.divui %7, %c6 : index
      %9 = arith.remui %7, %c6 : index
      %10 = arith.muli %9, %c256 : index
      %11 = arith.addi %10, %6 : index
      %12 = arith.cmpi ult, %11, %c1300 : index
      scf.if %12 {
        %13 = arith.muli %8, %c32 : index
        %14 = scf.for %arg4 = %c0 to %c32 step %c1 iter_args(%arg5 = %cst) -> (f32) {
          %16 = arith.addi %13, %arg4 : index
          %17 = arith.cmpi ult, %16, %c110 : index
          %18 = scf.if %17 -> (f32) {
            %19 = arith.muli %16, %c1300 : index
            %20 = arith.addi %19, %11 : index
            %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
            %21 = memref.load %reinterpret_cast[%20] : memref<143000xf32, "gpu">
            %22 = arith.cmpf oge, %arg5, %21 : f32
            %23 = arith.select %22, %arg5, %21 : f32
            scf.yield %23 : f32
          } else {
            scf.yield %cst : f32
          }
          scf.yield %18 : f32
        }
        %15 = memref.generic_atomic_rmw %arg3[%11] : memref<1300xf32, "gpu"> {
        ^bb0(%arg4: f32):
          %16 = arith.cmpf ogt, %arg4, %14 : f32
          %17 = arith.select %16, %arg4, %14 : f32
          memref.atomic_yield %17 : f32
        }
      }
    }
    gpu.return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__3_1_0_1(%arg0: index, %arg1: index, %arg2: memref<110x100x13xf32, "gpu">, %arg3: memref<1300xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c110 = arith.constant 110 : index
    %c32 = arith.constant 32 : index
    %c1300 = arith.constant 1300 : index
    %c6 = arith.constant 6 : index
    %c256 = arith.constant 256 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%0)[%arg0, %c0]
    %3 = affine.apply affine_map<(d0)[s0, s1] -> (d0 * s0 + s1)>(%1)[%c1, %c0]
    %4 = arith.addi %3, %2 : index
    %5 = arith.cmpi ult, %4, %arg1 : index
    cf.cond_br %5, ^bb2, ^bb12
  ^bb2:  // pred: ^bb1
    %6 = arith.remsi %4, %c256 : index
    %7 = arith.divsi %4, %c256 : index
    %8 = arith.divui %7, %c6 : index
    %9 = arith.remui %7, %c6 : index
    %10 = arith.muli %9, %c256 : index
    %11 = arith.addi %10, %6 : index
    %12 = arith.cmpi ult, %11, %c1300 : index
    cf.cond_br %12, ^bb3, ^bb11
  ^bb3:  // pred: ^bb2
    %13 = arith.muli %8, %c32 : index
    cf.br ^bb4(%c0, %cst : index, f32)
  ^bb4(%14: index, %15: f32):  // 2 preds: ^bb3, ^bb9
    %16 = arith.cmpi slt, %14, %c32 : index
    cf.cond_br %16, ^bb5, ^bb10
  ^bb5:  // pred: ^bb4
    %17 = arith.addi %13, %14 : index
    %18 = arith.cmpi ult, %17, %c110 : index
    cf.cond_br %18, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %19 = arith.muli %17, %c1300 : index
    %20 = arith.addi %19, %11 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
    %21 = memref.load %reinterpret_cast[%20] : memref<143000xf32, "gpu">
    %22 = arith.cmpf oge, %15, %21 : f32
    %23 = arith.select %22, %15, %21 : f32
    cf.br ^bb8(%23 : f32)
  ^bb7:  // pred: ^bb5
    cf.br ^bb8(%cst : f32)
  ^bb8(%24: f32):  // 2 preds: ^bb6, ^bb7
    cf.br ^bb9
  ^bb9:  // pred: ^bb8
    %25 = arith.addi %14, %c1 : index
    cf.br ^bb4(%25, %24 : index, f32)
  ^bb10:  // pred: ^bb4
    %26 = memref.generic_atomic_rmw %arg3[%11] : memref<1300xf32, "gpu"> {
    ^bb0(%arg4: f32):
      %27 = arith.cmpf ogt, %arg4, %15 : f32
      %28 = arith.select %27, %arg4, %15 : f32
      memref.atomic_yield %28 : f32
    }
    cf.br ^bb11
  ^bb11:  // 2 preds: ^bb2, ^bb10
    cf.br ^bb12
  ^bb12:  // 2 preds: ^bb1, ^bb11
    gpu.return
  }
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__3_1_0_1(%arg0: index, %arg1: index, %arg2: memref<110x100x13xf32, "gpu">, %arg3: memref<1300xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c110 = arith.constant 110 : index
    %c32 = arith.constant 32 : index
    %c1300 = arith.constant 1300 : index
    %c6 = arith.constant 6 : index
    %c256 = arith.constant 256 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb12
  ^bb2:  // pred: ^bb1
    %8 = arith.remsi %6, %c256 : index
    %9 = arith.divsi %6, %c256 : index
    %10 = arith.divui %9, %c6 : index
    %11 = arith.remui %9, %c6 : index
    %12 = arith.muli %11, %c256 : index
    %13 = arith.addi %12, %8 : index
    %14 = arith.cmpi ult, %13, %c1300 : index
    cf.cond_br %14, ^bb3, ^bb11
  ^bb3:  // pred: ^bb2
    %15 = arith.muli %10, %c32 : index
    cf.br ^bb4(%c0, %cst : index, f32)
  ^bb4(%16: index, %17: f32):  // 2 preds: ^bb3, ^bb9
    %18 = arith.cmpi slt, %16, %c32 : index
    cf.cond_br %18, ^bb5, ^bb10
  ^bb5:  // pred: ^bb4
    %19 = arith.addi %15, %16 : index
    %20 = arith.cmpi ult, %19, %c110 : index
    cf.cond_br %20, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %21 = arith.muli %19, %c1300 : index
    %22 = arith.addi %21, %13 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
    %23 = memref.load %reinterpret_cast[%22] : memref<143000xf32, "gpu">
    %24 = arith.cmpf oge, %17, %23 : f32
    %25 = arith.select %24, %17, %23 : f32
    cf.br ^bb8(%25 : f32)
  ^bb7:  // pred: ^bb5
    cf.br ^bb8(%cst : f32)
  ^bb8(%26: f32):  // 2 preds: ^bb6, ^bb7
    cf.br ^bb9
  ^bb9:  // pred: ^bb8
    %27 = arith.addi %16, %c1 : index
    cf.br ^bb4(%27, %26 : index, f32)
  ^bb10:  // pred: ^bb4
    %28 = memref.generic_atomic_rmw %arg3[%13] : memref<1300xf32, "gpu"> {
    ^bb0(%arg4: f32):
      %29 = arith.cmpf ogt, %arg4, %17 : f32
      %30 = arith.select %29, %arg4, %17 : f32
      memref.atomic_yield %30 : f32
    }
    cf.br ^bb11
  ^bb11:  // 2 preds: ^bb2, ^bb10
    cf.br ^bb12
  ^bb12:  // 2 preds: ^bb1, ^bb11
    gpu.return
  }
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
gpu.module @main_kernel_0 {
  gpu.func @main_kColReduction_reduce__3_1_0_1(%arg0: index, %arg1: index, %arg2: memref<110x100x13xf32, "gpu">, %arg3: memref<1300xf32, "gpu">) kernel {
    %cst = arith.constant 0xFF800000 : f32
    %c110 = arith.constant 110 : index
    %c32 = arith.constant 32 : index
    %c1300 = arith.constant 1300 : index
    %c6 = arith.constant 6 : index
    %c256 = arith.constant 256 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = gpu.block_id  x
    %1 = gpu.thread_id  x
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = arith.muli %0, %arg0 : index
    %3 = arith.addi %2, %c0 : index
    %4 = arith.muli %1, %c1 : index
    %5 = arith.addi %4, %c0 : index
    %6 = arith.addi %5, %3 : index
    %7 = arith.cmpi ult, %6, %arg1 : index
    cf.cond_br %7, ^bb2, ^bb12
  ^bb2:  // pred: ^bb1
    %8 = arith.remsi %6, %c256 : index
    %9 = arith.divsi %6, %c256 : index
    %10 = arith.divui %9, %c6 : index
    %11 = arith.remui %9, %c6 : index
    %12 = arith.muli %11, %c256 : index
    %13 = arith.addi %12, %8 : index
    %14 = arith.cmpi ult, %13, %c1300 : index
    cf.cond_br %14, ^bb3, ^bb11
  ^bb3:  // pred: ^bb2
    %15 = arith.muli %10, %c32 : index
    cf.br ^bb4(%c0, %cst : index, f32)
  ^bb4(%16: index, %17: f32):  // 2 preds: ^bb3, ^bb9
    %18 = arith.cmpi slt, %16, %c32 : index
    cf.cond_br %18, ^bb5, ^bb10
  ^bb5:  // pred: ^bb4
    %19 = arith.addi %15, %16 : index
    %20 = arith.cmpi ult, %19, %c110 : index
    cf.cond_br %20, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %21 = arith.muli %19, %c1300 : index
    %22 = arith.addi %21, %13 : index
    %reinterpret_cast = memref.reinterpret_cast %arg2 to offset: [0], sizes: [143000], strides: [1] : memref<110x100x13xf32, "gpu"> to memref<143000xf32, "gpu">
    %23 = memref.load %reinterpret_cast[%22] : memref<143000xf32, "gpu">
    %24 = arith.cmpf oge, %17, %23 : f32
    %25 = arith.select %24, %17, %23 : f32
    cf.br ^bb8(%25 : f32)
  ^bb7:  // pred: ^bb5
    cf.br ^bb8(%cst : f32)
  ^bb8(%26: f32):  // 2 preds: ^bb6, ^bb7
    cf.br ^bb9
  ^bb9:  // pred: ^bb8
    %27 = arith.addi %16, %c1 : index
    cf.br ^bb4(%27, %26 : index, f32)
  ^bb10:  // pred: ^bb4
    %28 = memref.generic_atomic_rmw %arg3[%13] : memref<1300xf32, "gpu"> {
    ^bb0(%arg4: f32):
      %29 = arith.cmpf ogt, %arg4, %17 : f32
      %30 = arith.select %29, %arg4, %17 : f32
      memref.atomic_yield %30 : f32
    }
    cf.br ^bb11
  ^bb11:  // 2 preds: ^bb2, ^bb10
    cf.br ^bb12
  ^bb12:  // 2 preds: ^bb1, ^bb11
    gpu.return
  }
}

// -----// IR Dump After DiscLowerGpuOpsToNVVMOpsPass (disc-convert-gpu-to-nvvm) //----- //
gpu.module @main_kernel_0 {
  llvm.func @main_kColReduction_reduce__3_1_0_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: !llvm.ptr<f32>, %arg12: !llvm.ptr<f32>, %arg13: i32, %arg14: i32, %arg15: i32) attributes {gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)>
    %1 = llvm.insertvalue %arg2, %0[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %2 = llvm.insertvalue %arg3, %1[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %3 = llvm.insertvalue %arg4, %2[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %4 = llvm.insertvalue %arg5, %3[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %5 = llvm.insertvalue %arg8, %4[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %6 = llvm.insertvalue %arg6, %5[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %7 = llvm.insertvalue %arg9, %6[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %8 = llvm.insertvalue %arg7, %7[3, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %9 = llvm.insertvalue %arg10, %8[4, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %10 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %11 = llvm.insertvalue %arg11, %10[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %12 = llvm.insertvalue %arg12, %11[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %13 = llvm.insertvalue %arg13, %12[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %14 = llvm.insertvalue %arg14, %13[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %15 = llvm.insertvalue %arg15, %14[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %16 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %17 = llvm.mlir.constant(110 : index) : i32
    %18 = llvm.mlir.constant(32 : index) : i32
    %19 = llvm.mlir.constant(1300 : index) : i32
    %20 = llvm.mlir.constant(6 : index) : i32
    %21 = llvm.mlir.constant(256 : index) : i32
    %22 = llvm.mlir.constant(1 : index) : i32
    %23 = llvm.mlir.constant(0 : index) : i32
    %24 = nvvm.read.ptx.sreg.ctaid.x : i32
    %25 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %26 = llvm.mul %24, %arg0  : i32
    %27 = llvm.add %25, %26  : i32
    %28 = llvm.icmp "ult" %27, %arg1 : i32
    llvm.cond_br %28, ^bb2, ^bb14
  ^bb2:  // pred: ^bb1
    %29 = llvm.srem %27, %21  : i32
    %30 = llvm.sdiv %27, %21  : i32
    %31 = llvm.udiv %30, %20  : i32
    %32 = llvm.urem %30, %20  : i32
    %33 = llvm.mul %32, %21  : i32
    %34 = llvm.add %33, %29  : i32
    %35 = llvm.icmp "ult" %34, %19 : i32
    llvm.cond_br %35, ^bb3, ^bb13
  ^bb3:  // pred: ^bb2
    %36 = llvm.mul %31, %18  : i32
    llvm.br ^bb4(%23, %16 : i32, f32)
  ^bb4(%37: i32, %38: f32):  // 2 preds: ^bb3, ^bb9
    %39 = llvm.icmp "slt" %37, %18 : i32
    llvm.cond_br %39, ^bb5, ^bb10
  ^bb5:  // pred: ^bb4
    %40 = llvm.add %36, %37  : i32
    %41 = llvm.icmp "ult" %40, %17 : i32
    llvm.cond_br %41, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %42 = llvm.mul %40, %19  : i32
    %43 = llvm.add %42, %34  : i32
    %44 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)>
    %45 = llvm.extractvalue %9[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %46 = llvm.extractvalue %9[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<3 x i32>, array<3 x i32>)> 
    %47 = llvm.insertvalue %45, %44[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %48 = llvm.insertvalue %46, %47[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %49 = llvm.mlir.constant(0 : index) : i32
    %50 = llvm.insertvalue %49, %48[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %51 = llvm.mlir.constant(143000 : index) : i32
    %52 = llvm.insertvalue %51, %50[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %53 = llvm.mlir.constant(1 : index) : i32
    %54 = llvm.insertvalue %53, %52[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %55 = llvm.extractvalue %54[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %56 = llvm.getelementptr %55[%43] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %57 = llvm.load %56 : !llvm.ptr<f32>
    %58 = llvm.fcmp "oge" %38, %57 : f32
    %59 = llvm.select %58, %38, %57 : i1, f32
    llvm.br ^bb8(%59 : f32)
  ^bb7:  // pred: ^bb5
    llvm.br ^bb8(%16 : f32)
  ^bb8(%60: f32):  // 2 preds: ^bb6, ^bb7
    llvm.br ^bb9
  ^bb9:  // pred: ^bb8
    %61 = llvm.add %37, %22  : i32
    llvm.br ^bb4(%61, %60 : i32, f32)
  ^bb10:  // pred: ^bb4
    %62 = llvm.extractvalue %15[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i32, array<1 x i32>, array<1 x i32>)> 
    %63 = llvm.getelementptr %62[%34] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %64 = llvm.load %63 : !llvm.ptr<f32>
    llvm.br ^bb11(%64 : f32)
  ^bb11(%65: f32):  // 2 preds: ^bb10, ^bb11
    %66 = llvm.fcmp "ogt" %65, %38 : f32
    %67 = llvm.select %66, %65, %38 : i1, f32
    %68 = llvm.bitcast %63 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %69 = llvm.bitcast %65 : f32 to i32
    %70 = llvm.bitcast %67 : f32 to i32
    %71 = llvm.cmpxchg %68, %69, %70 acq_rel monotonic : !llvm.ptr<i32>, i32
    %72 = llvm.extractvalue %71[0] : !llvm.struct<(i32, i1)> 
    %73 = llvm.bitcast %72 : i32 to f32
    %74 = llvm.extractvalue %71[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %74, ^bb12, ^bb11(%73 : f32)
  ^bb12:  // pred: ^bb11
    llvm.br ^bb13
  ^bb13:  // 2 preds: ^bb2, ^bb12
    llvm.br ^bb14
  ^bb14:  // 2 preds: ^bb1, ^bb13
    llvm.return
  }
}

// -----// IR Dump After LLVMInsertValueSimplifierPass (disc-llvm-insert-value-simplifier) //----- //
llvm.func @main_kColReduction_reduce__3_1_0_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: !llvm.ptr<f32>, %arg12: !llvm.ptr<f32>, %arg13: i32, %arg14: i32, %arg15: i32) attributes {gpu.kernel, nvvm.kernel} {
  %0 = llvm.mlir.constant(0 : index) : i32
  %1 = llvm.mlir.constant(1 : index) : i32
  %2 = llvm.mlir.constant(256 : index) : i32
  %3 = llvm.mlir.constant(6 : index) : i32
  %4 = llvm.mlir.constant(1300 : index) : i32
  %5 = llvm.mlir.constant(32 : index) : i32
  %6 = llvm.mlir.constant(110 : index) : i32
  %7 = llvm.mlir.constant(0xFF800000 : f32) : f32
  %8 = nvvm.read.ptx.sreg.ctaid.x : i32
  %9 = nvvm.read.ptx.sreg.tid.x : i32
  llvm.br ^bb1
^bb1:  // pred: ^bb0
  %10 = llvm.mul %8, %arg0  : i32
  %11 = llvm.add %9, %10  : i32
  %12 = llvm.icmp "ult" %11, %arg1 : i32
  llvm.cond_br %12, ^bb2, ^bb14
^bb2:  // pred: ^bb1
  %13 = llvm.srem %11, %2  : i32
  %14 = llvm.sdiv %11, %2  : i32
  %15 = llvm.udiv %14, %3  : i32
  %16 = llvm.urem %14, %3  : i32
  %17 = llvm.mul %16, %2  : i32
  %18 = llvm.add %17, %13  : i32
  %19 = llvm.icmp "ult" %18, %4 : i32
  llvm.cond_br %19, ^bb3, ^bb13
^bb3:  // pred: ^bb2
  %20 = llvm.mul %15, %5  : i32
  llvm.br ^bb4(%0, %7 : i32, f32)
^bb4(%21: i32, %22: f32):  // 2 preds: ^bb3, ^bb9
  %23 = llvm.icmp "slt" %21, %5 : i32
  llvm.cond_br %23, ^bb5, ^bb10
^bb5:  // pred: ^bb4
  %24 = llvm.add %20, %21  : i32
  %25 = llvm.icmp "ult" %24, %6 : i32
  llvm.cond_br %25, ^bb6, ^bb7
^bb6:  // pred: ^bb5
  %26 = llvm.mul %24, %4  : i32
  %27 = llvm.add %26, %18  : i32
  %28 = llvm.getelementptr %arg3[%27] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %29 = llvm.load %28 : !llvm.ptr<f32>
  %30 = llvm.fcmp "oge" %22, %29 : f32
  %31 = llvm.select %30, %22, %29 : i1, f32
  llvm.br ^bb8(%31 : f32)
^bb7:  // pred: ^bb5
  llvm.br ^bb8(%7 : f32)
^bb8(%32: f32):  // 2 preds: ^bb6, ^bb7
  llvm.br ^bb9
^bb9:  // pred: ^bb8
  %33 = llvm.add %21, %1  : i32
  llvm.br ^bb4(%33, %32 : i32, f32)
^bb10:  // pred: ^bb4
  %34 = llvm.getelementptr %arg12[%18] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
  %35 = llvm.load %34 : !llvm.ptr<f32>
  llvm.br ^bb11(%35 : f32)
^bb11(%36: f32):  // 2 preds: ^bb10, ^bb11
  %37 = llvm.fcmp "ogt" %36, %22 : f32
  %38 = llvm.select %37, %36, %22 : i1, f32
  %39 = llvm.bitcast %34 : !llvm.ptr<f32> to !llvm.ptr<i32>
  %40 = llvm.bitcast %36 : f32 to i32
  %41 = llvm.bitcast %38 : f32 to i32
  %42 = llvm.cmpxchg %39, %40, %41 acq_rel monotonic : !llvm.ptr<i32>, i32
  %43 = llvm.extractvalue %42[0] : !llvm.struct<(i32, i1)> 
  %44 = llvm.bitcast %43 : i32 to f32
  %45 = llvm.extractvalue %42[1] : !llvm.struct<(i32, i1)> 
  llvm.cond_br %45, ^bb12, ^bb11(%44 : f32)
^bb12:  // pred: ^bb11
  llvm.br ^bb13
^bb13:  // 2 preds: ^bb2, ^bb12
  llvm.br ^bb14
^bb14:  // 2 preds: ^bb1, ^bb13
  llvm.return
}

// -----// IR Dump After FunctionDeadArgumentEliminationPass (disc-function-dead-argument-elimination) //----- //
gpu.module @main_kernel_0 {
  llvm.func @main_kColReduction_reduce__3_1_0_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 10 : index, 11 : index, 13 : index, 14 : index, 15 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(0 : index) : i32
    %1 = llvm.mlir.constant(1 : index) : i32
    %2 = llvm.mlir.constant(256 : index) : i32
    %3 = llvm.mlir.constant(6 : index) : i32
    %4 = llvm.mlir.constant(1300 : index) : i32
    %5 = llvm.mlir.constant(32 : index) : i32
    %6 = llvm.mlir.constant(110 : index) : i32
    %7 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %8 = nvvm.read.ptx.sreg.ctaid.x : i32
    %9 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %10 = llvm.mul %8, %arg0  : i32
    %11 = llvm.add %9, %10  : i32
    %12 = llvm.icmp "ult" %11, %arg1 : i32
    llvm.cond_br %12, ^bb2, ^bb14
  ^bb2:  // pred: ^bb1
    %13 = llvm.srem %11, %2  : i32
    %14 = llvm.sdiv %11, %2  : i32
    %15 = llvm.udiv %14, %3  : i32
    %16 = llvm.urem %14, %3  : i32
    %17 = llvm.mul %16, %2  : i32
    %18 = llvm.add %17, %13  : i32
    %19 = llvm.icmp "ult" %18, %4 : i32
    llvm.cond_br %19, ^bb3, ^bb13
  ^bb3:  // pred: ^bb2
    %20 = llvm.mul %15, %5  : i32
    llvm.br ^bb4(%0, %7 : i32, f32)
  ^bb4(%21: i32, %22: f32):  // 2 preds: ^bb3, ^bb9
    %23 = llvm.icmp "slt" %21, %5 : i32
    llvm.cond_br %23, ^bb5, ^bb10
  ^bb5:  // pred: ^bb4
    %24 = llvm.add %20, %21  : i32
    %25 = llvm.icmp "ult" %24, %6 : i32
    llvm.cond_br %25, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %26 = llvm.mul %24, %4  : i32
    %27 = llvm.add %26, %18  : i32
    %28 = llvm.getelementptr %arg2[%27] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %29 = llvm.load %28 : !llvm.ptr<f32>
    %30 = llvm.fcmp "oge" %22, %29 : f32
    %31 = llvm.select %30, %22, %29 : i1, f32
    llvm.br ^bb8(%31 : f32)
  ^bb7:  // pred: ^bb5
    llvm.br ^bb8(%7 : f32)
  ^bb8(%32: f32):  // 2 preds: ^bb6, ^bb7
    llvm.br ^bb9
  ^bb9:  // pred: ^bb8
    %33 = llvm.add %21, %1  : i32
    llvm.br ^bb4(%33, %32 : i32, f32)
  ^bb10:  // pred: ^bb4
    %34 = llvm.getelementptr %arg3[%18] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %35 = llvm.load %34 : !llvm.ptr<f32>
    llvm.br ^bb11(%35 : f32)
  ^bb11(%36: f32):  // 2 preds: ^bb10, ^bb11
    %37 = llvm.fcmp "ogt" %36, %22 : f32
    %38 = llvm.select %37, %36, %22 : i1, f32
    %39 = llvm.bitcast %34 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %40 = llvm.bitcast %36 : f32 to i32
    %41 = llvm.bitcast %38 : f32 to i32
    %42 = llvm.cmpxchg %39, %40, %41 acq_rel monotonic : !llvm.ptr<i32>, i32
    %43 = llvm.extractvalue %42[0] : !llvm.struct<(i32, i1)> 
    %44 = llvm.bitcast %43 : i32 to f32
    %45 = llvm.extractvalue %42[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %45, ^bb12, ^bb11(%44 : f32)
  ^bb12:  // pred: ^bb11
    llvm.br ^bb13
  ^bb13:  // 2 preds: ^bb2, ^bb12
    llvm.br ^bb14
  ^bb14:  // 2 preds: ^bb1, ^bb13
    llvm.return
  }
}

// -----// IR Dump After GpuKernelToBlobPass (disc-gpu-kernel-to-blob) //----- //
gpu.module @main_kernel_0 attributes {gpu.binary = "P\EDU\BA\01\00\10\00\10\0C\00\00\00\00\00\00\02\00\01\01@\00\00\00\D0\0B\00\00\00\00\00\00\CA\0B\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\1D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\1C\00\01\00\11\1A\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\A5e__3_1_0_12\00\0F,\00\15oshared.\00\12Orela\88\00\17?rel\B5\00\1A\9Fconstant01\00\12\B2debug_framek\00\09\11\00!nv\14\00\11a=\00\0Fn\01 \0F\82\00\0F\0F\91\01\FDo_param\98\01\1C\0F\01\00\06\8CU\00\00\00\03\00\0A\00\01\00 3\01\18\00,\09\00\01\00\11k\18\00,\04\00\01\00\11\89\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\12\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\22\04X\AC\00\90\04/\08\00\05\00\00\00\18\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04h\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\18\00\03\19\18\00\04\17\0C$\00u\03\00\10\00\00\F0!\10\009\02\00\08\10\00\10\01(\01%\F0\11\10\00\01\01\00\C2\F0\11\00\03\1B\FF\00\04\1C\0C\00P%\00r\00\C0\11\00\00\04\1E\A8\00#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08_\00\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00H\01/\05\00\01\00\FF\98@$v\01\FF\1F\04\B1\FF\00\8E\07\00\C4\0F\00\19y\03\18\00 \00%s\02R\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00X\E9\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\B0\80\03\00\EA\0F\00\19x\00\FF\1FL\03\90\14\01\00\00\C8\0F\00\11rX\03`\00\00\FF@\8F\07\10\00A\19x\02\FFI\02\00 \00S\E4\0F\00\12x\09\04\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\AB\AA\AA\AA\A0\00\80\C8\0F\00$x\00\03\010\00P\0A\8E\07\00\E2@\00 \04\FFt\02`\04\16\01\00\00\CA \00\84\05\04\FA\FF\FF\FF\02\020\00D\05\05\00\01\B0\00\CF\0F\00\0Cx\00\05\13\05\00\00p@\B0\00\03c$x\00\04 \00\10\01\B1\E2\0F\04\B9z\04\00\00F\00\00C\05\10\E2 \00\82\03\04\80\9C\00\00\03\02\A0\001\10x\02_\00\D0\FF\E0\FF\07\00\E4\0F\04\0Cx\00\00m\B0\04Q@\F8\03\00\E4p\00\12\02\10\00!\FA\03@\00Dt\02\FF\04`\00\B1\D4\0F\00%\C6\06\03\00Z\00\00\B0\00\93\E4\0F\04\10\D8\09\03\14\05P\00q\C6\0F\00\81\C9\0D\06:\04\B5\19\1E\0C\00\A4\00\00%\D6\08\090\00u\CA\0F\00\81\D9\0F\08 \00\84\E2\02\00\10x\04\00\02\90\00\11\C8\80\003\04m\00\F0\00!\E4\0F \00\1F\03 \00\02\15\F2 \00\17\04\D0\00\22\10x4\05\02\10\00\17/0\00\12\F40\00S\88\0B\03(\0A \00u\CA\0F\00%\86\0A\0B\A0\00\93\E2\0F\00\10\98\07\03<\0F \00u\C8\1F\00\81\89\04\0A\B0\00x\22\01\00%\96\06\070\00B\0Cx\00\08`\00\13\F6\90\00G\09\03P\14\10\01&\99\06\10\01\84\22\03\00\10x\0E\00\06\A0\00W\E2\0F\00%\A6 \01\00\00\02qt\0C\FF\00\00\80\FFp\01\00P\00T\B8\0B\03d\190\00h\1F\00\81\A9\09\08\90\006$t\110\00W\C6\0F\00%\B6\D0\00i\CC\0F\00\81\B9\0A\C0\00@\0B\C8\00\0D0\00\B2\00\C0\FC\03\00\C8O\00\08\C8\0C\10\00!\00\00\C0\00H\0Cx\00\0E\10\02P\0B\D2\00\0C\0F@\00\C6`\FC\03\00\E4\8F\08\10x\0D\00\07p\01B\00\08\D2\11 \00\06@\00\15\0D@\02\97\CA\0F\00\10\C8\0D\03x\1Ep\015\C6\0C\0D\A0\00\00\90\02V\D8\0F\03\8C#P\00E\81\C9\08\0C\B0\00u\A6\10\00%\D6\0E\0F0\00\01@\02%\07\0E \00\84\E2\22\00\0B\82\00\11\04\A0\00i\E2\0F\01$t\13\10\012\08\82\13 \00%\00\000\02%\08\00p\00a\04\0B\92\00\13\06@\00\10\F0@\00F\0C$t\10@\00\00\10\02Hx\0B\00\09\F0\00\22\92\100\00\00\01\00\1B\E4\B0\02\11\C4\10\00\18\0B\A0\02U\0B\A2\00\10\09@\01 \0F\08\80\00\17\0AP\00f\10x\0D\03\A0(\E0\017$t\0F\80\00R/\00\08\A2\0F@\00\06`\01\06\D0\02\00@\02\17\86P\01\84\E2\0F\00\0B\B2\00\0F\0Ap\00\10\C4`\008\06\00\0Bp\00T\98\0B\03\B4-p\00\1A\0F@\02 \E2\0F\F0\02\18\0C0\022\08\B2\11P\00\06\80\00\15\06\F0\02\00\80\00\1B\96@\03V\A8\0F\03\C82\B0\03H\81\99\06\0A\00\03J%\A6\0E\0F\F0\02\0Ap\016\81\A9\09\E0\01\93\22\05\00\10\B8\0D\03\DC7P\00\84\E4\1F\00\10x\0C\00\0D\D0\00\01\C0\00\19\130\037%\B6\0A\10\01\11/`\01$\F0<@\00t\0F\00\0B\C2\00\11\08 \01\00\00\03\22\C2\10\10\00\03\E0\00\00@\04'\0C\000\00G\D2\00\10\07\00\03\06\F0\03\02 \032\08\D2\13 \00\06 \01\18\0C@\056\81\B9\10\00\01*\B0\00\00\03\12\C8\00\03&\04B\D0\00\09\00\03/\E8\02\00\03\0Cy\00\00\10x\11\00\0E\10\01\19\15P\01U\0B\82\00\13\04\F0\00R\0F\01\08\82\15\10\00\06\B0\00\1C\11p\05\18\0F\00\01D\92\00\15\06@\00\01`\00\16\0A`\00b\C6\1F\00\08\92\0A \00\0D\A0\02\02\A0\05G\0B\A2\00\0A\00\03\10\0C\80\05(\18G\B0\00\19\0F\B0\002\08\A2\0F0\00%\00\00\90\00\16\10\E0\00\1D\04\B0\05Dx\06\00\11 \00\1B\C4 \03\00@\00T\98\0D\03,L@\00\1F/\F0\02\01\06\A0\01\10&\E0\05\0AP\03X\10x\09\00\12\10\01H\B2\00\0F\10@\02\22\B2\11\10\00\0F \03\01\01\C0\00D\0F\03@Q\80\00\01\10\03\06\E0\01-\A2\02\00\03\09\A0\02*\E4\8F0\03*\E4\0F\B0\02\02\F0\00\18\09\90\026\81\A9\0E \02\9F\A2\06\00\10\B8\09\03TV\D0\02\05\00\90\04O\08\00\13\00\10\04\076\08\D2\11\E0\02\11\E2`\03\06\B0\06'\E2\1F\00\07\12\FAp\04V\C8\09\03h[p\00\09\00\03\10\A6\00\03(\08\09\A0\06f\10\D8\0D\03|`\A0\016\81\C9\08\E0\06\10\A8\00\03+\0C\0D\00\03\07@\01\1B\00@\02\1A\8F\10\06\01\F0\02\1D\0F\00\06&\14\00P\02\0C\F0\00h\10x\0A\00\15\00\90\05\17\09 \00\00P\04H\0B\03\90e0\01\19\12@\00E\0B\92\00\0FP\06\00 \02\22\92\11\10\00\0D0\06\14\F20\02\18\0A\80\03T\0B\A2\00\11\0E\C0\00\000\03Vx\04\00\16\00P\012\08\A2\09 \00\06\00\02\0A\F0\02Ex\04\00\17\C0\00\0E\A0\05E\0B\B2\00\09\C0\02\1E\C6\F0\01g\10\88\0D\03\A4jp\00\22\B2\110\00\03@\01\06p\00\02\E0\02H\81\99\04\0A\90\01\0C\90\06\00\10\06/\B8o\80\05\04\10\C4\80\03(\06\0C\10\0A\09\F0\02\00\80\02G\C2\12\11\08\80\00\00\B0\02)\18\00\D0\02'\12\07\A0\04\09\00\03\87\E2\08\00\10x\10\00\190\00\09\C0\05\0F\F0\02\00\000\03&\CCtP\042\08\D2\11`\00\06\00\01\18\10\E0\05\0C\10\03\00\00\0A#\E0y@\00\1B\C8\00\03\1F\E2\00\03\03/\F4~\00\03\04\1F\E8\00\03\0C*\E2\04\00\07\11\E2p\04\01{\14\02P\00\00\10\09\16\0B \00\1E\E4\D0\02(\0B\920\03\00\B0\02\0A0\09I\0Cx\00\0F\D0\05\14\820\09\00\A0\02\11\8F\A0\02\17\1B`\01_\08\82\0B\13\060\02\02\02 \09U\0B\A2\00\0B\0Ep\00\01\D0\02\02\10\00\030\00\00\A0\08&\08\84P\00\00`\00\19\1C\E0\0B?\06\00\1D\E0\02\159\E4\0F\08 \03\0Fp\06\00\00\F0\02&\1C\89P\00\0C\D0\026\08\B2\0F\00\03\1E\C4\00\09\0D\80\09I\C2\00\0F\08`\057\0E\00\1E\B0\00\0C\F0\05\000\02'0\8E\80\00\0B\10\032\08\C2\10P\00\0F\A0\0B\01\0C@\0C\1B\E2\E0\05\01\00\0A9\00\00\1F\80\00\0C\F0\02O\0B\03D\93`\0C\07\09\00\06\02\80\00\1B\00\00\03\06\80\01\12\E4\F0\0B#X\98P\00+\C8/\80\0C\0B\00\0C\12\CA\00\09$l\9D\80\00\00\00\09\16\0C\00\01*(\0F\00\09\00\D0\0C9\D9\0E\0EP\00Vv\02\05\00\\P\00E\81y\08\02 \00fb\11\00$t\05\F0\00\10\E4\00\01\1B\00\10\00\1C\07\C0\05\0B\10\03\16\05\10\03\11\C8\00\03\11\05\E0\02\84`\F2\03\00\C8\8F\00\08\10\00\22\00\80p\0F)t\05\80\0CU\0B\A2\00\00\09\10\06R\0F\01\08\A2\05\10\00\00\01\00\11\C8\B0\02&\05\0A \00B\00\08\B2\07\10\00/\00\00P\00\03H\C2\00\07\0C0\00\22\C2\05\10\00\050\00\1A\070\00H\D2\00\05\0E0\00\22\D2\07\10\00\01\80\00a\1F\00\0Br\00\08\E0\01\00\A0\03W\E2\0F\0EFy`\10b\E6\0F\00\08r\09 \00\00\01\00p\CC\0F\00\A9s\09\02\90\02\C0\09\E1\1E\00\00\A4\0E\00\0Cr\00\09\10\00 pR@\00`O\00$r\08\FFM\0E\10\09\80\00\80\D8\0F\00G\09\00\00\90 \11!\FF\83\B0\10*My\C0\10TGy\00\00\F0 \00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\22\01\00P\12\0C\01\00\22@\00\01\00=n\01\000\00\08\01\00\1F\0B@\00\04\13\AE)\00\1F\98@\00\0C\13\13\F4\14\0C\01\00\13HU\00&\90\00\18\15#\04\00m\15\03\A8\16\00\01\00.A\01T\00\00\01\00\13\D8@\00/p\00\80\00\0B\1F)'\00\03#\00He\03\04P\17\04\E4\00*\04\00\01\00\1F[@\00\04\13x)\00&x\00@\00\1F\0A@\00\00!_\01D\01\0D@\00\13\F0)\00*\D8\00\01\00\1B\08\08\00#N\01\D0\03\0B\01\00\13\C8E\16\17\10\80\00\17\048\00\04\18\00\13\10@\01\0C\84\01\13\D8@\00\17x1\01\0F\C0\00\01\132T\01*\06\00\01\00*\80\07\D0\18\12\03\D8\16:\18\80\00\01\00\13\06\F0\16\05\A8\1C\0B\01\00*\A8\00\08\00\17\08\C8\01\17\05\A8\00\0C\01\009(\14\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
  llvm.func @main_kColReduction_reduce__3_1_0_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 10 : index, 11 : index, 13 : index, 14 : index, 15 : index], gpu.kernel, nvvm.kernel} {
    %0 = llvm.mlir.constant(0 : index) : i32
    %1 = llvm.mlir.constant(1 : index) : i32
    %2 = llvm.mlir.constant(256 : index) : i32
    %3 = llvm.mlir.constant(6 : index) : i32
    %4 = llvm.mlir.constant(1300 : index) : i32
    %5 = llvm.mlir.constant(32 : index) : i32
    %6 = llvm.mlir.constant(110 : index) : i32
    %7 = llvm.mlir.constant(0xFF800000 : f32) : f32
    %8 = nvvm.read.ptx.sreg.ctaid.x : i32
    %9 = nvvm.read.ptx.sreg.tid.x : i32
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    %10 = llvm.mul %8, %arg0  : i32
    %11 = llvm.add %9, %10  : i32
    %12 = llvm.icmp "ult" %11, %arg1 : i32
    llvm.cond_br %12, ^bb2, ^bb14
  ^bb2:  // pred: ^bb1
    %13 = llvm.srem %11, %2  : i32
    %14 = llvm.sdiv %11, %2  : i32
    %15 = llvm.udiv %14, %3  : i32
    %16 = llvm.urem %14, %3  : i32
    %17 = llvm.mul %16, %2  : i32
    %18 = llvm.add %17, %13  : i32
    %19 = llvm.icmp "ult" %18, %4 : i32
    llvm.cond_br %19, ^bb3, ^bb13
  ^bb3:  // pred: ^bb2
    %20 = llvm.mul %15, %5  : i32
    llvm.br ^bb4(%0, %7 : i32, f32)
  ^bb4(%21: i32, %22: f32):  // 2 preds: ^bb3, ^bb9
    %23 = llvm.icmp "slt" %21, %5 : i32
    llvm.cond_br %23, ^bb5, ^bb10
  ^bb5:  // pred: ^bb4
    %24 = llvm.add %20, %21  : i32
    %25 = llvm.icmp "ult" %24, %6 : i32
    llvm.cond_br %25, ^bb6, ^bb7
  ^bb6:  // pred: ^bb5
    %26 = llvm.mul %24, %4  : i32
    %27 = llvm.add %26, %18  : i32
    %28 = llvm.getelementptr %arg2[%27] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %29 = llvm.load %28 : !llvm.ptr<f32>
    %30 = llvm.fcmp "oge" %22, %29 : f32
    %31 = llvm.select %30, %22, %29 : i1, f32
    llvm.br ^bb8(%31 : f32)
  ^bb7:  // pred: ^bb5
    llvm.br ^bb8(%7 : f32)
  ^bb8(%32: f32):  // 2 preds: ^bb6, ^bb7
    llvm.br ^bb9
  ^bb9:  // pred: ^bb8
    %33 = llvm.add %21, %1  : i32
    llvm.br ^bb4(%33, %32 : i32, f32)
  ^bb10:  // pred: ^bb4
    %34 = llvm.getelementptr %arg3[%18] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
    %35 = llvm.load %34 : !llvm.ptr<f32>
    llvm.br ^bb11(%35 : f32)
  ^bb11(%36: f32):  // 2 preds: ^bb10, ^bb11
    %37 = llvm.fcmp "ogt" %36, %22 : f32
    %38 = llvm.select %37, %36, %22 : i1, f32
    %39 = llvm.bitcast %34 : !llvm.ptr<f32> to !llvm.ptr<i32>
    %40 = llvm.bitcast %36 : f32 to i32
    %41 = llvm.bitcast %38 : f32 to i32
    %42 = llvm.cmpxchg %39, %40, %41 acq_rel monotonic : !llvm.ptr<i32>, i32
    %43 = llvm.extractvalue %42[0] : !llvm.struct<(i32, i1)> 
    %44 = llvm.bitcast %43 : i32 to f32
    %45 = llvm.extractvalue %42[1] : !llvm.struct<(i32, i1)> 
    llvm.cond_br %45, ^bb12, ^bb11(%44 : f32)
  ^bb12:  // pred: ^bb11
    llvm.br ^bb13
  ^bb13:  // 2 preds: ^bb2, ^bb12
    llvm.br ^bb14
  ^bb14:  // 2 preds: ^bb1, ^bb13
    llvm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
  %c256 = arith.constant 256 : index
  %c24 = arith.constant 24 : index
  %c6144 = arith.constant 6144 : index
  %c6 = arith.constant 6 : index
  %0 = llvm.mlir.constant(0 : i32) : i32
  %c0 = arith.constant 0 : index
  %c100 = arith.constant 100 : index
  %c1 = arith.constant 1 : index
  %c13 = arith.constant 13 : index
  %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
  %alloc = memref.alloc() : memref<1300xf32, "gpu">
  gpu.launch_func  @main_kernel::@main_kColReduction_reduce__3_1_0 blocks in (%c6, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %alloc : memref<1300xf32, "gpu">)
  gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__3_1_0_1 blocks in (%c24, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %c6144 : index, %1 : memref<110x100x13xf32, "gpu">, %alloc : memref<1300xf32, "gpu">)
  %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
  %alloca = memref.alloca() : memref<2xindex, "cpu">
  memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
  memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
  %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
  %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
  memref.dealloc %alloc : memref<1300xf32, "gpu">
  "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
  return
}

// -----// IR Dump After StripDebugInfo (strip-debuginfo) //----- //
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c256 = arith.constant 256 : index
    %c24 = arith.constant 24 : index
    %c6144 = arith.constant 6144 : index
    %c6 = arith.constant 6 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c100 = arith.constant 100 : index
    %c1 = arith.constant 1 : index
    %c13 = arith.constant 13 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
    %alloc = memref.alloc() : memref<1300xf32, "gpu">
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__3_1_0 blocks in (%c6, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %alloc : memref<1300xf32, "gpu">)
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__3_1_0_1 blocks in (%c24, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %c6144 : index, %1 : memref<110x100x13xf32, "gpu">, %alloc : memref<1300xf32, "gpu">)
    %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
    %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
    memref.dealloc %alloc : memref<1300xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary = "P\EDU\BA\01\00\10\00 \04\00\00\00\00\00\00\02\00\01\01@\00\00\00\E0\03\00\00\00\00\00\00\E0\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\0A\00\01\00\11\08\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\85e__3_1_00\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FA\01debug_frame\00.rel\11\00!nv\14\00\11a;\00\0F\0B\01 \0F\80\00\0D\0F,\01\9Ao_param3\01\1C\0F\01\00\06\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\11$\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00C/\08\00\05_\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\A0\03\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C$\00\10\01N\00%\F0!\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00v\02\02\08\10\0A/\22\EA\03\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00 \01/\05\00\01\00\FF\88A\02z\01\00\E7\03\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%c\02Q\0E\00\19y\03\0F\00 \00!\CD\03\F5\14\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cx\00\02\13\05\00\00p@\F0\03\00\DA\0F\00M\1B\04\A0\80\03\00\EA\0F\005t\03\FF{\03\10\FF\88\03P\E2\0F\00\02x\0E\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\90\D0\0F\00%v\02\02\00Z4\04\00`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F0\01\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=\0B\01\000\00\08\01\00\1F\0B@\00\04\13K)\00\1F3@\00\0C\13\13\E4\03\0C\01\00\13\80\15\00&\90\00\08\04#\04\00]\04\00\CE\04\12\00\01\00\1F\DET\00\00\00\01\00\13\10\95\00/p\00\80\00\0B\1F)'\00\03#\00\80@\00\04\18\06\04\E4\00*\04\00\01\00\1FY@\00\04\13\B01\00&L\00@\00\1F\0A@\00\00\12\FCD\01\0D@\00\04)\00*\D8\00\01\00\1B\08\08\00?\EB\00\00N\07\003\00\00\D8@\00&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01*\E8\04\00\07\1F\00\C0\00\04\132@\00*\06\00\01\00*\80\06\98\07\12\03\C8\05:\08\80\00\01\00\13\06\E0\05\05\A8\0A\0B\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009\18\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__3_1_0(%arg0: i32, %arg1: !llvm.ptr<f32>) attributes {disc.elimargs = [1 : index, 3 : index, 4 : index, 5 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(1300 : index) : i32
      %1 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %2 = nvvm.read.ptx.sreg.ctaid.x : i32
      %3 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %4 = llvm.mul %2, %arg0  : i32
      %5 = llvm.add %3, %4  : i32
      %6 = llvm.icmp "ult" %5, %0 : i32
      llvm.cond_br %6, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %7 = llvm.getelementptr %arg1[%5] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %1, %7 : !llvm.ptr<f32>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary = "P\EDU\BA\01\00\10\00\10\0C\00\00\00\00\00\00\02\00\01\01@\00\00\00\D0\0B\00\00\00\00\00\00\CA\0B\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\1D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\1C\00\01\00\11\1A\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\A5e__3_1_0_12\00\0F,\00\15oshared.\00\12Orela\88\00\17?rel\B5\00\1A\9Fconstant01\00\12\B2debug_framek\00\09\11\00!nv\14\00\11a=\00\0Fn\01 \0F\82\00\0F\0F\91\01\FDo_param\98\01\1C\0F\01\00\06\8CU\00\00\00\03\00\0A\00\01\00 3\01\18\00,\09\00\01\00\11k\18\00,\04\00\01\00\11\89\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\12\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\22\04X\AC\00\90\04/\08\00\05\00\00\00\18\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04h\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\18\00\03\19\18\00\04\17\0C$\00u\03\00\10\00\00\F0!\10\009\02\00\08\10\00\10\01(\01%\F0\11\10\00\01\01\00\C2\F0\11\00\03\1B\FF\00\04\1C\0C\00P%\00r\00\C0\11\00\00\04\1E\A8\00#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08_\00\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00H\01/\05\00\01\00\FF\98@$v\01\FF\1F\04\B1\FF\00\8E\07\00\C4\0F\00\19y\03\18\00 \00%s\02R\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00X\E9\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\B0\80\03\00\EA\0F\00\19x\00\FF\1FL\03\90\14\01\00\00\C8\0F\00\11rX\03`\00\00\FF@\8F\07\10\00A\19x\02\FFI\02\00 \00S\E4\0F\00\12x\09\04\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\AB\AA\AA\AA\A0\00\80\C8\0F\00$x\00\03\010\00P\0A\8E\07\00\E2@\00 \04\FFt\02`\04\16\01\00\00\CA \00\84\05\04\FA\FF\FF\FF\02\020\00D\05\05\00\01\B0\00\CF\0F\00\0Cx\00\05\13\05\00\00p@\B0\00\03c$x\00\04 \00\10\01\B1\E2\0F\04\B9z\04\00\00F\00\00C\05\10\E2 \00\82\03\04\80\9C\00\00\03\02\A0\001\10x\02_\00\D0\FF\E0\FF\07\00\E4\0F\04\0Cx\00\00m\B0\04Q@\F8\03\00\E4p\00\12\02\10\00!\FA\03@\00Dt\02\FF\04`\00\B1\D4\0F\00%\C6\06\03\00Z\00\00\B0\00\93\E4\0F\04\10\D8\09\03\14\05P\00q\C6\0F\00\81\C9\0D\06:\04\B5\19\1E\0C\00\A4\00\00%\D6\08\090\00u\CA\0F\00\81\D9\0F\08 \00\84\E2\02\00\10x\04\00\02\90\00\11\C8\80\003\04m\00\F0\00!\E4\0F \00\1F\03 \00\02\15\F2 \00\17\04\D0\00\22\10x4\05\02\10\00\17/0\00\12\F40\00S\88\0B\03(\0A \00u\CA\0F\00%\86\0A\0B\A0\00\93\E2\0F\00\10\98\07\03<\0F \00u\C8\1F\00\81\89\04\0A\B0\00x\22\01\00%\96\06\070\00B\0Cx\00\08`\00\13\F6\90\00G\09\03P\14\10\01&\99\06\10\01\84\22\03\00\10x\0E\00\06\A0\00W\E2\0F\00%\A6 \01\00\00\02qt\0C\FF\00\00\80\FFp\01\00P\00T\B8\0B\03d\190\00h\1F\00\81\A9\09\08\90\006$t\110\00W\C6\0F\00%\B6\D0\00i\CC\0F\00\81\B9\0A\C0\00@\0B\C8\00\0D0\00\B2\00\C0\FC\03\00\C8O\00\08\C8\0C\10\00!\00\00\C0\00H\0Cx\00\0E\10\02P\0B\D2\00\0C\0F@\00\C6`\FC\03\00\E4\8F\08\10x\0D\00\07p\01B\00\08\D2\11 \00\06@\00\15\0D@\02\97\CA\0F\00\10\C8\0D\03x\1Ep\015\C6\0C\0D\A0\00\00\90\02V\D8\0F\03\8C#P\00E\81\C9\08\0C\B0\00u\A6\10\00%\D6\0E\0F0\00\01@\02%\07\0E \00\84\E2\22\00\0B\82\00\11\04\A0\00i\E2\0F\01$t\13\10\012\08\82\13 \00%\00\000\02%\08\00p\00a\04\0B\92\00\13\06@\00\10\F0@\00F\0C$t\10@\00\00\10\02Hx\0B\00\09\F0\00\22\92\100\00\00\01\00\1B\E4\B0\02\11\C4\10\00\18\0B\A0\02U\0B\A2\00\10\09@\01 \0F\08\80\00\17\0AP\00f\10x\0D\03\A0(\E0\017$t\0F\80\00R/\00\08\A2\0F@\00\06`\01\06\D0\02\00@\02\17\86P\01\84\E2\0F\00\0B\B2\00\0F\0Ap\00\10\C4`\008\06\00\0Bp\00T\98\0B\03\B4-p\00\1A\0F@\02 \E2\0F\F0\02\18\0C0\022\08\B2\11P\00\06\80\00\15\06\F0\02\00\80\00\1B\96@\03V\A8\0F\03\C82\B0\03H\81\99\06\0A\00\03J%\A6\0E\0F\F0\02\0Ap\016\81\A9\09\E0\01\93\22\05\00\10\B8\0D\03\DC7P\00\84\E4\1F\00\10x\0C\00\0D\D0\00\01\C0\00\19\130\037%\B6\0A\10\01\11/`\01$\F0<@\00t\0F\00\0B\C2\00\11\08 \01\00\00\03\22\C2\10\10\00\03\E0\00\00@\04'\0C\000\00G\D2\00\10\07\00\03\06\F0\03\02 \032\08\D2\13 \00\06 \01\18\0C@\056\81\B9\10\00\01*\B0\00\00\03\12\C8\00\03&\04B\D0\00\09\00\03/\E8\02\00\03\0Cy\00\00\10x\11\00\0E\10\01\19\15P\01U\0B\82\00\13\04\F0\00R\0F\01\08\82\15\10\00\06\B0\00\1C\11p\05\18\0F\00\01D\92\00\15\06@\00\01`\00\16\0A`\00b\C6\1F\00\08\92\0A \00\0D\A0\02\02\A0\05G\0B\A2\00\0A\00\03\10\0C\80\05(\18G\B0\00\19\0F\B0\002\08\A2\0F0\00%\00\00\90\00\16\10\E0\00\1D\04\B0\05Dx\06\00\11 \00\1B\C4 \03\00@\00T\98\0D\03,L@\00\1F/\F0\02\01\06\A0\01\10&\E0\05\0AP\03X\10x\09\00\12\10\01H\B2\00\0F\10@\02\22\B2\11\10\00\0F \03\01\01\C0\00D\0F\03@Q\80\00\01\10\03\06\E0\01-\A2\02\00\03\09\A0\02*\E4\8F0\03*\E4\0F\B0\02\02\F0\00\18\09\90\026\81\A9\0E \02\9F\A2\06\00\10\B8\09\03TV\D0\02\05\00\90\04O\08\00\13\00\10\04\076\08\D2\11\E0\02\11\E2`\03\06\B0\06'\E2\1F\00\07\12\FAp\04V\C8\09\03h[p\00\09\00\03\10\A6\00\03(\08\09\A0\06f\10\D8\0D\03|`\A0\016\81\C9\08\E0\06\10\A8\00\03+\0C\0D\00\03\07@\01\1B\00@\02\1A\8F\10\06\01\F0\02\1D\0F\00\06&\14\00P\02\0C\F0\00h\10x\0A\00\15\00\90\05\17\09 \00\00P\04H\0B\03\90e0\01\19\12@\00E\0B\92\00\0FP\06\00 \02\22\92\11\10\00\0D0\06\14\F20\02\18\0A\80\03T\0B\A2\00\11\0E\C0\00\000\03Vx\04\00\16\00P\012\08\A2\09 \00\06\00\02\0A\F0\02Ex\04\00\17\C0\00\0E\A0\05E\0B\B2\00\09\C0\02\1E\C6\F0\01g\10\88\0D\03\A4jp\00\22\B2\110\00\03@\01\06p\00\02\E0\02H\81\99\04\0A\90\01\0C\90\06\00\10\06/\B8o\80\05\04\10\C4\80\03(\06\0C\10\0A\09\F0\02\00\80\02G\C2\12\11\08\80\00\00\B0\02)\18\00\D0\02'\12\07\A0\04\09\00\03\87\E2\08\00\10x\10\00\190\00\09\C0\05\0F\F0\02\00\000\03&\CCtP\042\08\D2\11`\00\06\00\01\18\10\E0\05\0C\10\03\00\00\0A#\E0y@\00\1B\C8\00\03\1F\E2\00\03\03/\F4~\00\03\04\1F\E8\00\03\0C*\E2\04\00\07\11\E2p\04\01{\14\02P\00\00\10\09\16\0B \00\1E\E4\D0\02(\0B\920\03\00\B0\02\0A0\09I\0Cx\00\0F\D0\05\14\820\09\00\A0\02\11\8F\A0\02\17\1B`\01_\08\82\0B\13\060\02\02\02 \09U\0B\A2\00\0B\0Ep\00\01\D0\02\02\10\00\030\00\00\A0\08&\08\84P\00\00`\00\19\1C\E0\0B?\06\00\1D\E0\02\159\E4\0F\08 \03\0Fp\06\00\00\F0\02&\1C\89P\00\0C\D0\026\08\B2\0F\00\03\1E\C4\00\09\0D\80\09I\C2\00\0F\08`\057\0E\00\1E\B0\00\0C\F0\05\000\02'0\8E\80\00\0B\10\032\08\C2\10P\00\0F\A0\0B\01\0C@\0C\1B\E2\E0\05\01\00\0A9\00\00\1F\80\00\0C\F0\02O\0B\03D\93`\0C\07\09\00\06\02\80\00\1B\00\00\03\06\80\01\12\E4\F0\0B#X\98P\00+\C8/\80\0C\0B\00\0C\12\CA\00\09$l\9D\80\00\00\00\09\16\0C\00\01*(\0F\00\09\00\D0\0C9\D9\0E\0EP\00Vv\02\05\00\\P\00E\81y\08\02 \00fb\11\00$t\05\F0\00\10\E4\00\01\1B\00\10\00\1C\07\C0\05\0B\10\03\16\05\10\03\11\C8\00\03\11\05\E0\02\84`\F2\03\00\C8\8F\00\08\10\00\22\00\80p\0F)t\05\80\0CU\0B\A2\00\00\09\10\06R\0F\01\08\A2\05\10\00\00\01\00\11\C8\B0\02&\05\0A \00B\00\08\B2\07\10\00/\00\00P\00\03H\C2\00\07\0C0\00\22\C2\05\10\00\050\00\1A\070\00H\D2\00\05\0E0\00\22\D2\07\10\00\01\80\00a\1F\00\0Br\00\08\E0\01\00\A0\03W\E2\0F\0EFy`\10b\E6\0F\00\08r\09 \00\00\01\00p\CC\0F\00\A9s\09\02\90\02\C0\09\E1\1E\00\00\A4\0E\00\0Cr\00\09\10\00 pR@\00`O\00$r\08\FFM\0E\10\09\80\00\80\D8\0F\00G\09\00\00\90 \11!\FF\83\B0\10*My\C0\10TGy\00\00\F0 \00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\22\01\00P\12\0C\01\00\22@\00\01\00=n\01\000\00\08\01\00\1F\0B@\00\04\13\AE)\00\1F\98@\00\0C\13\13\F4\14\0C\01\00\13HU\00&\90\00\18\15#\04\00m\15\03\A8\16\00\01\00.A\01T\00\00\01\00\13\D8@\00/p\00\80\00\0B\1F)'\00\03#\00He\03\04P\17\04\E4\00*\04\00\01\00\1F[@\00\04\13x)\00&x\00@\00\1F\0A@\00\00!_\01D\01\0D@\00\13\F0)\00*\D8\00\01\00\1B\08\08\00#N\01\D0\03\0B\01\00\13\C8E\16\17\10\80\00\17\048\00\04\18\00\13\10@\01\0C\84\01\13\D8@\00\17x1\01\0F\C0\00\01\132T\01*\06\00\01\00*\80\07\D0\18\12\03\D8\16:\18\80\00\01\00\13\06\F0\16\05\A8\1C\0B\01\00*\A8\00\08\00\17\08\C8\01\17\05\A8\00\0C\01\009(\14\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__3_1_0_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 10 : index, 11 : index, 13 : index, 14 : index, 15 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0 : index) : i32
      %1 = llvm.mlir.constant(1 : index) : i32
      %2 = llvm.mlir.constant(256 : index) : i32
      %3 = llvm.mlir.constant(6 : index) : i32
      %4 = llvm.mlir.constant(1300 : index) : i32
      %5 = llvm.mlir.constant(32 : index) : i32
      %6 = llvm.mlir.constant(110 : index) : i32
      %7 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %8 = nvvm.read.ptx.sreg.ctaid.x : i32
      %9 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %10 = llvm.mul %8, %arg0  : i32
      %11 = llvm.add %9, %10  : i32
      %12 = llvm.icmp "ult" %11, %arg1 : i32
      llvm.cond_br %12, ^bb2, ^bb14
    ^bb2:  // pred: ^bb1
      %13 = llvm.srem %11, %2  : i32
      %14 = llvm.sdiv %11, %2  : i32
      %15 = llvm.udiv %14, %3  : i32
      %16 = llvm.urem %14, %3  : i32
      %17 = llvm.mul %16, %2  : i32
      %18 = llvm.add %17, %13  : i32
      %19 = llvm.icmp "ult" %18, %4 : i32
      llvm.cond_br %19, ^bb3, ^bb13
    ^bb3:  // pred: ^bb2
      %20 = llvm.mul %15, %5  : i32
      llvm.br ^bb4(%0, %7 : i32, f32)
    ^bb4(%21: i32, %22: f32):  // 2 preds: ^bb3, ^bb9
      %23 = llvm.icmp "slt" %21, %5 : i32
      llvm.cond_br %23, ^bb5, ^bb10
    ^bb5:  // pred: ^bb4
      %24 = llvm.add %20, %21  : i32
      %25 = llvm.icmp "ult" %24, %6 : i32
      llvm.cond_br %25, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      %26 = llvm.mul %24, %4  : i32
      %27 = llvm.add %26, %18  : i32
      %28 = llvm.getelementptr %arg2[%27] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %29 = llvm.load %28 : !llvm.ptr<f32>
      %30 = llvm.fcmp "oge" %22, %29 : f32
      %31 = llvm.select %30, %22, %29 : i1, f32
      llvm.br ^bb8(%31 : f32)
    ^bb7:  // pred: ^bb5
      llvm.br ^bb8(%7 : f32)
    ^bb8(%32: f32):  // 2 preds: ^bb6, ^bb7
      llvm.br ^bb9
    ^bb9:  // pred: ^bb8
      %33 = llvm.add %21, %1  : i32
      llvm.br ^bb4(%33, %32 : i32, f32)
    ^bb10:  // pred: ^bb4
      %34 = llvm.getelementptr %arg3[%18] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %35 = llvm.load %34 : !llvm.ptr<f32>
      llvm.br ^bb11(%35 : f32)
    ^bb11(%36: f32):  // 2 preds: ^bb10, ^bb11
      %37 = llvm.fcmp "ogt" %36, %22 : f32
      %38 = llvm.select %37, %36, %22 : i1, f32
      %39 = llvm.bitcast %34 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %40 = llvm.bitcast %36 : f32 to i32
      %41 = llvm.bitcast %38 : f32 to i32
      %42 = llvm.cmpxchg %39, %40, %41 acq_rel monotonic : !llvm.ptr<i32>, i32
      %43 = llvm.extractvalue %42[0] : !llvm.struct<(i32, i1)> 
      %44 = llvm.bitcast %43 : i32 to f32
      %45 = llvm.extractvalue %42[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %45, ^bb12, ^bb11(%44 : f32)
    ^bb12:  // pred: ^bb11
      llvm.br ^bb13
    ^bb13:  // 2 preds: ^bb2, ^bb12
      llvm.br ^bb14
    ^bb14:  // 2 preds: ^bb1, ^bb13
      llvm.return
    }
  }
  func.func @shape_constraint_graph() {
    return
  }
}


// -----// IR Dump After DiscStripShapeConstraintOpsPass (disc-strip-shape-constraint-ops) //----- //
module attributes {gpu.container_module} {
  func.func @main(%arg0: !disc_ral.context) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %c256 = arith.constant 256 : index
    %c24 = arith.constant 24 : index
    %c6144 = arith.constant 6144 : index
    %c6 = arith.constant 6 : index
    %0 = llvm.mlir.constant(0 : i32) : i32
    %c0 = arith.constant 0 : index
    %c100 = arith.constant 100 : index
    %c1 = arith.constant 1 : index
    %c13 = arith.constant 13 : index
    %1 = "disc_ral.dispatch"(%arg0, %c0) {backend_config = "", call_target_name = "ral_recv_input", device = "cpu", has_side_effect = false} : (!disc_ral.context, index) -> memref<110x100x13xf32, "gpu">
    %alloc = memref.alloc() : memref<1300xf32, "gpu">
    gpu.launch_func  @main_kernel::@main_kColReduction_reduce__3_1_0 blocks in (%c6, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %alloc : memref<1300xf32, "gpu">)
    gpu.launch_func  @main_kernel_0::@main_kColReduction_reduce__3_1_0_1 blocks in (%c24, %c1, %c1) threads in (%c256, %c1, %c1) args(%c256 : index, %c6144 : index, %1 : memref<110x100x13xf32, "gpu">, %alloc : memref<1300xf32, "gpu">)
    %2 = llvm.inttoptr %0 : i32 to !llvm.ptr<i8>
    %alloca = memref.alloca() : memref<2xindex, "cpu">
    memref.store %c100, %alloca[%c0] : memref<2xindex, "cpu">
    memref.store %c13, %alloca[%c1] : memref<2xindex, "cpu">
    %3 = "disc_ral.dispatch"(%arg0, %2, %alloc, %alloca) {backend_config = "", call_target_name = "inc_ref", device = "gpu", has_side_effect = false} : (!disc_ral.context, !llvm.ptr<i8>, memref<1300xf32, "gpu">, memref<2xindex, "cpu">) -> memref<100x13xf32, "gpu">
    %reinterpret_cast = memref.reinterpret_cast %3 to offset: [0], sizes: [100, 13], strides: [13, 1] : memref<100x13xf32, "gpu"> to memref<100x13xf32, "gpu">
    memref.dealloc %alloc : memref<1300xf32, "gpu">
    "disc_ral.dispatch"(%arg0, %c0, %reinterpret_cast) {backend_config = "", call_target_name = "ral_send_output", device = "cpu", has_side_effect = false} : (!disc_ral.context, index, memref<100x13xf32, "gpu">) -> ()
    return
  }
  gpu.module @main_kernel attributes {gpu.binary = "P\EDU\BA\01\00\10\00 \04\00\00\00\00\00\00\02\00\01\01@\00\00\00\E0\03\00\00\00\00\00\00\E0\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\0A\00\01\00\11\08\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\85e__3_1_00\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FA\01debug_frame\00.rel\11\00!nv\14\00\11a;\00\0F\0B\01 \0F\80\00\0D\0F,\01\9Ao_param3\01\1C\0F\01\00\06\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\11$\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00C/\08\00\05_\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\A0\03\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C$\00\10\01N\00%\F0!\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00v\02\02\08\10\0A/\22\EA\03\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00 \01/\05\00\01\00\FF\88A\02z\01\00\E7\03\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%c\02Q\0E\00\19y\03\0F\00 \00!\CD\03\F5\14\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cx\00\02\13\05\00\00p@\F0\03\00\DA\0F\00M\1B\04\A0\80\03\00\EA\0F\005t\03\FF{\03\10\FF\88\03P\E2\0F\00\02x\0E\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\90\D0\0F\00%v\02\02\00Z4\04\00`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F0\01\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=\0B\01\000\00\08\01\00\1F\0B@\00\04\13K)\00\1F3@\00\0C\13\13\E4\03\0C\01\00\13\80\15\00&\90\00\08\04#\04\00]\04\00\CE\04\12\00\01\00\1F\DET\00\00\00\01\00\13\10\95\00/p\00\80\00\0B\1F)'\00\03#\00\80@\00\04\18\06\04\E4\00*\04\00\01\00\1FY@\00\04\13\B01\00&L\00@\00\1F\0A@\00\00\12\FCD\01\0D@\00\04)\00*\D8\00\01\00\1B\08\08\00?\EB\00\00N\07\003\00\00\D8@\00&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01*\E8\04\00\07\1F\00\C0\00\04\132@\00*\06\00\01\00*\80\06\98\07\12\03\C8\05:\08\80\00\01\00\13\06\E0\05\05\A8\0A\0B\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009\18\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__3_1_0(%arg0: i32, %arg1: !llvm.ptr<f32>) attributes {disc.elimargs = [1 : index, 3 : index, 4 : index, 5 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(1300 : index) : i32
      %1 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %2 = nvvm.read.ptx.sreg.ctaid.x : i32
      %3 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %4 = llvm.mul %2, %arg0  : i32
      %5 = llvm.add %3, %4  : i32
      %6 = llvm.icmp "ult" %5, %0 : i32
      llvm.cond_br %6, ^bb2, ^bb3
    ^bb2:  // pred: ^bb1
      %7 = llvm.getelementptr %arg1[%5] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      llvm.store %1, %7 : !llvm.ptr<f32>
      llvm.br ^bb3
    ^bb3:  // 2 preds: ^bb1, ^bb2
      llvm.return
    }
  }
  gpu.module @main_kernel_0 attributes {gpu.binary = "P\EDU\BA\01\00\10\00\10\0C\00\00\00\00\00\00\02\00\01\01@\00\00\00\D0\0B\00\00\00\00\00\00\CA\0B\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\1D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\1C\00\01\00\11\1A\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\A5e__3_1_0_12\00\0F,\00\15oshared.\00\12Orela\88\00\17?rel\B5\00\1A\9Fconstant01\00\12\B2debug_framek\00\09\11\00!nv\14\00\11a=\00\0Fn\01 \0F\82\00\0F\0F\91\01\FDo_param\98\01\1C\0F\01\00\06\8CU\00\00\00\03\00\0A\00\01\00 3\01\18\00,\09\00\01\00\11k\18\00,\04\00\01\00\11\89\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\12\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\22\04X\AC\00\90\04/\08\00\05\00\00\00\18\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04h\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\18\00\03\19\18\00\04\17\0C$\00u\03\00\10\00\00\F0!\10\009\02\00\08\10\00\10\01(\01%\F0\11\10\00\01\01\00\C2\F0\11\00\03\1B\FF\00\04\1C\0C\00P%\00r\00\C0\11\00\00\04\1E\A8\00#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08_\00\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00H\01/\05\00\01\00\FF\98@$v\01\FF\1F\04\B1\FF\00\8E\07\00\C4\0F\00\19y\03\18\00 \00%s\02R\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00X\E9\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\B0\80\03\00\EA\0F\00\19x\00\FF\1FL\03\90\14\01\00\00\C8\0F\00\11rX\03`\00\00\FF@\8F\07\10\00A\19x\02\FFI\02\00 \00S\E4\0F\00\12x\09\04\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\AB\AA\AA\AA\A0\00\80\C8\0F\00$x\00\03\010\00P\0A\8E\07\00\E2@\00 \04\FFt\02`\04\16\01\00\00\CA \00\84\05\04\FA\FF\FF\FF\02\020\00D\05\05\00\01\B0\00\CF\0F\00\0Cx\00\05\13\05\00\00p@\B0\00\03c$x\00\04 \00\10\01\B1\E2\0F\04\B9z\04\00\00F\00\00C\05\10\E2 \00\82\03\04\80\9C\00\00\03\02\A0\001\10x\02_\00\D0\FF\E0\FF\07\00\E4\0F\04\0Cx\00\00m\B0\04Q@\F8\03\00\E4p\00\12\02\10\00!\FA\03@\00Dt\02\FF\04`\00\B1\D4\0F\00%\C6\06\03\00Z\00\00\B0\00\93\E4\0F\04\10\D8\09\03\14\05P\00q\C6\0F\00\81\C9\0D\06:\04\B5\19\1E\0C\00\A4\00\00%\D6\08\090\00u\CA\0F\00\81\D9\0F\08 \00\84\E2\02\00\10x\04\00\02\90\00\11\C8\80\003\04m\00\F0\00!\E4\0F \00\1F\03 \00\02\15\F2 \00\17\04\D0\00\22\10x4\05\02\10\00\17/0\00\12\F40\00S\88\0B\03(\0A \00u\CA\0F\00%\86\0A\0B\A0\00\93\E2\0F\00\10\98\07\03<\0F \00u\C8\1F\00\81\89\04\0A\B0\00x\22\01\00%\96\06\070\00B\0Cx\00\08`\00\13\F6\90\00G\09\03P\14\10\01&\99\06\10\01\84\22\03\00\10x\0E\00\06\A0\00W\E2\0F\00%\A6 \01\00\00\02qt\0C\FF\00\00\80\FFp\01\00P\00T\B8\0B\03d\190\00h\1F\00\81\A9\09\08\90\006$t\110\00W\C6\0F\00%\B6\D0\00i\CC\0F\00\81\B9\0A\C0\00@\0B\C8\00\0D0\00\B2\00\C0\FC\03\00\C8O\00\08\C8\0C\10\00!\00\00\C0\00H\0Cx\00\0E\10\02P\0B\D2\00\0C\0F@\00\C6`\FC\03\00\E4\8F\08\10x\0D\00\07p\01B\00\08\D2\11 \00\06@\00\15\0D@\02\97\CA\0F\00\10\C8\0D\03x\1Ep\015\C6\0C\0D\A0\00\00\90\02V\D8\0F\03\8C#P\00E\81\C9\08\0C\B0\00u\A6\10\00%\D6\0E\0F0\00\01@\02%\07\0E \00\84\E2\22\00\0B\82\00\11\04\A0\00i\E2\0F\01$t\13\10\012\08\82\13 \00%\00\000\02%\08\00p\00a\04\0B\92\00\13\06@\00\10\F0@\00F\0C$t\10@\00\00\10\02Hx\0B\00\09\F0\00\22\92\100\00\00\01\00\1B\E4\B0\02\11\C4\10\00\18\0B\A0\02U\0B\A2\00\10\09@\01 \0F\08\80\00\17\0AP\00f\10x\0D\03\A0(\E0\017$t\0F\80\00R/\00\08\A2\0F@\00\06`\01\06\D0\02\00@\02\17\86P\01\84\E2\0F\00\0B\B2\00\0F\0Ap\00\10\C4`\008\06\00\0Bp\00T\98\0B\03\B4-p\00\1A\0F@\02 \E2\0F\F0\02\18\0C0\022\08\B2\11P\00\06\80\00\15\06\F0\02\00\80\00\1B\96@\03V\A8\0F\03\C82\B0\03H\81\99\06\0A\00\03J%\A6\0E\0F\F0\02\0Ap\016\81\A9\09\E0\01\93\22\05\00\10\B8\0D\03\DC7P\00\84\E4\1F\00\10x\0C\00\0D\D0\00\01\C0\00\19\130\037%\B6\0A\10\01\11/`\01$\F0<@\00t\0F\00\0B\C2\00\11\08 \01\00\00\03\22\C2\10\10\00\03\E0\00\00@\04'\0C\000\00G\D2\00\10\07\00\03\06\F0\03\02 \032\08\D2\13 \00\06 \01\18\0C@\056\81\B9\10\00\01*\B0\00\00\03\12\C8\00\03&\04B\D0\00\09\00\03/\E8\02\00\03\0Cy\00\00\10x\11\00\0E\10\01\19\15P\01U\0B\82\00\13\04\F0\00R\0F\01\08\82\15\10\00\06\B0\00\1C\11p\05\18\0F\00\01D\92\00\15\06@\00\01`\00\16\0A`\00b\C6\1F\00\08\92\0A \00\0D\A0\02\02\A0\05G\0B\A2\00\0A\00\03\10\0C\80\05(\18G\B0\00\19\0F\B0\002\08\A2\0F0\00%\00\00\90\00\16\10\E0\00\1D\04\B0\05Dx\06\00\11 \00\1B\C4 \03\00@\00T\98\0D\03,L@\00\1F/\F0\02\01\06\A0\01\10&\E0\05\0AP\03X\10x\09\00\12\10\01H\B2\00\0F\10@\02\22\B2\11\10\00\0F \03\01\01\C0\00D\0F\03@Q\80\00\01\10\03\06\E0\01-\A2\02\00\03\09\A0\02*\E4\8F0\03*\E4\0F\B0\02\02\F0\00\18\09\90\026\81\A9\0E \02\9F\A2\06\00\10\B8\09\03TV\D0\02\05\00\90\04O\08\00\13\00\10\04\076\08\D2\11\E0\02\11\E2`\03\06\B0\06'\E2\1F\00\07\12\FAp\04V\C8\09\03h[p\00\09\00\03\10\A6\00\03(\08\09\A0\06f\10\D8\0D\03|`\A0\016\81\C9\08\E0\06\10\A8\00\03+\0C\0D\00\03\07@\01\1B\00@\02\1A\8F\10\06\01\F0\02\1D\0F\00\06&\14\00P\02\0C\F0\00h\10x\0A\00\15\00\90\05\17\09 \00\00P\04H\0B\03\90e0\01\19\12@\00E\0B\92\00\0FP\06\00 \02\22\92\11\10\00\0D0\06\14\F20\02\18\0A\80\03T\0B\A2\00\11\0E\C0\00\000\03Vx\04\00\16\00P\012\08\A2\09 \00\06\00\02\0A\F0\02Ex\04\00\17\C0\00\0E\A0\05E\0B\B2\00\09\C0\02\1E\C6\F0\01g\10\88\0D\03\A4jp\00\22\B2\110\00\03@\01\06p\00\02\E0\02H\81\99\04\0A\90\01\0C\90\06\00\10\06/\B8o\80\05\04\10\C4\80\03(\06\0C\10\0A\09\F0\02\00\80\02G\C2\12\11\08\80\00\00\B0\02)\18\00\D0\02'\12\07\A0\04\09\00\03\87\E2\08\00\10x\10\00\190\00\09\C0\05\0F\F0\02\00\000\03&\CCtP\042\08\D2\11`\00\06\00\01\18\10\E0\05\0C\10\03\00\00\0A#\E0y@\00\1B\C8\00\03\1F\E2\00\03\03/\F4~\00\03\04\1F\E8\00\03\0C*\E2\04\00\07\11\E2p\04\01{\14\02P\00\00\10\09\16\0B \00\1E\E4\D0\02(\0B\920\03\00\B0\02\0A0\09I\0Cx\00\0F\D0\05\14\820\09\00\A0\02\11\8F\A0\02\17\1B`\01_\08\82\0B\13\060\02\02\02 \09U\0B\A2\00\0B\0Ep\00\01\D0\02\02\10\00\030\00\00\A0\08&\08\84P\00\00`\00\19\1C\E0\0B?\06\00\1D\E0\02\159\E4\0F\08 \03\0Fp\06\00\00\F0\02&\1C\89P\00\0C\D0\026\08\B2\0F\00\03\1E\C4\00\09\0D\80\09I\C2\00\0F\08`\057\0E\00\1E\B0\00\0C\F0\05\000\02'0\8E\80\00\0B\10\032\08\C2\10P\00\0F\A0\0B\01\0C@\0C\1B\E2\E0\05\01\00\0A9\00\00\1F\80\00\0C\F0\02O\0B\03D\93`\0C\07\09\00\06\02\80\00\1B\00\00\03\06\80\01\12\E4\F0\0B#X\98P\00+\C8/\80\0C\0B\00\0C\12\CA\00\09$l\9D\80\00\00\00\09\16\0C\00\01*(\0F\00\09\00\D0\0C9\D9\0E\0EP\00Vv\02\05\00\\P\00E\81y\08\02 \00fb\11\00$t\05\F0\00\10\E4\00\01\1B\00\10\00\1C\07\C0\05\0B\10\03\16\05\10\03\11\C8\00\03\11\05\E0\02\84`\F2\03\00\C8\8F\00\08\10\00\22\00\80p\0F)t\05\80\0CU\0B\A2\00\00\09\10\06R\0F\01\08\A2\05\10\00\00\01\00\11\C8\B0\02&\05\0A \00B\00\08\B2\07\10\00/\00\00P\00\03H\C2\00\07\0C0\00\22\C2\05\10\00\050\00\1A\070\00H\D2\00\05\0E0\00\22\D2\07\10\00\01\80\00a\1F\00\0Br\00\08\E0\01\00\A0\03W\E2\0F\0EFy`\10b\E6\0F\00\08r\09 \00\00\01\00p\CC\0F\00\A9s\09\02\90\02\C0\09\E1\1E\00\00\A4\0E\00\0Cr\00\09\10\00 pR@\00`O\00$r\08\FFM\0E\10\09\80\00\80\D8\0F\00G\09\00\00\90 \11!\FF\83\B0\10*My\C0\10TGy\00\00\F0 \00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\22\01\00P\12\0C\01\00\22@\00\01\00=n\01\000\00\08\01\00\1F\0B@\00\04\13\AE)\00\1F\98@\00\0C\13\13\F4\14\0C\01\00\13HU\00&\90\00\18\15#\04\00m\15\03\A8\16\00\01\00.A\01T\00\00\01\00\13\D8@\00/p\00\80\00\0B\1F)'\00\03#\00He\03\04P\17\04\E4\00*\04\00\01\00\1F[@\00\04\13x)\00&x\00@\00\1F\0A@\00\00!_\01D\01\0D@\00\13\F0)\00*\D8\00\01\00\1B\08\08\00#N\01\D0\03\0B\01\00\13\C8E\16\17\10\80\00\17\048\00\04\18\00\13\10@\01\0C\84\01\13\D8@\00\17x1\01\0F\C0\00\01\132T\01*\06\00\01\00*\80\07\D0\18\12\03\D8\16:\18\80\00\01\00\13\06\F0\16\05\A8\1C\0B\01\00*\A8\00\08\00\17\08\C8\01\17\05\A8\00\0C\01\009(\14\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00"} {
    llvm.func @main_kColReduction_reduce__3_1_0_1(%arg0: i32, %arg1: i32, %arg2: !llvm.ptr<f32>, %arg3: !llvm.ptr<f32>) attributes {disc.elimargs = [2 : index, 4 : index, 5 : index, 6 : index, 7 : index, 8 : index, 9 : index, 10 : index, 11 : index, 13 : index, 14 : index, 15 : index], gpu.kernel, nvvm.kernel} {
      %0 = llvm.mlir.constant(0 : index) : i32
      %1 = llvm.mlir.constant(1 : index) : i32
      %2 = llvm.mlir.constant(256 : index) : i32
      %3 = llvm.mlir.constant(6 : index) : i32
      %4 = llvm.mlir.constant(1300 : index) : i32
      %5 = llvm.mlir.constant(32 : index) : i32
      %6 = llvm.mlir.constant(110 : index) : i32
      %7 = llvm.mlir.constant(0xFF800000 : f32) : f32
      %8 = nvvm.read.ptx.sreg.ctaid.x : i32
      %9 = nvvm.read.ptx.sreg.tid.x : i32
      llvm.br ^bb1
    ^bb1:  // pred: ^bb0
      %10 = llvm.mul %8, %arg0  : i32
      %11 = llvm.add %9, %10  : i32
      %12 = llvm.icmp "ult" %11, %arg1 : i32
      llvm.cond_br %12, ^bb2, ^bb14
    ^bb2:  // pred: ^bb1
      %13 = llvm.srem %11, %2  : i32
      %14 = llvm.sdiv %11, %2  : i32
      %15 = llvm.udiv %14, %3  : i32
      %16 = llvm.urem %14, %3  : i32
      %17 = llvm.mul %16, %2  : i32
      %18 = llvm.add %17, %13  : i32
      %19 = llvm.icmp "ult" %18, %4 : i32
      llvm.cond_br %19, ^bb3, ^bb13
    ^bb3:  // pred: ^bb2
      %20 = llvm.mul %15, %5  : i32
      llvm.br ^bb4(%0, %7 : i32, f32)
    ^bb4(%21: i32, %22: f32):  // 2 preds: ^bb3, ^bb9
      %23 = llvm.icmp "slt" %21, %5 : i32
      llvm.cond_br %23, ^bb5, ^bb10
    ^bb5:  // pred: ^bb4
      %24 = llvm.add %20, %21  : i32
      %25 = llvm.icmp "ult" %24, %6 : i32
      llvm.cond_br %25, ^bb6, ^bb7
    ^bb6:  // pred: ^bb5
      %26 = llvm.mul %24, %4  : i32
      %27 = llvm.add %26, %18  : i32
      %28 = llvm.getelementptr %arg2[%27] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %29 = llvm.load %28 : !llvm.ptr<f32>
      %30 = llvm.fcmp "oge" %22, %29 : f32
      %31 = llvm.select %30, %22, %29 : i1, f32
      llvm.br ^bb8(%31 : f32)
    ^bb7:  // pred: ^bb5
      llvm.br ^bb8(%7 : f32)
    ^bb8(%32: f32):  // 2 preds: ^bb6, ^bb7
      llvm.br ^bb9
    ^bb9:  // pred: ^bb8
      %33 = llvm.add %21, %1  : i32
      llvm.br ^bb4(%33, %32 : i32, f32)
    ^bb10:  // pred: ^bb4
      %34 = llvm.getelementptr %arg3[%18] : (!llvm.ptr<f32>, i32) -> !llvm.ptr<f32>
      %35 = llvm.load %34 : !llvm.ptr<f32>
      llvm.br ^bb11(%35 : f32)
    ^bb11(%36: f32):  // 2 preds: ^bb10, ^bb11
      %37 = llvm.fcmp "ogt" %36, %22 : f32
      %38 = llvm.select %37, %36, %22 : i1, f32
      %39 = llvm.bitcast %34 : !llvm.ptr<f32> to !llvm.ptr<i32>
      %40 = llvm.bitcast %36 : f32 to i32
      %41 = llvm.bitcast %38 : f32 to i32
      %42 = llvm.cmpxchg %39, %40, %41 acq_rel monotonic : !llvm.ptr<i32>, i32
      %43 = llvm.extractvalue %42[0] : !llvm.struct<(i32, i1)> 
      %44 = llvm.bitcast %43 : i32 to f32
      %45 = llvm.extractvalue %42[1] : !llvm.struct<(i32, i1)> 
      llvm.cond_br %45, ^bb12, ^bb11(%44 : f32)
    ^bb12:  // pred: ^bb11
      llvm.br ^bb13
    ^bb13:  // 2 preds: ^bb2, ^bb12
      llvm.br ^bb14
    ^bb14:  // 2 preds: ^bb1, ^bb13
      llvm.return
    }
  }
}


// -----// IR Dump After DiscToLLVMPass (disc-to-llvm) //----- //
module attributes {gpu.container_module} {
  llvm.mlir.global internal constant @ral_send_output___cpu___pvoid_i64_m2df32___void("ral_send_output___cpu___pvoid_i64_m2df32___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @dealloc___gpu___pvoid_pvoid___void("dealloc___gpu___pvoid_pvoid___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32("inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_0_main_kColReduction_reduce__3_1_0_1_kernel_name("main_kColReduction_reduce__3_1_0_1\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_0_blob_gpu.binary("P\EDU\BA\01\00\10\00\10\0C\00\00\00\00\00\00\02\00\01\01@\00\00\00\D0\0B\00\00\00\00\00\00\CA\0B\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\1D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\1C\00\01\00\11\1A\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\A5e__3_1_0_12\00\0F,\00\15oshared.\00\12Orela\88\00\17?rel\B5\00\1A\9Fconstant01\00\12\B2debug_framek\00\09\11\00!nv\14\00\11a=\00\0Fn\01 \0F\82\00\0F\0F\91\01\FDo_param\98\01\1C\0F\01\00\06\8CU\00\00\00\03\00\0A\00\01\00 3\01\18\00,\09\00\01\00\11k\18\00,\04\00\01\00\11\89\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\12\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\22\04X\AC\00\90\04/\08\00\05\00\00\00\18\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04h\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\18\00\03\19\18\00\04\17\0C$\00u\03\00\10\00\00\F0!\10\009\02\00\08\10\00\10\01(\01%\F0\11\10\00\01\01\00\C2\F0\11\00\03\1B\FF\00\04\1C\0C\00P%\00r\00\C0\11\00\00\04\1E\A8\00#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08_\00\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00H\01/\05\00\01\00\FF\98@$v\01\FF\1F\04\B1\FF\00\8E\07\00\C4\0F\00\19y\03\18\00 \00%s\02R\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00X\E9\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\B0\80\03\00\EA\0F\00\19x\00\FF\1FL\03\90\14\01\00\00\C8\0F\00\11rX\03`\00\00\FF@\8F\07\10\00A\19x\02\FFI\02\00 \00S\E4\0F\00\12x\09\04\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\AB\AA\AA\AA\A0\00\80\C8\0F\00$x\00\03\010\00P\0A\8E\07\00\E2@\00 \04\FFt\02`\04\16\01\00\00\CA \00\84\05\04\FA\FF\FF\FF\02\020\00D\05\05\00\01\B0\00\CF\0F\00\0Cx\00\05\13\05\00\00p@\B0\00\03c$x\00\04 \00\10\01\B1\E2\0F\04\B9z\04\00\00F\00\00C\05\10\E2 \00\82\03\04\80\9C\00\00\03\02\A0\001\10x\02_\00\D0\FF\E0\FF\07\00\E4\0F\04\0Cx\00\00m\B0\04Q@\F8\03\00\E4p\00\12\02\10\00!\FA\03@\00Dt\02\FF\04`\00\B1\D4\0F\00%\C6\06\03\00Z\00\00\B0\00\93\E4\0F\04\10\D8\09\03\14\05P\00q\C6\0F\00\81\C9\0D\06:\04\B5\19\1E\0C\00\A4\00\00%\D6\08\090\00u\CA\0F\00\81\D9\0F\08 \00\84\E2\02\00\10x\04\00\02\90\00\11\C8\80\003\04m\00\F0\00!\E4\0F \00\1F\03 \00\02\15\F2 \00\17\04\D0\00\22\10x4\05\02\10\00\17/0\00\12\F40\00S\88\0B\03(\0A \00u\CA\0F\00%\86\0A\0B\A0\00\93\E2\0F\00\10\98\07\03<\0F \00u\C8\1F\00\81\89\04\0A\B0\00x\22\01\00%\96\06\070\00B\0Cx\00\08`\00\13\F6\90\00G\09\03P\14\10\01&\99\06\10\01\84\22\03\00\10x\0E\00\06\A0\00W\E2\0F\00%\A6 \01\00\00\02qt\0C\FF\00\00\80\FFp\01\00P\00T\B8\0B\03d\190\00h\1F\00\81\A9\09\08\90\006$t\110\00W\C6\0F\00%\B6\D0\00i\CC\0F\00\81\B9\0A\C0\00@\0B\C8\00\0D0\00\B2\00\C0\FC\03\00\C8O\00\08\C8\0C\10\00!\00\00\C0\00H\0Cx\00\0E\10\02P\0B\D2\00\0C\0F@\00\C6`\FC\03\00\E4\8F\08\10x\0D\00\07p\01B\00\08\D2\11 \00\06@\00\15\0D@\02\97\CA\0F\00\10\C8\0D\03x\1Ep\015\C6\0C\0D\A0\00\00\90\02V\D8\0F\03\8C#P\00E\81\C9\08\0C\B0\00u\A6\10\00%\D6\0E\0F0\00\01@\02%\07\0E \00\84\E2\22\00\0B\82\00\11\04\A0\00i\E2\0F\01$t\13\10\012\08\82\13 \00%\00\000\02%\08\00p\00a\04\0B\92\00\13\06@\00\10\F0@\00F\0C$t\10@\00\00\10\02Hx\0B\00\09\F0\00\22\92\100\00\00\01\00\1B\E4\B0\02\11\C4\10\00\18\0B\A0\02U\0B\A2\00\10\09@\01 \0F\08\80\00\17\0AP\00f\10x\0D\03\A0(\E0\017$t\0F\80\00R/\00\08\A2\0F@\00\06`\01\06\D0\02\00@\02\17\86P\01\84\E2\0F\00\0B\B2\00\0F\0Ap\00\10\C4`\008\06\00\0Bp\00T\98\0B\03\B4-p\00\1A\0F@\02 \E2\0F\F0\02\18\0C0\022\08\B2\11P\00\06\80\00\15\06\F0\02\00\80\00\1B\96@\03V\A8\0F\03\C82\B0\03H\81\99\06\0A\00\03J%\A6\0E\0F\F0\02\0Ap\016\81\A9\09\E0\01\93\22\05\00\10\B8\0D\03\DC7P\00\84\E4\1F\00\10x\0C\00\0D\D0\00\01\C0\00\19\130\037%\B6\0A\10\01\11/`\01$\F0<@\00t\0F\00\0B\C2\00\11\08 \01\00\00\03\22\C2\10\10\00\03\E0\00\00@\04'\0C\000\00G\D2\00\10\07\00\03\06\F0\03\02 \032\08\D2\13 \00\06 \01\18\0C@\056\81\B9\10\00\01*\B0\00\00\03\12\C8\00\03&\04B\D0\00\09\00\03/\E8\02\00\03\0Cy\00\00\10x\11\00\0E\10\01\19\15P\01U\0B\82\00\13\04\F0\00R\0F\01\08\82\15\10\00\06\B0\00\1C\11p\05\18\0F\00\01D\92\00\15\06@\00\01`\00\16\0A`\00b\C6\1F\00\08\92\0A \00\0D\A0\02\02\A0\05G\0B\A2\00\0A\00\03\10\0C\80\05(\18G\B0\00\19\0F\B0\002\08\A2\0F0\00%\00\00\90\00\16\10\E0\00\1D\04\B0\05Dx\06\00\11 \00\1B\C4 \03\00@\00T\98\0D\03,L@\00\1F/\F0\02\01\06\A0\01\10&\E0\05\0AP\03X\10x\09\00\12\10\01H\B2\00\0F\10@\02\22\B2\11\10\00\0F \03\01\01\C0\00D\0F\03@Q\80\00\01\10\03\06\E0\01-\A2\02\00\03\09\A0\02*\E4\8F0\03*\E4\0F\B0\02\02\F0\00\18\09\90\026\81\A9\0E \02\9F\A2\06\00\10\B8\09\03TV\D0\02\05\00\90\04O\08\00\13\00\10\04\076\08\D2\11\E0\02\11\E2`\03\06\B0\06'\E2\1F\00\07\12\FAp\04V\C8\09\03h[p\00\09\00\03\10\A6\00\03(\08\09\A0\06f\10\D8\0D\03|`\A0\016\81\C9\08\E0\06\10\A8\00\03+\0C\0D\00\03\07@\01\1B\00@\02\1A\8F\10\06\01\F0\02\1D\0F\00\06&\14\00P\02\0C\F0\00h\10x\0A\00\15\00\90\05\17\09 \00\00P\04H\0B\03\90e0\01\19\12@\00E\0B\92\00\0FP\06\00 \02\22\92\11\10\00\0D0\06\14\F20\02\18\0A\80\03T\0B\A2\00\11\0E\C0\00\000\03Vx\04\00\16\00P\012\08\A2\09 \00\06\00\02\0A\F0\02Ex\04\00\17\C0\00\0E\A0\05E\0B\B2\00\09\C0\02\1E\C6\F0\01g\10\88\0D\03\A4jp\00\22\B2\110\00\03@\01\06p\00\02\E0\02H\81\99\04\0A\90\01\0C\90\06\00\10\06/\B8o\80\05\04\10\C4\80\03(\06\0C\10\0A\09\F0\02\00\80\02G\C2\12\11\08\80\00\00\B0\02)\18\00\D0\02'\12\07\A0\04\09\00\03\87\E2\08\00\10x\10\00\190\00\09\C0\05\0F\F0\02\00\000\03&\CCtP\042\08\D2\11`\00\06\00\01\18\10\E0\05\0C\10\03\00\00\0A#\E0y@\00\1B\C8\00\03\1F\E2\00\03\03/\F4~\00\03\04\1F\E8\00\03\0C*\E2\04\00\07\11\E2p\04\01{\14\02P\00\00\10\09\16\0B \00\1E\E4\D0\02(\0B\920\03\00\B0\02\0A0\09I\0Cx\00\0F\D0\05\14\820\09\00\A0\02\11\8F\A0\02\17\1B`\01_\08\82\0B\13\060\02\02\02 \09U\0B\A2\00\0B\0Ep\00\01\D0\02\02\10\00\030\00\00\A0\08&\08\84P\00\00`\00\19\1C\E0\0B?\06\00\1D\E0\02\159\E4\0F\08 \03\0Fp\06\00\00\F0\02&\1C\89P\00\0C\D0\026\08\B2\0F\00\03\1E\C4\00\09\0D\80\09I\C2\00\0F\08`\057\0E\00\1E\B0\00\0C\F0\05\000\02'0\8E\80\00\0B\10\032\08\C2\10P\00\0F\A0\0B\01\0C@\0C\1B\E2\E0\05\01\00\0A9\00\00\1F\80\00\0C\F0\02O\0B\03D\93`\0C\07\09\00\06\02\80\00\1B\00\00\03\06\80\01\12\E4\F0\0B#X\98P\00+\C8/\80\0C\0B\00\0C\12\CA\00\09$l\9D\80\00\00\00\09\16\0C\00\01*(\0F\00\09\00\D0\0C9\D9\0E\0EP\00Vv\02\05\00\\P\00E\81y\08\02 \00fb\11\00$t\05\F0\00\10\E4\00\01\1B\00\10\00\1C\07\C0\05\0B\10\03\16\05\10\03\11\C8\00\03\11\05\E0\02\84`\F2\03\00\C8\8F\00\08\10\00\22\00\80p\0F)t\05\80\0CU\0B\A2\00\00\09\10\06R\0F\01\08\A2\05\10\00\00\01\00\11\C8\B0\02&\05\0A \00B\00\08\B2\07\10\00/\00\00P\00\03H\C2\00\07\0C0\00\22\C2\05\10\00\050\00\1A\070\00H\D2\00\05\0E0\00\22\D2\07\10\00\01\80\00a\1F\00\0Br\00\08\E0\01\00\A0\03W\E2\0F\0EFy`\10b\E6\0F\00\08r\09 \00\00\01\00p\CC\0F\00\A9s\09\02\90\02\C0\09\E1\1E\00\00\A4\0E\00\0Cr\00\09\10\00 pR@\00`O\00$r\08\FFM\0E\10\09\80\00\80\D8\0F\00G\09\00\00\90 \11!\FF\83\B0\10*My\C0\10TGy\00\00\F0 \00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\22\01\00P\12\0C\01\00\22@\00\01\00=n\01\000\00\08\01\00\1F\0B@\00\04\13\AE)\00\1F\98@\00\0C\13\13\F4\14\0C\01\00\13HU\00&\90\00\18\15#\04\00m\15\03\A8\16\00\01\00.A\01T\00\00\01\00\13\D8@\00/p\00\80\00\0B\1F)'\00\03#\00He\03\04P\17\04\E4\00*\04\00\01\00\1F[@\00\04\13x)\00&x\00@\00\1F\0A@\00\00!_\01D\01\0D@\00\13\F0)\00*\D8\00\01\00\1B\08\08\00#N\01\D0\03\0B\01\00\13\C8E\16\17\10\80\00\17\048\00\04\18\00\13\10@\01\0C\84\01\13\D8@\00\17x1\01\0F\C0\00\01\132T\01*\06\00\01\00*\80\07\D0\18\12\03\D8\16:\18\80\00\01\00\13\06\F0\16\05\A8\1C\0B\01\00*\A8\00\08\00\17\08\C8\01\17\05\A8\00\0C\01\009(\14\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void("ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_main_kColReduction_reduce__3_1_0_kernel_name("main_kColReduction_reduce__3_1_0\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @main_kernel_blob_gpu.binary("P\EDU\BA\01\00\10\00 \04\00\00\00\00\00\00\02\00\01\01@\00\00\00\E0\03\00\00\00\00\00\00\E0\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\0A\00\01\00\11\08\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\85e__3_1_00\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FA\01debug_frame\00.rel\11\00!nv\14\00\11a;\00\0F\0B\01 \0F\80\00\0D\0F,\01\9Ao_param3\01\1C\0F\01\00\06\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\11$\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00C/\08\00\05_\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\A0\03\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C$\00\10\01N\00%\F0!\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00v\02\02\08\10\0A/\22\EA\03\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00 \01/\05\00\01\00\FF\88A\02z\01\00\E7\03\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%c\02Q\0E\00\19y\03\0F\00 \00!\CD\03\F5\14\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cx\00\02\13\05\00\00p@\F0\03\00\DA\0F\00M\1B\04\A0\80\03\00\EA\0F\005t\03\FF{\03\10\FF\88\03P\E2\0F\00\02x\0E\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\90\D0\0F\00%v\02\02\00Z4\04\00`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F0\01\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=\0B\01\000\00\08\01\00\1F\0B@\00\04\13K)\00\1F3@\00\0C\13\13\E4\03\0C\01\00\13\80\15\00&\90\00\08\04#\04\00]\04\00\CE\04\12\00\01\00\1F\DET\00\00\00\01\00\13\10\95\00/p\00\80\00\0B\1F)'\00\03#\00\80@\00\04\18\06\04\E4\00*\04\00\01\00\1FY@\00\04\13\B01\00&L\00@\00\1F\0A@\00\00\12\FCD\01\0D@\00\04)\00*\D8\00\01\00\1B\08\08\00?\EB\00\00N\07\003\00\00\D8@\00&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01*\E8\04\00\07\1F\00\C0\00\04\132@\00*\06\00\01\00*\80\06\98\07\12\03\C8\05:\08\80\00\01\00\13\06\E0\05\05\A8\0A\0B\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009\18\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @alloc___gpu___pvoid_i64___pvoid("alloc___gpu___pvoid_i64___pvoid\00") {addr_space = 0 : i32}
  llvm.mlir.global internal constant @ral_recv_input___cpu___pvoid_i64___m3df32("ral_recv_input___cpu___pvoid_i64___m3df32\00") {addr_space = 0 : i32}
  llvm.func @disc_ral_call(!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>)
  llvm.func @main(%arg0: !llvm.ptr<i8>) attributes {tf.entry_function = {input_placements = "gpu", inputs = "input0", output_placements = "gpu", outputs = "output0"}} {
    %0 = llvm.mlir.constant(256 : index) : i64
    %1 = llvm.mlir.constant(24 : index) : i64
    %2 = llvm.mlir.constant(6144 : index) : i64
    %3 = llvm.mlir.constant(6 : index) : i64
    %4 = llvm.mlir.constant(0 : i32) : i32
    %5 = llvm.mlir.constant(0 : index) : i64
    %6 = llvm.mlir.constant(100 : index) : i64
    %7 = llvm.mlir.constant(1 : index) : i64
    %8 = llvm.mlir.constant(13 : index) : i64
    %9 = llvm.mlir.constant(0 : i32) : i32
    %10 = llvm.mlir.constant(1 : i32) : i32
    %11 = llvm.alloca %10 x !llvm.struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>)> : (i32) -> !llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>)>>
    %12 = llvm.mlir.constant(3 : i32) : i32
    %13 = llvm.alloca %12 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %14 = llvm.mlir.constant(0 : i32) : i32
    %15 = llvm.getelementptr %11[%9, 0] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %15 : !llvm.ptr<ptr<i8>>
    %16 = llvm.getelementptr %13[%14] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %17 = llvm.bitcast %15 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %17, %16 : !llvm.ptr<ptr<i8>>
    %18 = llvm.mlir.constant(1 : i32) : i32
    %19 = llvm.getelementptr %11[%9, 1] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %5, %19 : !llvm.ptr<i64>
    %20 = llvm.getelementptr %13[%18] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %21 = llvm.bitcast %19 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %21, %20 : !llvm.ptr<ptr<i8>>
    %22 = llvm.mlir.constant(2 : i32) : i32
    %23 = llvm.getelementptr %11[%9, 2] : (!llvm.ptr<struct<"", (ptr<i8>, i64, struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>>
    %24 = llvm.getelementptr %13[%22] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %25 = llvm.bitcast %23 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>> to !llvm.ptr<i8>
    llvm.store %25, %24 : !llvm.ptr<ptr<i8>>
    %26 = llvm.mlir.addressof @ral_recv_input___cpu___pvoid_i64___m3df32 : !llvm.ptr<array<42 x i8>>
    %27 = llvm.mlir.constant(0 : index) : i64
    %28 = llvm.getelementptr %26[%27, %27] : (!llvm.ptr<array<42 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %28, %13) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %29 = llvm.load %23 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)>>
    %30 = llvm.mlir.constant(1300 : index) : i64
    %31 = llvm.mlir.constant(1 : index) : i64
    %32 = llvm.mlir.null : !llvm.ptr<f32>
    %33 = llvm.getelementptr %32[%30] : (!llvm.ptr<f32>, i64) -> !llvm.ptr<f32>
    %34 = llvm.ptrtoint %33 : !llvm.ptr<f32> to i64
    %35 = llvm.mlir.constant(0 : i32) : i32
    %36 = llvm.mlir.constant(1 : i32) : i32
    %37 = llvm.alloca %36 x !llvm.struct<".1", (ptr<i8>, i64, ptr<i8>)> : (i32) -> !llvm.ptr<struct<".1", (ptr<i8>, i64, ptr<i8>)>>
    %38 = llvm.mlir.constant(3 : i32) : i32
    %39 = llvm.alloca %38 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %40 = llvm.mlir.constant(0 : i32) : i32
    %41 = llvm.getelementptr %37[%35, 0] : (!llvm.ptr<struct<".1", (ptr<i8>, i64, ptr<i8>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %41 : !llvm.ptr<ptr<i8>>
    %42 = llvm.getelementptr %39[%40] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %43 = llvm.bitcast %41 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %43, %42 : !llvm.ptr<ptr<i8>>
    %44 = llvm.mlir.constant(1 : i32) : i32
    %45 = llvm.getelementptr %37[%35, 1] : (!llvm.ptr<struct<".1", (ptr<i8>, i64, ptr<i8>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %34, %45 : !llvm.ptr<i64>
    %46 = llvm.getelementptr %39[%44] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %47 = llvm.bitcast %45 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %47, %46 : !llvm.ptr<ptr<i8>>
    %48 = llvm.mlir.constant(2 : i32) : i32
    %49 = llvm.getelementptr %37[%35, 2] : (!llvm.ptr<struct<".1", (ptr<i8>, i64, ptr<i8>)>>, i32) -> !llvm.ptr<ptr<i8>>
    %50 = llvm.getelementptr %39[%48] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %51 = llvm.bitcast %49 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %51, %50 : !llvm.ptr<ptr<i8>>
    %52 = llvm.mlir.addressof @alloc___gpu___pvoid_i64___pvoid : !llvm.ptr<array<32 x i8>>
    %53 = llvm.mlir.constant(0 : index) : i64
    %54 = llvm.getelementptr %52[%53, %53] : (!llvm.ptr<array<32 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %54, %39) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %55 = llvm.load %49 : !llvm.ptr<ptr<i8>>
    %56 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)>
    %57 = llvm.bitcast %55 : !llvm.ptr<i8> to !llvm.ptr<f32>
    %58 = llvm.insertvalue %57, %56[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %59 = llvm.insertvalue %57, %58[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %60 = llvm.mlir.constant(0 : index) : i64
    %61 = llvm.insertvalue %60, %59[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %62 = llvm.mlir.constant(1 : index) : i64
    %63 = llvm.insertvalue %30, %61[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %64 = llvm.insertvalue %62, %63[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %65 = llvm.mlir.addressof @main_kernel_blob_gpu.binary : !llvm.ptr<array<1072 x i8>>
    %66 = llvm.mlir.constant(0 : index) : i64
    %67 = llvm.getelementptr %65[%66, %66] : (!llvm.ptr<array<1072 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %68 = llvm.mlir.constant(1 : i32) : i32
    %69 = llvm.alloca %68 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %70 = llvm.mlir.constant(0 : i32) : i32
    %71 = llvm.getelementptr %69[%70] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %67, %71 : !llvm.ptr<ptr<i8>>
    %72 = llvm.mlir.constant(1 : i64) : i64
    %73 = llvm.mlir.addressof @main_kernel_main_kColReduction_reduce__3_1_0_kernel_name : !llvm.ptr<array<33 x i8>>
    %74 = llvm.mlir.constant(0 : index) : i64
    %75 = llvm.getelementptr %73[%74, %74] : (!llvm.ptr<array<33 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %76 = llvm.extractvalue %64[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %77 = llvm.extractvalue %64[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %78 = llvm.extractvalue %64[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %79 = llvm.extractvalue %64[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %80 = llvm.extractvalue %64[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %81 = llvm.mlir.constant(1 : i32) : i32
    %82 = llvm.alloca %81 x !llvm.struct<".2", (i64, ptr<f32>)> : (i32) -> !llvm.ptr<struct<".2", (i64, ptr<f32>)>>
    %83 = llvm.mlir.constant(2 : i32) : i32
    %84 = llvm.alloca %83 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %85 = llvm.mlir.constant(0 : i32) : i32
    %86 = llvm.mlir.constant(0 : i32) : i32
    %87 = llvm.getelementptr %82[%85, 0] : (!llvm.ptr<struct<".2", (i64, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %87 : !llvm.ptr<i64>
    %88 = llvm.getelementptr %84[%86] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %89 = llvm.bitcast %87 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %89, %88 : !llvm.ptr<ptr<i8>>
    %90 = llvm.mlir.constant(1 : i32) : i32
    %91 = llvm.getelementptr %82[%85, 1] : (!llvm.ptr<struct<".2", (i64, ptr<f32>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %77, %91 : !llvm.ptr<ptr<f32>>
    %92 = llvm.getelementptr %84[%90] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %93 = llvm.bitcast %91 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %93, %92 : !llvm.ptr<ptr<i8>>
    %94 = llvm.mlir.constant(0 : i32) : i32
    %95 = llvm.mlir.constant(2 : i32) : i32
    %96 = llvm.inttoptr %94 : i32 to !llvm.ptr<i8>
    %97 = llvm.mlir.constant(0 : i32) : i32
    %98 = llvm.mlir.constant(1 : i32) : i32
    %99 = llvm.alloca %98 x !llvm.struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %100 = llvm.mlir.constant(14 : i32) : i32
    %101 = llvm.alloca %100 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %102 = llvm.mlir.constant(0 : i32) : i32
    %103 = llvm.getelementptr %99[%97, 0] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %103 : !llvm.ptr<ptr<i8>>
    %104 = llvm.getelementptr %101[%102] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %105 = llvm.bitcast %103 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %105, %104 : !llvm.ptr<ptr<i8>>
    %106 = llvm.mlir.constant(1 : i32) : i32
    %107 = llvm.getelementptr %99[%97, 1] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %69, %107 : !llvm.ptr<ptr<ptr<i8>>>
    %108 = llvm.getelementptr %101[%106] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %109 = llvm.bitcast %107 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %109, %108 : !llvm.ptr<ptr<i8>>
    %110 = llvm.mlir.constant(2 : i32) : i32
    %111 = llvm.getelementptr %99[%97, 2] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %72, %111 : !llvm.ptr<i64>
    %112 = llvm.getelementptr %101[%110] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %113 = llvm.bitcast %111 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %113, %112 : !llvm.ptr<ptr<i8>>
    %114 = llvm.mlir.constant(3 : i32) : i32
    %115 = llvm.getelementptr %99[%97, 3] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %75, %115 : !llvm.ptr<ptr<i8>>
    %116 = llvm.getelementptr %101[%114] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %117 = llvm.bitcast %115 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %117, %116 : !llvm.ptr<ptr<i8>>
    %118 = llvm.mlir.constant(4 : i32) : i32
    %119 = llvm.getelementptr %99[%97, 4] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %3, %119 : !llvm.ptr<i64>
    %120 = llvm.getelementptr %101[%118] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %121 = llvm.bitcast %119 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %121, %120 : !llvm.ptr<ptr<i8>>
    %122 = llvm.mlir.constant(5 : i32) : i32
    %123 = llvm.getelementptr %99[%97, 5] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %7, %123 : !llvm.ptr<i64>
    %124 = llvm.getelementptr %101[%122] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %125 = llvm.bitcast %123 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %125, %124 : !llvm.ptr<ptr<i8>>
    %126 = llvm.mlir.constant(6 : i32) : i32
    %127 = llvm.getelementptr %99[%97, 6] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %7, %127 : !llvm.ptr<i64>
    %128 = llvm.getelementptr %101[%126] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %129 = llvm.bitcast %127 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %129, %128 : !llvm.ptr<ptr<i8>>
    %130 = llvm.mlir.constant(7 : i32) : i32
    %131 = llvm.getelementptr %99[%97, 7] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %131 : !llvm.ptr<i64>
    %132 = llvm.getelementptr %101[%130] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %133 = llvm.bitcast %131 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %133, %132 : !llvm.ptr<ptr<i8>>
    %134 = llvm.mlir.constant(8 : i32) : i32
    %135 = llvm.getelementptr %99[%97, 8] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %7, %135 : !llvm.ptr<i64>
    %136 = llvm.getelementptr %101[%134] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %137 = llvm.bitcast %135 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %137, %136 : !llvm.ptr<ptr<i8>>
    %138 = llvm.mlir.constant(9 : i32) : i32
    %139 = llvm.getelementptr %99[%97, 9] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %7, %139 : !llvm.ptr<i64>
    %140 = llvm.getelementptr %101[%138] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %141 = llvm.bitcast %139 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %141, %140 : !llvm.ptr<ptr<i8>>
    %142 = llvm.mlir.constant(10 : i32) : i32
    %143 = llvm.getelementptr %99[%97, 10] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %94, %143 : !llvm.ptr<i32>
    %144 = llvm.getelementptr %101[%142] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %145 = llvm.bitcast %143 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %145, %144 : !llvm.ptr<ptr<i8>>
    %146 = llvm.mlir.constant(11 : i32) : i32
    %147 = llvm.getelementptr %99[%97, 11] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %96, %147 : !llvm.ptr<ptr<i8>>
    %148 = llvm.getelementptr %101[%146] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %149 = llvm.bitcast %147 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %149, %148 : !llvm.ptr<ptr<i8>>
    %150 = llvm.mlir.constant(12 : i32) : i32
    %151 = llvm.getelementptr %99[%97, 12] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %95, %151 : !llvm.ptr<i32>
    %152 = llvm.getelementptr %101[%150] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %153 = llvm.bitcast %151 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %153, %152 : !llvm.ptr<ptr<i8>>
    %154 = llvm.mlir.constant(13 : i32) : i32
    %155 = llvm.getelementptr %99[%97, 13] : (!llvm.ptr<struct<".3", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %84, %155 : !llvm.ptr<ptr<ptr<i8>>>
    %156 = llvm.getelementptr %101[%154] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %157 = llvm.bitcast %155 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %157, %156 : !llvm.ptr<ptr<i8>>
    %158 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %159 = llvm.mlir.constant(0 : index) : i64
    %160 = llvm.getelementptr %158[%159, %159] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %160, %101) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %161 = llvm.mlir.addressof @main_kernel_0_blob_gpu.binary : !llvm.ptr<array<3104 x i8>>
    %162 = llvm.mlir.constant(0 : index) : i64
    %163 = llvm.getelementptr %161[%162, %162] : (!llvm.ptr<array<3104 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %164 = llvm.mlir.constant(1 : i32) : i32
    %165 = llvm.alloca %164 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %166 = llvm.mlir.constant(0 : i32) : i32
    %167 = llvm.getelementptr %165[%166] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %163, %167 : !llvm.ptr<ptr<i8>>
    %168 = llvm.mlir.constant(1 : i64) : i64
    %169 = llvm.mlir.addressof @main_kernel_0_main_kColReduction_reduce__3_1_0_1_kernel_name : !llvm.ptr<array<35 x i8>>
    %170 = llvm.mlir.constant(0 : index) : i64
    %171 = llvm.getelementptr %169[%170, %170] : (!llvm.ptr<array<35 x i8>>, i64, i64) -> !llvm.ptr<i8>
    %172 = llvm.extractvalue %29[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %173 = llvm.extractvalue %29[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %174 = llvm.extractvalue %29[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %175 = llvm.extractvalue %29[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %176 = llvm.extractvalue %29[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %177 = llvm.extractvalue %29[3, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %178 = llvm.extractvalue %29[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %179 = llvm.extractvalue %29[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %180 = llvm.extractvalue %29[4, 2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<3 x i64>, array<3 x i64>)> 
    %181 = llvm.extractvalue %64[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %182 = llvm.extractvalue %64[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %183 = llvm.extractvalue %64[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %184 = llvm.extractvalue %64[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %185 = llvm.extractvalue %64[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %186 = llvm.mlir.constant(1 : i32) : i32
    %187 = llvm.alloca %186 x !llvm.struct<".4", (i64, i64, ptr<f32>, ptr<f32>)> : (i32) -> !llvm.ptr<struct<".4", (i64, i64, ptr<f32>, ptr<f32>)>>
    %188 = llvm.mlir.constant(4 : i32) : i32
    %189 = llvm.alloca %188 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %190 = llvm.mlir.constant(0 : i32) : i32
    %191 = llvm.mlir.constant(0 : i32) : i32
    %192 = llvm.getelementptr %187[%190, 0] : (!llvm.ptr<struct<".4", (i64, i64, ptr<f32>, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %192 : !llvm.ptr<i64>
    %193 = llvm.getelementptr %189[%191] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %194 = llvm.bitcast %192 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %194, %193 : !llvm.ptr<ptr<i8>>
    %195 = llvm.mlir.constant(1 : i32) : i32
    %196 = llvm.getelementptr %187[%190, 1] : (!llvm.ptr<struct<".4", (i64, i64, ptr<f32>, ptr<f32>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %2, %196 : !llvm.ptr<i64>
    %197 = llvm.getelementptr %189[%195] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %198 = llvm.bitcast %196 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %198, %197 : !llvm.ptr<ptr<i8>>
    %199 = llvm.mlir.constant(2 : i32) : i32
    %200 = llvm.getelementptr %187[%190, 2] : (!llvm.ptr<struct<".4", (i64, i64, ptr<f32>, ptr<f32>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %173, %200 : !llvm.ptr<ptr<f32>>
    %201 = llvm.getelementptr %189[%199] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %202 = llvm.bitcast %200 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %202, %201 : !llvm.ptr<ptr<i8>>
    %203 = llvm.mlir.constant(3 : i32) : i32
    %204 = llvm.getelementptr %187[%190, 3] : (!llvm.ptr<struct<".4", (i64, i64, ptr<f32>, ptr<f32>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %182, %204 : !llvm.ptr<ptr<f32>>
    %205 = llvm.getelementptr %189[%203] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %206 = llvm.bitcast %204 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %206, %205 : !llvm.ptr<ptr<i8>>
    %207 = llvm.mlir.constant(0 : i32) : i32
    %208 = llvm.mlir.constant(4 : i32) : i32
    %209 = llvm.inttoptr %207 : i32 to !llvm.ptr<i8>
    %210 = llvm.mlir.constant(0 : i32) : i32
    %211 = llvm.mlir.constant(1 : i32) : i32
    %212 = llvm.alloca %211 x !llvm.struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)> : (i32) -> !llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>
    %213 = llvm.mlir.constant(14 : i32) : i32
    %214 = llvm.alloca %213 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %215 = llvm.mlir.constant(0 : i32) : i32
    %216 = llvm.getelementptr %212[%210, 0] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %216 : !llvm.ptr<ptr<i8>>
    %217 = llvm.getelementptr %214[%215] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %218 = llvm.bitcast %216 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %218, %217 : !llvm.ptr<ptr<i8>>
    %219 = llvm.mlir.constant(1 : i32) : i32
    %220 = llvm.getelementptr %212[%210, 1] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %165, %220 : !llvm.ptr<ptr<ptr<i8>>>
    %221 = llvm.getelementptr %214[%219] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %222 = llvm.bitcast %220 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %222, %221 : !llvm.ptr<ptr<i8>>
    %223 = llvm.mlir.constant(2 : i32) : i32
    %224 = llvm.getelementptr %212[%210, 2] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %168, %224 : !llvm.ptr<i64>
    %225 = llvm.getelementptr %214[%223] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %226 = llvm.bitcast %224 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %226, %225 : !llvm.ptr<ptr<i8>>
    %227 = llvm.mlir.constant(3 : i32) : i32
    %228 = llvm.getelementptr %212[%210, 3] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %171, %228 : !llvm.ptr<ptr<i8>>
    %229 = llvm.getelementptr %214[%227] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %230 = llvm.bitcast %228 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %230, %229 : !llvm.ptr<ptr<i8>>
    %231 = llvm.mlir.constant(4 : i32) : i32
    %232 = llvm.getelementptr %212[%210, 4] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %1, %232 : !llvm.ptr<i64>
    %233 = llvm.getelementptr %214[%231] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %234 = llvm.bitcast %232 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %234, %233 : !llvm.ptr<ptr<i8>>
    %235 = llvm.mlir.constant(5 : i32) : i32
    %236 = llvm.getelementptr %212[%210, 5] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %7, %236 : !llvm.ptr<i64>
    %237 = llvm.getelementptr %214[%235] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %238 = llvm.bitcast %236 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %238, %237 : !llvm.ptr<ptr<i8>>
    %239 = llvm.mlir.constant(6 : i32) : i32
    %240 = llvm.getelementptr %212[%210, 6] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %7, %240 : !llvm.ptr<i64>
    %241 = llvm.getelementptr %214[%239] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %242 = llvm.bitcast %240 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %242, %241 : !llvm.ptr<ptr<i8>>
    %243 = llvm.mlir.constant(7 : i32) : i32
    %244 = llvm.getelementptr %212[%210, 7] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %0, %244 : !llvm.ptr<i64>
    %245 = llvm.getelementptr %214[%243] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %246 = llvm.bitcast %244 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %246, %245 : !llvm.ptr<ptr<i8>>
    %247 = llvm.mlir.constant(8 : i32) : i32
    %248 = llvm.getelementptr %212[%210, 8] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %7, %248 : !llvm.ptr<i64>
    %249 = llvm.getelementptr %214[%247] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %250 = llvm.bitcast %248 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %250, %249 : !llvm.ptr<ptr<i8>>
    %251 = llvm.mlir.constant(9 : i32) : i32
    %252 = llvm.getelementptr %212[%210, 9] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %7, %252 : !llvm.ptr<i64>
    %253 = llvm.getelementptr %214[%251] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %254 = llvm.bitcast %252 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %254, %253 : !llvm.ptr<ptr<i8>>
    %255 = llvm.mlir.constant(10 : i32) : i32
    %256 = llvm.getelementptr %212[%210, 10] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %207, %256 : !llvm.ptr<i32>
    %257 = llvm.getelementptr %214[%255] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %258 = llvm.bitcast %256 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %258, %257 : !llvm.ptr<ptr<i8>>
    %259 = llvm.mlir.constant(11 : i32) : i32
    %260 = llvm.getelementptr %212[%210, 11] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %209, %260 : !llvm.ptr<ptr<i8>>
    %261 = llvm.getelementptr %214[%259] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %262 = llvm.bitcast %260 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %262, %261 : !llvm.ptr<ptr<i8>>
    %263 = llvm.mlir.constant(12 : i32) : i32
    %264 = llvm.getelementptr %212[%210, 12] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<i32>
    llvm.store %208, %264 : !llvm.ptr<i32>
    %265 = llvm.getelementptr %214[%263] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %266 = llvm.bitcast %264 : !llvm.ptr<i32> to !llvm.ptr<i8>
    llvm.store %266, %265 : !llvm.ptr<ptr<i8>>
    %267 = llvm.mlir.constant(13 : i32) : i32
    %268 = llvm.getelementptr %212[%210, 13] : (!llvm.ptr<struct<".5", (ptr<i8>, ptr<ptr<i8>>, i64, ptr<i8>, i64, i64, i64, i64, i64, i64, i32, ptr<i8>, i32, ptr<ptr<i8>>)>>, i32) -> !llvm.ptr<ptr<ptr<i8>>>
    llvm.store %189, %268 : !llvm.ptr<ptr<ptr<i8>>>
    %269 = llvm.getelementptr %214[%267] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %270 = llvm.bitcast %268 : !llvm.ptr<ptr<ptr<i8>>> to !llvm.ptr<i8>
    llvm.store %270, %269 : !llvm.ptr<ptr<i8>>
    %271 = llvm.mlir.addressof @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void : !llvm.ptr<array<101 x i8>>
    %272 = llvm.mlir.constant(0 : index) : i64
    %273 = llvm.getelementptr %271[%272, %272] : (!llvm.ptr<array<101 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %273, %214) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %274 = llvm.inttoptr %4 : i32 to !llvm.ptr<i8>
    %275 = llvm.mlir.constant(2 : index) : i64
    %276 = llvm.mlir.constant(1 : index) : i64
    %277 = llvm.mlir.null : !llvm.ptr<i64>
    %278 = llvm.getelementptr %277[%275] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>
    %279 = llvm.ptrtoint %278 : !llvm.ptr<i64> to i64
    %280 = llvm.alloca %279 x i64 : (i64) -> !llvm.ptr<i64>
    %281 = llvm.mlir.undef : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)>
    %282 = llvm.insertvalue %280, %281[0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %283 = llvm.insertvalue %280, %282[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %284 = llvm.mlir.constant(0 : index) : i64
    %285 = llvm.insertvalue %284, %283[2] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %286 = llvm.insertvalue %275, %285[3, 0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %287 = llvm.insertvalue %276, %286[4, 0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %288 = llvm.extractvalue %287[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %289 = llvm.getelementptr %288[%5] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>
    llvm.store %6, %289 : !llvm.ptr<i64>
    %290 = llvm.extractvalue %287[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %291 = llvm.getelementptr %290[%7] : (!llvm.ptr<i64>, i64) -> !llvm.ptr<i64>
    llvm.store %8, %291 : !llvm.ptr<i64>
    %292 = llvm.mlir.constant(0 : i32) : i32
    %293 = llvm.mlir.constant(1 : i32) : i32
    %294 = llvm.extractvalue %64[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %295 = llvm.extractvalue %64[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %296 = llvm.extractvalue %64[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %297 = llvm.extractvalue %64[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %298 = llvm.extractvalue %64[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %299 = llvm.extractvalue %287[0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %300 = llvm.extractvalue %287[1] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %301 = llvm.extractvalue %287[2] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %302 = llvm.extractvalue %287[3, 0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %303 = llvm.extractvalue %287[4, 0] : !llvm.struct<(ptr<i64>, ptr<i64>, i64, array<1 x i64>, array<1 x i64>)> 
    %304 = llvm.alloca %293 x !llvm.struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)> : (i32) -> !llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>
    %305 = llvm.mlir.constant(13 : i32) : i32
    %306 = llvm.alloca %305 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %307 = llvm.mlir.constant(0 : i32) : i32
    %308 = llvm.getelementptr %304[%292, 0] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %308 : !llvm.ptr<ptr<i8>>
    %309 = llvm.getelementptr %306[%307] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %310 = llvm.bitcast %308 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %310, %309 : !llvm.ptr<ptr<i8>>
    %311 = llvm.mlir.constant(1 : i32) : i32
    %312 = llvm.getelementptr %304[%292, 1] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %274, %312 : !llvm.ptr<ptr<i8>>
    %313 = llvm.getelementptr %306[%311] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %314 = llvm.bitcast %312 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %314, %313 : !llvm.ptr<ptr<i8>>
    %315 = llvm.mlir.constant(2 : i32) : i32
    %316 = llvm.getelementptr %304[%292, 2] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %294, %316 : !llvm.ptr<ptr<f32>>
    %317 = llvm.getelementptr %306[%315] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %318 = llvm.bitcast %316 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %318, %317 : !llvm.ptr<ptr<i8>>
    %319 = llvm.mlir.constant(3 : i32) : i32
    %320 = llvm.getelementptr %304[%292, 3] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %295, %320 : !llvm.ptr<ptr<f32>>
    %321 = llvm.getelementptr %306[%319] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %322 = llvm.bitcast %320 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %322, %321 : !llvm.ptr<ptr<i8>>
    %323 = llvm.mlir.constant(4 : i32) : i32
    %324 = llvm.getelementptr %304[%292, 4] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %296, %324 : !llvm.ptr<i64>
    %325 = llvm.getelementptr %306[%323] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %326 = llvm.bitcast %324 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %326, %325 : !llvm.ptr<ptr<i8>>
    %327 = llvm.mlir.constant(5 : i32) : i32
    %328 = llvm.getelementptr %304[%292, 5] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %297, %328 : !llvm.ptr<i64>
    %329 = llvm.getelementptr %306[%327] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %330 = llvm.bitcast %328 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %330, %329 : !llvm.ptr<ptr<i8>>
    %331 = llvm.mlir.constant(6 : i32) : i32
    %332 = llvm.getelementptr %304[%292, 6] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %298, %332 : !llvm.ptr<i64>
    %333 = llvm.getelementptr %306[%331] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %334 = llvm.bitcast %332 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %334, %333 : !llvm.ptr<ptr<i8>>
    %335 = llvm.mlir.constant(7 : i32) : i32
    %336 = llvm.getelementptr %304[%292, 7] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i64>>
    llvm.store %299, %336 : !llvm.ptr<ptr<i64>>
    %337 = llvm.getelementptr %306[%335] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %338 = llvm.bitcast %336 : !llvm.ptr<ptr<i64>> to !llvm.ptr<i8>
    llvm.store %338, %337 : !llvm.ptr<ptr<i8>>
    %339 = llvm.mlir.constant(8 : i32) : i32
    %340 = llvm.getelementptr %304[%292, 8] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<ptr<i64>>
    llvm.store %300, %340 : !llvm.ptr<ptr<i64>>
    %341 = llvm.getelementptr %306[%339] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %342 = llvm.bitcast %340 : !llvm.ptr<ptr<i64>> to !llvm.ptr<i8>
    llvm.store %342, %341 : !llvm.ptr<ptr<i8>>
    %343 = llvm.mlir.constant(9 : i32) : i32
    %344 = llvm.getelementptr %304[%292, 9] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %301, %344 : !llvm.ptr<i64>
    %345 = llvm.getelementptr %306[%343] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %346 = llvm.bitcast %344 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %346, %345 : !llvm.ptr<ptr<i8>>
    %347 = llvm.mlir.constant(10 : i32) : i32
    %348 = llvm.getelementptr %304[%292, 10] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %302, %348 : !llvm.ptr<i64>
    %349 = llvm.getelementptr %306[%347] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %350 = llvm.bitcast %348 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %350, %349 : !llvm.ptr<ptr<i8>>
    %351 = llvm.mlir.constant(11 : i32) : i32
    %352 = llvm.getelementptr %304[%292, 11] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<i64>
    llvm.store %303, %352 : !llvm.ptr<i64>
    %353 = llvm.getelementptr %306[%351] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %354 = llvm.bitcast %352 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %354, %353 : !llvm.ptr<ptr<i8>>
    %355 = llvm.mlir.constant(12 : i32) : i32
    %356 = llvm.getelementptr %304[%292, 12] : (!llvm.ptr<struct<".6", (ptr<i8>, ptr<i8>, ptr<f32>, ptr<f32>, i64, i64, i64, ptr<i64>, ptr<i64>, i64, i64, i64, struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>)>>, i32) -> !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>>
    %357 = llvm.getelementptr %306[%355] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %358 = llvm.bitcast %356 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>> to !llvm.ptr<i8>
    llvm.store %358, %357 : !llvm.ptr<ptr<i8>>
    %359 = llvm.mlir.addressof @inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32 : !llvm.ptr<array<51 x i8>>
    %360 = llvm.mlir.constant(0 : index) : i64
    %361 = llvm.getelementptr %359[%360, %360] : (!llvm.ptr<array<51 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %361, %306) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %362 = llvm.load %356 : !llvm.ptr<struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>>
    %363 = llvm.mlir.undef : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)>
    %364 = llvm.extractvalue %362[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %365 = llvm.extractvalue %362[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %366 = llvm.insertvalue %364, %363[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %367 = llvm.insertvalue %365, %366[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %368 = llvm.mlir.constant(0 : index) : i64
    %369 = llvm.insertvalue %368, %367[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %370 = llvm.mlir.constant(100 : index) : i64
    %371 = llvm.insertvalue %370, %369[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %372 = llvm.mlir.constant(13 : index) : i64
    %373 = llvm.insertvalue %372, %371[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %374 = llvm.mlir.constant(13 : index) : i64
    %375 = llvm.insertvalue %374, %373[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %376 = llvm.mlir.constant(1 : index) : i64
    %377 = llvm.insertvalue %376, %375[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %378 = llvm.extractvalue %64[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<1 x i64>, array<1 x i64>)> 
    %379 = llvm.bitcast %378 : !llvm.ptr<f32> to !llvm.ptr<i8>
    %380 = llvm.mlir.constant(0 : i32) : i32
    %381 = llvm.mlir.constant(1 : i32) : i32
    %382 = llvm.alloca %381 x !llvm.struct<".7", (ptr<i8>, ptr<i8>)> : (i32) -> !llvm.ptr<struct<".7", (ptr<i8>, ptr<i8>)>>
    %383 = llvm.mlir.constant(2 : i32) : i32
    %384 = llvm.alloca %383 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %385 = llvm.mlir.constant(0 : i32) : i32
    %386 = llvm.getelementptr %382[%380, 0] : (!llvm.ptr<struct<".7", (ptr<i8>, ptr<i8>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %386 : !llvm.ptr<ptr<i8>>
    %387 = llvm.getelementptr %384[%385] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %388 = llvm.bitcast %386 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %388, %387 : !llvm.ptr<ptr<i8>>
    %389 = llvm.mlir.constant(1 : i32) : i32
    %390 = llvm.getelementptr %382[%380, 1] : (!llvm.ptr<struct<".7", (ptr<i8>, ptr<i8>)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %379, %390 : !llvm.ptr<ptr<i8>>
    %391 = llvm.getelementptr %384[%389] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %392 = llvm.bitcast %390 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %392, %391 : !llvm.ptr<ptr<i8>>
    %393 = llvm.mlir.addressof @dealloc___gpu___pvoid_pvoid___void : !llvm.ptr<array<35 x i8>>
    %394 = llvm.mlir.constant(0 : index) : i64
    %395 = llvm.getelementptr %393[%394, %394] : (!llvm.ptr<array<35 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %395, %384) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    %396 = llvm.mlir.constant(0 : i32) : i32
    %397 = llvm.mlir.constant(1 : i32) : i32
    %398 = llvm.extractvalue %377[0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %399 = llvm.extractvalue %377[1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %400 = llvm.extractvalue %377[2] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %401 = llvm.extractvalue %377[3, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %402 = llvm.extractvalue %377[3, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %403 = llvm.extractvalue %377[4, 0] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %404 = llvm.extractvalue %377[4, 1] : !llvm.struct<(ptr<f32>, ptr<f32>, i64, array<2 x i64>, array<2 x i64>)> 
    %405 = llvm.alloca %397 x !llvm.struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)> : (i32) -> !llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>
    %406 = llvm.mlir.constant(9 : i32) : i32
    %407 = llvm.alloca %406 x !llvm.ptr<i8> : (i32) -> !llvm.ptr<ptr<i8>>
    %408 = llvm.mlir.constant(0 : i32) : i32
    %409 = llvm.getelementptr %405[%396, 0] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<i8>>
    llvm.store %arg0, %409 : !llvm.ptr<ptr<i8>>
    %410 = llvm.getelementptr %407[%408] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %411 = llvm.bitcast %409 : !llvm.ptr<ptr<i8>> to !llvm.ptr<i8>
    llvm.store %411, %410 : !llvm.ptr<ptr<i8>>
    %412 = llvm.mlir.constant(1 : i32) : i32
    %413 = llvm.getelementptr %405[%396, 1] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %5, %413 : !llvm.ptr<i64>
    %414 = llvm.getelementptr %407[%412] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %415 = llvm.bitcast %413 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %415, %414 : !llvm.ptr<ptr<i8>>
    %416 = llvm.mlir.constant(2 : i32) : i32
    %417 = llvm.getelementptr %405[%396, 2] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %398, %417 : !llvm.ptr<ptr<f32>>
    %418 = llvm.getelementptr %407[%416] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %419 = llvm.bitcast %417 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %419, %418 : !llvm.ptr<ptr<i8>>
    %420 = llvm.mlir.constant(3 : i32) : i32
    %421 = llvm.getelementptr %405[%396, 3] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<ptr<f32>>
    llvm.store %399, %421 : !llvm.ptr<ptr<f32>>
    %422 = llvm.getelementptr %407[%420] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %423 = llvm.bitcast %421 : !llvm.ptr<ptr<f32>> to !llvm.ptr<i8>
    llvm.store %423, %422 : !llvm.ptr<ptr<i8>>
    %424 = llvm.mlir.constant(4 : i32) : i32
    %425 = llvm.getelementptr %405[%396, 4] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %400, %425 : !llvm.ptr<i64>
    %426 = llvm.getelementptr %407[%424] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %427 = llvm.bitcast %425 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %427, %426 : !llvm.ptr<ptr<i8>>
    %428 = llvm.mlir.constant(5 : i32) : i32
    %429 = llvm.getelementptr %405[%396, 5] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %401, %429 : !llvm.ptr<i64>
    %430 = llvm.getelementptr %407[%428] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %431 = llvm.bitcast %429 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %431, %430 : !llvm.ptr<ptr<i8>>
    %432 = llvm.mlir.constant(6 : i32) : i32
    %433 = llvm.getelementptr %405[%396, 6] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %402, %433 : !llvm.ptr<i64>
    %434 = llvm.getelementptr %407[%432] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %435 = llvm.bitcast %433 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %435, %434 : !llvm.ptr<ptr<i8>>
    %436 = llvm.mlir.constant(7 : i32) : i32
    %437 = llvm.getelementptr %405[%396, 7] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %403, %437 : !llvm.ptr<i64>
    %438 = llvm.getelementptr %407[%436] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %439 = llvm.bitcast %437 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %439, %438 : !llvm.ptr<ptr<i8>>
    %440 = llvm.mlir.constant(8 : i32) : i32
    %441 = llvm.getelementptr %405[%396, 8] : (!llvm.ptr<struct<".8", (ptr<i8>, i64, ptr<f32>, ptr<f32>, i64, i64, i64, i64, i64)>>, i32) -> !llvm.ptr<i64>
    llvm.store %404, %441 : !llvm.ptr<i64>
    %442 = llvm.getelementptr %407[%440] : (!llvm.ptr<ptr<i8>>, i32) -> !llvm.ptr<ptr<i8>>
    %443 = llvm.bitcast %441 : !llvm.ptr<i64> to !llvm.ptr<i8>
    llvm.store %443, %442 : !llvm.ptr<ptr<i8>>
    %444 = llvm.mlir.addressof @ral_send_output___cpu___pvoid_i64_m2df32___void : !llvm.ptr<array<48 x i8>>
    %445 = llvm.mlir.constant(0 : index) : i64
    %446 = llvm.getelementptr %444[%445, %445] : (!llvm.ptr<array<48 x i8>>, i64, i64) -> !llvm.ptr<i8>
    llvm.call @disc_ral_call(%arg0, %446, %407) : (!llvm.ptr<i8>, !llvm.ptr<i8>, !llvm.ptr<ptr<i8>>) -> ()
    llvm.return
  }
}


===-------------------------------------------------------------------------===
                         ... Execution time report ...
===-------------------------------------------------------------------------===
  Total Execution Time: 0.2050 seconds

  ----Wall Time----  ----Name----
    0.0004 (  0.2%)  Inliner
    0.0000 (  0.0%)    (A) CallGraph
    0.0001 (  0.1%)  'func.func' Pipeline
    0.0001 (  0.1%)    Canonicalizer
    0.0003 (  0.1%)  'func.func' Pipeline
    0.0000 (  0.0%)    MhloDecompositionRewriterPass
    0.0000 (  0.0%)    RemoveShapeConstraintsPass
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    DiscCustomCallRewriterPass
    0.0000 (  0.0%)    DiscConvertFakeQuantOpPass
    0.0000 (  0.0%)    DiscLowerGpuQuantizeAndDequantizePass
    0.0000 (  0.0%)    ConvertShapeToStandardPass
    0.0010 (  0.5%)  DiscShapeOptimizationPass
    0.0004 (  0.2%)  'builtin.func' Pipeline
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0003 (  0.1%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0004 (  0.2%)  'func.func' Pipeline
    0.0000 (  0.0%)    ConvertTensorToStandardPass
    0.0000 (  0.0%)    ConvertHloToStandardPass
    0.0001 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    DiscAlgebraicSimplifierPass
    0.0000 (  0.0%)    SplitLargeOpsPass
    0.0000 (  0.0%)    DotRewriterPass
    0.0008 (  0.4%)  DiscShapeOptimizationPass
    0.0001 (  0.0%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscDotMergePass
    0.0008 (  0.4%)  DiscShapeOptimizationPass
    0.0004 (  0.2%)  'func.func' Pipeline
    0.0004 (  0.2%)    HloCanonicalizeReductionPass
    0.0014 (  0.7%)  DiscShapeOptimizationPass
    0.0000 (  0.0%)  DiscMarkShapeCalculationPass
    0.0002 (  0.1%)  PlaceOpsPass
    0.0003 (  0.1%)  'func.func' Pipeline
    0.0001 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    ElementTypeConverterPass
    0.0008 (  0.4%)  DiscShapeOptimizationPass
    0.0001 (  0.0%)  'func.func' Pipeline
    0.0000 (  0.0%)    ReductionRewriterPass
    0.0000 (  0.0%)    ConvRewriterPass
    0.0000 (  0.0%)    ConvRewriterPass
    0.0000 (  0.0%)    QuantizedDotRewriterPass
    0.0008 (  0.4%)  DiscShapeOptimizationPass
    0.0015 (  0.7%)  'func.func' Pipeline
    0.0001 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.1%)    Canonicalizer
    0.0012 (  0.6%)    TransposeSimplifierPass
    0.0000 (  0.0%)    GpuConvPaddingLegalizationPass
    0.0008 (  0.4%)  DiscShapeOptimizationPass
    0.0000 (  0.0%)  'func.func' Pipeline
    0.0000 (  0.0%)    DiscAlgebraicSimplifierPass
    0.0010 (  0.5%)  DiscShapeOptimizationPass
    0.0004 (  0.2%)  'func.func' Pipeline
    0.0003 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.1%)    Canonicalizer
    0.0003 (  0.2%)  FuncBufferize
    0.0000 (  0.0%)  DiscHloLegalizeToLhloPass
    0.0006 (  0.3%)  HloLegalizeToLhloPass
    0.0004 (  0.2%)  'func.func' Pipeline
    0.0004 (  0.2%)    Canonicalizer
    0.0000 (  0.0%)  DiscLhloRewriterPass
    0.0005 (  0.2%)  'func.func' Pipeline
    0.0001 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    ConvertShapeToStandardPass
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    LegalizeToTensorOpPass
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    StdBufferizePass
    0.0000 (  0.0%)  ArithBufferize
    0.0003 (  0.1%)  'func.func' Pipeline
    0.0000 (  0.0%)    TensorBufferize
    0.0000 (  0.0%)    FinalizingBufferize
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    DiscMemrefCanonicalizer
    0.0004 (  0.2%)  DiscAssignMemorySpacePass
    0.0013 (  0.6%)  'func.func' Pipeline
    0.0000 (  0.0%)    DiscDuplicateComputationForFusionPass
    0.0000 (  0.0%)    PromoteBuffersToStack
    0.0000 (  0.0%)    DiscMemRefLoadStoreSimplifierPass
    0.0004 (  0.2%)    DiscFusionPass
    0.0000 (  0.0%)    DiscFuseSplatConstPass
    0.0000 (  0.0%)    DiscSpecializeFusionWithSpeculationPass
    0.0001 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0001 (  0.0%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.0%)    Canonicalizer
    0.0003 (  0.1%)    BufferDeallocation
    0.0000 (  0.0%)    DiscBufferDeallocationPass
    0.0005 (  0.2%)  RalInjectExecutionContextPass
    0.0008 (  0.4%)  'func.func' Pipeline
    0.0008 (  0.4%)    DiscLowerToLibraryCallPass
    0.0002 (  0.1%)  DiscConstToRALPass
    0.0130 (  6.3%)  'func.func' Pipeline
    0.0001 (  0.0%)    DiscMemRefLoadStoreSimplifierPass
    0.0012 (  0.6%)    DiscLhloLegalizeRootsToParallelLoopsPass
    0.0010 (  0.5%)    ExpandOps
    0.0001 (  0.1%)    UnhandledAtomicRMWConverterPass
    0.0011 (  0.5%)    InputInlineFusionPass
    0.0001 (  0.0%)    ForLoopUnrollInterleave
    0.0001 (  0.0%)    ArithExpandOps
    0.0001 (  0.1%)    DiscBF16ExpansionPass
    0.0001 (  0.1%)    FoldMemRefAliasOps
    0.0011 (  0.5%)    DiscFlattenMemrefAccessPass
    0.0011 (  0.5%)    Canonicalizer
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.1%)    Canonicalizer
    0.0001 (  0.1%)    DiscMemRefCSEPass
    0.0009 (  0.4%)    ConvertShapeToStandardPass
    0.0010 (  0.5%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0002 (  0.1%)    Canonicalizer
    0.0009 (  0.4%)    ParallelLoopCollapsing
    0.0011 (  0.5%)    SCFParallelLoopTiling
    0.0011 (  0.5%)    GpuMapParallelLoopsPass
    0.0014 (  0.7%)    ConvertParallelLoopToGpu
    0.0001 (  0.0%)  'func' Pipeline
    0.0001 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0014 (  0.7%)  GpuLaunchSinkIndexComputations
    0.0018 (  0.9%)  GpuKernelOutlining
    0.0016 (  0.8%)  AssignKernelNamePass
    0.0007 (  0.3%)  'func.func' Pipeline
    0.0007 (  0.3%)    LhloFusionInlinerPass
    0.0001 (  0.1%)  DiscCompIntensFusionToCUDASourcePass
    0.0001 (  0.1%)  ReviseGpuKernelOutliningPass
    0.1340 ( 65.4%)  'gpu.module' Pipeline
    0.0001 (  0.1%)    LoopInvariantCodeMotion
    0.0009 (  0.4%)    'gpu.func' Pipeline
    0.0009 (  0.4%)      SideEffectLoopInvariantCodeMotionPass
    0.0001 (  0.0%)    LoopInvariantCodeMotion
    0.0008 (  0.4%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0009 (  0.4%)    SCFToControlFlow
    0.0008 (  0.4%)    ConvertAffineToStandard
    0.0008 (  0.4%)    StripDebugInfo
    0.0026 (  1.2%)    DiscLowerGpuOpsToNVVMOpsPass
    0.0010 (  0.5%)    'llvm.func' Pipeline
    0.0010 (  0.5%)      LLVMInsertValueSimplifierPass
    0.0010 (  0.5%)    FunctionDeadArgumentEliminationPass
    0.1250 ( 61.0%)    GpuKernelToBlobPass
    0.0001 (  0.1%)  DiscGPUSourceToLibPass
    0.0009 (  0.4%)  'func.func' Pipeline
    0.0007 (  0.3%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    RemoveDeadBufferPass
    0.0001 (  0.0%)    LinalgLowerToLoops
    0.0001 (  0.1%)  SCFToControlFlow
    0.0003 (  0.2%)  'func.func' Pipeline
    0.0001 (  0.0%)    ExpandStridedMetadata
    0.0001 (  0.1%)    Canonicalizer
    0.0000 (  0.0%)    CSE
    0.0000 (  0.0%)      (A) DominanceInfo
    0.0001 (  0.1%)    Canonicalizer
    0.0001 (  0.1%)  ConvertAffineToStandard
    0.0073 (  3.5%)  StripDebugInfo
    0.0063 (  3.1%)  DiscStripShapeConstraintOpsPass
    0.0124 (  6.0%)  DiscToLLVMPass
    0.0069 (  3.4%)  Rest
    0.2050 (100.0%)  Total
[DISC] LowerHLOToLLVM takes: 2.055810e-01 s.
before optimize llvm module:
; ModuleID = 'LLVMDialectModule'
source_filename = "LLVMDialectModule"

%0 = type { ptr, i64, { ptr, ptr, i64, [3 x i64], [3 x i64] } }
%.1 = type { ptr, i64, ptr }
%.2 = type { i64, ptr }
%.3 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.4 = type { i64, i64, ptr, ptr }
%.5 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.6 = type { ptr, ptr, ptr, ptr, i64, i64, i64, ptr, ptr, i64, i64, i64, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.7 = type { ptr, ptr }
%.8 = type { ptr, i64, ptr, ptr, i64, i64, i64, i64, i64 }

@ral_send_output___cpu___pvoid_i64_m2df32___void = internal constant [48 x i8] c"ral_send_output___cpu___pvoid_i64_m2df32___void\00"
@dealloc___gpu___pvoid_pvoid___void = internal constant [35 x i8] c"dealloc___gpu___pvoid_pvoid___void\00"
@inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32 = internal constant [51 x i8] c"inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32\00"
@main_kernel_0_main_kColReduction_reduce__3_1_0_1_kernel_name = internal constant [35 x i8] c"main_kColReduction_reduce__3_1_0_1\00"
@main_kernel_0_blob_gpu.binary = internal constant [3104 x i8] c"P\EDU\BA\01\00\10\00\10\0C\00\00\00\00\00\00\02\00\01\01@\00\00\00\D0\0B\00\00\00\00\00\00\CA\0B\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\1D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\1C\00\01\00\11\1A\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\A5e__3_1_0_12\00\0F,\00\15oshared.\00\12Orela\88\00\17?rel\B5\00\1A\9Fconstant01\00\12\B2debug_framek\00\09\11\00!nv\14\00\11a=\00\0Fn\01 \0F\82\00\0F\0F\91\01\FDo_param\98\01\1C\0F\01\00\06\8CU\00\00\00\03\00\0A\00\01\00 3\01\18\00,\09\00\01\00\11k\18\00,\04\00\01\00\11\89\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\12\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\22\04X\AC\00\90\04/\08\00\05\00\00\00\18\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04h\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\18\00\03\19\18\00\04\17\0C$\00u\03\00\10\00\00\F0!\10\009\02\00\08\10\00\10\01(\01%\F0\11\10\00\01\01\00\C2\F0\11\00\03\1B\FF\00\04\1C\0C\00P%\00r\00\C0\11\00\00\04\1E\A8\00#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08_\00\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00H\01/\05\00\01\00\FF\98@$v\01\FF\1F\04\B1\FF\00\8E\07\00\C4\0F\00\19y\03\18\00 \00%s\02R\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00X\E9\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\B0\80\03\00\EA\0F\00\19x\00\FF\1FL\03\90\14\01\00\00\C8\0F\00\11rX\03`\00\00\FF@\8F\07\10\00A\19x\02\FFI\02\00 \00S\E4\0F\00\12x\09\04\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\AB\AA\AA\AA\A0\00\80\C8\0F\00$x\00\03\010\00P\0A\8E\07\00\E2@\00 \04\FFt\02`\04\16\01\00\00\CA \00\84\05\04\FA\FF\FF\FF\02\020\00D\05\05\00\01\B0\00\CF\0F\00\0Cx\00\05\13\05\00\00p@\B0\00\03c$x\00\04 \00\10\01\B1\E2\0F\04\B9z\04\00\00F\00\00C\05\10\E2 \00\82\03\04\80\9C\00\00\03\02\A0\001\10x\02_\00\D0\FF\E0\FF\07\00\E4\0F\04\0Cx\00\00m\B0\04Q@\F8\03\00\E4p\00\12\02\10\00!\FA\03@\00Dt\02\FF\04`\00\B1\D4\0F\00%\C6\06\03\00Z\00\00\B0\00\93\E4\0F\04\10\D8\09\03\14\05P\00q\C6\0F\00\81\C9\0D\06:\04\B5\19\1E\0C\00\A4\00\00%\D6\08\090\00u\CA\0F\00\81\D9\0F\08 \00\84\E2\02\00\10x\04\00\02\90\00\11\C8\80\003\04m\00\F0\00!\E4\0F \00\1F\03 \00\02\15\F2 \00\17\04\D0\00\22\10x4\05\02\10\00\17/0\00\12\F40\00S\88\0B\03(\0A \00u\CA\0F\00%\86\0A\0B\A0\00\93\E2\0F\00\10\98\07\03<\0F \00u\C8\1F\00\81\89\04\0A\B0\00x\22\01\00%\96\06\070\00B\0Cx\00\08`\00\13\F6\90\00G\09\03P\14\10\01&\99\06\10\01\84\22\03\00\10x\0E\00\06\A0\00W\E2\0F\00%\A6 \01\00\00\02qt\0C\FF\00\00\80\FFp\01\00P\00T\B8\0B\03d\190\00h\1F\00\81\A9\09\08\90\006$t\110\00W\C6\0F\00%\B6\D0\00i\CC\0F\00\81\B9\0A\C0\00@\0B\C8\00\0D0\00\B2\00\C0\FC\03\00\C8O\00\08\C8\0C\10\00!\00\00\C0\00H\0Cx\00\0E\10\02P\0B\D2\00\0C\0F@\00\C6`\FC\03\00\E4\8F\08\10x\0D\00\07p\01B\00\08\D2\11 \00\06@\00\15\0D@\02\97\CA\0F\00\10\C8\0D\03x\1Ep\015\C6\0C\0D\A0\00\00\90\02V\D8\0F\03\8C#P\00E\81\C9\08\0C\B0\00u\A6\10\00%\D6\0E\0F0\00\01@\02%\07\0E \00\84\E2\22\00\0B\82\00\11\04\A0\00i\E2\0F\01$t\13\10\012\08\82\13 \00%\00\000\02%\08\00p\00a\04\0B\92\00\13\06@\00\10\F0@\00F\0C$t\10@\00\00\10\02Hx\0B\00\09\F0\00\22\92\100\00\00\01\00\1B\E4\B0\02\11\C4\10\00\18\0B\A0\02U\0B\A2\00\10\09@\01 \0F\08\80\00\17\0AP\00f\10x\0D\03\A0(\E0\017$t\0F\80\00R/\00\08\A2\0F@\00\06`\01\06\D0\02\00@\02\17\86P\01\84\E2\0F\00\0B\B2\00\0F\0Ap\00\10\C4`\008\06\00\0Bp\00T\98\0B\03\B4-p\00\1A\0F@\02 \E2\0F\F0\02\18\0C0\022\08\B2\11P\00\06\80\00\15\06\F0\02\00\80\00\1B\96@\03V\A8\0F\03\C82\B0\03H\81\99\06\0A\00\03J%\A6\0E\0F\F0\02\0Ap\016\81\A9\09\E0\01\93\22\05\00\10\B8\0D\03\DC7P\00\84\E4\1F\00\10x\0C\00\0D\D0\00\01\C0\00\19\130\037%\B6\0A\10\01\11/`\01$\F0<@\00t\0F\00\0B\C2\00\11\08 \01\00\00\03\22\C2\10\10\00\03\E0\00\00@\04'\0C\000\00G\D2\00\10\07\00\03\06\F0\03\02 \032\08\D2\13 \00\06 \01\18\0C@\056\81\B9\10\00\01*\B0\00\00\03\12\C8\00\03&\04B\D0\00\09\00\03/\E8\02\00\03\0Cy\00\00\10x\11\00\0E\10\01\19\15P\01U\0B\82\00\13\04\F0\00R\0F\01\08\82\15\10\00\06\B0\00\1C\11p\05\18\0F\00\01D\92\00\15\06@\00\01`\00\16\0A`\00b\C6\1F\00\08\92\0A \00\0D\A0\02\02\A0\05G\0B\A2\00\0A\00\03\10\0C\80\05(\18G\B0\00\19\0F\B0\002\08\A2\0F0\00%\00\00\90\00\16\10\E0\00\1D\04\B0\05Dx\06\00\11 \00\1B\C4 \03\00@\00T\98\0D\03,L@\00\1F/\F0\02\01\06\A0\01\10&\E0\05\0AP\03X\10x\09\00\12\10\01H\B2\00\0F\10@\02\22\B2\11\10\00\0F \03\01\01\C0\00D\0F\03@Q\80\00\01\10\03\06\E0\01-\A2\02\00\03\09\A0\02*\E4\8F0\03*\E4\0F\B0\02\02\F0\00\18\09\90\026\81\A9\0E \02\9F\A2\06\00\10\B8\09\03TV\D0\02\05\00\90\04O\08\00\13\00\10\04\076\08\D2\11\E0\02\11\E2`\03\06\B0\06'\E2\1F\00\07\12\FAp\04V\C8\09\03h[p\00\09\00\03\10\A6\00\03(\08\09\A0\06f\10\D8\0D\03|`\A0\016\81\C9\08\E0\06\10\A8\00\03+\0C\0D\00\03\07@\01\1B\00@\02\1A\8F\10\06\01\F0\02\1D\0F\00\06&\14\00P\02\0C\F0\00h\10x\0A\00\15\00\90\05\17\09 \00\00P\04H\0B\03\90e0\01\19\12@\00E\0B\92\00\0FP\06\00 \02\22\92\11\10\00\0D0\06\14\F20\02\18\0A\80\03T\0B\A2\00\11\0E\C0\00\000\03Vx\04\00\16\00P\012\08\A2\09 \00\06\00\02\0A\F0\02Ex\04\00\17\C0\00\0E\A0\05E\0B\B2\00\09\C0\02\1E\C6\F0\01g\10\88\0D\03\A4jp\00\22\B2\110\00\03@\01\06p\00\02\E0\02H\81\99\04\0A\90\01\0C\90\06\00\10\06/\B8o\80\05\04\10\C4\80\03(\06\0C\10\0A\09\F0\02\00\80\02G\C2\12\11\08\80\00\00\B0\02)\18\00\D0\02'\12\07\A0\04\09\00\03\87\E2\08\00\10x\10\00\190\00\09\C0\05\0F\F0\02\00\000\03&\CCtP\042\08\D2\11`\00\06\00\01\18\10\E0\05\0C\10\03\00\00\0A#\E0y@\00\1B\C8\00\03\1F\E2\00\03\03/\F4~\00\03\04\1F\E8\00\03\0C*\E2\04\00\07\11\E2p\04\01{\14\02P\00\00\10\09\16\0B \00\1E\E4\D0\02(\0B\920\03\00\B0\02\0A0\09I\0Cx\00\0F\D0\05\14\820\09\00\A0\02\11\8F\A0\02\17\1B`\01_\08\82\0B\13\060\02\02\02 \09U\0B\A2\00\0B\0Ep\00\01\D0\02\02\10\00\030\00\00\A0\08&\08\84P\00\00`\00\19\1C\E0\0B?\06\00\1D\E0\02\159\E4\0F\08 \03\0Fp\06\00\00\F0\02&\1C\89P\00\0C\D0\026\08\B2\0F\00\03\1E\C4\00\09\0D\80\09I\C2\00\0F\08`\057\0E\00\1E\B0\00\0C\F0\05\000\02'0\8E\80\00\0B\10\032\08\C2\10P\00\0F\A0\0B\01\0C@\0C\1B\E2\E0\05\01\00\0A9\00\00\1F\80\00\0C\F0\02O\0B\03D\93`\0C\07\09\00\06\02\80\00\1B\00\00\03\06\80\01\12\E4\F0\0B#X\98P\00+\C8/\80\0C\0B\00\0C\12\CA\00\09$l\9D\80\00\00\00\09\16\0C\00\01*(\0F\00\09\00\D0\0C9\D9\0E\0EP\00Vv\02\05\00\\P\00E\81y\08\02 \00fb\11\00$t\05\F0\00\10\E4\00\01\1B\00\10\00\1C\07\C0\05\0B\10\03\16\05\10\03\11\C8\00\03\11\05\E0\02\84`\F2\03\00\C8\8F\00\08\10\00\22\00\80p\0F)t\05\80\0CU\0B\A2\00\00\09\10\06R\0F\01\08\A2\05\10\00\00\01\00\11\C8\B0\02&\05\0A \00B\00\08\B2\07\10\00/\00\00P\00\03H\C2\00\07\0C0\00\22\C2\05\10\00\050\00\1A\070\00H\D2\00\05\0E0\00\22\D2\07\10\00\01\80\00a\1F\00\0Br\00\08\E0\01\00\A0\03W\E2\0F\0EFy`\10b\E6\0F\00\08r\09 \00\00\01\00p\CC\0F\00\A9s\09\02\90\02\C0\09\E1\1E\00\00\A4\0E\00\0Cr\00\09\10\00 pR@\00`O\00$r\08\FFM\0E\10\09\80\00\80\D8\0F\00G\09\00\00\90 \11!\FF\83\B0\10*My\C0\10TGy\00\00\F0 \00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\22\01\00P\12\0C\01\00\22@\00\01\00=n\01\000\00\08\01\00\1F\0B@\00\04\13\AE)\00\1F\98@\00\0C\13\13\F4\14\0C\01\00\13HU\00&\90\00\18\15#\04\00m\15\03\A8\16\00\01\00.A\01T\00\00\01\00\13\D8@\00/p\00\80\00\0B\1F)'\00\03#\00He\03\04P\17\04\E4\00*\04\00\01\00\1F[@\00\04\13x)\00&x\00@\00\1F\0A@\00\00!_\01D\01\0D@\00\13\F0)\00*\D8\00\01\00\1B\08\08\00#N\01\D0\03\0B\01\00\13\C8E\16\17\10\80\00\17\048\00\04\18\00\13\10@\01\0C\84\01\13\D8@\00\17x1\01\0F\C0\00\01\132T\01*\06\00\01\00*\80\07\D0\18\12\03\D8\16:\18\80\00\01\00\13\06\F0\16\05\A8\1C\0B\01\00*\A8\00\08\00\17\08\C8\01\17\05\A8\00\0C\01\009(\14\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00"
@ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void = internal constant [101 x i8] c"ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00"
@main_kernel_main_kColReduction_reduce__3_1_0_kernel_name = internal constant [33 x i8] c"main_kColReduction_reduce__3_1_0\00"
@main_kernel_blob_gpu.binary = internal constant [1072 x i8] c"P\EDU\BA\01\00\10\00 \04\00\00\00\00\00\00\02\00\01\01@\00\00\00\E0\03\00\00\00\00\00\00\E0\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\0A\00\01\00\11\08\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\85e__3_1_00\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FA\01debug_frame\00.rel\11\00!nv\14\00\11a;\00\0F\0B\01 \0F\80\00\0D\0F,\01\9Ao_param3\01\1C\0F\01\00\06\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\11$\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00C/\08\00\05_\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\A0\03\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C$\00\10\01N\00%\F0!\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00v\02\02\08\10\0A/\22\EA\03\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00 \01/\05\00\01\00\FF\88A\02z\01\00\E7\03\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%c\02Q\0E\00\19y\03\0F\00 \00!\CD\03\F5\14\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cx\00\02\13\05\00\00p@\F0\03\00\DA\0F\00M\1B\04\A0\80\03\00\EA\0F\005t\03\FF{\03\10\FF\88\03P\E2\0F\00\02x\0E\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\90\D0\0F\00%v\02\02\00Z4\04\00`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F0\01\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=\0B\01\000\00\08\01\00\1F\0B@\00\04\13K)\00\1F3@\00\0C\13\13\E4\03\0C\01\00\13\80\15\00&\90\00\08\04#\04\00]\04\00\CE\04\12\00\01\00\1F\DET\00\00\00\01\00\13\10\95\00/p\00\80\00\0B\1F)'\00\03#\00\80@\00\04\18\06\04\E4\00*\04\00\01\00\1FY@\00\04\13\B01\00&L\00@\00\1F\0A@\00\00\12\FCD\01\0D@\00\04)\00*\D8\00\01\00\1B\08\08\00?\EB\00\00N\07\003\00\00\D8@\00&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01*\E8\04\00\07\1F\00\C0\00\04\132@\00*\06\00\01\00*\80\06\98\07\12\03\C8\05:\08\80\00\01\00\13\06\E0\05\05\A8\0A\0B\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009\18\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"
@alloc___gpu___pvoid_i64___pvoid = internal constant [32 x i8] c"alloc___gpu___pvoid_i64___pvoid\00"
@ral_recv_input___cpu___pvoid_i64___m3df32 = internal constant [42 x i8] c"ral_recv_input___cpu___pvoid_i64___m3df32\00"

declare ptr @malloc(i64)

declare void @free(ptr)

declare void @disc_ral_call(ptr, ptr, ptr)

define void @main(ptr %0) {
  %2 = alloca %0, align 8
  %3 = alloca ptr, i32 3, align 8
  %4 = getelementptr %0, ptr %2, i32 0, i32 0
  store ptr %0, ptr %4, align 8
  %5 = getelementptr ptr, ptr %3, i32 0
  store ptr %4, ptr %5, align 8
  %6 = getelementptr %0, ptr %2, i32 0, i32 1
  store i64 0, ptr %6, align 4
  %7 = getelementptr ptr, ptr %3, i32 1
  store ptr %6, ptr %7, align 8
  %8 = getelementptr %0, ptr %2, i32 0, i32 2
  %9 = getelementptr ptr, ptr %3, i32 2
  store ptr %8, ptr %9, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_recv_input___cpu___pvoid_i64___m3df32, ptr %3)
  %10 = load { ptr, ptr, i64, [3 x i64], [3 x i64] }, ptr %8, align 8
  %11 = alloca %.1, align 8
  %12 = alloca ptr, i32 3, align 8
  %13 = getelementptr %.1, ptr %11, i32 0, i32 0
  store ptr %0, ptr %13, align 8
  %14 = getelementptr ptr, ptr %12, i32 0
  store ptr %13, ptr %14, align 8
  %15 = getelementptr %.1, ptr %11, i32 0, i32 1
  store i64 ptrtoint (ptr getelementptr (float, ptr null, i64 1300) to i64), ptr %15, align 4
  %16 = getelementptr ptr, ptr %12, i32 1
  store ptr %15, ptr %16, align 8
  %17 = getelementptr %.1, ptr %11, i32 0, i32 2
  %18 = getelementptr ptr, ptr %12, i32 2
  store ptr %17, ptr %18, align 8
  call void @disc_ral_call(ptr %0, ptr @alloc___gpu___pvoid_i64___pvoid, ptr %12)
  %19 = load ptr, ptr %17, align 8
  %20 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } undef, ptr %19, 0
  %21 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %20, ptr %19, 1
  %22 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %21, i64 0, 2
  %23 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %22, i64 1300, 3, 0
  %24 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %23, i64 1, 4, 0
  %25 = alloca ptr, align 8
  %26 = getelementptr ptr, ptr %25, i32 0
  store ptr @main_kernel_blob_gpu.binary, ptr %26, align 8
  %27 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 0
  %28 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 1
  %29 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 2
  %30 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 3, 0
  %31 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 4, 0
  %32 = alloca %.2, align 8
  %33 = alloca ptr, i32 2, align 8
  %34 = getelementptr %.2, ptr %32, i32 0, i32 0
  store i64 256, ptr %34, align 4
  %35 = getelementptr ptr, ptr %33, i32 0
  store ptr %34, ptr %35, align 8
  %36 = getelementptr %.2, ptr %32, i32 0, i32 1
  store ptr %28, ptr %36, align 8
  %37 = getelementptr ptr, ptr %33, i32 1
  store ptr %36, ptr %37, align 8
  %38 = alloca %.3, align 8
  %39 = alloca ptr, i32 14, align 8
  %40 = getelementptr %.3, ptr %38, i32 0, i32 0
  store ptr %0, ptr %40, align 8
  %41 = getelementptr ptr, ptr %39, i32 0
  store ptr %40, ptr %41, align 8
  %42 = getelementptr %.3, ptr %38, i32 0, i32 1
  store ptr %25, ptr %42, align 8
  %43 = getelementptr ptr, ptr %39, i32 1
  store ptr %42, ptr %43, align 8
  %44 = getelementptr %.3, ptr %38, i32 0, i32 2
  store i64 1, ptr %44, align 4
  %45 = getelementptr ptr, ptr %39, i32 2
  store ptr %44, ptr %45, align 8
  %46 = getelementptr %.3, ptr %38, i32 0, i32 3
  store ptr @main_kernel_main_kColReduction_reduce__3_1_0_kernel_name, ptr %46, align 8
  %47 = getelementptr ptr, ptr %39, i32 3
  store ptr %46, ptr %47, align 8
  %48 = getelementptr %.3, ptr %38, i32 0, i32 4
  store i64 6, ptr %48, align 4
  %49 = getelementptr ptr, ptr %39, i32 4
  store ptr %48, ptr %49, align 8
  %50 = getelementptr %.3, ptr %38, i32 0, i32 5
  store i64 1, ptr %50, align 4
  %51 = getelementptr ptr, ptr %39, i32 5
  store ptr %50, ptr %51, align 8
  %52 = getelementptr %.3, ptr %38, i32 0, i32 6
  store i64 1, ptr %52, align 4
  %53 = getelementptr ptr, ptr %39, i32 6
  store ptr %52, ptr %53, align 8
  %54 = getelementptr %.3, ptr %38, i32 0, i32 7
  store i64 256, ptr %54, align 4
  %55 = getelementptr ptr, ptr %39, i32 7
  store ptr %54, ptr %55, align 8
  %56 = getelementptr %.3, ptr %38, i32 0, i32 8
  store i64 1, ptr %56, align 4
  %57 = getelementptr ptr, ptr %39, i32 8
  store ptr %56, ptr %57, align 8
  %58 = getelementptr %.3, ptr %38, i32 0, i32 9
  store i64 1, ptr %58, align 4
  %59 = getelementptr ptr, ptr %39, i32 9
  store ptr %58, ptr %59, align 8
  %60 = getelementptr %.3, ptr %38, i32 0, i32 10
  store i32 0, ptr %60, align 4
  %61 = getelementptr ptr, ptr %39, i32 10
  store ptr %60, ptr %61, align 8
  %62 = getelementptr %.3, ptr %38, i32 0, i32 11
  store ptr null, ptr %62, align 8
  %63 = getelementptr ptr, ptr %39, i32 11
  store ptr %62, ptr %63, align 8
  %64 = getelementptr %.3, ptr %38, i32 0, i32 12
  store i32 2, ptr %64, align 4
  %65 = getelementptr ptr, ptr %39, i32 12
  store ptr %64, ptr %65, align 8
  %66 = getelementptr %.3, ptr %38, i32 0, i32 13
  store ptr %33, ptr %66, align 8
  %67 = getelementptr ptr, ptr %39, i32 13
  store ptr %66, ptr %67, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %39)
  %68 = alloca ptr, align 8
  %69 = getelementptr ptr, ptr %68, i32 0
  store ptr @main_kernel_0_blob_gpu.binary, ptr %69, align 8
  %70 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 0
  %71 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 1
  %72 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 2
  %73 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 0
  %74 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 1
  %75 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 3, 2
  %76 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 4, 0
  %77 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 4, 1
  %78 = extractvalue { ptr, ptr, i64, [3 x i64], [3 x i64] } %10, 4, 2
  %79 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 0
  %80 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 1
  %81 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 2
  %82 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 3, 0
  %83 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 4, 0
  %84 = alloca %.4, align 8
  %85 = alloca ptr, i32 4, align 8
  %86 = getelementptr %.4, ptr %84, i32 0, i32 0
  store i64 256, ptr %86, align 4
  %87 = getelementptr ptr, ptr %85, i32 0
  store ptr %86, ptr %87, align 8
  %88 = getelementptr %.4, ptr %84, i32 0, i32 1
  store i64 6144, ptr %88, align 4
  %89 = getelementptr ptr, ptr %85, i32 1
  store ptr %88, ptr %89, align 8
  %90 = getelementptr %.4, ptr %84, i32 0, i32 2
  store ptr %71, ptr %90, align 8
  %91 = getelementptr ptr, ptr %85, i32 2
  store ptr %90, ptr %91, align 8
  %92 = getelementptr %.4, ptr %84, i32 0, i32 3
  store ptr %80, ptr %92, align 8
  %93 = getelementptr ptr, ptr %85, i32 3
  store ptr %92, ptr %93, align 8
  %94 = alloca %.5, align 8
  %95 = alloca ptr, i32 14, align 8
  %96 = getelementptr %.5, ptr %94, i32 0, i32 0
  store ptr %0, ptr %96, align 8
  %97 = getelementptr ptr, ptr %95, i32 0
  store ptr %96, ptr %97, align 8
  %98 = getelementptr %.5, ptr %94, i32 0, i32 1
  store ptr %68, ptr %98, align 8
  %99 = getelementptr ptr, ptr %95, i32 1
  store ptr %98, ptr %99, align 8
  %100 = getelementptr %.5, ptr %94, i32 0, i32 2
  store i64 1, ptr %100, align 4
  %101 = getelementptr ptr, ptr %95, i32 2
  store ptr %100, ptr %101, align 8
  %102 = getelementptr %.5, ptr %94, i32 0, i32 3
  store ptr @main_kernel_0_main_kColReduction_reduce__3_1_0_1_kernel_name, ptr %102, align 8
  %103 = getelementptr ptr, ptr %95, i32 3
  store ptr %102, ptr %103, align 8
  %104 = getelementptr %.5, ptr %94, i32 0, i32 4
  store i64 24, ptr %104, align 4
  %105 = getelementptr ptr, ptr %95, i32 4
  store ptr %104, ptr %105, align 8
  %106 = getelementptr %.5, ptr %94, i32 0, i32 5
  store i64 1, ptr %106, align 4
  %107 = getelementptr ptr, ptr %95, i32 5
  store ptr %106, ptr %107, align 8
  %108 = getelementptr %.5, ptr %94, i32 0, i32 6
  store i64 1, ptr %108, align 4
  %109 = getelementptr ptr, ptr %95, i32 6
  store ptr %108, ptr %109, align 8
  %110 = getelementptr %.5, ptr %94, i32 0, i32 7
  store i64 256, ptr %110, align 4
  %111 = getelementptr ptr, ptr %95, i32 7
  store ptr %110, ptr %111, align 8
  %112 = getelementptr %.5, ptr %94, i32 0, i32 8
  store i64 1, ptr %112, align 4
  %113 = getelementptr ptr, ptr %95, i32 8
  store ptr %112, ptr %113, align 8
  %114 = getelementptr %.5, ptr %94, i32 0, i32 9
  store i64 1, ptr %114, align 4
  %115 = getelementptr ptr, ptr %95, i32 9
  store ptr %114, ptr %115, align 8
  %116 = getelementptr %.5, ptr %94, i32 0, i32 10
  store i32 0, ptr %116, align 4
  %117 = getelementptr ptr, ptr %95, i32 10
  store ptr %116, ptr %117, align 8
  %118 = getelementptr %.5, ptr %94, i32 0, i32 11
  store ptr null, ptr %118, align 8
  %119 = getelementptr ptr, ptr %95, i32 11
  store ptr %118, ptr %119, align 8
  %120 = getelementptr %.5, ptr %94, i32 0, i32 12
  store i32 4, ptr %120, align 4
  %121 = getelementptr ptr, ptr %95, i32 12
  store ptr %120, ptr %121, align 8
  %122 = getelementptr %.5, ptr %94, i32 0, i32 13
  store ptr %85, ptr %122, align 8
  %123 = getelementptr ptr, ptr %95, i32 13
  store ptr %122, ptr %123, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr %95)
  %124 = alloca i64, i64 ptrtoint (ptr getelementptr (i64, ptr null, i64 2) to i64), align 8
  %125 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } undef, ptr %124, 0
  %126 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %125, ptr %124, 1
  %127 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %126, i64 0, 2
  %128 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %127, i64 2, 3, 0
  %129 = insertvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %128, i64 1, 4, 0
  %130 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %129, 1
  %131 = getelementptr i64, ptr %130, i64 0
  store i64 100, ptr %131, align 4
  %132 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %129, 1
  %133 = getelementptr i64, ptr %132, i64 1
  store i64 13, ptr %133, align 4
  %134 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 0
  %135 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 1
  %136 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 2
  %137 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 3, 0
  %138 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 4, 0
  %139 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %129, 0
  %140 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %129, 1
  %141 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %129, 2
  %142 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %129, 3, 0
  %143 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %129, 4, 0
  %144 = alloca %.6, align 8
  %145 = alloca ptr, i32 13, align 8
  %146 = getelementptr %.6, ptr %144, i32 0, i32 0
  store ptr %0, ptr %146, align 8
  %147 = getelementptr ptr, ptr %145, i32 0
  store ptr %146, ptr %147, align 8
  %148 = getelementptr %.6, ptr %144, i32 0, i32 1
  store ptr null, ptr %148, align 8
  %149 = getelementptr ptr, ptr %145, i32 1
  store ptr %148, ptr %149, align 8
  %150 = getelementptr %.6, ptr %144, i32 0, i32 2
  store ptr %134, ptr %150, align 8
  %151 = getelementptr ptr, ptr %145, i32 2
  store ptr %150, ptr %151, align 8
  %152 = getelementptr %.6, ptr %144, i32 0, i32 3
  store ptr %135, ptr %152, align 8
  %153 = getelementptr ptr, ptr %145, i32 3
  store ptr %152, ptr %153, align 8
  %154 = getelementptr %.6, ptr %144, i32 0, i32 4
  store i64 %136, ptr %154, align 4
  %155 = getelementptr ptr, ptr %145, i32 4
  store ptr %154, ptr %155, align 8
  %156 = getelementptr %.6, ptr %144, i32 0, i32 5
  store i64 %137, ptr %156, align 4
  %157 = getelementptr ptr, ptr %145, i32 5
  store ptr %156, ptr %157, align 8
  %158 = getelementptr %.6, ptr %144, i32 0, i32 6
  store i64 %138, ptr %158, align 4
  %159 = getelementptr ptr, ptr %145, i32 6
  store ptr %158, ptr %159, align 8
  %160 = getelementptr %.6, ptr %144, i32 0, i32 7
  store ptr %139, ptr %160, align 8
  %161 = getelementptr ptr, ptr %145, i32 7
  store ptr %160, ptr %161, align 8
  %162 = getelementptr %.6, ptr %144, i32 0, i32 8
  store ptr %140, ptr %162, align 8
  %163 = getelementptr ptr, ptr %145, i32 8
  store ptr %162, ptr %163, align 8
  %164 = getelementptr %.6, ptr %144, i32 0, i32 9
  store i64 %141, ptr %164, align 4
  %165 = getelementptr ptr, ptr %145, i32 9
  store ptr %164, ptr %165, align 8
  %166 = getelementptr %.6, ptr %144, i32 0, i32 10
  store i64 %142, ptr %166, align 4
  %167 = getelementptr ptr, ptr %145, i32 10
  store ptr %166, ptr %167, align 8
  %168 = getelementptr %.6, ptr %144, i32 0, i32 11
  store i64 %143, ptr %168, align 4
  %169 = getelementptr ptr, ptr %145, i32 11
  store ptr %168, ptr %169, align 8
  %170 = getelementptr %.6, ptr %144, i32 0, i32 12
  %171 = getelementptr ptr, ptr %145, i32 12
  store ptr %170, ptr %171, align 8
  call void @disc_ral_call(ptr %0, ptr @inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32, ptr %145)
  %172 = load { ptr, ptr, i64, [2 x i64], [2 x i64] }, ptr %170, align 8
  %173 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %172, 0
  %174 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %172, 1
  %175 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } undef, ptr %173, 0
  %176 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %175, ptr %174, 1
  %177 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %176, i64 0, 2
  %178 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %177, i64 100, 3, 0
  %179 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %178, i64 13, 4, 0
  %180 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %179, i64 13, 3, 1
  %181 = insertvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %180, i64 1, 4, 1
  %182 = extractvalue { ptr, ptr, i64, [1 x i64], [1 x i64] } %24, 0
  %183 = alloca %.7, align 8
  %184 = alloca ptr, i32 2, align 8
  %185 = getelementptr %.7, ptr %183, i32 0, i32 0
  store ptr %0, ptr %185, align 8
  %186 = getelementptr ptr, ptr %184, i32 0
  store ptr %185, ptr %186, align 8
  %187 = getelementptr %.7, ptr %183, i32 0, i32 1
  store ptr %182, ptr %187, align 8
  %188 = getelementptr ptr, ptr %184, i32 1
  store ptr %187, ptr %188, align 8
  call void @disc_ral_call(ptr %0, ptr @dealloc___gpu___pvoid_pvoid___void, ptr %184)
  %189 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %181, 0
  %190 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %181, 1
  %191 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %181, 2
  %192 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %181, 3, 0
  %193 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %181, 3, 1
  %194 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %181, 4, 0
  %195 = extractvalue { ptr, ptr, i64, [2 x i64], [2 x i64] } %181, 4, 1
  %196 = alloca %.8, align 8
  %197 = alloca ptr, i32 9, align 8
  %198 = getelementptr %.8, ptr %196, i32 0, i32 0
  store ptr %0, ptr %198, align 8
  %199 = getelementptr ptr, ptr %197, i32 0
  store ptr %198, ptr %199, align 8
  %200 = getelementptr %.8, ptr %196, i32 0, i32 1
  store i64 0, ptr %200, align 4
  %201 = getelementptr ptr, ptr %197, i32 1
  store ptr %200, ptr %201, align 8
  %202 = getelementptr %.8, ptr %196, i32 0, i32 2
  store ptr %189, ptr %202, align 8
  %203 = getelementptr ptr, ptr %197, i32 2
  store ptr %202, ptr %203, align 8
  %204 = getelementptr %.8, ptr %196, i32 0, i32 3
  store ptr %190, ptr %204, align 8
  %205 = getelementptr ptr, ptr %197, i32 3
  store ptr %204, ptr %205, align 8
  %206 = getelementptr %.8, ptr %196, i32 0, i32 4
  store i64 %191, ptr %206, align 4
  %207 = getelementptr ptr, ptr %197, i32 4
  store ptr %206, ptr %207, align 8
  %208 = getelementptr %.8, ptr %196, i32 0, i32 5
  store i64 %192, ptr %208, align 4
  %209 = getelementptr ptr, ptr %197, i32 5
  store ptr %208, ptr %209, align 8
  %210 = getelementptr %.8, ptr %196, i32 0, i32 6
  store i64 %193, ptr %210, align 4
  %211 = getelementptr ptr, ptr %197, i32 6
  store ptr %210, ptr %211, align 8
  %212 = getelementptr %.8, ptr %196, i32 0, i32 7
  store i64 %194, ptr %212, align 4
  %213 = getelementptr ptr, ptr %197, i32 7
  store ptr %212, ptr %213, align 8
  %214 = getelementptr %.8, ptr %196, i32 0, i32 8
  store i64 %195, ptr %214, align 4
  %215 = getelementptr ptr, ptr %197, i32 8
  store ptr %214, ptr %215, align 8
  call void @disc_ral_call(ptr %0, ptr @ral_send_output___cpu___pvoid_i64_m2df32___void, ptr %197)
  ret void
}

host default target triple: x86_64-unknown-linux-gnu
host cpu name: icelake-server
host cpu features: -avx512pf,-tsxldtrk,+cx16,+sahf,-tbm,+avx512ifma,+sha,+crc32,-fma4,+vpclmulqdq,+prfchw,+bmi2,-cldemote,+fsgsbase,-avx512bf16,-amx-tile,-raoint,-uintr,+gfni,+popcnt,-ptwrite,+aes,+avx512bitalg,-movdiri,-widekl,+xsaves,-avx512er,-avxvnni,-avx512fp16,+avx512vnni,-amx-bf16,-avxvnniint8,+avx512vpopcntdq,-pconfig,+clwb,-cmpccxadd,+avx512f,+xsavec,-clzero,-pku,-amx-fp16,+mmx,-lwp,+rdpid,-xop,+rdseed,-waitpkg,-prefetchi,-kl,-movdir64b,-sse4a,+avx512bw,-avxneconvert,+clflushopt,+xsave,+avx512vbmi2,+64bit,+avx512vl,-serialize,-hreset,+invpcid,+avx512cd,+avx,+vaes,-amx-int8,+cx8,+fma,-rtm,+bmi,-enqcmd,+rdrnd,-mwaitx,+sse4.1,+sse4.2,+avx2,+fxsr,+wbnoinvd,+sse,+lzcnt,+pclmul,-rdpru,-avxifma,+f16c,+ssse3,-sgx,-prefetchwt1,+cmov,+avx512vbmi,-shstk,+movbe,-avx512vp2intersect,+xsaveopt,+avx512dq,+sse2,+adx,+sse3
after optimize llvm module:
; ModuleID = 'LLVMDialectModule'
source_filename = "LLVMDialectModule"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%0 = type { ptr, i64, { ptr, ptr, i64, [3 x i64], [3 x i64] } }
%.1 = type { ptr, i64, ptr }
%.2 = type { i64, ptr }
%.3 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.4 = type { i64, i64, ptr, ptr }
%.5 = type { ptr, ptr, i64, ptr, i64, i64, i64, i64, i64, i64, i32, ptr, i32, ptr }
%.6 = type { ptr, ptr, ptr, ptr, i64, i64, i64, ptr, ptr, i64, i64, i64, { ptr, ptr, i64, [2 x i64], [2 x i64] } }
%.7 = type { ptr, ptr }
%.8 = type { ptr, i64, ptr, ptr, i64, i64, i64, i64, i64 }

@ral_send_output___cpu___pvoid_i64_m2df32___void = internal constant [48 x i8] c"ral_send_output___cpu___pvoid_i64_m2df32___void\00"
@dealloc___gpu___pvoid_pvoid___void = internal constant [35 x i8] c"dealloc___gpu___pvoid_pvoid___void\00"
@inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32 = internal constant [51 x i8] c"inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32\00"
@main_kernel_0_main_kColReduction_reduce__3_1_0_1_kernel_name = internal constant [35 x i8] c"main_kColReduction_reduce__3_1_0_1\00"
@main_kernel_0_blob_gpu.binary = internal constant [3104 x i8] c"P\EDU\BA\01\00\10\00\10\0C\00\00\00\00\00\00\02\00\01\01@\00\00\00\D0\0B\00\00\00\00\00\00\CA\0B\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\1D\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\1C\00\01\00\11\1A\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\A5e__3_1_0_12\00\0F,\00\15oshared.\00\12Orela\88\00\17?rel\B5\00\1A\9Fconstant01\00\12\B2debug_framek\00\09\11\00!nv\14\00\11a=\00\0Fn\01 \0F\82\00\0F\0F\91\01\FDo_param\98\01\1C\0F\01\00\06\8CU\00\00\00\03\00\0A\00\01\00 3\01\18\00,\09\00\01\00\11k\18\00,\04\00\01\00\11\89\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\12\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\22\04X\AC\00\90\04/\08\00\05\00\00\00\18\0C\00\12#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04h\04\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\18\00\03\19\18\00\04\17\0C$\00u\03\00\10\00\00\F0!\10\009\02\00\08\10\00\10\01(\01%\F0\11\10\00\01\01\00\C2\F0\11\00\03\1B\FF\00\04\1C\0C\00P%\00r\00\C0\11\00\00\04\1E\A8\00#K\00\01\00\B1\02\02\08\10\0A/\22\00\00\00\08\10\00#\00\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00#8\08_\00\03\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00H\01/\05\00\01\00\FF\98@$v\01\FF\1F\04\B1\FF\00\8E\07\00\C4\0F\00\19y\03\18\00 \00%s\02R\0E\00\19y\00\01\00\10!-\00\80\0E\00$z\03\03\00X\E9\01\F5\08\8E\07\00\CA\1F\00\0Cz\00\03\00Y\00\00p`\F0\03\00\DA\0F\00MS\04\B0\80\03\00\EA\0F\00\19x\00\FF\1FL\03\90\14\01\00\00\C8\0F\00\11rX\03`\00\00\FF@\8F\07\10\00A\19x\02\FFI\02\00 \00S\E4\0F\00\12x\09\04\F1\00\C0\8E\07\00\C6\0F\00'x\04\02\AB\AA\AA\AA\A0\00\80\C8\0F\00$x\00\03\010\00P\0A\8E\07\00\E2@\00 \04\FFt\02`\04\16\01\00\00\CA \00\84\05\04\FA\FF\FF\FF\02\020\00D\05\05\00\01\B0\00\CF\0F\00\0Cx\00\05\13\05\00\00p@\B0\00\03c$x\00\04 \00\10\01\B1\E2\0F\04\B9z\04\00\00F\00\00C\05\10\E2 \00\82\03\04\80\9C\00\00\03\02\A0\001\10x\02_\00\D0\FF\E0\FF\07\00\E4\0F\04\0Cx\00\00m\B0\04Q@\F8\03\00\E4p\00\12\02\10\00!\FA\03@\00Dt\02\FF\04`\00\B1\D4\0F\00%\C6\06\03\00Z\00\00\B0\00\93\E4\0F\04\10\D8\09\03\14\05P\00q\C6\0F\00\81\C9\0D\06:\04\B5\19\1E\0C\00\A4\00\00%\D6\08\090\00u\CA\0F\00\81\D9\0F\08 \00\84\E2\02\00\10x\04\00\02\90\00\11\C8\80\003\04m\00\F0\00!\E4\0F \00\1F\03 \00\02\15\F2 \00\17\04\D0\00\22\10x4\05\02\10\00\17/0\00\12\F40\00S\88\0B\03(\0A \00u\CA\0F\00%\86\0A\0B\A0\00\93\E2\0F\00\10\98\07\03<\0F \00u\C8\1F\00\81\89\04\0A\B0\00x\22\01\00%\96\06\070\00B\0Cx\00\08`\00\13\F6\90\00G\09\03P\14\10\01&\99\06\10\01\84\22\03\00\10x\0E\00\06\A0\00W\E2\0F\00%\A6 \01\00\00\02qt\0C\FF\00\00\80\FFp\01\00P\00T\B8\0B\03d\190\00h\1F\00\81\A9\09\08\90\006$t\110\00W\C6\0F\00%\B6\D0\00i\CC\0F\00\81\B9\0A\C0\00@\0B\C8\00\0D0\00\B2\00\C0\FC\03\00\C8O\00\08\C8\0C\10\00!\00\00\C0\00H\0Cx\00\0E\10\02P\0B\D2\00\0C\0F@\00\C6`\FC\03\00\E4\8F\08\10x\0D\00\07p\01B\00\08\D2\11 \00\06@\00\15\0D@\02\97\CA\0F\00\10\C8\0D\03x\1Ep\015\C6\0C\0D\A0\00\00\90\02V\D8\0F\03\8C#P\00E\81\C9\08\0C\B0\00u\A6\10\00%\D6\0E\0F0\00\01@\02%\07\0E \00\84\E2\22\00\0B\82\00\11\04\A0\00i\E2\0F\01$t\13\10\012\08\82\13 \00%\00\000\02%\08\00p\00a\04\0B\92\00\13\06@\00\10\F0@\00F\0C$t\10@\00\00\10\02Hx\0B\00\09\F0\00\22\92\100\00\00\01\00\1B\E4\B0\02\11\C4\10\00\18\0B\A0\02U\0B\A2\00\10\09@\01 \0F\08\80\00\17\0AP\00f\10x\0D\03\A0(\E0\017$t\0F\80\00R/\00\08\A2\0F@\00\06`\01\06\D0\02\00@\02\17\86P\01\84\E2\0F\00\0B\B2\00\0F\0Ap\00\10\C4`\008\06\00\0Bp\00T\98\0B\03\B4-p\00\1A\0F@\02 \E2\0F\F0\02\18\0C0\022\08\B2\11P\00\06\80\00\15\06\F0\02\00\80\00\1B\96@\03V\A8\0F\03\C82\B0\03H\81\99\06\0A\00\03J%\A6\0E\0F\F0\02\0Ap\016\81\A9\09\E0\01\93\22\05\00\10\B8\0D\03\DC7P\00\84\E4\1F\00\10x\0C\00\0D\D0\00\01\C0\00\19\130\037%\B6\0A\10\01\11/`\01$\F0<@\00t\0F\00\0B\C2\00\11\08 \01\00\00\03\22\C2\10\10\00\03\E0\00\00@\04'\0C\000\00G\D2\00\10\07\00\03\06\F0\03\02 \032\08\D2\13 \00\06 \01\18\0C@\056\81\B9\10\00\01*\B0\00\00\03\12\C8\00\03&\04B\D0\00\09\00\03/\E8\02\00\03\0Cy\00\00\10x\11\00\0E\10\01\19\15P\01U\0B\82\00\13\04\F0\00R\0F\01\08\82\15\10\00\06\B0\00\1C\11p\05\18\0F\00\01D\92\00\15\06@\00\01`\00\16\0A`\00b\C6\1F\00\08\92\0A \00\0D\A0\02\02\A0\05G\0B\A2\00\0A\00\03\10\0C\80\05(\18G\B0\00\19\0F\B0\002\08\A2\0F0\00%\00\00\90\00\16\10\E0\00\1D\04\B0\05Dx\06\00\11 \00\1B\C4 \03\00@\00T\98\0D\03,L@\00\1F/\F0\02\01\06\A0\01\10&\E0\05\0AP\03X\10x\09\00\12\10\01H\B2\00\0F\10@\02\22\B2\11\10\00\0F \03\01\01\C0\00D\0F\03@Q\80\00\01\10\03\06\E0\01-\A2\02\00\03\09\A0\02*\E4\8F0\03*\E4\0F\B0\02\02\F0\00\18\09\90\026\81\A9\0E \02\9F\A2\06\00\10\B8\09\03TV\D0\02\05\00\90\04O\08\00\13\00\10\04\076\08\D2\11\E0\02\11\E2`\03\06\B0\06'\E2\1F\00\07\12\FAp\04V\C8\09\03h[p\00\09\00\03\10\A6\00\03(\08\09\A0\06f\10\D8\0D\03|`\A0\016\81\C9\08\E0\06\10\A8\00\03+\0C\0D\00\03\07@\01\1B\00@\02\1A\8F\10\06\01\F0\02\1D\0F\00\06&\14\00P\02\0C\F0\00h\10x\0A\00\15\00\90\05\17\09 \00\00P\04H\0B\03\90e0\01\19\12@\00E\0B\92\00\0FP\06\00 \02\22\92\11\10\00\0D0\06\14\F20\02\18\0A\80\03T\0B\A2\00\11\0E\C0\00\000\03Vx\04\00\16\00P\012\08\A2\09 \00\06\00\02\0A\F0\02Ex\04\00\17\C0\00\0E\A0\05E\0B\B2\00\09\C0\02\1E\C6\F0\01g\10\88\0D\03\A4jp\00\22\B2\110\00\03@\01\06p\00\02\E0\02H\81\99\04\0A\90\01\0C\90\06\00\10\06/\B8o\80\05\04\10\C4\80\03(\06\0C\10\0A\09\F0\02\00\80\02G\C2\12\11\08\80\00\00\B0\02)\18\00\D0\02'\12\07\A0\04\09\00\03\87\E2\08\00\10x\10\00\190\00\09\C0\05\0F\F0\02\00\000\03&\CCtP\042\08\D2\11`\00\06\00\01\18\10\E0\05\0C\10\03\00\00\0A#\E0y@\00\1B\C8\00\03\1F\E2\00\03\03/\F4~\00\03\04\1F\E8\00\03\0C*\E2\04\00\07\11\E2p\04\01{\14\02P\00\00\10\09\16\0B \00\1E\E4\D0\02(\0B\920\03\00\B0\02\0A0\09I\0Cx\00\0F\D0\05\14\820\09\00\A0\02\11\8F\A0\02\17\1B`\01_\08\82\0B\13\060\02\02\02 \09U\0B\A2\00\0B\0Ep\00\01\D0\02\02\10\00\030\00\00\A0\08&\08\84P\00\00`\00\19\1C\E0\0B?\06\00\1D\E0\02\159\E4\0F\08 \03\0Fp\06\00\00\F0\02&\1C\89P\00\0C\D0\026\08\B2\0F\00\03\1E\C4\00\09\0D\80\09I\C2\00\0F\08`\057\0E\00\1E\B0\00\0C\F0\05\000\02'0\8E\80\00\0B\10\032\08\C2\10P\00\0F\A0\0B\01\0C@\0C\1B\E2\E0\05\01\00\0A9\00\00\1F\80\00\0C\F0\02O\0B\03D\93`\0C\07\09\00\06\02\80\00\1B\00\00\03\06\80\01\12\E4\F0\0B#X\98P\00+\C8/\80\0C\0B\00\0C\12\CA\00\09$l\9D\80\00\00\00\09\16\0C\00\01*(\0F\00\09\00\D0\0C9\D9\0E\0EP\00Vv\02\05\00\\P\00E\81y\08\02 \00fb\11\00$t\05\F0\00\10\E4\00\01\1B\00\10\00\1C\07\C0\05\0B\10\03\16\05\10\03\11\C8\00\03\11\05\E0\02\84`\F2\03\00\C8\8F\00\08\10\00\22\00\80p\0F)t\05\80\0CU\0B\A2\00\00\09\10\06R\0F\01\08\A2\05\10\00\00\01\00\11\C8\B0\02&\05\0A \00B\00\08\B2\07\10\00/\00\00P\00\03H\C2\00\07\0C0\00\22\C2\05\10\00\050\00\1A\070\00H\D2\00\05\0E0\00\22\D2\07\10\00\01\80\00a\1F\00\0Br\00\08\E0\01\00\A0\03W\E2\0F\0EFy`\10b\E6\0F\00\08r\09 \00\00\01\00p\CC\0F\00\A9s\09\02\90\02\C0\09\E1\1E\00\00\A4\0E\00\0Cr\00\09\10\00 pR@\00`O\00$r\08\FFM\0E\10\09\80\00\80\D8\0F\00G\09\00\00\90 \11!\FF\83\B0\10*My\C0\10TGy\00\00\F0 \00f\C0\0F\00\18y\00\01\00\0F\10\00\80\0F\01\00-\22\01\00P\12\0C\01\00\22@\00\01\00=n\01\000\00\08\01\00\1F\0B@\00\04\13\AE)\00\1F\98@\00\0C\13\13\F4\14\0C\01\00\13HU\00&\90\00\18\15#\04\00m\15\03\A8\16\00\01\00.A\01T\00\00\01\00\13\D8@\00/p\00\80\00\0B\1F)'\00\03#\00He\03\04P\17\04\E4\00*\04\00\01\00\1F[@\00\04\13x)\00&x\00@\00\1F\0A@\00\00!_\01D\01\0D@\00\13\F0)\00*\D8\00\01\00\1B\08\08\00#N\01\D0\03\0B\01\00\13\C8E\16\17\10\80\00\17\048\00\04\18\00\13\10@\01\0C\84\01\13\D8@\00\17x1\01\0F\C0\00\01\132T\01*\06\00\01\00*\80\07\D0\18\12\03\D8\16:\18\80\00\01\00\13\06\F0\16\05\A8\1C\0B\01\00*\A8\00\08\00\17\08\C8\01\17\05\A8\00\0C\01\009(\14\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00\00\00\00\00\00\00"
@ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void = internal constant [101 x i8] c"ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void\00"
@main_kernel_main_kColReduction_reduce__3_1_0_kernel_name = internal constant [33 x i8] c"main_kColReduction_reduce__3_1_0\00"
@main_kernel_blob_gpu.binary = internal constant [1072 x i8] c"P\EDU\BA\01\00\10\00 \04\00\00\00\00\00\00\02\00\01\01@\00\00\00\E0\03\00\00\00\00\00\00\E0\03\00\00\00\00\00\00\07\00\01\00P\00\00\00\00\00\00\00\00\00\00\00\11 \00\00\00\00\00\00\00\00\00\00\00\00\00\00h\0B\00\00\00\00\00\00\A2\7FELF\02\01\013\07\00\01\00f\02\00\BE\00q\00\01\002\C0\0A\00\01\00\11\08\06\00\F5\0E\00P\05P\00@\008\00\03\00@\00\0B\00\01\00\00.shstrtab\00.\08\00'ym\08\00\F0\1B_shndx\00.nv.info\00.text.main_kColReduction_r\0A\00\85e__3_1_00\00\0F*\00\13oshared,\00\13\9Fconstant0/\00\10\FA\01debug_frame\00.rel\11\00!nv\14\00\11a;\00\0F\0B\01 \0F\80\00\0D\0F,\01\9Ao_param3\01\1C\0F\01\00\06\8CS\00\00\00\03\00\0A\00\01\00\11\D0\18\00,\09\00\01\00 \06\01\18\00,\04\00\01\00\11$\18\00,\07\00\01\00f2\00\00\00\12\10`\00!\80\01\07\00v\00\FF\FF\FF\FF(\00\0C\00\00\01\00@\03\00\04|\08\00\D1\0F\0C\81\80\80(\00\08\FF\81\80(\08\0B\00\06(\00/0\00\01\00\03\13pX\00\10\04\9B\00R\04\14\00\00\00E\00\01\0B\00\00\13\00C/\08\00\05_\03\22\04#\0C\00\00\01\00'\04\12\0C\00\17\11\0C\00!7\04\A0\03\F1\08\015\00\00\04\0A\08\00\02\00\00\00`\01\10\00\03\19\10\00\04\17\0C$\00\10\01N\00%\F0!\10\00\01\01\00\F2\02\F0\11\00\03\1B\FF\00\04\1C\08\00P\00\00\00\B0\00\01\00#K\00\01\00v\02\02\08\10\0A/\22\EA\03\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\228\08|\00\13\00\08\00\13\08\08\00\13\10\08\00\13\18\08\00\13 \08\00\13(\08\00\130\08\00\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\13\02@\00\A2\00\00\00\14,\00\00\00H\00\01\00\00 \01/\05\00\01\00\FF\88A\02z\01\00\E7\03\B1\0F\00\00\00\C4\0F\00\19y\02\00\01\00\10%c\02Q\0E\00\19y\03\0F\00 \00!\CD\03\F5\14\0E\00$z\02\02\00X\00\00\03\02\8E\07\00\CA\1F\00\0Cx\00\02\13\05\00\00p@\F0\03\00\DA\0F\00M\1B\04\A0\80\03\00\EA\0F\005t\03\FF{\03\10\FF\88\03P\E2\0F\00\02x\0E\02B\80\FF\00\0F\10\00r\B9z\04\00\00F\00\84\00\90\D0\0F\00%v\02\02\00Z4\04\00`\00`\0F\00\86y\00\022\00@\04\19\10\0C0\009My\00`\00PGy\00\00\F0\01\04\A6\FF\83\03\00\C0\0F\00\18y\00\01\00\0F\10\00\90\0F\01\00-\00W\01.\03\00\01\00\22@\00\01\00=\0B\01\000\00\08\01\00\1F\0B@\00\04\13K)\00\1F3@\00\0C\13\13\E4\03\0C\01\00\13\80\15\00&\90\00\08\04#\04\00]\04\00\CE\04\12\00\01\00\1F\DET\00\00\00\01\00\13\10\95\00/p\00\80\00\0B\1F)'\00\03#\00\80@\00\04\18\06\04\E4\00*\04\00\01\00\1FY@\00\04\13\B01\00&L\00@\00\1F\0A@\00\00\12\FCD\01\0D@\00\04)\00*\D8\00\01\00\1B\08\08\00?\EB\00\00N\07\003\00\00\D8@\00&\10\00\80\00\17\048\00\04\18\00\13\AF\14\01\0C\84\01*\E8\04\00\07\1F\00\C0\00\04\132@\00*\06\00\01\00*\80\06\98\07\12\03\C8\05:\08\80\00\01\00\13\06\E0\05\05\A8\0A\0B\01\00*\A8\00\08\00\04\F8\00\13\018\00\04\A8\00\0C\01\009\18\03\00\08\00\088\00/\06\00\01\00\17\80\08\00\00\00\00\00\00\00"
@alloc___gpu___pvoid_i64___pvoid = internal constant [32 x i8] c"alloc___gpu___pvoid_i64___pvoid\00"
@ral_recv_input___cpu___pvoid_i64___m3df32 = internal constant [42 x i8] c"ral_recv_input___cpu___pvoid_i64___m3df32\00"

define void @disc_ral_call(ptr nocapture readonly %0, ptr %1, ptr %2) local_unnamed_addr {
entry:
  %3 = load ptr, ptr %0, align 8
  %4 = getelementptr ptr, ptr %0, i64 1
  %5 = load ptr, ptr %4, align 8
  %6 = load ptr, ptr %2, align 8
  store ptr %3, ptr %6, align 8
  tail call void %5(ptr %3, ptr %1, ptr nonnull %2)
  ret void
}

define void @main(ptr %0) local_unnamed_addr {
  %2 = alloca %0, align 8
  %3 = alloca [3 x ptr], align 8
  store ptr %2, ptr %3, align 8
  %4 = getelementptr inbounds %0, ptr %2, i64 0, i32 1
  store i64 0, ptr %4, align 8
  %5 = getelementptr inbounds ptr, ptr %3, i64 1
  store ptr %4, ptr %5, align 8
  %6 = getelementptr inbounds %0, ptr %2, i64 0, i32 2
  %7 = getelementptr inbounds ptr, ptr %3, i64 2
  store ptr %6, ptr %7, align 8
  %8 = load ptr, ptr %0, align 8
  %9 = getelementptr ptr, ptr %0, i64 1
  %10 = load ptr, ptr %9, align 8
  store ptr %8, ptr %2, align 8
  call void %10(ptr %8, ptr nonnull @ral_recv_input___cpu___pvoid_i64___m3df32, ptr nonnull %3)
  %.fca.1.gep4 = getelementptr inbounds %0, ptr %2, i64 0, i32 2, i32 1
  %.fca.1.load5 = load ptr, ptr %.fca.1.gep4, align 8
  %11 = alloca %.1, align 8
  %12 = alloca [3 x ptr], align 8
  store ptr %11, ptr %12, align 8
  %13 = getelementptr inbounds %.1, ptr %11, i64 0, i32 1
  store i64 5200, ptr %13, align 8
  %14 = getelementptr inbounds ptr, ptr %12, i64 1
  store ptr %13, ptr %14, align 8
  %15 = getelementptr inbounds %.1, ptr %11, i64 0, i32 2
  %16 = getelementptr inbounds ptr, ptr %12, i64 2
  store ptr %15, ptr %16, align 8
  %17 = load ptr, ptr %0, align 8
  %18 = load ptr, ptr %9, align 8
  store ptr %17, ptr %11, align 8
  call void %18(ptr %17, ptr nonnull @alloc___gpu___pvoid_i64___pvoid, ptr nonnull %12)
  %19 = load ptr, ptr %15, align 8
  %20 = alloca ptr, align 8
  store ptr @main_kernel_blob_gpu.binary, ptr %20, align 8
  %21 = alloca %.2, align 8
  %22 = alloca [2 x ptr], align 8
  store i64 256, ptr %21, align 8
  store ptr %21, ptr %22, align 8
  %23 = getelementptr inbounds %.2, ptr %21, i64 0, i32 1
  store ptr %19, ptr %23, align 8
  %24 = getelementptr inbounds ptr, ptr %22, i64 1
  store ptr %23, ptr %24, align 8
  %25 = alloca %.3, align 8
  %26 = alloca [14 x ptr], align 8
  store ptr %25, ptr %26, align 8
  %27 = getelementptr inbounds %.3, ptr %25, i64 0, i32 1
  store ptr %20, ptr %27, align 8
  %28 = getelementptr inbounds ptr, ptr %26, i64 1
  store ptr %27, ptr %28, align 8
  %29 = getelementptr inbounds %.3, ptr %25, i64 0, i32 2
  store i64 1, ptr %29, align 8
  %30 = getelementptr inbounds ptr, ptr %26, i64 2
  store ptr %29, ptr %30, align 8
  %31 = getelementptr inbounds %.3, ptr %25, i64 0, i32 3
  store ptr @main_kernel_main_kColReduction_reduce__3_1_0_kernel_name, ptr %31, align 8
  %32 = getelementptr inbounds ptr, ptr %26, i64 3
  store ptr %31, ptr %32, align 8
  %33 = getelementptr inbounds %.3, ptr %25, i64 0, i32 4
  store i64 6, ptr %33, align 8
  %34 = getelementptr inbounds ptr, ptr %26, i64 4
  store ptr %33, ptr %34, align 8
  %35 = getelementptr inbounds %.3, ptr %25, i64 0, i32 5
  store i64 1, ptr %35, align 8
  %36 = getelementptr inbounds ptr, ptr %26, i64 5
  store ptr %35, ptr %36, align 8
  %37 = getelementptr inbounds %.3, ptr %25, i64 0, i32 6
  store i64 1, ptr %37, align 8
  %38 = getelementptr inbounds ptr, ptr %26, i64 6
  store ptr %37, ptr %38, align 8
  %39 = getelementptr inbounds %.3, ptr %25, i64 0, i32 7
  store i64 256, ptr %39, align 8
  %40 = getelementptr inbounds ptr, ptr %26, i64 7
  store ptr %39, ptr %40, align 8
  %41 = getelementptr inbounds %.3, ptr %25, i64 0, i32 8
  store i64 1, ptr %41, align 8
  %42 = getelementptr inbounds ptr, ptr %26, i64 8
  store ptr %41, ptr %42, align 8
  %43 = getelementptr inbounds %.3, ptr %25, i64 0, i32 9
  store i64 1, ptr %43, align 8
  %44 = getelementptr inbounds ptr, ptr %26, i64 9
  store ptr %43, ptr %44, align 8
  %45 = getelementptr inbounds %.3, ptr %25, i64 0, i32 10
  store i32 0, ptr %45, align 8
  %46 = getelementptr inbounds ptr, ptr %26, i64 10
  store ptr %45, ptr %46, align 8
  %47 = getelementptr inbounds %.3, ptr %25, i64 0, i32 11
  store ptr null, ptr %47, align 8
  %48 = getelementptr inbounds ptr, ptr %26, i64 11
  store ptr %47, ptr %48, align 8
  %49 = getelementptr inbounds %.3, ptr %25, i64 0, i32 12
  store i32 2, ptr %49, align 8
  %50 = getelementptr inbounds ptr, ptr %26, i64 12
  store ptr %49, ptr %50, align 8
  %51 = getelementptr inbounds %.3, ptr %25, i64 0, i32 13
  store ptr %22, ptr %51, align 8
  %52 = getelementptr inbounds ptr, ptr %26, i64 13
  store ptr %51, ptr %52, align 8
  %53 = load ptr, ptr %0, align 8
  %54 = load ptr, ptr %9, align 8
  store ptr %53, ptr %25, align 8
  call void %54(ptr %53, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %26)
  %55 = alloca ptr, align 8
  store ptr @main_kernel_0_blob_gpu.binary, ptr %55, align 8
  %56 = alloca %.4, align 8
  %57 = alloca [4 x ptr], align 8
  store i64 256, ptr %56, align 8
  store ptr %56, ptr %57, align 8
  %58 = getelementptr inbounds %.4, ptr %56, i64 0, i32 1
  store i64 6144, ptr %58, align 8
  %59 = getelementptr inbounds ptr, ptr %57, i64 1
  store ptr %58, ptr %59, align 8
  %60 = getelementptr inbounds %.4, ptr %56, i64 0, i32 2
  store ptr %.fca.1.load5, ptr %60, align 8
  %61 = getelementptr inbounds ptr, ptr %57, i64 2
  store ptr %60, ptr %61, align 8
  %62 = getelementptr inbounds %.4, ptr %56, i64 0, i32 3
  store ptr %19, ptr %62, align 8
  %63 = getelementptr inbounds ptr, ptr %57, i64 3
  store ptr %62, ptr %63, align 8
  %64 = alloca %.5, align 8
  %65 = alloca [14 x ptr], align 8
  store ptr %64, ptr %65, align 8
  %66 = getelementptr inbounds %.5, ptr %64, i64 0, i32 1
  store ptr %55, ptr %66, align 8
  %67 = getelementptr inbounds ptr, ptr %65, i64 1
  store ptr %66, ptr %67, align 8
  %68 = getelementptr inbounds %.5, ptr %64, i64 0, i32 2
  store i64 1, ptr %68, align 8
  %69 = getelementptr inbounds ptr, ptr %65, i64 2
  store ptr %68, ptr %69, align 8
  %70 = getelementptr inbounds %.5, ptr %64, i64 0, i32 3
  store ptr @main_kernel_0_main_kColReduction_reduce__3_1_0_1_kernel_name, ptr %70, align 8
  %71 = getelementptr inbounds ptr, ptr %65, i64 3
  store ptr %70, ptr %71, align 8
  %72 = getelementptr inbounds %.5, ptr %64, i64 0, i32 4
  store i64 24, ptr %72, align 8
  %73 = getelementptr inbounds ptr, ptr %65, i64 4
  store ptr %72, ptr %73, align 8
  %74 = getelementptr inbounds %.5, ptr %64, i64 0, i32 5
  store i64 1, ptr %74, align 8
  %75 = getelementptr inbounds ptr, ptr %65, i64 5
  store ptr %74, ptr %75, align 8
  %76 = getelementptr inbounds %.5, ptr %64, i64 0, i32 6
  store i64 1, ptr %76, align 8
  %77 = getelementptr inbounds ptr, ptr %65, i64 6
  store ptr %76, ptr %77, align 8
  %78 = getelementptr inbounds %.5, ptr %64, i64 0, i32 7
  store i64 256, ptr %78, align 8
  %79 = getelementptr inbounds ptr, ptr %65, i64 7
  store ptr %78, ptr %79, align 8
  %80 = getelementptr inbounds %.5, ptr %64, i64 0, i32 8
  store i64 1, ptr %80, align 8
  %81 = getelementptr inbounds ptr, ptr %65, i64 8
  store ptr %80, ptr %81, align 8
  %82 = getelementptr inbounds %.5, ptr %64, i64 0, i32 9
  store i64 1, ptr %82, align 8
  %83 = getelementptr inbounds ptr, ptr %65, i64 9
  store ptr %82, ptr %83, align 8
  %84 = getelementptr inbounds %.5, ptr %64, i64 0, i32 10
  store i32 0, ptr %84, align 8
  %85 = getelementptr inbounds ptr, ptr %65, i64 10
  store ptr %84, ptr %85, align 8
  %86 = getelementptr inbounds %.5, ptr %64, i64 0, i32 11
  store ptr null, ptr %86, align 8
  %87 = getelementptr inbounds ptr, ptr %65, i64 11
  store ptr %86, ptr %87, align 8
  %88 = getelementptr inbounds %.5, ptr %64, i64 0, i32 12
  store i32 4, ptr %88, align 8
  %89 = getelementptr inbounds ptr, ptr %65, i64 12
  store ptr %88, ptr %89, align 8
  %90 = getelementptr inbounds %.5, ptr %64, i64 0, i32 13
  store ptr %57, ptr %90, align 8
  %91 = getelementptr inbounds ptr, ptr %65, i64 13
  store ptr %90, ptr %91, align 8
  %92 = load ptr, ptr %0, align 8
  %93 = load ptr, ptr %9, align 8
  store ptr %92, ptr %64, align 8
  call void %93(ptr %92, ptr nonnull @ral_kernel_launch___gpu___pvoid_ppvoid_i64_pvoid_i64_i64_i64_i64_i64_i64_i32_pvoid_i32_ppvoid___void, ptr nonnull %65)
  %94 = alloca [16 x i64], align 8
  store i64 100, ptr %94, align 8
  %95 = getelementptr inbounds i64, ptr %94, i64 1
  store i64 13, ptr %95, align 8
  %96 = alloca %.6, align 8
  %97 = alloca [13 x ptr], align 8
  store ptr %96, ptr %97, align 8
  %98 = getelementptr inbounds %.6, ptr %96, i64 0, i32 1
  store ptr null, ptr %98, align 8
  %99 = getelementptr inbounds ptr, ptr %97, i64 1
  store ptr %98, ptr %99, align 8
  %100 = getelementptr inbounds %.6, ptr %96, i64 0, i32 2
  store ptr %19, ptr %100, align 8
  %101 = getelementptr inbounds ptr, ptr %97, i64 2
  store ptr %100, ptr %101, align 8
  %102 = getelementptr inbounds %.6, ptr %96, i64 0, i32 3
  store ptr %19, ptr %102, align 8
  %103 = getelementptr inbounds ptr, ptr %97, i64 3
  store ptr %102, ptr %103, align 8
  %104 = getelementptr inbounds %.6, ptr %96, i64 0, i32 4
  store i64 0, ptr %104, align 8
  %105 = getelementptr inbounds ptr, ptr %97, i64 4
  store ptr %104, ptr %105, align 8
  %106 = getelementptr inbounds %.6, ptr %96, i64 0, i32 5
  store i64 1300, ptr %106, align 8
  %107 = getelementptr inbounds ptr, ptr %97, i64 5
  store ptr %106, ptr %107, align 8
  %108 = getelementptr inbounds %.6, ptr %96, i64 0, i32 6
  store i64 1, ptr %108, align 8
  %109 = getelementptr inbounds ptr, ptr %97, i64 6
  store ptr %108, ptr %109, align 8
  %110 = getelementptr inbounds %.6, ptr %96, i64 0, i32 7
  store ptr %94, ptr %110, align 8
  %111 = getelementptr inbounds ptr, ptr %97, i64 7
  store ptr %110, ptr %111, align 8
  %112 = getelementptr inbounds %.6, ptr %96, i64 0, i32 8
  store ptr %94, ptr %112, align 8
  %113 = getelementptr inbounds ptr, ptr %97, i64 8
  store ptr %112, ptr %113, align 8
  %114 = getelementptr inbounds %.6, ptr %96, i64 0, i32 9
  store i64 0, ptr %114, align 8
  %115 = getelementptr inbounds ptr, ptr %97, i64 9
  store ptr %114, ptr %115, align 8
  %116 = getelementptr inbounds %.6, ptr %96, i64 0, i32 10
  store i64 2, ptr %116, align 8
  %117 = getelementptr inbounds ptr, ptr %97, i64 10
  store ptr %116, ptr %117, align 8
  %118 = getelementptr inbounds %.6, ptr %96, i64 0, i32 11
  store i64 1, ptr %118, align 8
  %119 = getelementptr inbounds ptr, ptr %97, i64 11
  store ptr %118, ptr %119, align 8
  %120 = getelementptr inbounds %.6, ptr %96, i64 0, i32 12
  %121 = getelementptr inbounds ptr, ptr %97, i64 12
  store ptr %120, ptr %121, align 8
  %122 = load ptr, ptr %0, align 8
  %123 = load ptr, ptr %9, align 8
  store ptr %122, ptr %96, align 8
  call void %123(ptr %122, ptr nonnull @inc_ref___gpu___pvoid_pvoid_m1df32_m1di64___m2df32, ptr nonnull %97)
  %.fca.0.load = load ptr, ptr %120, align 8
  %.fca.1.gep = getelementptr inbounds %.6, ptr %96, i64 0, i32 12, i32 1
  %.fca.1.load = load ptr, ptr %.fca.1.gep, align 8
  %124 = alloca %.7, align 8
  %125 = alloca [2 x ptr], align 8
  store ptr %124, ptr %125, align 8
  %126 = getelementptr inbounds %.7, ptr %124, i64 0, i32 1
  store ptr %19, ptr %126, align 8
  %127 = getelementptr inbounds ptr, ptr %125, i64 1
  store ptr %126, ptr %127, align 8
  %128 = load ptr, ptr %0, align 8
  %129 = load ptr, ptr %9, align 8
  store ptr %128, ptr %124, align 8
  call void %129(ptr %128, ptr nonnull @dealloc___gpu___pvoid_pvoid___void, ptr nonnull %125)
  %130 = alloca %.8, align 8
  %131 = alloca [9 x ptr], align 8
  store ptr %130, ptr %131, align 8
  %132 = getelementptr inbounds %.8, ptr %130, i64 0, i32 1
  store i64 0, ptr %132, align 8
  %133 = getelementptr inbounds ptr, ptr %131, i64 1
  store ptr %132, ptr %133, align 8
  %134 = getelementptr inbounds %.8, ptr %130, i64 0, i32 2
  store ptr %.fca.0.load, ptr %134, align 8
  %135 = getelementptr inbounds ptr, ptr %131, i64 2
  store ptr %134, ptr %135, align 8
  %136 = getelementptr inbounds %.8, ptr %130, i64 0, i32 3
  store ptr %.fca.1.load, ptr %136, align 8
  %137 = getelementptr inbounds ptr, ptr %131, i64 3
  store ptr %136, ptr %137, align 8
  %138 = getelementptr inbounds %.8, ptr %130, i64 0, i32 4
  store i64 0, ptr %138, align 8
  %139 = getelementptr inbounds ptr, ptr %131, i64 4
  store ptr %138, ptr %139, align 8
  %140 = getelementptr inbounds %.8, ptr %130, i64 0, i32 5
  store i64 100, ptr %140, align 8
  %141 = getelementptr inbounds ptr, ptr %131, i64 5
  store ptr %140, ptr %141, align 8
  %142 = getelementptr inbounds %.8, ptr %130, i64 0, i32 6
  store i64 13, ptr %142, align 8
  %143 = getelementptr inbounds ptr, ptr %131, i64 6
  store ptr %142, ptr %143, align 8
  %144 = getelementptr inbounds %.8, ptr %130, i64 0, i32 7
  store i64 13, ptr %144, align 8
  %145 = getelementptr inbounds ptr, ptr %131, i64 7
  store ptr %144, ptr %145, align 8
  %146 = getelementptr inbounds %.8, ptr %130, i64 0, i32 8
  store i64 1, ptr %146, align 8
  %147 = getelementptr inbounds ptr, ptr %131, i64 8
  store ptr %146, ptr %147, align 8
  %148 = load ptr, ptr %0, align 8
  %149 = load ptr, ptr %9, align 8
  store ptr %148, ptr %130, align 8
  call void %149(ptr %148, ptr nonnull @ral_send_output___cpu___pvoid_i64_m2df32___void, ptr nonnull %131)
  ret void
}

[DISC] LowerLLVMToBinary takes: 1.452400e-02 s.
object file to shared library command: gcc --shared -o /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceStaticShape3DF32_0.so /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceStaticShape3DF32_0.so.o
save shared lib file to : /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceStaticShape3DF32_0.so
[DISC] BinaryStrToSharedLibrary takes: 9.259000e-03 s.
[DISC] LowerHLOToSharedLibrary takes: 4.055850e-01 s.

============ END ============

2023-06-09 07:26:16.353111: I mlir/disc/tests/mlir_test.cc:275] ret: 0

2023-06-09 07:26:16.353147: I mlir/disc/tests/mlir_test.cc:241] run compiled program

2023-06-09 07:26:16.559725: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:16.562565: I mlir/disc/tests/mlir_test.cc:932] --- MLIR Execution uses: 2.851 ms
2023-06-09 07:26:16.562662: I mlir/disc/tests/mlir_test.cc:183] out buffer = 0x7f753328bc00
2023-06-09 07:26:16.562669: I mlir/disc/tests/mlir_test.cc:184] out shape:
2023-06-09 07:26:16.562689: I mlir/disc/tests/mlir_test.cc:186]   dim #0: 100
2023-06-09 07:26:16.562691: I mlir/disc/tests/mlir_test.cc:186]   dim #1: 13
2023-06-09 07:26:16.562734: I mlir/disc/tests/mlir_test.cc:244] run golden tf

2023-06-09 07:26:16.562743: I mlir/disc/tests/mlir_test.cc:257] program_path: external/org_tensorflow/tensorflow/compiler/mlir/tf-mlir-translate

2023-06-09 07:26:16.620177: I mlir/disc/tests/mlir_test.cc:269] Executed: external/org_tensorflow/tensorflow/compiler/mlir/tf-mlir-translate -mlir-to-graphdef /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617bea/tempfile-adf59ec6ac82-b50697a0-360183-5fdad48c7e849 -o /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceStaticShape3DF32_0.pbtxt 
2023-06-09 07:26:16.620189: I mlir/disc/tests/mlir_test.cc:270] external/org_tensorflow/tensorflow/compiler/mlir/tf-mlir-translate: 0
2023-06-09 07:26:16.620192: I mlir/disc/tests/mlir_test.cc:271] -- stdout:

============ END ============

2023-06-09 07:26:16.620195: I mlir/disc/tests/mlir_test.cc:273] -- stderr:

============ END ============

2023-06-09 07:26:16.620198: I mlir/disc/tests/mlir_test.cc:275] ret: 0

2023-06-09 07:26:16.620207: I mlir/disc/tests/mlir_test.cc:391] graphdef_path: /root/.cache/bazel/_bazel_root/54ece412abe75fa85ab728a2c061e33c/execroot/org_disc_compiler/_tmp/b247c1654ecfc81b23b002417f617beaColReduceStaticShape3DF32_0.pbtxt
2023-06-09 07:26:16.621565: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-09 07:26:17.446245: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.448715: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.451067: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.453416: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.456645: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.458971: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.461284: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.463649: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.577699: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.580104: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.582445: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.584812: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.587128: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.589435: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.591760: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.594068: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.596377: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.598701: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.601002: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.603334: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.605638: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.607948: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.610260: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:17.612572: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.155962: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.158468: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.160855: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.163253: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.165611: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.167965: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.170305: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.172646: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.175007: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.177353: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.179684: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.182022: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.184339: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.186653: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.188967: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.191280: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.193592: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.195894: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79147 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:07.0, compute capability: 8.0
2023-06-09 07:26:20.196750: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.199030: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79149 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:08.0, compute capability: 8.0
2023-06-09 07:26:20.199582: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.201863: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79149 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:09.0, compute capability: 8.0
2023-06-09 07:26:20.202394: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.204669: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 79149 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:0a.0, compute capability: 8.0
2023-06-09 07:26:20.205200: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.208616: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 79149 MB memory:  -> device: 4, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:0b.0, compute capability: 8.0
2023-06-09 07:26:20.209142: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.211418: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 79149 MB memory:  -> device: 5, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:0c.0, compute capability: 8.0
2023-06-09 07:26:20.211927: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.214184: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 79149 MB memory:  -> device: 6, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:0d.0, compute capability: 8.0
2023-06-09 07:26:20.214707: I external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2023-06-09 07:26:20.216966: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 79149 MB memory:  -> device: 7, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:0e.0, compute capability: 8.0
2023-06-09 07:26:20.253597: I mlir/disc/tests/mlir_test.cc:467] --- TF Execution uses: 21.078 ms
2023-06-09 07:26:20.253623: I mlir/disc/tests/mlir_test.cc:474] 	output shape #0: [100,13]
2023-06-09 07:26:20.254011: I mlir/disc/tests/mlir_test.cc:467] --- TF Execution uses: 0.373 ms
2023-06-09 07:26:20.254031: I mlir/disc/tests/mlir_test.cc:474] 	output shape #0: [100,13]
2023-06-09 07:26:20.254393: I mlir/disc/tests/mlir_test.cc:467] --- TF Execution uses: 0.349 ms
2023-06-09 07:26:20.254397: I mlir/disc/tests/mlir_test.cc:474] 	output shape #0: [100,13]
2023-06-09 07:26:20.254641: I mlir/disc/tests/mlir_test.cc:467] --- TF Execution uses: 0.239 ms
2023-06-09 07:26:20.254644: I mlir/disc/tests/mlir_test.cc:474] 	output shape #0: [100,13]
2023-06-09 07:26:20.254897: I mlir/disc/tests/mlir_test.cc:467] --- TF Execution uses: 0.248 ms
2023-06-09 07:26:20.254901: I mlir/disc/tests/mlir_test.cc:474] 	output shape #0: [100,13]
2023-06-09 07:26:20.254908: I mlir/disc/tests/mlir_test.cc:484] processing output 0
2023-06-09 07:26:20.254925: I mlir/disc/tests/mlir_feature_test.cc:168] [[FAILED]]: Error in output 0:
0 index: 0 expected: 141701, actual: 123501

2023-06-09 07:26:20.256400: I ./mlir/disc/tests/mlir_feature_test.h:37] Unset env setting:
mlir/disc/tests/tensorflow_ops/max.cpp:33: Failure
Value of: feature_test_main( c_ft_path + "max_col_s_f32.mlir", kSupportedBackendList, 1, 1, {"110x100x13xf32_X"}, {"f32_X"})
  Actual: false
Expected: true
[  FAILED  ] TFMaxOpTest.ColReduceStaticShape3DF32 (4473 ms)
[----------] 1 test from TFMaxOpTest (4473 ms total)

[----------] Global test environment tear-down
[==========] 1 test from 1 test suite ran. (4473 ms total)
[  PASSED  ] 0 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] TFMaxOpTest.ColReduceStaticShape3DF32

 1 FAILED TEST
